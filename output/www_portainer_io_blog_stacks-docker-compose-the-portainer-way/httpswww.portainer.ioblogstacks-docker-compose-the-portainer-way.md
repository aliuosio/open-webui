# https://www.portainer.io/blog/stacks-docker-compose-the-portainer-way

<!--
URL: https://www.portainer.io/blog/stacks-docker-compose-the-portainer-way
title: Stacks = docker-compose, the Portainer way
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/stacks-docker-compose-the-portainer-way
hostname: portainer.io
description: Learn how you can use Portainer and its stacks feature to use docker-compose files, as well as wins from using Portainer instead of Docker command line.
sitename: PORTAINER.IO
date: 2021-07-14
categories: []
tags: []
image: https://www.portainer.io/hubfs/Copy%20of%20Portainer%20new%20release%20%20-%20CE%20and%20BE%202.13.png
pagetype: article
filedate: 2025-01-18
-->

You might be wondering why would you need to run a docker-compose container in the first place? Well, if you look at Synology's Docker UI, you will find out soon that it does not cover all potential options and features that you might need with certain solutions out there that you want to run inside Docker.

That will turn you towards a docker-compose file that will have all the instructions needed to run the container, and in order to run it, you start by going into the command line and run a simple single line.

So what's the advantage of running a "Stack" using Portainer? Well, you have a nice UI that will give you all the tools needed including a web editor that will check if the YML file is formated and structured correctly. Meaning you will be able to have a color-coded docker-compose file ready to be executed and changed on the fly if you have the need to do it.

There are several ways you can start with docker-compose in Portainer. As you can see from the image above, there are four methods of doing this.

Web editor , uploading a file , using a GIT repository , or using a custom template .

For my personal use case, I use web editor or upload methods just because most of the time I just write my own compose files, or if I already have them saved, simply upload them or again just copy the content of the file into the web editor.

Another reason I favor web editor is that I can just quickly edit (and correct it if needed) the composed file content and redeploy the container.

Bad indentation in line 16. Another great asset of Portainer web editor
Portainer Stacks
Example of Stack options
Now just to be clear you can still use and manipulate your container created via the Stack the same way as you would any other container. As you can see on the image above, there are still tools that allow you to start, stop, kill or restart your container.

On top of these tools, you will have the section on Stack tools as well. There is a way to stop, delete and create a template from that stack.

In case you were wondering, stoping the Stack will stop all the containers in the stack and there will be no exceptions around this, so choose what containers you want to be part of a single Stack.

One thing that you can also see is that while the container and stack are running you also have access to the Editor part of the Stack.

Edit the Stack/Container and redeploy in a matter of seconds
From the above example you can see that while the Container is in the running state, you can edit the docker-compose and use the Update the stack button to remove the old container and redeploy a new one.

One example that this might be useful is that you want to change the port number on the fly, or use a different image tag to deploy the same container but with a new repo tag, or just change the name of the container. The point is that you have it all right there in a single window with no need to use a different code editor, save your changes, and then use the up/down docker-compose CLI command.

Manage "Stacks" created outside Portainer
Now there are some cases at the moment that you might not be able to use the full potential of docker-compose CLI commands inside Portainer. One example is using the `env_file`

command.

Just to show you how a "Stack" (or how it is called a "project") created via command line looks like on the Portainer end.

"Stack" created using docker-compose command line
Clear notice that control over the Stack will be limited
If we compare the images you will notice that the stack tools are missing. So there are no options to stop, delete or make a template out of this Stack if it was not initiated from the Portainer in the first place.

Still, you do have an overview and you can control the containers that are the result of this stack.

Not really a topic for this particular article but will just mention one thing about agents that will in the end make sense when dealing with Stacks.

Portainer agents - aggregate your Docker hosts in a single UI
One more way that a web editor might be handy is the quick deployment of the same container on multiple Docker hosts. Templates or again, web editor, can come in handy to switch from one host to the other using the same Portainer UI.

Let's say you have a Portainer host running on one of your Docker hosts, but you also have a number of other Docker hosts as well. Instead of having multiple Portainers on all of those hosts, and the need to log into each of them, why not pull them together under a single Portainer instance with Agents ?

Info on how to connect multiple Docker hosts using the agents can be found in Luka's other Portainer article here , under the Add Docker host to your Portainer using an agent heading.

The reason I am saying this is that in this configuration there are other cool benefits of running stacks and using Portainer at the same time.

Migration and duplication of stacks
If you have a Docker Swarm cluster up and running and controlled by the Portainer or simply have multiple hosts connected with agents, you can migrate your Stack from one host to the other.

Stack about to be migrated to a new host
Once you have decided on the Stack you want to migrate, give it a new destination name and select the host from the list of endpoints.

One final warning and confirmation
To make this happen and work keep a few things in mind:

Volume bind and content will NOT be migrated, on top of that make sure that if you do use any volume binds or mounts they need to be prepared beforehand on the destination side (same as always), and finally, if there will be any clash of the port mappings (port in use ), your migration will fail.
So basically, just like when you are making a new fresh Container/Stack on your host, you will need to make sure that all those prerequisites are met in the migration process as well.

Conclusion
If you are serious about Containers on any platform, you should consider using Portainer. It will allow you all the features that Docker offers, as well as allow you to use it with Kubernetes, Docker Swarm, and Azure ACI.

There are still people that like to use CLI of course and there is nothing wrong with that, but Portainer will be there for anyone that wants to have a powerful UI to do all those tasks. Also, with its support for users and teams, Portainer will be a one-stop-shop for all your collaborative needs as well.

Let me know down in the comments if you use Portainer, and for what, and if so, has it helped you out, or is it missing some features that you need or would like to be able to use.

Try Portainer with 3 Nodes Free

If you're ready to get started with Portainer Business, 3 nodes free is a great place to begin. If you'd prefer to get in touch with us , we'd love to hear from you!

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/author/neil-cresswell
title: Portainer News and Blog | Neil Cresswell, CEO
author: Neil Cresswell; CEO December
url: https://www.portainer.io/blog/author/neil-cresswell
hostname: portainer.io
description: Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.
sitename: Portainer.io
date: 2024-12-22
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

### Blog Post by Neil Cresswell, CEO

[
](https://www.portainer.io/blog/breaking-the-hero-complex-why-simplicity-outshines-complexity-in-platform-engineering)

Neil Cresswell, CEODecember 22, 20243 min read

### Breaking the Hero Complex: Why Simplicity Outshines Complexity in Platform Engineering

Discover why simplicity in platform engineering outshines complexity and how user-centric ...

Start Reading
[
](https://www.portainer.io/blog/innovation-on-a-budget-the-cios-guide-to-doing-more-with-less)

Neil Cresswell, CEODecember 17, 20244 min read

### Innovation on a Budget: The CIO’s Guide to Doing More with Less

How does the modern CIO operate with the overwhelming constraints imposed on them each ...

Start Reading
[
](https://www.portainer.io/blog/when-kubernetes-fails-reflections-on-the-openai-outage)

Neil Cresswell, CEODecember 14, 20243 min read

### When Kubernetes Fails: Reflections on the OpenAI Outage

The OpenAI Kubernetes platform outage should serve as a wakeup call for the industry. ...

Start Reading
[
](https://www.portainer.io/blog/when-kubernetes-feels-like-a-burden-understanding-the-challenges-and-how-to-avoid-them)

Neil Cresswell, CEONovember 28, 20245 min read

### When Kubernetes Feels Like a Burden: Understanding the Challenges and How to Avoid Them

Kubernetes doesn't need to be as stressful as it might seem. Read why you might be ...

Start Reading
[
](https://www.portainer.io/blog/portainer-the-essential-tool-for-docker-swarm-users-facing-a-kubernetes-future)

Neil Cresswell, CEONovember 19, 20243 min read

### Portainer: The Essential Tool for Docker Swarm Users Facing a Kubernetes Future

Portainer offers a seamless transition for Docker Swarm users to Kubernetes, ensuring ...

Start Reading
[
](https://www.portainer.io/blog/building-a-bare-metal-kubernetes-cluster-hardware-specifications-and-best-practices)

Neil Cresswell, CEONovember 19, 20243 min read

### Building a Bare Metal Kubernetes Cluster: Hardware Specifications and Best Practices

How to size a bare metal Kubernetes Cluster

Start Reading
[
](https://www.portainer.io/blog/does-platform-engineering-leadership-needs-a-rethink)

Neil Cresswell, CEOOctober 31, 20244 min read

### Does Platform Engineering Leadership Need a Rethink?

Platform Engineering leadership needs a rethink.. one that is very much focussed on the ...

Start Reading
[
](https://www.portainer.io/blog/devops-a-stop-gap-not-the-future)

Neil Cresswell, CEOOctober 30, 20244 min read

### DevOps: A Stop-Gap, Not the Future

DevOps, requirement or stop-gap?

Start Reading
[
](https://www.portainer.io/blog/why-we-built-portainer-simplifying-kubernetes-in-a-complex-tooling-ecosystem)

Neil Cresswell, CEOOctober 30, 20243 min read

### Why We Built Portainer: Simplifying Kubernetes in a Complex Tooling Ecosystem

Learn how Portainer fits into the Cloud Native ecosystem and tooling.

Start Reading
[
](https://www.portainer.io/blog/gitops-with-portainer-real-world-use-cases-and-worked-examples)

Neil Cresswell, CEOOctober 23, 20245 min read

### GitOps with Portainer: Real-World Use Cases and Worked Examples

Learn how you can streamline your application deployments with examples of GitOps ...

Start Reading
[
](https://www.portainer.io/blog/unlocking-kubernetes-security-with-opa-gatekeeper-how-portainer-makes-it-effortless)

Neil Cresswell, CEOOctober 21, 20245 min read

### Unlocking Kubernetes Security with OPA Gatekeeper: How Portainer Makes It Effortless

Learn how Portainer lets you take advantage of the power of OPA Gatekeeper to secure your ...

Start Reading
[
](https://www.portainer.io/blog/why-portainer-and-sidero-talos-makes-kubernetes-easier-for-emerging-platform-engineers)

Neil Cresswell, CEOOctober 10, 20242 min read

### Why Portainer and Talos Kubernetes makes Kubernetes Easier for Emerging Platform Engineers

Simplify Kubernetes management with Portainer, Omni, and Talos Kubernetes. Learn how ...

Start Reading

---
<!--
URL: https://www.portainer.io/blog/why-portainer-and-sidero-talos-makes-kubernetes-easier-for-emerging-platform-engineers
title: Why Portainer and Talos Kubernetes makes Kubernetes Easier for Emerging Platform Engineers
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/why-portainer-and-sidero-talos-makes-kubernetes-easier-for-emerging-platform-engineers
hostname: portainer.io
description: Simplify Kubernetes management with Portainer, Omni, and Talos Kubernetes. Learn how these tools automate tasks, enhance security, and streamline operations for new platform engineers.
sitename: PORTAINER.IO
date: 2024-10-10
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/A%20easy%20to%20use%20kubernetes%20environment-1.jpeg
pagetype: article
filedate: 2025-01-18
-->

For those new to [platform engineering](/solutions/for-platform-engineering) and just getting into Kubernetes, managing clusters, keeping everything secure, and maintaining operational efficiency can feel like a lot to handle. But combining **Portainer, Omni,** and [ Talos Kubernetes](https://www.siderolabs.com/platform/talos-os-for-kubernetes/) (both from Sidero Labs) can make your life a lot easier by simplifying cluster management, automating tasks, and boosting security. Here’s how:

**Cluster Management, Made Simple**

Kubernetes is powerful, but setting it up and managing it across environments (cloud, edge, or bare metal) can be a pain. **Talos Linux for Kubernetes** [includes only the most essential Linux system components](https://www.siderolabs.com/blog/there-are-only-12-binaries-in-talos-linux/), making it much simpler to deploy and manage clusters without worrying about OS updates, SSH access, or other distractions. **Omni extends the simplicity of Talos Linux even further, making cluster creation as simple as booting a machine off the appropriate image.**

When you add **Portainer**, it provides an easy-to-use UI to handle things like deploying apps and managing workloads. Instead of diving into the command line for everything, you can control multiple clusters from one dashboard. This is great when you’re still learning the ropes of Kubernetes but need to manage it like a pro.

**Security That Doesn’t Require a Security Expert**

Kubernetes security is [tough to get right](/blog/why-most-teams-get-kubernetes-user-authentication-and-rbac-wrong-and-how-portainer-fixes-it), especially when you’re new to it. **Talos** helps by minimizing the attack surface—there’s no SSH and only essential services running, so there are fewer ways for someone to compromise your cluster. **Omni** ensures your Kubernetes API is protected and integrated into your enterprise IDP, provides an encrypted management channel to all nodes, and prevents Kubernetes secrets from leaking.

**Portainer** helps on the application side by giving you **role-based access control (RBAC)**, so you can control who has access to different parts of the cluster. It’s simple to set up, even if you don’t have a deep security background yet.

**Designed for Bare Metal, Cloud, or Edge**

One of the cool things about Talos Kubernetes is that it works well in different environments. Whether you’re managing a bare-metal setup, Virtual Machines, cloud IaaS VMs, or edge devices, it’s consistent. **Portainer** lets you manage all of these environments in one place, so you don’t have to switch between tools as you scale out. This is especially useful if you’re running different types of infrastructure as you learn Kubernetes.

**Automation Handles the Hard Stuff**

Managing Kubernetes clusters means you’re constantly updating, scaling, and deploying new services. **Talos and Omni** automate the heavy lifting involved in cluster updates, and **Portainer** lets you deploy applications quickly with templates that are ready to go. You can focus more on learning and less on routine management tasks.

**Visibility and Troubleshooting Without the Headache**

Knowing what’s going on in your clusters is key, especially when things go wrong. **Portainer** gives you an easy way to view logs, monitor performance, and track what’s happening in real-time. Instead of digging through a pile of terminal commands, you get everything in one clean UI. This makes troubleshooting a lot less painful, especially as you’re still building your expertise.

Cutting to the chase: combining **Portainer, Omni,** and **Talos Kubernetes** takes a lot of the hassle out of Kubernetes. They automate the hard stuff, give you an intuitive UI, and offer a secure foundation—all of which is perfect for someone starting out in platform engineering.

This way, you can spend more time learning and experimenting, and less time firefighting Kubernetes.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/when-kubernetes-fails-reflections-on-the-openai-outage
title: When Kubernetes Fails: Reflections on the OpenAI Outage
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/when-kubernetes-fails-reflections-on-the-openai-outage
hostname: portainer.io
description: The OpenAI Kubernetes platform outage should serve as a wakeup call for the industry. Even a company as advanced as OpenAI got stung by Kubernetes.
sitename: PORTAINER.IO
date: 2024-12-14
categories: []
tags: []
image: https://www.portainer.io/hubfs/1680688052479.png
pagetype: article
filedate: 2025-01-18
-->

[incident report](https://status.openai.com/incidents/ctrsv3lwd797), highlights the challenges of managing Kubernetes in real-world scenarios. Despite being one of the most advanced AI organizations in the world, OpenAI faced a significant service interruption caused by the deployment of a new telemetry stack in its Kubernetes environment.

The incident wasn’t triggered by a flaw in Kubernetes itself but rather by an operational issue during the rollout of a critical update. Even with their expertise, resources, and processes, OpenAI experienced widespread disruption and took time to resolve the issue entirely. This raises an important question: **if even well-resourced organizations can struggle with Kubernetes, what hope do smaller teams have?**

**The Incident: What happened?**

According to OpenAI’s report, the outage began while deploying a new telemetry stack in their Kubernetes clusters. This deployment inadvertently caused issues by overloading the Kubernetes API Server, which directly impacted the Kubernetes DNS service and OpenAI’s ability to access their Kubernetes control planes. Without control-plane access, managing or restoring services became a significant challenge.

The details highlight that this wasn’t an esoteric Kubernetes bug or a lack of technical expertise—it was a real-world operational scenario that could happen to any team. However, the consequences of the issue were far-reaching, affecting customer-facing services and requiring a coordinated effort to recover.

**Key lessons from the OpenAI outage**

-
**Kubernetes is complex, even for experts**The incident highlights the intricate dependencies in Kubernetes environments. A deployment as routine as updating a telemetry stack can trigger unexpected failures, cascading into broader system unavailability. -
**Control plane access is mission-critical**Losing control-plane access in Kubernetes is akin to being locked out of the cockpit mid-flight. Recovery becomes exponentially harder without the ability to manage or troubleshoot the affected clusters. -
**Recovery takes time, even for the best**Despite their expertise and resources, OpenAI needed hours to restore access and resolve the outage. For less-equipped organizations, similar incidents could lead to much longer recovery times—or worse, an inability to recover without external help.

**What does this mean for smaller organizations?**

For many organizations, Kubernetes is both a powerful enabler and a potential point of failure. The platform’s flexibility and scalability come with a steep learning curve and significant operational complexity. Incidents like OpenAI’s show that:

**Kubernetes expertise is not optional**Organizations without in-house Kubernetes expertise are at a higher risk of facing similar incidents and not being able to resolve them efficiently.**Proactive safeguards are essential**Monitoring, change management, and rollback mechanisms must be robust enough to mitigate the risks of operational failures.**The cost of downtime is universal**While OpenAI’s outage impacted millions of users globally, downtime damages trust and revenue regardless of scale.

**Simplifying Kubernetes management**

This incident reminds us that Kubernetes needs to become more approachable for everyday organizations. While highly skilled teams may have the resources to recover from outages, smaller teams often lack the expertise to navigate similar crises. This is where simplified Kubernetes management solutions come in.

Platforms like Portainer provide user-friendly interfaces and operational safeguards that reduce the complexity of managing Kubernetes. By abstracting many of the platform’s intricacies, tools like these enable teams to focus on delivering value rather than firefighting infrastructure problems.

**A wake-up call for Kubernetes adoption**

The OpenAI outage offers valuable lessons for teams at all stages of their Kubernetes journey. It underscores the importance of:

**Planning for failure**No deployment is foolproof, and no team is immune to mistakes. Robust processes for testing, monitoring, and rollback are essential.**Investing in simplification**Choosing tools or managed services that reduce operational complexity is critical for organizations without extensive Kubernetes expertise.**Acknowledging the risks**While Kubernetes is a powerful tool, its complexity means that even routine operations can lead to significant challenges if not handled carefully.

As organizations consider adopting Kubernetes, they must ask themselves: **Are we ready to handle the risks, or do we need a more straightforward approach to Kubernetes management?**

For smaller teams, the takeaway is clear: it’s not about mastering Kubernetes in all its complexity—it’s about finding ways to make Kubernetes work for you safely and efficiently.

This is why Portainer exists today, to make the hard, easier.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/innovation-on-a-budget-the-cios-guide-to-doing-more-with-less
title: Innovation on a Budget: The CIO’s Guide to Doing More with Less
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/innovation-on-a-budget-the-cios-guide-to-doing-more-with-less
hostname: portainer.io
description: How does the modern CIO operate with the overwhelming constraints imposed on them each day... fiscal, political, resource, technological...
sitename: PORTAINER.IO
date: 2024-12-17
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/The%20image%20depicts%20a%20set%20of%20scales%20with%20a%20pile%20of%20US%20dollars%20on%20one%20side%20and%20a%20light%20bulb%20on%20the%20other.jpeg
pagetype: article
filedate: 2025-01-18
-->

The modern CIO is a magician — pulling innovation out of a hat while juggling a dozen flaming swords. You’re expected to modernize infrastructure without breaking the bank, keep systems stable while delivering exceptional service, and roll out new capabilities on technologies your team may not even know yet.

And yet, despite all this, you’re still seen as a cost center—a line item on a balance sheet that’s scrutinized for every dollar spent.

Meanwhile, you’re being squeezed on all sides: legacy systems that won’t go quietly, non-IT stakeholders buying tools behind your back, and a workforce that’s more comfortable with yesterday’s tech than tomorrow’s solutions. The demands are endless, but the resources to meet them? Not so much.

The truth is, today’s CIO lives in an era of **“more with less”**—more innovation, more speed, more efficiency, all with fewer people, fewer dollars, and absolutely no room for error.

**The Four Pressures That Are Squeezing CIOs**

**First, there’s the talent crunch.**

Hiring Kubernetes experts sounds great—until you see the salaries they’re commanding. You don’t have Google or Amazon’s bottomless pockets to attract the rockstars, and even when you land someone great, they rarely stick around. Burnout, better offers, or frustration with legacy systems drive them out the door faster than you can train them.

One person isn’t a team, and talent gaps have a way of stalling progress. As *Forbes* puts it: “[Enterprises struggle to retain top IT talent, particularly in emerging areas like cloud and containerization].”

**Then there’s the political squeeze.**

Tools are flying in from every direction. Business units, finance teams, and even individual developers are buying the tech they want—because they can. Vendors are more than happy to sell directly to non-IT stakeholders with flashy promises of productivity gains.

By the time the chaos lands in your lap, you’re the one stitching it all together, trying to make rogue solutions “just work” without breaking critical systems. *CIO.com* warns this isn’t a small issue anymore: “[Non-IT executives bypassing IT governance is becoming a widespread problem].”

**Next comes the budget paradox.**

You’re asked to deliver better, faster outcomes—but IT is still treated as an expense to be cut, not an investment to be grown. Budgets are either shrinking or tied up in existing commitments, leaving little room for innovation.

And yet, every modernization effort has to come with a guarantee: How much ROI? How soon? Can you prove it before you’ve even started? As *The Wall Street Journal* puts it: “[CIOs are under pressure to demonstrate measurable ROI for every investment].”

**Finally, you’re trapped by legacy systems.**

Your IT org chart still looks like it’s from 2015. Dev, Ops, and Security are siloed, and cross-team collaboration feels like herding cats. Your workforce? Reliable and experienced, but cautious and who value their personal time. This results in teams wanting to stick with existing systems that “just work” instead of embracing the unknown.

Legacy systems don’t just slow you down; they create a mindset of resistance, where stability becomes the enemy of progress. McKinsey points this out clearly: “[Legacy IT structures are a primary barrier to innovation and modernization].”

**So, How Do You Escape the Squeeze?**

The way forward doesn’t start with a blank check or a room full of unicorn engineers. It starts with a different approach.

The CIOs who introduce modern technologies like containers and Kubernetes without adding chaos or costs have a few things in common:

They **simplify complexity**—choosing solutions that their existing teams can actually use, rather than tools designed only for experts.

They **modernize incrementally**—adopting small, manageable wins that build momentum without demanding immediate transformation.

And they **change the conversation**—focusing not on “cool tech” but on the tangible business outcomes that containers unlock: agility, cost savings, and IT proving itself as a strategic enabler.

**Innovation Without the Drama**

The pressures you face are real. But innovation doesn’t have to mean endless complexity or reckless spending. Sometimes, less is more—if you focus on tools and approaches that align with your reality:

- Budgets that won’t grow overnight.
- A workforce that needs to be empowered, not replaced.
- Legacy systems that aren’t disappearing tomorrow.

Modernizing with containers is less about technology and more about **simplifying how your team works today**. It’s about proving quick wins that build trust, creating space for real innovation, and keeping IT from being seen as the department of “no.”

Because let’s face it: in a world where over-investment can hurt as much as under-investment, the right balance matters more than ever.

**Final Thoughts**

The modern CIO’s role isn’t for the faint of heart. You’re balancing cost, innovation, and stability while putting out fires and pulling off miracles.

But here’s the good news: You don’t need an endless budget or an army of Kubernetes experts to escape the squeeze. You just need a smarter, simpler approach—one that turns IT from a cost center into a driver of business value.

You’ve already proven you can juggle flaming swords. Now it’s time to pull off the next magic trick: innovation without the drama.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/breaking-the-hero-complex-why-simplicity-outshines-complexity-in-platform-engineering
title: Breaking the Hero Complex: Why Simplicity Outshines Complexity in Platform Engineering
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/breaking-the-hero-complex-why-simplicity-outshines-complexity-in-platform-engineering
hostname: portainer.io
description: Discover why simplicity in platform engineering outshines complexity and how user-centric design can transform your development efforts for greater impact and efficiency.
sitename: PORTAINER.IO
date: 2024-12-22
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/The%20image%20depicts%20a%20bustling%20modern%20office%20space%20filled%20with%20collaborative%20energy.jpeg
pagetype: article
filedate: 2025-01-18
-->

In cloud-native engineering, there’s this persistent myth that complexity equals brilliance. Teams pour their energy into creating intricate, highly customized systems, thinking they’re solving problems in ways only they can. Instead of building bridges to innovation, these platforms end up becoming walls; they are hard to scale, expensive to maintain, and frustratingly disconnected from the people who actually use them.

This mindset, often fuelled by what I like to call the “hero complex,” does more harm than good. It’s not about how clever the system looks on paper. It’s about how effective it is in practice. As many organizations are discovering, simplicity combined with a commitment to understanding the end user outshines technical bravado every single time.

I recently heard a story about a platform engineering team that started with all the best intentions but struggled to deliver results. The team was primarily made up of Site Reliability Engineers (SREs). While they built a functional platform, developer adoption was limited. The platform worked, technically speaking, but it didn’t resonate with its users. Developers felt like they were being handed a tool that wasn’t designed with them in mind, and as a result, engagement was lukewarm at best.

The turning point came when the team decided to add developers into the mix. This wasn’t just about broadening the skill set; it was about shortening the feedback loop between platform engineers and developers. Suddenly, the platform wasn’t being built in isolation. Developers became active participants in its evolution. Their needs and ideas started shaping the platform’s direction. Adoption skyrocketed. Additional development teams began clamoring for the same kind of support, and the platform team found itself at the center of the organization’s development efforts.

This shift underscores an important lesson. No matter how technically impressive a platform might be, it’s worthless if it doesn’t meet the needs of its users. By embedding developers into the team and focusing on continuous feedback, this group transformed a struggling project into a runaway success.

Of course, complexity isn’t always about the technical design of the platform. Sometimes, it’s about the decisions we make around how we manage it. There’s a common refrain among engineering teams: “We can’t outsource this; it’s too customized.” It’s the kind of reasoning that keeps teams locked in a cycle of over-engineering and under-delivering. But here’s the thing. If your platform is too customized to hand off to someone else, that’s not a sign of its sophistication. It’s a red flag.

Customization often creates more problems than it solves. It makes platforms harder to maintain, harder to scale, and harder for anyone else to work with. Simplifying isn’t about giving up control. It’s about focusing your energy where it matters most. Instead of burning cycles on maintaining something overly complicated, why not free up your team to focus on solving problems for your users?

Simplicity isn’t just a technical choice. It’s a business strategy. A streamlined platform is easier to adopt, easier to scale, and far less expensive to manage. When developers don’t have to wrestle with tools that don’t align with their workflows, they can focus on delivering value. And when your platform is simple enough to grow with your organization, it becomes an enabler of innovation, not a bottleneck.

At the end of the day, platform engineering isn’t about building monuments to technical brilliance. It’s about solving real problems for real people. When we let go of the hero complex, listen to our users, and prioritize simplicity, we stop building for applause and start building for impact. That is what truly matters.

Portainer embraces this very philosophy in our product strategy. By focusing on simplicity and user-centric design, Portainer offers just enough capability for most organizations to get started with containerization and Kubernetes without the need for deep expertise. The platform reduces operational overhead and complexity, enabling teams to focus on delivering value rather than wrestling with bespoke solutions. Portainer provides a practical, scalable foundation that evolves with needs; all while maintaining a commitment to simplicity and usability.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/unlocking-kubernetes-security-with-opa-gatekeeper-how-portainer-makes-it-effortless
title: Unlocking Kubernetes Security with OPA Gatekeeper: How Portainer Makes It Effortless
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/unlocking-kubernetes-security-with-opa-gatekeeper-how-portainer-makes-it-effortless
hostname: portainer.io
description: Learn how Portainer lets you take advantage of the power of OPA Gatekeeper to secure your Kubernetes clusters without having to learn a whole new language.
sitename: PORTAINER.IO
date: 2024-10-21
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/An%20image%20of%20a%20secure%20and%20controlled%20Kubernetes%20cluster%20environment%20with%20OPA%20Gatekeeper%20policies%20enforced%20effortlessly%20through%20Portainer.jpeg
pagetype: article
filedate: 2025-01-18
-->

When it comes to securing your Kubernetes clusters, few tools are as effective as Open Policy Agent (OPA) Gatekeeper. With OPA Gatekeeper, you can enforce policies that prevent misconfigurations, unauthorized access, and insecure deployments, giving you fine-grained control over every aspect of your cluster. Whether you need to block containers from running with elevated privileges or enforce strict resource limits, OPA Gatekeeper has the power to keep your clusters secure.

But here’s the catch: **writing custom OPA policies is hard**. OPA's Rego policy language is flexible, but for most teams, it’s a steep learning curve. What was supposed to be a simple way to enforce security often becomes a complex, time-consuming process of trial and error. You end up spending more time writing and debugging policies than actually securing your clusters.

**Portainer changes all of that.** With Portainer’s built-in OPA Gatekeeper policies, you can enable advanced security in your Kubernetes environments with just the flick of a switch—no need to wrestle with Rego or write custom code. Portainer brings the full power of OPA to everyone, making security simple, fast, and accessible.

#### The Benefits of Deploying OPA Gatekeeper

OPA Gatekeeper allows you to define policies that ensure your Kubernetes clusters stay compliant with best practices and organizational security guidelines. Here are some of the key benefits OPA Gatekeeper brings to the table:

-
**Enforced Consistency**: OPA Gatekeeper ensures that every resource deployed into your cluster complies with your security policies. Whether it’s restricting resource usage, enforcing image signing, or preventing privileged containers, you have total control over what can (and can’t) run in your environment. -
**Automated Policy Enforcement**: OPA Gatekeeper automatically applies policies across your cluster, so there’s no need for manual checks. It prevents violations before they can impact your infrastructure, giving you peace of mind that your clusters are always secure. -
**Audit and Compliance**: Gatekeeper doesn’t just block policy violations—it also lets you audit your clusters to ensure they’re compliant with security standards. Whether you’re adhering to internal policies or external regulations, Gatekeeper helps you prove compliance at any time. -
**Flexibility with Rego**: OPA’s policy language, Rego, is powerful and flexible, allowing you to write custom rules to enforce practically any policy you can imagine.

But as powerful as OPA Gatekeeper is, **its complexity is often a barrier**. Rego, while flexible, isn’t something you can master in a few hours, and building custom policies from scratch can feel overwhelming. For many teams, getting OPA up and running means months of learning, writing, and testing policies, not to mention debugging when things go wrong.

#### The Complexity of Writing OPA Policies

Here’s where most teams run into trouble: OPA Gatekeeper requires policies to be written in Rego, a policy language that is powerful but notoriously difficult to master. Writing a basic policy might take hours, but writing a robust policy that accounts for all edge cases? That’s a much bigger challenge.

Consider some of the common issues teams face when working with Rego:

**Steep learning curve**: Rego isn’t a language most teams are familiar with, and learning its syntax and logic can take time.**Trial and error**: Writing effective policies often involves a lot of back-and-forth testing, debugging, and tweaking.**Time-consuming**: Even once you’ve learned Rego, crafting the policies that cover your specific security needs can take days or even weeks.**Risk of misconfigurations**: A poorly written policy can break deployments or allow security gaps to go unnoticed.

For teams that don’t have the time or expertise to dive deep into Rego, securing a Kubernetes cluster with OPA Gatekeeper can feel more like a burden than a benefit. But it doesn’t have to be this way.

#### How Portainer Simplifies OPA Gatekeeper with Built-In Policies

Portainer’s solution to the OPA complexity problem is simple yet transformative: **built-in, pre-configured OPA Gatekeeper policies that you can enable with a single click**. No more digging through Rego documentation. No more writing and testing complex policies. Portainer brings advanced Kubernetes security to everyone—whether you're a seasoned Kubernetes expert or new to cluster security.

Here’s how Portainer simplifies OPA Gatekeeper:

-
**Easy Management**: Portainer’s UI makes it easy to manage and monitor OPA policies across your clusters. You can quickly see which policies are active, audit compliance, and adjust settings as needed—all without touching a line of code. **Predefined Policies**: Portainer comes with built-in OPA policies for common security needs. Whether you want to prevent containers from running as root, enforce CPU/memory limits, or block the use of certain container images, Portainer has you covered with a set of predefined policies that work right out of the box. Importantly, Portainer also handles the creation of exceptions, so you don't accidentally lock yourself out of your cluster by applying policies to critical system services!-
**Accessible for Everyone**: You don’t need to be an expert in Rego or Kubernetes security to benefit from OPA. Portainer takes the complexity out of policy management, making advanced security accessible to everyone, no matter your level of expertise.

Portainer’s approach to OPA Gatekeeper democratizes Kubernetes security, giving teams of all sizes access to advanced policy enforcement without requiring deep technical expertise. By eliminating the need to write custom Rego policies, Portainer allows you to focus on what matters most—running your applications securely—without the complexity and overhead that typically comes with OPA.

#### Advanced Kubernetes Security, Made Easy with Portainer

OPA Gatekeeper is a powerful tool that brings unparalleled control and security to your Kubernetes clusters, but writing custom policies can be a time-consuming and difficult process. For many teams, the complexity of OPA is a barrier to achieving the security they need.

**Portainer changes the game by making OPA Gatekeeper accessible to everyone**. With built-in policies that can be enabled with a single click, Portainer delivers the full power of OPA without the complexity. Advanced Kubernetes security is now within reach, whether you're managing a small cluster or operating at enterprise scale.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/when-kubernetes-feels-like-a-burden-understanding-the-challenges-and-how-to-avoid-them
title: When Kubernetes Feels Like a Burden: Understanding the Challenges and How to Avoid Them
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/when-kubernetes-feels-like-a-burden-understanding-the-challenges-and-how-to-avoid-them
hostname: portainer.io
description: Kubernetes doesn't need to be as stressful as it might seem. Read why you might be feeling like ditching Kube, and how you can make Kubernetes management less of a burden.
sitename: PORTAINER.IO
date: 2024-11-28
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/complexity%20of%20kubernetes.jpeg
pagetype: article
filedate: 2025-01-18
-->

I [recently read](https://blog.stackademic.com/i-stopped-using-kubernetes-our-devops-team-is-happier-than-ever-a5519f916ec0) about an organization that abandoned Kubernetes (in their case, in favor of AWS ECS), and how it led to a noticeably happier DevOps team.

Stories like this are becoming more common, and it's tempting to see such a move as the only solution when Kubernetes doesn't meet expectations. However, swiftly shifting away from Kubernetes might be more of an emotional response to immediate pain rather than offering strategic, long-term benefits.

Let's explore why this happens and how organizations can prevent reaching a point where Kubernetes feels more like a burden than a benefit.

Kubernetes is the standard for container orchestration, delivering scalability, flexibility, and operational efficiency. Its powerful features significantly transform how applications and infrastructure are deployed and managed. However, with these advantages comes a level of complexity that can catch teams off guard.

Often, organizations adopt Kubernetes expecting it to be a cure-all for their infrastructure challenges. They might underestimate the learning curve and the operational overhead required to run it effectively. When the reality doesn't align with these high expectations, frustration can quickly set in. When the frustrations reach a boiling-over point, "get this tech out of here!" might echo around the IT executive office.

Kubernetes has many moving parts, and even with a highly competent DevOps and SRE team its maintenance overhead can be overwhelming. As the article points out, even with 8 senior DevOps engineers, 3 dedicated SRE teams, 24/7 on-call rotations, and an enterprise support agreement, there were still significant outages and team burnout. Imagine running Kubernetes without this level of experience in-house. How much worse would it be?

#### It's not the platform, it's how you use the platform

Often, though, the issues surrounding Kubernetes are caused by the platform's overengineering. The more tools and capabilities you deploy, the more elements you need to maintain, triage, and support. While appealing, adding advanced Kubernetes technologies like ServiceMesh, GitOps, IaC, or Gatekeeper services too early can complicate your setup.

Another factor that can overwhelm teams is the operational overhead of managing Kubernetes clusters. Maintaining consistent and secure user access, monitoring utilization and availability, handling upgrades, applying security patches, and managing scaling can add a significant workload. If a team isn't prepared for these responsibilities, they can detract from other essential activities. The organization in the article spent 60% of their DevOps engineering time on maintenance! The number of discrete management tools you choose to deploy can also negatively affect the operational overhead. If you have nine different management tools, then you have nine places to work within every day, let alone the ongoing management of those very tools themselves.

Also, one often neglected overhead is the creation and maintenance of the Kubernetes Manifests (or Helm charts) that are needed to deploy the applications upon the platform. Creating these manifests takes skills and experience, and knowing how to configure the manifest/deployment most efficiently and securely is often an exercise in trial and error. The organization in the article had 200+ YAML files for basic deployments, so that's 200 discrete files they needed to maintain and test. The more apps you have, the faster this scales too.

When teams face these persistent challenges, the instinctive reaction might be to abandon Kubernetes altogether. While moving to a simpler platform like AWS ECS can offer immediate relief, it may not address the underlying issues that led to the frustration. This reaction is often driven by immediate pain rather than a careful analysis of whether Kubernetes was the right fit and whether it was implemented effectively.

#### Make Kubernetes work for you, not you for it

So, how can organizations avoid these pitfalls and make Kubernetes work for them?

##### Do you even need Kubernetes?

Before diving into Kubernetes, it's crucial to evaluate whether it truly aligns with your organization's needs. Consider the complexity of your applications and whether they require the advanced orchestration Kubernetes provides. If your workloads are relatively straightforward, a simpler solution might be more appropriate. Adopting technology because it's popular rather than because it meets your specific needs can lead to unnecessary complications.

##### Upskill your team

Kubernetes is a sophisticated platform that demands a certain level of expertise. Investing in training for your existing team can build confidence and competence. Providing opportunities for learning through workshops, courses, or certifications ensures that your team is well-equipped to manage Kubernetes clusters effectively. Alternatively, hiring professionals (managed services) with experience in Kubernetes can also help navigate the complexities and establish best practices from the outset.

##### Less, not more

One of the issues highlighted is the sprawl of management tools. Juggling multiple monitoring and logging solutions can fragment the management experience and increase the learning curve. Consolidating your tools can significantly reduce complexity. Utilizing platforms that offer multi-functional capabilities, like Portainer, can provide a unified interface for managing containers, clusters, and associated resources. A simplified toolset means less time spent switching between applications and more time focused on delivering value.

##### Understand your requirements

While it might be tempting to implement advanced Kubernetes features, it's important to assess whether you truly need these capabilities at your current stage. Each additional feature introduces more elements to maintain and can complicate your setup. Focus on implementing only what is necessary to meet your immediate needs, and consider adding more advanced features as your team's proficiency grows.

##### Consider outsourcing

Managing Kubernetes manifests and Helm charts can be a daunting task, especially as the number of applications grows. Outsourced "DevOps as a Service" engineering offerings can shift this burden off your team and onto specialists proficient at this time-consuming task.

To reduce operational overhead, consider using managed Kubernetes services offered by cloud providers like AWS EKS, Google Kubernetes Engine, or Azure Kubernetes Service. These platforms handle much of the underlying infrastructure management, including control plane operations, upgrades, and security patches. This allows your team to concentrate on application development and deployment rather than the intricacies of cluster maintenance. For self-hosted environments, tools like Sidero Omni or Talos Kubernetes offer similar experiences, simplifying management without sacrificing control.

By taking these steps, organizations can mitigate the challenges often accompanying Kubernetes adoption. It's about being strategic, understanding the tool's capabilities, aligning them with your needs, and ensuring your team is prepared to manage them effectively. Kubernetes doesn't have to be a source of frustration. With thoughtful implementation it can be a powerful asset that drives innovation and efficiency within your organization.

Speak to us here at Portainer to learn about our Kubernetes DevOps as a Service and Platform Engineering as a Service offerings, which perfectly complement our Multi-Cluster management platform, Portainer Business.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/devops-a-stop-gap-not-the-future
title: DevOps: A Stop-Gap, Not the Future
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/devops-a-stop-gap-not-the-future
hostname: portainer.io
description: DevOps, requirement or stop-gap?
sitename: PORTAINER.IO
date: 2024-10-30
categories: []
tags: []
image: https://www.portainer.io/hubfs/DevOps%201600%20x%20900.png
pagetype: article
filedate: 2025-01-18
-->

In the world of software, DevOps emerged as a necessary crutch; a way to bridge the gap between the code developers create, and the production deployment of that code. But here’s the reality: DevOps, as most of us know it, is temporary. It exists because the technology we rely on is incomplete, not because it’s the ideal solution. And NO, platform engineering is not the successor to DevOps, as much as marketing strategies would have you believe, they serve different purposes!

As the CEO of Portainer, I’ve seen firsthand how the complexity of modern application deployment has driven businesses to create entire teams dedicated to DevOps. Employing experts who specialize in containerizing applications; creating Dockerfiles, deployment manifests, Helm charts, and the deployment pipelines that get all of this running on Kubernetes. Why? Because other than a limited few cloud-hosted services like Vercel, there isn’t suitable technology that can handle these processes on its own. DevOps was born out of necessity, not out of technological readiness.

##### What DevOps Offers Today

Let’s break it down. Developers are forced to work closely with experts to navigate the intricacies of deploying containerized applications. As shown in the chart below, they rely on DevOps engineers to:

-
**Create Dockerfiles and build images**: Even the most seasoned developers often need assistance in creating these, ensuring compatibility and security. Even something as simple as the incorrect selection of a base image (full of CVEs and not maintained) can put your production application at risk! -
**Craft deployment manifests and Helm charts**: Without precise specifications, deployment to Kubernetes is impossible, or at best unreliable. There is no escaping the specialist knowledge needed to lay out the application on the Kubernetes platform (load balancers, ingress controllers, secrets, configs, persistence, deployment modes, health checks, upgrade policies, etc). **Support the deployment tooling**: A container image and a deployment manifest does not equal a running application. You need to execute the deployment instructions against the environment, and that's where CD/GitOps tooling comes in. This is not simple and again requires specialist skills to set up and support.-
**Monitor and manage deployments on Kubernetes**: Once deployed, applications require continuous oversight to ensure uptime, performance, and security across dynamic clusters. And yup, once again, specialist skill required... see a trend yet?

These are all complicated, specialized, time-intensive tasks; tasks that software *should* handle automatically.

Oh, and just looping back to my initial comment re Platform Engineering... well that covers the scope of the bottom right box. Now, I agree that a well-established Platform Engineering team likely wants to design and deploy an Internal Developer Portal, but for many, that is an aspiration vs a reality.

##### Flashback: What was the way

You dont need to go back in time very far to recall how applications used to be promoted into Production. Microsoft Visual Studio has a "compile and deploy" button, that handled the deployment to an IIS server. PHP developers used products like cPanel to FTP their works to a web/db server.. it was all very simple. But technology designed to improve the developer experience seems to have taken us backwards. The sheer amount of time developers spend NOT developing is insane. By some accounts, up to 30% of a developer's time (and more often that not, senior developers), is spent troubleshooting DevOps tasks. Imagine if that 30% could be reclaimed and put back into business value-adding tasks like feature development! This is what we need to get back to.. simplicity.

##### The Future: Moving Beyond DevOps

Imagine a world where a developer’s path to production is as as easy as it was? Writing code and pressing “deploy.” We’re working toward that, and platforms are slowly catching up. The technology isn’t there *yet*, but we want to deliver that. If software could automate these steps, enabling seamless code-to-production workflows without human intervention, would we still need DevOps?

Here’s where I think we’re headed: developers should be able to rely on intelligent systems that take care of the operational heavy lifting introduced by container based deployment, making the current need for DevOps expertise redundant. DevOps is a reaction to the technology gap, not a permanent fixture. As we evolve, we won’t need entire teams managing infrastructure intricacies; the platform will do it for us. Even better, the DevOps engineers we all have today can elevate themselves, focus on site reliability engineering, and work on increasing the SLA and performance of an application, not on "busy" tasks of operating a platform.

##### DevOps is a Stop-Gap

So, is DevOps the future? I believe it’s a stepping stone; one that will eventually fade as technology catches up. The end goal is simple: let developers focus on building great software and let intelligent platforms handle the complexities of deployment and management.

We should challenge ourselves to look beyond DevOps and invest in solutions that simplify the entire journey from code to production. That’s the future Portainer is working toward.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/does-platform-engineering-leadership-needs-a-rethink
title: Does Platform Engineering Leadership Need a Rethink?
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/does-platform-engineering-leadership-needs-a-rethink
hostname: portainer.io
description: Platform Engineering leadership needs a rethink.. one that is very much focussed on the consumer of the service.
sitename: PORTAINER.IO
date: 2024-10-31
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/An%20image%20of%20a%20platform%20engineering%20team%20led%20by%20someone%20from%20an%20IT%20infrastructure%20background%20rather%20than%20someone%20who%20understands%20the%20needs%20of%20developer.jpeg
pagetype: article
filedate: 2025-01-18
-->

In today’s cloud-native era, a surprising yet common misalignment often arises within [platform engineering](/solutions/for-platform-engineering) teams: they’re led by someone from an IT infrastructure background rather than someone who has "lived the life" of the platform's primary users—developers.

This structure typically leads to a “build and mandate” approach, where the engineering team chooses all the platform tools, the platform is built to their specifications, and its use is enforced through policy.

This approach is seen repeatedly, and at the recent Gartner IT Symposium, several talks were given on this topic. The talks explained how Platform Engineering teams need to rethink their behaviors, stop designing to their wishes, and instead design to the explicit needs of their users.

##### The Problem: Developers Are Platform Engineering’s Primary Customers

In the modern software landscape, it’s the development teams, not the IT operations teams, that are the primary consumers of the systems delivered by platform engineering teams.

Developers rely on these platforms to be fast, flexible, and user-friendly, allowing them to build, test, and deploy code efficiently. However, when an IT infrastructure leader manages platform engineering, the approach can default to one that prioritizes stability and control over developer productivity and agility. Additionally, the platform engineering team often determines the developer-facing toolsets based on their assumptions of need rather than researching the actual needs (and constraints) of their users.

This difference in priorities leads to friction. Gartner’s research has consistently shown that for platform engineering to succeed, it must be customer-centric—designing around the needs of its users rather than the preferences of its builders. Developers, not platform engineers, should ultimately influence which tools are integrated and how they’re presented, ensuring the platform truly enhances productivity.

##### Why “Build and Mandate” Fails in the Cloud-Native World

When infrastructure-oriented leaders lead platform engineering teams, platforms are often developed with a top-down mandate approach. This can result in rigid platforms that don’t adapt well to the dynamic needs of modern development. Developers, who thrive in agile environments and prefer self-service tools, often find these platforms obstructive rather than supportive, time-wasters rather than time savers. What does this result in? Shadow IT, where developers seek out (and often create) alternate services to serve their needs.

In contrast, leaders with a DevOps or software engineering background bring an inherently different perspective. They understand the need for flexibility and on-demand access because they’ve lived through the challenges developers face daily. Instead of building platforms around control, they build platforms around demand, fostering a naturally attractive environment for developers to adopt and engage with.

##### The Case for Developer-Led Platform Engineering

To design a platform that developers want to use, leadership must have experience with the challenges of the development cycle. A leader with a development or DevOps background understands the pain points of slow pipelines, poor integration, and bottlenecks in deployment. They’re in a better position to create a platform that solves real problems and adds value, rather than just checking boxes.

Platforms built with this demand-driven approach avoid the mandate trap. Developers naturally gravitate toward tools and systems that make their jobs easier, and when these tools are designed with their needs in mind, adoption becomes organic rather than enforced. Demand-driven platforms grow because they solve real issues, not because they’re mandated.

##### Demand-Driven Platforms: A Blueprint for Success

Many companies that have adopted a developer-led approach to platform engineering report increased engagement and higher satisfaction among their development teams. These platforms are designed to adapt quickly to user needs, driven by someone who understands the workflows and bottlenecks that developers face. They are also very aware of the impact that context switching and increasing the cognitive load on developers creates. Developers don't want to spend hours navigating complex tools, regardless of how "best of breed" they purport to be (e.g., backstage); developers want a tool that allows them to get their job done fast, with very little context switching needed.

The demand-driven approach aligns with Gartner’s advice that platform engineering must avoid “engineering for the sake of engineering - i.e don't build a cruise ship when your developers want a kayak.” Rather than allowing platform engineers free rein to choose tools based on personal preference or technical curiosity, the platform’s functionality is shaped by what its users truly need and nothing more.

##### What would happen if a developer-focused team led your platform?

If platform engineering is to meet the needs of modern cloud-native development teams, is it now time to rethink its leadership structure?

Instead of handing the reins to IT infrastructure veterans, should we empower leaders from software engineering backgrounds? These leaders have the insight and experience to prioritize developer-friendly tools and functionality that align with the workflows of their users.

So, rather than “build and mandate,” let’s build for demand. A platform that solves genuine needs doesn’t require mandates to ensure its use. In the cloud-native era, the key to platform engineering success is a leader who understands that their primary customers are the developers—and they’re here to serve.

What are your thoughts on this?

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-the-essential-tool-for-docker-swarm-users-facing-a-kubernetes-future
title: Portainer: The Essential Tool for Docker Swarm Users Facing a Kubernetes Future
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-the-essential-tool-for-docker-swarm-users-facing-a-kubernetes-future
hostname: portainer.io
description: Portainer offers a seamless transition for Docker Swarm users to Kubernetes, ensuring continuity, flexibility, and advanced management features without operational disruptions. Main Point Summary: With the release of Mirantis Kubernetes Engine (MKE) 4, Docker Swarm users face a pivotal moment. Portainer provides an ideal solution by supporting Swarm and enabling a gradual transition to Kubernetes, ensuring continuity, simplicity, and advanced management capabilities.
sitename: PORTAINER.IO
date: 2024-11-19
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/docker%20swarm.jpeg
pagetype: article
filedate: 2025-01-18
-->

Mirantis recently announced the release of **Mirantis Kubernetes Engine (MKE) 4**, signaling a strategic pivot toward Kubernetes. In their official press release, Mirantis stated:

"For existing MKE users, upgrading to MKE 4 requires just one command or a single click. Users of MKE 3.7 can easily transition while keeping all workloads running. For Swarm users, Mirantis will continue support in MKE 3."

While Mirantis has pledged to maintain Swarm support in the MKE 3 series, the release of MKE 4—with its complete focus on Kubernetes—makes one thing clear: the clock is ticking for Swarm users. If you rely on Swarm as your container orchestration tool, now is the time to consider your next steps.

For those who, either by choice, or are required to remain on Swarm for legacy reasons, **Portainer** is the ideal solution. It offers continuity, a seamless transition path, and an unparalleled user experience for both Swarm and Kubernetes environments.

#### Why You Need to Plan for the Future of Swarm

Mirantis’ decision to limit Swarm support to MKE 3 raises several concerns for Swarm users:

-
**No New Features or Innovations**

The focus on Kubernetes in MKE 4 means Swarm is effectively in maintenance mode. While Mirantis will address critical issues, there’s no guarantee of future enhancements or compatibility improvements. -
**Increasing Security Risks**

Over time, relying on an older version of MKE with limited updates could expose your environment to unpatched vulnerabilities and compatibility issues with modern container runtimes. -
**Integration Challenges**

The industry is rapidly converging on Kubernetes as the standard for container orchestration. New tools, technologies, and platforms are increasingly designed with Kubernetes in mind, leaving Swarm users at risk of being left behind.

#### Why Portainer is the Ideal Solution for Swarm Users

Portainer bridges the gap between the simplicity of Swarm and the growing dominance of Kubernetes. Here’s why it’s the perfect fit for Swarm users facing this transition:

##### 1. **Seamless Swarm Support**

Portainer fully supports Docker Swarm, allowing you to continue managing your Swarm environments with ease. If you love Swarm’s straightforward approach to container orchestration, you can keep using it while benefiting from Portainer’s enhanced management capabilities.

##### 2. **Gradual Transition to Kubernetes**

Portainer doesn’t force you to choose between Swarm and Kubernetes. Instead, it allows you to:

**Manage Both Orchestrators:**Operate Swarm and Kubernetes clusters side by side within the same interface.**Transition at Your Own Pace:**Migrate workloads incrementally without operational disruptions.**Learn Kubernetes Slowly:**Use Portainer’s intuitive interface to manage Kubernetes without diving headfirst into its complexities.

##### 3. **Simplicity Meets Scalability**

Portainer combines the simplicity Swarm users love with the scalability of Kubernetes:

**Streamlined UI:**Manage stacks, networks, and services with ease.**Guided Kubernetes Workflows:**Deploy applications without writing complex Kubernetes manifests.**Built-in GitOps:**Automate codified deployments for both Swarm and Kubernetes environments.

##### 4. **Enterprise-Grade Features**

Portainer provides advanced functionality that makes it suitable for enterprise use:

**Multi-Cluster Management:**Oversee multiple Swarm or Kubernetes clusters from a single pane of glass.**Role-Based Access Control (RBAC):**Enforce granular permissions for secure, multi-team environments.**Monitoring and Troubleshooting:**Gain visibility into workloads and simplify debugging with integrated tools.

##### 5. **Reduced Costs and Operational Overhead**

Unlike Kubernetes, which often requires hiring specialized staff or investing in extensive training, Portainer empowers your existing team to manage Swarm and Kubernetes with minimal additional resources.

#### Why Swarm Users Should Choose Portainer

If you’re a Swarm user, switching to Portainer is not just a smart move—it’s a necessary one. Here’s why:

**Continuity:**Stick with Swarm while maintaining access to modern tools and active support.**Flexibility:**Transition to Kubernetes on your own terms, without a forced migration.**Ease of Use:**Manage both orchestrators through a unified, intuitive interface.**Support:**Enjoy the backing of an enterprise-grade platform used by Fortune 500 companies, governments, and aerospace organizations.

In summary, the release of MKE 4 marks a turning point for Docker Swarm users. While Mirantis has promised continued support in MKE 3, the writing is on the wall: Kubernetes is the future.

With Portainer, you don’t have to abandon the simplicity of Swarm or rush into the complexities of Kubernetes. Portainer provides the tools you need to manage Swarm today and transition to Kubernetes tomorrow—all without missing a beat.

For further information you might like to read about this customer's experience in migrating from Mirantis to Portainer. [Read more](/svs-portainer-migrating-from-mirantis-to-portainer).

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/why-we-built-portainer-simplifying-kubernetes-in-a-complex-tooling-ecosystem
title: Why We Built Portainer: Simplifying Kubernetes in a Complex Tooling Ecosystem
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/why-we-built-portainer-simplifying-kubernetes-in-a-complex-tooling-ecosystem
hostname: portainer.io
description: Learn how Portainer fits into the Cloud Native ecosystem and tooling.
sitename: PORTAINER.IO
date: 2024-10-30
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/get%20started%20with%20kubernetes.jpeg
pagetype: article
filedate: 2025-01-18
-->

As the CEO of Portainer, I’m often asked why we chose the path we did in a landscape where thousands of tools are vying for a place in the Kubernetes ecosystem. Survey after survey cites complexity as one of the main challenges to adopting Kubernetes, it's not that Kubernetes on its own is complex - it's the vast ecosystem and choices.. so let me explain a few things.

In my view, the [CNCF ecosystem’s](https://landscape.cncf.io/) abundance of tools offers incredible flexibility, but for most companies it also introduces unnecessary complexity. Many tools overlap in functionality or demand such specialized knowledge that only large, resource-rich organizations can manage them effectively. For most companies, especially those starting their journey with containers, this level of choice and complexity isn’t just overwhelming, it’s counterproductive.

Our vision with Portainer has always been about cutting through this complexity. We recognized very early on that the majority of organizations don’t need an intricate assembly of specialized tools just to run their applications on Kubernetes or Docker. For these organizations, we saw an opportunity to provide everything needed to get started and operate effectively within a single platform. Portainer was designed, from day 1, to be that all-in-one solution, a tool that allows organizations to get up and running with containers without the heavy investment and complexity typically required.

### A Unified Solution for the Real Needs of Most Organizations

Our focus is on practical simplicity. Portainer provides the core features needed to manage Kubernetes and Docker environments from start to finish. When companies deploy purchased software, Portainer can serve as their sole platform and deployment management tool. Even when companies develop their own applications, Portainer can cover nearly every operational need. A CI tool like GitHub Actions may be used for building container images and a container registry will house those images, but beyond that Portainer provides a complete set of tools to manage deployments, monitor performance, and secure the environment.

This is where Portainer’s true value lies: we take away the need for fragmented tools and interfaces, enabling companies to focus on their applications without worrying about mastering a myriad of technical components.

### Growing with Organizational Complexity

Of course, not all companies will remain at this foundational level forever, and we understand that as they scale, additional needs and complexities will arise. This is where Portainer’s flexibility comes into play. Our goal is to meet 70% of most companies’ needs out of the box, but we also make it easy for organizations to integrate more specialized tools as they grow.

When companies reach that stage, they might require:

-
**Infrastructure Management (IaC)**- For dynamic environments, tools like Ansible or Terraform might be added to automate the creation and scaling of clusters, while Portainer remains the management console. -
**Advanced CI/CD**- For complex deployments, a company might choose to integrate ArgoCD or Flux, moving beyond Portainer’s built-in GitOps/CD features. In these cases, Portainer’s Kubernetes API proxy allows[seamless integration](/blog/deploy-and-use-argocd-with-portainer). -
**Deep Observability**- As the criticality of applications grows, so does the need for more granular monitoring. Some companies may deploy centralized instances of[Prometheus and Grafana](/blog/deploy-prometheus-monitoring-stack-with-portainer), for example, connecting through Portainer’s API proxy. Others might need centralized logging and may look to Splunk or the ELK stack for insights that go beyond the per-pod logging Portainer offers. -
**Security Enhancements**- With increased workloads, organizations may need Security Information and Event Management (SIEM) systems, network introspection, or internal firewalling (network policies) within clusters. Portainer is built to allow these integrations as needed, though for many companies, our built-in capabilities like[OPA Gatekeeper](/blog/unlocking-kubernetes-security-with-opa-gatekeeper-how-portainer-makes-it-effortless)already cover essential security requirements.

### The Balance of Efficiency and Expansion

What we’ve built at Portainer is a practical, powerful platform that empowers teams to begin their container journey with confidence and simplicity. This is not about locking companies into a restricted tool but rather giving them the freedom to expand when the time is right. By delivering a robust set of built-in capabilities that are designed to handle the majority of operational needs, and offering easy integration for advanced tools, Portainer strikes the balance between efficient container management and seamless growth potential.

For us, it’s about redefining what a container management platform should offer. In the end, we believe companies shouldn’t be forced to adopt unnecessary complexity until they’re ready. Portainer exists to take the stress out of Kubernetes so that organizations can focus on what matters: delivering their applications and scaling at their own pace.

What do you think? Am I successful in my endeavors to remove complexity and reduce operational overhead?

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/author/neil-cresswell/page/2
title: Portainer News and Blog | Neil Cresswell, CEO (2)
author: Neil Cresswell; CEO September
url: https://www.portainer.io/blog/author/neil-cresswell
hostname: portainer.io
description: Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization. (2)
sitename: Portainer.io
date: 2024-09-28
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

### Blog Post by Neil Cresswell, CEO

[
](https://www.portainer.io/blog/the-gitops-minefield-why-most-tooling-is-overcomplicated-and-how-portainer-simplifies-it)

Neil Cresswell, CEOSeptember 28, 20245 min read

### The GitOps Minefield: Why Most Tooling is Overcomplicated and How Portainer Simplifies It

Why GitOps tooling can complicate your life, and how Portainer can bring simplicity back ...

Start Reading
[
](https://www.portainer.io/blog/streamline-iot-deployments-at-scale-why-portainer-is-the-smart-choice-for-managing-thousands-of-remote-containerized-environments)

Neil Cresswell, CEOSeptember 26, 20244 min read

### Streamline IoT Deployments at Scale: Why Portainer is the Smart Choice for Managing Thousands of Remote Containerized Environments

Simplify IoT deployments at scale with Portainer, the ideal tool for managing ...

Start Reading
[
](https://www.portainer.io/blog/why-most-teams-get-kubernetes-user-authentication-and-rbac-wrong-and-how-portainer-fixes-it)

Neil Cresswell, CEOSeptember 26, 20245 min read

### Why Most Teams Get Kubernetes User Authentication and RBAC Wrong (And How Portainer Fixes It)

Stop struggling with Kubernetes RBAC. Portainer is the antidote to complexity: five ...

Start Reading
[
](https://www.portainer.io/blog/the-harsh-truth-about-kubernetes-management-why-your-tools-are-failing-you)

Neil Cresswell, CEOSeptember 26, 20243 min read

### The Harsh Truth About Kubernetes Management: Why Your Tools Are Failing You

Discover why your Kubernetes management tools are failing you and how Portainer can ...

Start Reading
[
](https://www.portainer.io/blog/portainer-then-vs.-now-the-evolution-of-a-container-management-powerhouse)

Neil Cresswell, CEOSeptember 16, 20244 min read

### Portainer Then vs. Now: The Evolution of Container Management

Neil explores how Portainer has transformed from its origins and initial goals into what ...

Start Reading
[
](https://www.portainer.io/blog/is-docker-ce-ready-for-production-how-portainer-bridges-the-gaps)

Neil Cresswell, CEOSeptember 5, 20243 min read

### Is Docker-CE Ready for Production? How Portainer Bridges the Gaps

Our CEO Neil talks about the current state of Docker-CE, its issues with security, and ...

Start Reading
[
](https://www.portainer.io/blog/how-portainer-simplifies-industry-4.0-edge-device-management-overcoming-software-distribution-challenges)

Neil Cresswell, CEOSeptember 5, 20245 min read

### How Portainer Simplifies Industry 4.0 Edge Device Management: Overcoming Software Distribution Challenges

Managing Industry 4.0 edge devices can be a nightmare of complexity. Find out how ...

Start Reading
[
](https://www.portainer.io/blog/ensuring-consistent-and-simplified-operations-in-the-era-of-iiot)

Neil Cresswell, CEOSeptember 4, 20243 min read

### Ensuring Consistent and Simplified Operations in the Era of IIoT

Find out how Portainer can reduce the complexity and enhance the reliability of your IIoT ...

Start Reading
[
](https://www.portainer.io/blog/maximize-your-openshift-investment-with-portainer-multi-cluster-management-without-the-premium-price-tag)

Neil Cresswell, CEOSeptember 2, 20244 min read

### Maximize Your OpenShift Investment with Portainer: Multi-Cluster Management Without the Premium Price Tag

Learn how Portainer can work with your OpenShift environments to provide powerful ...

Start Reading
[
](https://www.portainer.io/blog/how-portainer-supercharges-your-internal-developer-platform-idp)

Neil Cresswell, CEOAugust 22, 20245 min read

### How Portainer Supercharges Your Internal Developer Platform (IDP)

Explore how Portainer’s features can be leveraged within an IDP to enhance your ...

Start Reading
[
](https://www.portainer.io/blog/managing-a-swarm-with-differing-node-configs-using-the-portainer-agent)

Neil Cresswell, CEOAugust 7, 20248 min read

### Managing a Swarm with differing node configs using the Portainer Agent

Learn how you can use placement constraints to deploy the Portainer Agent in a Swarm ...

Start Reading
[
](https://www.portainer.io/blog/does-talos-kubernetes-and-omni-live-up-to-the-hype)

Neil Cresswell, CEOAugust 5, 20244 min read

### Does Talos Kubernetes and Omni live up to the hype?

Using Sidero Omni to provision a Talos Kubernetes Cluster, which is then managed with ...

Start Reading

---
<!--
URL: https://www.portainer.io/blog/gitops-with-portainer-real-world-use-cases-and-worked-examples
title: GitOps with Portainer: Real-World Use Cases and Worked Examples
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/gitops-with-portainer-real-world-use-cases-and-worked-examples
hostname: portainer.io
description: Learn how you can streamline your application deployments with examples of GitOps deployments on Kubernetes using Portainer.
sitename: PORTAINER.IO
date: 2024-10-23
categories: []
tags: []
image: https://www.portainer.io/hubfs/Best%20CICD%20Concepts%20for%20DevOps%201600x900.png
pagetype: article
filedate: 2025-01-18
-->

Portainer is a powerful tool that simplifies managing containerized applications, and with its built-in GitOps capabilities, deploying and managing applications from Git repositories becomes a seamless experience. In this post we’ll walk through how to configure GitOps in Portainer by creating applications from Kubernetes manifests stored in Git, with real-world examples and practical use cases.

#### What is GitOps?

GitOps is a modern way of managing and automating deployments by treating Git as the source of truth for infrastructure and application configurations. With GitOps, all changes are made in a Git repository, and a GitOps tool like Portainer ensures that the live environment matches the desired state defined in Git. This offers benefits like traceability, version control, and automated rollbacks.

#### Setting Up GitOps in Portainer

In Portainer, you set up GitOps when creating a new application from a manifest stored in a Git repository. There’s no need to “enable” GitOps separately—it’s natively supported as part of the codified application deployment process.

##### Prerequisites:

- A running Kubernetes cluster
- Portainer Business Edition
[installed and configured](https://docs.portainer.io/start/install/server/kubernetes) - A Git repository containing Kubernetes manifests or Helm charts

##### Step 1: Navigate to Applications and "Create from Manifest"

**Log in to Portainer**and select your**Kubernetes**environment.- Navigate to the
**Applications**section. - Click
**Create from Manifest**to start the process of deploying an application using a manifest stored in a Git repository.

##### Step 2: Configure GitOps with the Manifest

When prompted, you will need to configure the connection to your Git repository:

**Namespace:**Decide if you want to use the namespace specified in your manifest, or to override and manually select a target namespace**Authentication:**If your Git Repo requires authentication, add the credentials**Repository URL:**Enter the Git URL where your Kubernetes manifests are stored (e.g., GitHub, GitLab).**Repository Reference:**Specify the Git branch from which you want to deploy (commonly`main`

or`master`

).**Manifest Path:**Provide the path within the repository where the manifest is located (e.g.,`/manifests/deployment.yaml`

). You can add as many manifest paths as you need for your application.

Here’s an example of a basic `deployment.yaml`

:

`apiVersion: apps/v1`

`kind: Deployment`

`metadata:`

`name: sample-app`

`spec:`

`replicas: 2`

`selector:`

`matchLabels:`

`app: sample-app`

`template:`

`metadata:`

`labels:`

`app: sample-app`

`spec:`

`containers:`

`- name: sample-app`

`image: nginx:1.17`

`ports:`

`- containerPort: 80`

Once you've configured the connection to your repository, Portainer will fetch and apply the manifests to your Kubernetes environment.

##### Step 3: Set Up GitOps Automatic Sync

During the setup, you can configure Portainer to sync with the Git repository automatically. This ensures that changes pushed to the repository (e.g., new image versions or configuration updates) are automatically applied to your Kubernetes cluster.

**GitOps Updates:**Select to enable the GitOps reconciliation engine**Mechanism:**You can enable Polling (default) or Webhook if you prefer push-based updates**Fetch Interval:**You can configure how often Portainer checks for updates in your Git repository (e.g., every 5 minutes).**Always Apply Manifest:**This option ensures that any local changes made live within the cluster are always overwritten, even if there are no changes in the Git repo.**Skip TLS verification:**If you are using self-signed certs on your Git repo, you can disable TLS warnings

#### Real-World Scenario 1: Updating Applications Automatically with GitOps

Let’s say you manage a containerized web service deployed via GitOps in Portainer. The application is a basic Nginx web server.

##### Workflow Example:

The team updates the Docker image version in the`deployment.yaml`

from `nginx:1.17`

to `nginx:1.18`

.
`containers:`

`- name: sample-app`

`image: nginx:1.18`

They then push the updated manifest is pushed to the `main`

branch of your Git repository.

Portainer’s GitOps feature detects the change (based on the sync interval you configured) and automatically redeploys the updated application to Kubernetes, switching to the new `nginx`

image version.

##### Key Benefits:

**Automation:**No need for manual updates, ensuring applications always match the latest configuration in Git.**Consistency:**The live environment always reflects the desired state as defined in Git.

#### Real-World Scenario 2: Rollbacks with GitOps

GitOps in Portainer also simplifies rollbacks, helping teams quickly revert to a previous known good state if something goes wrong during an update.

##### Workflow Example:

After deploying `nginx:1.18`

, you discover that the new version has introduced a bug.

To roll back, you simply revert the change in the Git repository to the previous `nginx:1.17`

version:

`containers:`

`- name: sample-app`

`image: nginx:1.17 # Revert to previous version`

Then push the change to the Git repository.

Portainer automatically detects the update and redeploys the previous working version (`nginx:1.17`

) to Kubernetes, effectively rolling back the change.

##### Key Benefits:

**Easy Rollback:**Simply revert the change in Git and let Portainer handle the redeployment.**Version Control:**Since every change is recorded in Git, you have a complete audit trail of all deployments.

#### Real-World Scenario 3: Multi-Environment GitOps Deployment

If you manage multiple environments, such as development, staging, and production, you can use GitOps with Portainer to manage deployments across all environments in a consistent and controlled manner.

##### Workflow Example:

Each environment (development, staging, production) is linked to a different branch in your Git repository.

- Development:
`dev`

branch - Staging:
`staging`

branch - Production:
`main`

branch

Developers push changes to the `dev`

branch, and once tested, they merge changes to the `staging`

branch for further validation.

Finally, once the changes are validated, the code is merged to the `main`

branch, which Portainer automatically deploys to the production Kubernetes cluster.

** **

##### Key Benefits:

**Environment Isolation:**Separate Git branches for each environment prevent untested changes from reaching production.**Automation:**Portainer automates deployment to the correct environment based on Git branch updates.

Portainer’s GitOps support provides a powerful way to manage and automate application deployments across Kubernetes environments. By using Git as the source of truth you can ensure consistency, reliability, and traceability in your deployment processes. Whether you need automated updates, easy rollbacks, or multi-environment management, GitOps with Portainer offers a flexible and scalable solution for your Kubernetes workloads.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/building-a-bare-metal-kubernetes-cluster-hardware-specifications-and-best-practices
title: Building a Bare Metal Kubernetes Cluster: Hardware Specifications and Best Practices
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/building-a-bare-metal-kubernetes-cluster-hardware-specifications-and-best-practices
hostname: portainer.io
description: How to size a bare metal Kubernetes Cluster
sitename: PORTAINER.IO
date: 2024-11-19
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/An%20image%20of%20a%20person%20building%20a%20bare%20metal%20Kubernetes%20cluster.jpeg
pagetype: article
filedate: 2025-01-18
-->

If you’re gearing up to build a bare metal Kubernetes cluster, you’ve probably got a lot of questions: What kind of servers should I buy? How much storage is enough? How do I make sure a single hardware failure doesn’t ruin my day?

Good news—you’re not alone! Let’s walk through the key decisions you’ll face when building your cluster and how to set yourself up for success.

**"What Happens When a Node Fails?"**

Great question! First, let’s agree on something: **hardware failures happen.** Maybe a fan dies, a power supply fizzles, or a disk just gives up. When this happens, Kubernetes will reschedule your workloads to other nodes—if you’ve planned for it.

To minimize the chaos:

**Smaller Nodes Are Better.**Instead of a few massive servers, go for more, smaller ones. If one goes down, fewer workloads are impacted.**Spread the Load.**Use Kubernetes’ features like**node affinity**and**anti-affinity rules**to make sure replicas of critical apps aren’t all sitting on the same node.**Stateless Nodes Are Key.**Store only temporary stuff—like container images and working directories—on local disks. All the important data should live on shared storage.

**"Wait, Shared Storage? What’s That About?"**

Exactly! In Kubernetes, you want your nodes to be **stateless**. This means if a server dies, you can replace it without worrying about lost data. Here’s how you do it:

- Use
**NFS, iSCSI, or SAN**for Kubernetes persistent volumes. - Local storage? Just enough for the OS, container runtimes, and a little breathing room. Think
**1–2 TB SSDs**—plenty for most setups.

By keeping nodes lightweight and stateless, you make recovery simple. One node down? No problem—your cluster doesn’t skip a beat.

**"What’s This ‘Scale-Out’ Thing I Keep Hearing About?"**

Ah, the magic of **scale-out**! It’s all about horizontal growth—a lagger number of smaller nodes vs a small number of big beefy nodes. Kubernetes loves this approach.

Here’s why:

**Cost Savings:**Instead of splurging on high-end hardware, you can go with more affordable, single-socket servers.**Flexibility:**Need more capacity? Just add another node. No downtime, no drama.**Resilience:**Smaller nodes mean less impact if one fails.

For a good scale-out setup:

- Stick to
**single-socket servers**with**8–16 cores**and**32–64 GB of RAM.** - Use network interfaces that can handle traffic—
**10 Gbps or more**should do the trick.

**"How Do I Plan for Node Failures?"**

You’re thinking ahead—nice! Here’s the deal: If you don’t plan for node failures, you’re tempting fate. When a node goes down, the cluster has to reschedule its workloads. To do this, there needs to be spare capacity.

Here’s the math:

- Let’s say you have five nodes, each running at 80% capacity. If one node dies, that 20% buffer on the remaining nodes is what keeps things running smoothly.
- You might even want an
**extra node’s worth of capacity**sitting idle, ready to step in during a failure.

Sure, reserving capacity feels like a luxury, but it’s worth it. Downtime is expensive—whether it’s unhappy customers or disrupted workflows.

**"What’s the Bottom Line for Hardware?"**

Glad you asked. Here’s a quick checklist for a rock-solid Kubernetes cluster:

**Stateless Nodes:**Keep them simple. 1–2 TB SSDs for the OS and container working space.**Shared Storage:**NFS, iSCSI, or SAN for anything persistent.**Scale-Out Hardware:**Single-socket servers with moderate specs—8–16 cores, 64-128 GB RAM.**Networking:**At least 10 Gbps to handle traffic between nodes.**Plan for Failures:**Always have spare capacity in your cluster.

For example, a starter cluster might include:

**4 Dell PowerEdge R650 nodes**with 8-core CPUs, 64 GB RAM, and 1 TB SSDs.- A
**NetApp AFF shared storage system**for persistent volumes. **10 Gbps Intel NICs**and an**Arista 7050X switch**for networking.

**"Anything Else I Should Know?"**

Just one thing: Kubernetes is designed to be flexible and resilient, but hardware design still matters. By building a cluster with the right specs, you’re setting the stage for smooth operations—whether it’s handling day-to-day workloads or bouncing back from a hardware hiccup.

If you’re still unsure about your setup, feel free to reach out or check out resources from CNCF—they’re packed with tips to help you get it right.

Happy clustering! 🎉

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/why-most-teams-get-kubernetes-user-authentication-and-rbac-wrong-and-how-portainer-fixes-it
title: Why Most Teams Get Kubernetes User Authentication and RBAC Wrong (And How Portainer Fixes It)
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/why-most-teams-get-kubernetes-user-authentication-and-rbac-wrong-and-how-portainer-fixes-it
hostname: portainer.io
description: Stop struggling with Kubernetes RBAC. Portainer is the antidote to complexity: five roles, zero confusion.
sitename: PORTAINER.IO
date: 2024-09-26
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/Complicated%20representation%20of%20different%20levels%20of%20user%20access%20to%20a%20computer%20system.jpeg
pagetype: article
filedate: 2025-01-18
-->

**user authentication and Role-Based Access Control (RBAC)**. If you’re being honest, how much time have you wasted trying to configure users and roles in Kubernetes, only to realize that you got it completely wrong? Or worse, how often have you thought you got it right, only to open the door to security vulnerabilities or operational headaches down the line?

The truth is, Kubernetes’ RBAC model is notoriously misunderstood, and most teams are making it harder on themselves than it needs to be. User management in Kubernetes is complex, counterintuitive, and frankly, over-engineered for most real-world scenarios. But while others are busy drowning in YAML files and policies, Portainer offers a much simpler path to success.

#### Kubernetes RBAC: Why Is It So Hard?

Kubernetes was designed for flexibility and scale. That’s great—if you’re Google or Facebook. But for most businesses, that flexibility leads to complexity, and it all starts with RBAC.

Kubernetes RBAC is fundamentally built around four key resources: Roles, RoleBindings, ClusterRoles, and ClusterRoleBindings. These define who can do what, and where. On paper, it sounds simple enough: you define a role (what someone can do) and then assign it to a user (who can do it) via a binding. But the reality is far messier.

For starters, Kubernetes doesn’t have native support for user authentication. That’s right—you need external systems to even create user identities. Then you need to manually map those identities to appropriate roles using bindings. And here’s where most teams stumble: understanding the difference between `Roles`

(namespace-specific permissions) and `ClusterRoles`

(permissions that span the entire cluster) can become a confusing exercise in trial and error.

Add in the fact that every new project, microservice, or team requires a different configuration of roles and permissions, and suddenly you’re neck-deep in a forest of YAML files. Each new permission introduces the potential for misconfigurations, creating a fragile web of access controls that breaks if you pull the wrong thread.

#### The Common Missteps

Let’s look at some common mistakes that teams make when configuring Kubernetes user authentication and RBAC:

-
**Over-privileged users**: In an attempt to avoid the hassle of creating complex role bindings, many teams grant users far more permissions than they need. This is an open invitation for disaster, as a single mistake by an over-privileged user could take down an entire cluster. It also surprisingly common to see teams sharing the primary "cluster-admin" role, simply because its easier to get going. It doesn't take a rocket scientist to realize that's a terrible idea. -
**Role confusion**: Many teams don’t fully understand the difference between namespace-specific`Roles`

and cluster-wide`ClusterRoles`

, resulting in users having too much or too little access. Misconfigurations here can lead to security breaches or broken workflows. -
**Manual user management**: Without native user authentication in Kubernetes, teams rely on external tools or even manual processes to manage identities. This introduces inconsistencies and increases the risk of errors, especially as teams and clusters grow. -
**Policy sprawl**: Each project or microservice demands its own custom role definitions and bindings. Over time, this leads to policy sprawl, making it nearly impossible to keep track of who has access to what. And the more policies you have, the more likely you are to make a mistake.

#### Portainer’s Antidote: Five Simple Roles to Tame the Chaos

Enter Portainer. While Kubernetes’ native RBAC model might be endlessly flexible, it’s also endlessly complicated. Portainer takes a different approach: simplicity without sacrificing control. Instead of forcing you to manage dozens of bespoke roles, Portainer simplifies the process by providing five built-in roles that cover the vast majority of use cases. These predefined roles eliminate the guesswork and confusion, allowing you to secure your Kubernetes clusters with just a few clicks.

Here’s how the Portainer roles break down:

-
**Environment Admin**: The Admin role has full control over everything in the environment. This includes managing users, configuring settings, and deploying services. -
**Operator**: The Operator role gives users control over currently deployed resources, allowing them to triage, redeploy, and remediate as needed, but without granting them the ability to create new resources or delete what is running. -
**Helpdesk**: The Helpdesk role is a read-only role, designed for users who need to monitor or audit cluster resources but shouldn’t be making any changes. Perfect for support staff. -
**Standard User**: The Standard User role allows users to deploy, modify, and manage resources within their assigned namespaces. This ensures that users can focus on building and deploying applications without overstepping into administrative territory. -
**Read Only User**: The read only user role is the least privileged, designed for users who need to monitor a subset of an environment, constrained to visibility into only a select number of namespaces.

To see how Portainer's simplified RBAC can be utilized for your company, you can walk through a live example as part of the Portainer Academy's [Best Practice Install Guide](https://academy.portainer.io/install/#/lessons/FRBtcFGedd2Vby2ntSBpBinU6OB9Lfn6).

#### Why Portainer’s Approach Works

Portainer’s approach to RBAC works because it’s pragmatic. Most organizations don’t need dozens of custom roles with fine-grained permissions. They need a system that balances security and ease of use, without introducing unnecessary complexity.

Here’s why Portainer’s approach makes sense:

-
**Predefined roles, not policy sprawl**: By offering just five roles, Portainer keeps things simple. You don’t have to worry about role proliferation or policy sprawl. Each role is carefully designed to meet the needs of real-world teams. -
**Clear distinctions**: The roles in Portainer are clearly defined, with no ambiguity. Operators operate, Users deploy applications, and Helpdesk monitors. This prevents the role confusion that often plagues Kubernetes’ native RBAC model. -
**Less YAML, more productivity**: With Portainer, you don’t have to write YAML files to manage access control. It’s all built into the UI, allowing you to assign roles with just a few clicks. That means less time wrangling configurations and more time building applications.

#### Take Back Control with Portainer

Kubernetes user authentication and RBAC don’t have to be this hard. The complexity that most teams face is a result of misunderstanding the system and trying to manage access at a level of detail that’s unnecessary for most real-world use cases. Instead of drowning in YAML files, over-privileged users, and policy sprawl, it’s time to adopt a simpler, more effective approach.

Portainer’s five built-in roles cut through the complexity, offering a streamlined solution that balances security and simplicity. With Portainer, you can take back control of your Kubernetes clusters, ensure that the right people have the right access, and get back to focusing on what really matters: delivering value.

Stop struggling with Kubernetes RBAC. Portainer is the antidote to complexity—five roles, zero confusion.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/deploy-prometheus-monitoring-stack-with-portainer
title: Deploy Prometheus Monitoring Stack with Portainer
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/deploy-prometheus-monitoring-stack-with-portainer
hostname: portainer.io
description: Deploy Prometheus Monitoring Stack with Portainer, and use as a substitute for metric-server.
sitename: PORTAINER.IO
date: 2022-03-06
categories: []
tags: []
image: https://www.portainer.io/hubfs/Deploy%20Prometheus%20Monitoring%20Stack%20with%20Portainer.png
pagetype: article
filedate: 2025-01-18
-->

Out of the box, Portainer supports monitoring Kubernetes clusters via the metrics server/API, which gives you basic CPU and Memory stats for Pods and Nodes. But what if you want more bells and whistles?

Most people are familiar with Prometheus and Grafana, but how do you go about deploying them into Portainer managed Kubernetes Clusters? Let me show you.

First up, login to a Portainer instance that is managing one or more Kubernetes cluster.

Select the Cluster you wish to install Prometheus on,,then click on "Namespaces" and create a simple namespace.

Now click on 'HELM'.

in the "Additional Respostories" field, type in [https://prometheus-community.github.io/helm-charts, ](https://prometheus-community.github.io/helm-charts)then click "Add Repository"

Choose "Kube-Prometheus-stack".

*Note, for this to deploy, my nodes needed >4GB RAM, else OOM errors will be generated (the cluster was empty except this stack)*

Select the namespace, give the deployment a name, then click "Install".

Note that this "default" deployment does not persist the Prometheus data, so if you want to do that, you need to edit the custom values.

Alert Manager:

Grafana:

Prometheus:

Once the deployment has finished, navigate to "Applications" and check that all is good.

If your cluster does NOT have the metrics server installed ,and you would like to use Prometheus as your metrics server, go back into HELM, and deploy the chart "prometheus-adapter", which will configure Prometheus as a pseudo "metrics-server".

Edit the custom values,

1) In Line 31, Add the URL of the Prometheus instance deployed above.. in this case it is: http://prometheus-stack-kube-prom-prometheus.prometheus

2) Starting line 102 and going through to line 126, uncomment all of the "resources:" section (note, make sure to remove the {} brackets after resources:). Click "Install"

Once that is installed and running, go into "Cluster" and then "Setup" and enable features that use the metrics API. It should succeed if the HELM chart above deployed OK.

To check, click on "Cluster" and then view the stats for a node..

OK, so now Prometheus is installed, the adapter is installed to provide metrics services via the metrics API, but how do you actually access Grafana and Prometheus UI?

Go back to applications, expand the "prometheus-stack" and then click on "prometheus-stack-grafana"

Note it is only presenting itself inside the cluster, as a clusterIP

If you want to access it externally, you can just click "edit application" and add a service that suits your needs, in my case I have selected "LoadBalancer" and exposed Port 3000.

After updating the service presentation, you should now get the default admin password for Grafana. Scroll down to "config" and click on the config for admin-password

Here are the default credentials:

OK, so let's open Grafana.

And open a default dashboard, Node (Pods)

Success.

If you choose to expose the Prometheus UI, you'll not it has no authentication in front of it, so I would be hesitant mapping it to a load balancer.

So this is how you can deploy Prometheus and Grafana with Portainer, and use it as a substitute for metrics server.

For optional Part 2 of this blog, adding additional Prometheus instances to this Grafana deployment, click here ->. [https://www.portainer.io/blog/deploy-prometheus-monitoring-stack-with-portainer-part-2](https://www.portainer.io/blog/deploy-prometheus-monitoring-stack-with-portainer-part-2)

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/deploy-and-use-argocd-with-portainer
title: Deploy and use ArgoCD with Portainer (Part 1)
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/deploy-and-use-argocd-with-portainer
hostname: portainer.io
description: Portainer has an excellent continuous delivery (CD) engine built-in, but what if you want to use ArgoCD with Portainer? This 2 part blog shows you how.
sitename: PORTAINER.IO
date: 2022-02-10
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Feb-10-2022-05-57-34-11-PM.png
pagetype: article
filedate: 2025-01-18
-->

Portainer already has a good continuous delivery (CD) engine built in, one that ensures applications running in Portainer managed Kubernetes clusters are consistent with their mainifest definitions stored within a Git repo.

But, what if you want to use ArgoCD? Does that mean you can't use Portainer for your centralized Kubernetes management? The answer is 'no'. This two-part blog shows you how to set it up.

Part 1 is deploying an ArgoCD management instance on a Kubernetes cluster. [Part 2](/blog/deploy-and-use-argocd-with-portainer-part-2) is connecting that management instance to additional Kubernetes clusters. This blog focuses on Part 1, with Part 2 linked at the end.

The easiest way to get ArgoCD installed is to use the helm chart provided in Portainer, under our HELM page.

Jump Into Portainer and connect to the Kubernetes environment that you want to host the ArgoCD server. In my case, it's my laptop, but for an organization, this will likely be an instance in your data center.

Click on namespaces, and create a namespace called argocd (note it has to be called this to work, else you need to modify the argo manifests)

Now, click on "HELM", and then "Argo-CD"

Select the "argocd" namespace, and give the deployment a name, argocd, then click the "show custom values".

In the web editor, scroll to lines 1041 and change the service type to NodePort, then on lines 1046/1047 and replace the " " with two free nodeports in your system. I used 30080 and 30443 (dont forget to remove the speechmarks), then click "Install"

Switch to "Applications" view, and wait for all 5 components go green.

Click on the "argocd-argo-cd-server" component and see the 2x NodePorts you assigned.

Now let's open the ArgoCD UI. In my case, its https://localhost:30443

Ah, but what's the username and password? Well that was auto-generated by ArgoCD at install time, so let's retrieve it.

Go back to Portainer, and click on ConfigMaps&Secrets. Click on the secret called "argocd-secret". Look for "clearPassword". Copy the value, as that's the password for the "admin" user.

Now, login to ArgoCD UI as admin, with that password.

ArgoCD is now installed, and ready to be used. You can use this instance to deploy applications on this local cluster. Here's how:

Click on Settings and then Repositories.

Add credentials for your Git repo. In my case, I am connecting to a repo using https. Click "Connect"

Make sure your repo has connected successfully.

Now that's done, you can deploy your first gitops app. Click on Apps, then "Create Application" and fill in the details for your Git repo.

Give your app a name, select the default project (unless you are using custom projects). Select "prune resources" and "self heal" if you want Kubernetes to ALWAYS reflect the settings you have for your app in Git.

Now select the repository URL you defined previously, set the branch revision from git (in my case, its just HEAD), and set the path to the manifest files (in my case, demo).

Set your destination cluster (we only have the local one defined at the moment), then select the target namespace. Note the namespace needs to exist first, else Argo will fail.

In my case, I selected a namespace that doesn't exist, and this is what you see in Argo UI.

So let's go back into Portainer and create the namespace.

Click on "Namespaces", then click "Add namespace from form"

Name it demoapp (as used in your Argo deployment),disable resource assignment, and then click create.

Go back into Argo UI, click Applications, find your app, and click "Refresh"

See that it now switches to "Healthy" and "Synced"

Back in Portainer, click on Applications, and see the app is deployed and running.

Now, go into Git, edit your deployment file, and then wait for the change to propagate. In my case, I will increase replicas to 2.

in a few minutes, Portainer will reflect 2 replicas.

This is how you use Portainer and ArgoCD together. Easy.

[In PART 2 of the blog](/blog/deploy-and-use-argocd-with-portainer-part-2), I will show how to add Portainer Managed Kubernetes Clusters to this ArgoCD instance.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/author/neil-cresswell/page/3
title: Portainer News and Blog | Neil Cresswell, CEO (3)
author: Neil Cresswell; CEO August 1
url: https://www.portainer.io/blog/author/neil-cresswell
hostname: portainer.io
description: Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization. (3)
sitename: Portainer.io
date: 2024-08-01
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

### Blog Post by Neil Cresswell, CEO

[
](https://www.portainer.io/blog/which-kubernetes-distros-does-portainer-work-with)

Neil Cresswell, CEOAugust 1, 20242 min read

### Which Kubernetes distros does Portainer work with?

Discover how Portainer seamlessly integrates with various Kubernetes distributions, ...

Start Reading
[
](https://www.portainer.io/blog/as-a-ceo-why-do-i-still-run-a-homelab)

Neil Cresswell, CEOJuly 29, 20244 min read

### As a CEO, why do I still run a homelab?

Learn why the CEO of Portainer runs a homelab, exploring various container runtimes and ...

Start Reading
[
](https://www.portainer.io/blog/secure-your-kubernetes-deployment-the-portainer-way)

Neil Cresswell, CEOJuly 29, 20243 min read

### Secure your Kubernetes deployment, the Portainer way

Our CEO Neil expands on a recent LinkedIn post on the complexities of securing a ...

Start Reading
[
](https://www.portainer.io/blog/help-me-pitch-portainer-to-my-business)

Neil Cresswell, CEOJune 9, 20242 min read

### Help me pitch Portainer to my business (email template)

Learn how to pitch Portainer to your business with this email template. Discover the ...

Start Reading
[
](https://www.portainer.io/blog/portainer-community-edition-ce-vs-portainer-business-edition-be-whats-the-difference)

Neil Cresswell, CEOMay 16, 20245 min read

### Portainer CE vs Portainer BE – What’s the Difference?

Portainer exists in both Community and Business Editions. In this article we'll cover ...

Start Reading
[
](https://www.portainer.io/blog/operational-maturity-framework)

Neil Cresswell, CEOApril 26, 20242 min read

### Introducing the Containerization Operational Maturity Self-Assessment

Operational maturity in containerization is a multi-faceted concept, encompassing ...

Start Reading
[
](https://www.portainer.io/blog/operational-maturity-with-containers)

Neil Cresswell, CEOApril 4, 20242 min read

### Operational Maturity with Containers

Before you go "full steam" with containers, first ensure you know the operational impacts

Start Reading
[
](https://www.portainer.io/blog/the-great-vmware-exodus)

Neil Cresswell, CEOMarch 24, 20244 min read

### The Great VMware Exodus

Learn about the challenges of migrating from VMware to another hypervisor and explore an ...

Start Reading
[
](https://www.portainer.io/blog/cncf-project-independence)

Neil Cresswell, CEOFebruary 29, 20243 min read

### CNCF Project Independence

Portainer wants to share their perspective on the current situation with a CNCF graduate ...

Start Reading
[
](https://www.portainer.io/blog/how-to-use-the-digitalocean-container-registry-within-portainer)

Neil Cresswell, CEOFebruary 11, 20241 min read

### How to: Use the DigitalOcean Container Registry within Portainer

How To: Use The DigitialOcean Container Registry with Portainer

Start Reading
[
](https://www.portainer.io/blog/2024-release-principle)

Neil Cresswell, CEOJanuary 24, 20243 min read

### Our release principle is changing in 2024, what will this mean for you?

Need to know which version of Portainer to use for greatest stability, read on..

Start Reading
[
](https://www.portainer.io/blog/announcing-k2d.io)

Neil Cresswell, CEOJuly 4, 20234 min read

### Announcing k2d.io

Want Kubernetes on your edge devices, but not enough resources to run it and your apps? ...

Start Reading

---
<!--
URL: https://www.portainer.io/blog/how-portainer-supercharges-your-internal-developer-platform-idp
title: How Portainer Supercharges Your Internal Developer Platform (IDP)
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/how-portainer-supercharges-your-internal-developer-platform-idp
hostname: portainer.io
description: Explore how Portainer’s features can be leveraged within an IDP to enhance your organization's development lifecycle.
sitename: PORTAINER.IO
date: 2024-08-22
categories: []
tags: []
image: https://www.portainer.io/hubfs/Stock%20images/home.jpg
pagetype: article
filedate: 2025-01-18
-->

In today's fast-paced software development environment, organizations are increasingly adopting Internal Developer Platforms (IDPs) to streamline and optimize the developer experience. In this blog post, we'll explore how Portainer’s features can be leveraged within an IDP to enhance your organization's development lifecycle.

#### What is an Internal Developer Platform (IDP)?

An IDP is more than just a collection of tools; it's a platform that centralizes and simplifies access to everything developers need to build, test, and deploy software. The core components of an IDP typically include:

**Service Catalog:**A searchable, browsable list of internal services, APIs, and integrations that developers can easily discover and use.**Self-Service Infrastructure:**Tools that allow developers to provision and manage infrastructure on demand, automating repetitive tasks and reducing dependencies on IT teams.**Integrated CI/CD Pipelines:**Built-in continuous integration and delivery pipelines that streamline the path from code to production, ensuring consistency and reducing manual errors.**Developer Portal:**The interface that provides developers with easy access to the tools, services, and documentation they need, enhancing usability and reducing complexity.

These components work together to create a seamless and efficient development environment. However, the effectiveness of an IDP hinges on its ability to meet the needs of its users without becoming overly complex.

If an IDP is too difficult to navigate or use, it can become a bottleneck rather than a productivity booster.

#### How can Portainer supercharge my Internal Developer Platform?

-
**Centralized Container Management**

Containerization is the backbone of modern software architecture. At the core of Portainer is its ability to manage Docker containers and Kubernetes clusters with ease by providing a user-friendly interface that integrates seamlessly with your existing development workflows. Within an IDP, Portainer can serve as the hub for all container-related activities. Developers can deploy, monitor, and manage containers from a single interface, making it easier to build, ship, and run applications consistently across environments.

**Why it matters:** Portainer's intuitive container management platform reduces the learning curve for developers and helps them focus on writing code rather than managing infrastructure, which is crucial for maintaining an IDP that is effective yet simple to use.

-
**Enhanced Security and Governance**

Security is paramount in any development environment. Portainer offers robust security features, including role-based access control (RBAC) and detailed auditing logs. These features are critical when integrating Portainer into an IDP, as they ensure that only authorized personnel have access to specific resources and that all actions are traceable.

**Why it matters:** With Portainer integrated into your IDP, you can enforce security policies consistently across all development teams. This not only helps in maintaining compliance but also in identifying and addressing potential security issues early in the development process. Moreover, the simplicity of Portainer’s security features ensures that the IDP remains user-friendly, avoiding the pitfalls of overcomplicating security management.

-
**Streamlined DevOps Workflows**

Portainer is designed to integrate smoothly with CI/CD pipelines and other DevOps tools. By incorporating Portainer into your IDP, you can automate the deployment and management of applications, reducing the time it takes to move from code to production.

**Why it matters:** Streamlining DevOps workflows with Portainer within an IDP allows your teams to ship features faster and more reliably. The automation capabilities also reduce the likelihood of human error, making your deployments more consistent and predictable. This aligns perfectly with the goal of an IDP to simplify processes while maintaining efficiency.

-
**Simplified Onboarding**

Onboarding new developers can be a time-consuming process, especially in complex environments with multiple tools and platforms. Portainer’s intuitive interface and comprehensive documentation make it easier for new team members to get up to speed quickly. Within an IDP, Portainer can serve as a learning tool, guiding developers through container management and best practices.

**Why it matters:** Reducing the onboarding time for new developers means they can start contributing to projects sooner. This is particularly valuable in fast-moving industries where time-to-market is a critical success factor. Portainer’s simplicity ensures that your IDP does not become a barrier to entry but rather a facilitator of quick and effective onboarding.

-
**Scalability and Flexibility**

Portainer supports both Docker and Kubernetes, making it a versatile tool for managing different types of containerized workloads. Whether your organization is running a few containers or managing a complex microservices architecture, Portainer scales to meet your needs. Within an IDP, this flexibility ensures that your platform can grow alongside your business requirements.

**Why it matters:** As your organization grows, so does the complexity of your infrastructure. Portainer’s scalability within an IDP ensures that your developers have the tools they need to manage this complexity without being overwhelmed. The platform’s ability to scale without adding unnecessary complexity is key to maintaining a user-friendly IDP.

-
**User-Friendly Interface**

One of Portainer’s standout features is its clean, user-friendly interface. This is especially important within an IDP, where developers of varying skill levels will interact with the platform. The intuitive design of Portainer minimizes the learning curve and enhances productivity by making it easy to navigate and use the platform.

**Why it matters:** A user-friendly interface reduces frustration and boosts efficiency. Developers can quickly find and use the tools they need without getting bogged down by a steep learning curve or confusing interfaces. This simplicity is essential for an IDP to be effective and widely adopted within the organization.

#### Maximize your IDP's potential with Portainer

Integrating Portainer into your Internal Developer Platform is a strategic move that can significantly enhance your organization's development processes. From simplifying container management to streamlining DevOps workflows and enhancing security, Portainer provides a suite of features that can elevate your IDP to the next level. By centralizing these capabilities within an IDP, you empower your developers to focus on what they do best: building great software.

Crucially, Portainer aligns with the key principles of an effective IDP—offering powerful functionality while maintaining simplicity and ease of use. Whether you're a small team just starting with containerization or a large enterprise managing complex microservices, Portainer can scale to meet your needs and help your developers work more efficiently and effectively without introducing unnecessary complexity.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-then-vs.-now-the-evolution-of-a-container-management-powerhouse
title: Portainer Then vs. Now: The Evolution of Container Management
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-then-vs.-now-the-evolution-of-a-container-management-powerhouse
hostname: portainer.io
description: Neil explores how Portainer has transformed from its origins and initial goals into what Portainer now offers today.
sitename: PORTAINER.IO
date: 2024-09-16
categories: []
tags: []
image: https://www.portainer.io/hubfs/portainer-blog-header-1180x590.jpg
pagetype: article
filedate: 2025-01-18
-->

Software technology never stands still, and neither does Portainer. For many of you who have been with us since the beginning, Portainer started as a simple yet powerful tool, perfect for managing Docker containers. It was built with simplicity in mind, making container management easy for teams of all sizes. But over time, as the industry shifted and user needs grew more complex, so did Portainer.

Let’s explore how Portainer has transformed - from its origins to what it offers today - so you can fully appreciate the platform’s new capabilities.

#### Portainer Then: Simplifying Docker for Everyone

When Portainer first hit the scene, way back in 2016, the container world was dominated by Docker. Managing containers often meant diving into the command line which wasn’t always the most intuitive experience. Portainer made container management accessible to everyone, whether you were a developer working solo or part of a larger team.

**The Original Mission**

Portainer’s primary goal was clear: simplify Docker management with a sleek, easy-to-navigate interface. Its lightweight design offered users an at-a-glance view of their containers, volumes, networks, and images, making container orchestration much less daunting.

**Key Features of Portainer “Then”**

**Docker Focused:**At its core, Portainer was built for Docker. It provided an intuitive GUI that removed the need for constant command-line interaction, making container management easy and accessible.**Simplicity Above All:**You didn’t need to be a Docker expert to get the most out of Portainer. It streamlined common tasks like deploying new containers, managing resources, and monitoring performance.**Single-Node Environments:**Portainer excelled in managing single-node Docker environments, making it a perfect fit for developers who needed to quickly spin up and manage their containers without worrying about orchestration complexity.**UI-Centric:**Portainer was built with the UI, and "Click-Ops" as the primary mechanism to deploy, manage, and operate the container environment.

In short, Portainer was all about taking the power of Docker and putting it in the hands of the everyday user with minimal friction.

#### Portainer Now: A Complete Platform for Kubernetes and Beyond

Fast forward to today, and the container landscape looks very different. Kubernetes is the go-to solution for orchestrating containers across large-scale environments. As the industry has shifted, so too has Portainer. What began as a tool designed solely for Docker has grown into a comprehensive platform that simplifies container management across multiple technologies, including Kubernetes.

**The New Mission**

While Portainer still maintains its commitment to simplicity, it now tackles far more complex challenges. The focus is no longer just on Docker; it’s about managing the entire lifecycle of containers in hybrid, multi-node environments, with Kubernetes and GitOps at the forefront.

**Key Features of Portainer “Now”**

**Kubernetes Support:**One of the most significant evolutions is the full integration of Kubernetes management. Whether you’re managing a small dev cluster or a large-scale production environment, Portainer now offers the same ease of use that originally made it popular, but for Kubernetes.**Multi-Cluster Management:**Portainer isn’t limited to single-node environments anymore. You can manage multiple Kubernetes clusters or Docker Swarm environments, all from a single interface, no matter where they are deployed - on-premises, in the cloud, or at the edge.**Expanded Security and Access Control:**As enterprise needs have grown, so has Portainer’s security model. Role-based access control (RBAC), team management, and advanced authentication options ensure that only the right users have access to sensitive systems.**GitOps Support:**As the adoption of Kubernetes accelerated, so too did the operational concept known as GitOps. Portainer embedded a native GitOps engine, bringing the power of GitOps to Docker and Kubernetes, without the need for external tooling. If you elect to employ GitOps paradigms solely, you can disable the Portainer UI deployment assistance.**Comprehensive Tooling:**Portainer now integrates more deeply with other tools and services that your teams are using, offering expanded support for things like Helm charts, persistent storage, and advanced networking setups.**Edge Compute:**Portainer is now equipped with capabilities to manage fleets of environments (Docker or Kubernetes) at the network's edge. This is most commonly seen in IOT, and Industrial IOT deployments, but regardless, if you have hundreds, or even thousands of devices to manage, Portainer is your partner.

#### Why This Evolution Matters

For long-time users it might be easy to continue thinking of Portainer as "the Docker GUI." But Portainer has grown into a much more sophisticated solution. It’s no longer just a helper tool; it’s a critical part of managing modern containerized environments.

Portainer is now built for teams at scale, for hybrid deployments, and for organizations that need to manage both Docker and Kubernetes without the overhead of switching between tools or dealing with complex command-line interfaces.

#### Re-Introducing Portainer to You

If you’ve been with Portainer since the early days, now is the perfect time to explore how much more the platform can do. We’ve designed Portainer’s new features with scalability, security, and multi-cluster management in mind, making it the go-to solution for anyone managing containers in today’s world - whether you’re dealing with Docker, Kubernetes, or both.

It’s time to embrace what Portainer has become: a complete, unified platform for container management across Docker and Kubernetes.

#### What’s Next?

We’re not stopping here. As containers continue to evolve, so will Portainer. Whether you’re just managing your first container or overseeing a sprawling Kubernetes infrastructure, our goal remains the same: make container management simple, powerful, and accessible to everyone.

Are you ready to unlock the full potential of Portainer? Dive into our latest features, and see how much more you can achieve.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/maximize-your-openshift-investment-with-portainer-multi-cluster-management-without-the-premium-price-tag
title: Maximize Your OpenShift Investment with Portainer: Multi-Cluster Management Without the Premium Price Tag
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/maximize-your-openshift-investment-with-portainer-multi-cluster-management-without-the-premium-price-tag
hostname: portainer.io
description: Learn how Portainer can work with your OpenShift environments to provide powerful multi-cluster management at a lower cost.
sitename: PORTAINER.IO
date: 2024-09-02
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/multiple%20clusters%20of%20servers%20managed%20by%20a%20centralized%20system.jpeg
pagetype: article
filedate: 2025-01-18
-->

In the evolving landscape of enterprise IT, Kubernetes has emerged as the cornerstone of modern application deployment strategies. Red Hat® OpenShift® has quickly become a preferred Kubernetes distribution for enterprises, largely due to its extensive support from Independent Software Vendors (ISVs).

Many organizations choose OpenShift because their critical business applications are certified to run on this platform, ensuring reliability and support. However, as organizations scale, the complexity of managing multiple Kubernetes clusters can become a significant challenge.

This is where Portainer, a powerful multi-cluster management tool, comes into play. By integrating Portainer with OpenShift Kubernetes Engine, enterprises can manage their Kubernetes environments more efficiently and cost-effectively, without the need for the more expensive OpenShift Container Platform or Platform Plus licenses.

#### The Value of ISV Support with OpenShift

One of the primary reasons organizations adopt OpenShift Kubernetes is the broad ISV support it offers. Many leading software vendors certify their applications to run on OpenShift, making it a trusted choice for enterprises that rely on these critical applications. This certification provides assurance that the applications will perform optimally on OpenShift, with the added benefit of vendor support.

However, while OpenShift offers a solid Kubernetes foundation and ISV-backed reliability, managing multiple clusters still poses challenges. Organizations that run multiple clusters for reasons such as disaster recovery, compliance, or regional availability need robust multi-cluster management capabilities. With OpenShift, the only way to achieve this multi-cluster manager is with the premium license, Platform Plus. This is not only expensive but also relies on a cloud service, which means connecting your critical business systems to the internet for remote management.

This is where Portainer steps in as a valuable alternative.

#### Portainer: The Ideal Multi-Cluster Manager for OpenShift

Portainer is designed to simplify the management of Kubernetes environments, especially in multi-cluster scenarios. By using Portainer alongside OpenShift, enterprises can achieve a level of centralized control and simplicity that OpenShift’s basic offerings may not provide on their own. Here’s how Portainer enhances the OpenShift experience:

-
**Unified Multi-Cluster Management**: Portainer enables centralized management of multiple Kubernetes clusters from a single interface. This is particularly beneficial for organizations using OpenShift across different environments or geographic locations, providing consistency and simplifying operations. -
**Simplified Operations**: Portainer’s user-friendly interface abstracts much of the complexity involved in Kubernetes management. This means that DevOps teams can manage OpenShift clusters without needing deep Kubernetes expertise, reducing the learning curve and operational overhead. -
**Enhanced Security and Access Control**: With built-in Role-Based Access Control (RBAC), Portainer ensures that only authorized personnel can access specific clusters or resources. This is crucial for maintaining security and compliance, especially when managing clusters across different teams or departments. -
**Scalability Without the Premium Cost**: Organizations can scale their Kubernetes infrastructure using Portainer without needing to upgrade to OpenShift Platform Plus. Portainer offers essential multi-cluster management capabilities, making it a cost-effective solution that still leverages the robust OpenShift ecosystem.

#### Leveraging Portainer with OpenShift: A Strategic Advantage

By integrating Portainer with OpenShift Kubernetes Engine or OpenShift Platform Edition, enterprises can maximize their investment in OpenShift. They can benefit from the wide ISV support that OpenShift offers while also enjoying the streamlined, centralized management that Portainer provides. This combination allows organizations to:

-
**Optimize Resource Utilization**: With Portainer, enterprises can monitor resource usage across multiple clusters, identify inefficiencies, and optimize their Kubernetes deployments. -
**Maintain ISV Compliance**: Portainer’s multi-cluster management capabilities ensure that organizations can maintain compliance with ISV certifications, as applications can be managed consistently across all clusters. -
**Achieve Operational Efficiency**: By reducing the complexity of Kubernetes management, Portainer enables DevOps teams to focus on delivering value rather than managing infrastructure.

#### Achieving More with Portainer and OpenShift

Portainer provides a powerful solution for enterprises looking to enhance their OpenShift deployments. By offering comprehensive multi-cluster management without the need for a premium OpenShift license, Portainer allows organizations to scale effectively, maintain ISV compliance, and streamline operations. For enterprises invested in the OpenShift ecosystem, Portainer is the ideal companion to maximize their Kubernetes capabilities while keeping costs under control.

Below we've compared annual pricing* (in USD) for OpenShift Kubernetes Engine with Portainer, OpenShift Container Platform with Portainer, and the premium OpenShift Platform Plus products, for an example 3 cluster deployment where each cluster has 12 nodes, each with 8 vCPUs.

OpenShift Kubernetes Engine with Portainer |
OpenShift Container Platform with Portainer |
OpenShift Platform Plus |
$32,899 |
$46,435 |
$269,640 |

The price difference is immediately obvious. And remember, you only need the base OpenShift Kubernetes Engine license alongside Portainer to achieve full multi-cluster management in your organization, at one eighth the price of OpenShift Platform Plus.

Ready to enhance your OpenShift management with Portainer? [Try Portainer today](/get-started) and see how easy multi-cluster management can be. [Visit our website](https://portainer.io) to learn more or [reach out for a demo](/get-demo) to experience Portainer’s capabilities firsthand.

* Based on list pricing available from Insight.com, current as of September 2024.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/is-docker-ce-ready-for-production-how-portainer-bridges-the-gaps
title: Is Docker-CE Ready for Production? How Portainer Bridges the Gaps
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/is-docker-ce-ready-for-production-how-portainer-bridges-the-gaps
hostname: portainer.io
description: Our CEO Neil talks about the current state of Docker-CE, its issues with security, and how Portainer can help to improve and secure it for production.
sitename: PORTAINER.IO
date: 2024-09-05
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/A%20jigsaw%20puzzle%20with%20missing%20pieces%20as%20a%20metaphor%20for%20an%20IT%20security%20project%20that%20is%20missing%20critical%20security%20features.jpeg
pagetype: article
filedate: 2025-01-18
-->

In the early days of containerization, Docker was a revolutionary force, offering a simple yet powerful way to package, distribute, and run applications. Docker-CE (Community Edition) was the go-to choice, providing a free, open-source version of the Docker container engine. However, as time has passed and Docker Inc. has shifted its focus, Docker-CE has been left in a state that many would now describe as "unfinished"—especially in the context of enterprise production environments.

#### The Impact of Docker Inc.'s Strategic Shifts

Docker Inc. made headlines when it decided to divest its enterprise business, Docker Enterprise, to Mirantis. This decision marked a significant turning point in the trajectory of Docker-CE. Previously, the enterprise and community editions of Docker shared a close relationship, with innovations often trickling down to the community edition. Now with Docker Enterprise under the control of Mirantis, a significant gap has emerged between the capabilities of Docker-CE and its enterprise counterpart.

One of the most critical areas affected by this strategic shift is security. Docker Enterprise was known for its robust security features, including user authentication, role-based access control (RBAC), advanced policy management, and content-trust. These capabilities are crucial for any organization running containers in production, as they provide the necessary tools to enforce security policies, control access, and prevent unauthorized actions.

With Mirantis now bundling these security features within its much more substantial product offerings, Docker-CE users are left without native access to these critical capabilities. As a result, Docker-CE in its current state is arguably not fit for use in production environments—especially when security is a priority.

Whilst many organizations have already begun the migration from Docker to Kubernetes, there remains a strong demand for Docker-CE due to its simplicity of use and low resource footprint. For those organizations, they need ways to "fill the gaps" that exist with Docker-CE.

#### The Security Shortcomings of Docker-CE

Without the security features provided in Docker Enterprise, Docker-CE lacks several essential capabilities:

**Lack of User Authentication:**Docker-CE has no notion of "users", and so therefore has no built-in user authentication. Anyone with root-level access to the Docker host has full control over all containers, leading to potential security risks.**Absence of Role-Based Access Control (RBAC):**With Docker-CE having no notion of users, there is also no notion of access control, let alone role-based access control. Access Control and RBAC is critical for maintaining security in any production environment.**Inability to Enforce Security Policies:**Docker-CE does not natively support the creation or enforcement of security policies that can restrict what types of containers can run or more importantly which images can be used. This is particularly concerning given the sheer number of "hostile" images that exist on Docker Hub, with frequently used public images (eg nginx, mysql) being repurposed by hackers using common misspellings. Without controls a developer could accidentally run a compromised container in production.

#### How Portainer Fills the Gap

Given these limitations, organizations using Docker-CE in production are often left searching for a solution to enhance security and manageability. This is where Portainer comes into play.

Portainer is a management platform that provides a simplified and secure way to centrally manage Docker environments. By integrating with Docker-CE, Portainer brings much-needed security features to the table:

**User Authentication and RBAC:**Portainer adds the missing capability of user authentication and role-based access control, allowing administrators to create and manage users, assign roles, and define what actions each role can perform. This enables organizations to implement access controls that align with their security policies.**Policy Enforcement:**Portainer allows administrators to enforce security policies across their Docker environment. This includes restricting the types of containers that can be deployed, setting resource limits, and monitoring container activity. These capabilities are essential for maintaining a secure and compliant production environment.**Ease of Use and Accessibility:**One of Portainer's key strengths is its user-friendly interface, which makes it accessible to teams of all sizes and skill levels. By providing a centralized management console, Portainer simplifies the complexities of managing Docker-CE environments, reducing the potential for misconfigurations that could lead to security vulnerabilities.

#### Docker + Portainer is a Production-Ready solution.

In the ever-evolving landscape of container technology, one thing is clear: the days of relying solely on Docker-CE for production are behind us. Organizations must look to supplementary solutions like Portainer to ensure their containerized applications are secure, compliant, and well-managed. It's only with add-on tools like Portainer that Docker-CE can realistically be considered to run any production application services.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/does-talos-kubernetes-and-omni-live-up-to-the-hype
title: Does Talos Kubernetes and Omni live up to the hype?
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/does-talos-kubernetes-and-omni-live-up-to-the-hype
hostname: portainer.io
description: Using Sidero Omni to provision a Talos Kubernetes Cluster, which is then managed with Portainer.
sitename: PORTAINER.IO
date: 2024-08-05
categories: []
tags: []
image: https://www.portainer.io/hubfs/5e8ce847-4197-40e1-a5d8-95b2fb7e560e.png
pagetype: article
filedate: 2025-01-18
-->

As part of the process of validating Portainer functionality across a range of Kubernetes distributions, we have the opportunity to experiment with the vendor installation /configuration tools that they make available. This week it's Talos Kubernetes, and Sidero Omni. Talos has been getting a lot of love in the community, and I wanted to see if it is as good as everyone says it is.. spoiler alert.. it is!

I wanted to use Omni to manage the creation of a Talos Kubernetes cluster, without needing to SSH into my VMs, or do anything on the VMs other than boot them.

So, I started.

The first thing I needed to do was to set up an [Omni Account](https://signup.siderolabs.io/) on their SaaS Service. For my testing, I used: [https://portainer.omni.siderolabs.io/omni/](https://portainer.omni.siderolabs.io/omni/)

I then went through the validation process, and set my password. Once I had that I was able to login to that account.

You can see I have no machines, no clusters, nothing...

To get started, you need to download your ISO (or VM) customized image. This is an image that has the “call-home” pre-configured to ping back to your specific Omni account (and note, you can self-host Omni and in that case, it uses your self-hosted instance).

I then downloaded the ISO, spun up two VMs, and configured them to boot off the ISO… Powered them on, and did nothing more on them.

Switching back to Omni, I now see two entries in the “machines” view. Interestingly, its a UUID, and not immediately clear how to determine which is for each VM.

To understand which VM is which, I opened the console to one of the VMs. Here I can now see the UUID.

I also see its getting its IP from DHCP, which we will need to change.

*Note that if you don't use DHCP on your network, you can configure a fixed IP directly via the console of the server.*

So, let's setup a cluster. Go back into the Omni Web Page, click on Clusters, and then ‘create cluster’

Give the cluster a name, and set the nodes and their roles.. remember the UUIDs you collated before.

Now, before we continue, we will set the IP and Hostames of the machines to suit our needs.

Expand out the details for each node, and note down the network interface name for each (along with knowing which UUID corresponds to your VM). Also, whilst there, select the Kubernetes role you wish to assign each node (controlplane / worker).

Click on the “gear” icon next to each of the nodes

Set your hostname and network details FOR EACH MACHINE as appropriate, then click save.

Once that is done, click “create cluster”, and wait 10 minutes.

You can see the progress of the cluster creation.

Wait for the nodes to change name, and be running, then you are good to go.

You can also see in the console of the nodes that the IP has changed.

So, now that the cluster is up, you can download the kubeconfig file, and then add the Portainer agent.

Note that once you download the config file, this is to access the cluster INDIRECTLY, which means, via Omni.

And on a standard machine, which just has kubectl binary installed, you cannot immediately use this file... you must first install the [oidc extension](https://github.com/int128/kubelogin) to kubectl.

with kubelogin installed, you can now authenticate.

And you can see the nodes in the cluster.

Now we can add this cluster to an existing Portainer instance (or you can deploy a new Portainer instance if this is your first cluster).

Note you will get an error, due to Talos' explicit security policies, but we can amend this for the Portainer namespace

`kubectl label `

`namespace`

` portainer `

`pod-security.kubernetes.io/enforce=privileged`

Then in your Portainer instance, add the Talos Cluster.

You can now perform all application deployment activities, and configure some base cluster settings (user auth, RBAC, security, quotas etc) all from Portainer.

I also wanted to see how easy it is to scale a cluster, so I decided to add another worker node..

I booted another VM from the pre-configured ISO, went back into Omni, into the cluster, and clicked "Cluster Scaling"

I was presented my cluster config, and shown a list of machines not yet assigned to a cluster (just 1 in my case).

I repeated the same process, selecting it as a worker, and changing the network config using the machine config.

And done... I now have an additional node in my cluster, and I can see that node in Portainer too.

Final test, see how easy it is to update a cluster.

As you can see in the prior screenshots, I am running Kubernetes 1.30.1, and yet the latest version is 1.30.3. Lets upgrade.

You browse to your cluster, and in the right hand side, you can see your running version, and the icon indicator showing there is a newer version. Click it.

Select the version you want to upgrade to.. and click "upgrade"

You can see the cluster version status change... now you need to wait.

After a few minutes, you can see the cluster is now at 1.30.3... wow that was easy!

Some observations...

-
It would be awesome to be able to auto-deploy a Kube manifest (ala Portainer agent) post-deployment (like how they assign/apply a machine/cluster config…

-
Setting static IPs on the machines could have been more intuitive, actually set them at the machine level, vs only when creating the cluster.

All in all, the experience of using Omni and creating a Talos cluster was a breeze. Talos and Omni are significantly easier than any other distro I have used. I particularly liked the hands-off management, meaning I didn't need to touch the VMs themselves. Really impressive product and offering.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/ensuring-consistent-and-simplified-operations-in-the-era-of-iiot
title: Ensuring Consistent and Simplified Operations in the Era of IIoT
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/ensuring-consistent-and-simplified-operations-in-the-era-of-iiot
hostname: portainer.io
description: Find out how Portainer can reduce the complexity and enhance the reliability of your IIoT operations.
sitename: PORTAINER.IO
date: 2024-09-04
categories: []
tags: []
image: https://www.portainer.io/hubfs/Engineer%20Welding%20Robotics.jpg
pagetype: article
filedate: 2025-01-18
-->

The Industrial Internet of Things (IIoT) isn’t just another industry trend; it's changing how businesses operate by bridging the gap between physical machinery and digital systems. This connectivity allows for real-time data insights, smarter automation, and more proactive decision-making. But the path to these benefits can be complicated. As IIoT projects grow, companies often face a tangled web of diverse devices, different software environments, and complex network setups. That's where Portainer comes in. By managing Docker and Kubernetes-equipped gateways and PLCs, Portainer helps keep things consistent and operations running smoothly.

**Navigating the Challenges of IIoT**

Implementing an IIoT solution isn’t just about plugging things in and walking away. Here are some common challenges that organizations face and how Portainer can help:

**Managing a Variety of Devices**

IIoT environments usually involve a wide range of devices, each with its own set of specifications and requirements. These devices are often connected through Docker or Kubernetes-equipped gateways and PLCs, which need to be managed effectively to ensure the entire system functions correctly.

**Example: Handling Different Gateway and PLC Configurations**

Imagine a manufacturing plant using multiple Docker-equipped gateways to collect data from sensors monitoring temperature, humidity, and machine health. These gateways interact with PLCs that control the machinery. Keeping each gateway and PLC configured correctly is crucial but can be time-consuming and error-prone.

With Portainer, the plant’s operations team can manage all these gateways and PLCs from a single dashboard. This central management allows them to deploy standardized configurations and monitor all systems effectively, ensuring that data flows smoothly and machinery runs optimally.

**Scaling Up Operations**

One of the great things about IIoT is its scalability. You can start small and expand as needed. However, scaling up can quickly lead to headaches if you don’t have a plan for maintaining consistent configurations and updates across all gateways and PLCs.

**Example: Scaling Gateway Management Across Remote Locations**

Consider a utility company that monitors environmental data across a wide area using Kubernetes-enabled gateways. As they add more monitoring sites, the number of gateways grows. Keeping software up-to-date and configurations consistent across all these gateways can become a daunting task.

Portainer makes scaling manageable. By using Portainer, the utility company can automate the deployment of updates and maintain consistent configurations across all their gateways from a single platform. This capability allows them to expand their monitoring efforts without being overwhelmed by operational complexity.

**Enhancing Security**

Every gateway and PLC connected to an IIoT network adds a new point of vulnerability. It’s crucial to ensure that these devices are secure, with up-to-date patches and consistent security configurations.

**Example: Securing Gateways in Critical Infrastructure**

Think about a critical infrastructure provider using Docker-equipped gateways to manage a network of sensors across a city. Each gateway could potentially be a target for cyber threats, making security a top priority.

Portainer helps by allowing centralized security management. The provider can enforce security policies across all gateways, ensure regular updates, and monitor activity to detect and respond to potential threats quickly. This centralized control reduces the risk of breaches and helps maintain the integrity of the entire network.

**Reducing Operational Complexity**

Managing software deployments and configurations across a network of gateways and PLCs can be complex and time-consuming. Without the right tools, even routine tasks can lead to operational bottlenecks and errors.

**Example: Streamlining Gateway Management in Global Operations**

Imagine a logistics company that uses Kubernetes-enabled gateways to collect data from sensors on shipping containers. These gateways need to be managed remotely to ensure they’re always operational and that data flows correctly.

With Portainer, the logistics company can manage all their gateways and the software running on them from one location. This capability means they can deploy updates, monitor performance, and troubleshoot issues without needing to manually access each gateway. It streamlines operations, reduces errors, and keeps everything running smoothly.

**Bringing It All Together**

Managing an IIoT environment doesn’t have to be overwhelming. By using Portainer to handle Docker and Kubernetes-equipped gateways and PLCs, organizations can ensure consistent deployments, enhance security, and scale their operations without added complexity. This approach helps companies focus on what really matters: leveraging the power of IIoT to drive innovation, efficiency, and growth.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/streamline-iot-deployments-at-scale-why-portainer-is-the-smart-choice-for-managing-thousands-of-remote-containerized-environments
title: Streamline IoT Deployments at Scale: Why Portainer is the Smart Choice for Managing Thousands of Remote Containerized Environments
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/streamline-iot-deployments-at-scale-why-portainer-is-the-smart-choice-for-managing-thousands-of-remote-containerized-environments
hostname: portainer.io
description: Simplify IoT deployments at scale with Portainer, the ideal tool for managing containerized applications across thousands of Docker or Kubernetes-enabled devices effortlessly.
sitename: PORTAINER.IO
date: 2024-09-26
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/Large%20scale%20IoT%20deployments-1.jpeg
pagetype: article
filedate: 2025-01-18
-->

The Internet of Things (IoT) brings exciting possibilities—distributed intelligence, real-time insights, and automation across industries. But when it comes to deploying and managing software on thousands of remote devices, it’s easy to feel overwhelmed. The truth is, many organizations are struggling because they’re using solutions that weren’t designed to handle the complexities of container-based software deployments across a distributed IoT fleet.

Here’s the key distinction: when we talk about IoT, we’re not talking about managing physical devices like sensors or hardware infrastructure. **We’re talking about deploying and managing containerized applications on Docker- or Kubernetes-enabled devices in the field**. Whether it’s gateways, PLCs, or edge devices, these environments are powerful enough to run containers, but deploying software to them at scale requires the right toolset.

This is where Portainer comes in. **Portainer is not a physical device management platform—it’s a container management and deployment solution.** We help you deploy and manage containerized applications to your Docker or Kubernetes-enabled IoT fleet, ensuring that your apps are rolled out efficiently and reliably, no matter how many devices you’re working with.

If you’ve been struggling with the complexity of deploying containerized software across thousands of devices, it’s time to rethink your approach. Portainer is built for the real-world challenges of IoT software deployment at scale—simple, efficient, and designed to handle the unique needs of container-based environments.

#### The Real Challenges of Containerized IoT Deployments

Managing containerized applications in IoT environments is a whole different ball game compared to cloud or data center deployments. When you’re dealing with hundreds or thousands of devices in remote locations—each running Docker or Kubernetes—the complexity can quickly spiral out of control. If your current solution wasn’t designed for this type of environment, you’re likely facing a number of roadblocks:

-
**Complex deployment processes**: Deploying container-based applications to thousands of remote environments means you need a tool that simplifies the process. Traditional tools can make deployments unnecessarily complex, requiring manual configuration and specialized expertise to manage each unique environment. -
**Limited visibility across devices**: It’s difficult to gain a centralized view of your software deployments when your fleet is scattered across various locations. Without clear visibility into which devices are running which versions of your containerized applications, things can quickly fall apart. -
**Deployment inconsistencies**: Pushing updates across thousands of Docker- or Kubernetes-enabled devices can feel like a game of roulette. If your solution isn’t built for consistency, you risk having devices that fail to update or end up running incompatible versions of your apps. -
**Resource constraints and network variability**: Many IoT devices, whether in manufacturing plants, rural locations, or industrial sites, operate in resource-constrained environments with limited compute power and unreliable networks. Your deployment platform needs to handle these challenges seamlessly.

#### Why Portainer is the Smart Choice for Managing IoT Software Deployments

Portainer was built from the ground up to simplify the deployment and management of containerized applications, no matter the scale. If you’re deploying Docker or Kubernetes containers to thousands of IoT devices, Portainer is the logical solution—designed specifically to give you the control and visibility you need without the complexity that typically comes with distributed environments.

Here’s why Portainer stands out for containerized IoT software deployments:

-
**Simplicity at scale**: With Portainer, you can deploy and manage containerized applications on thousands of devices with ease. Our intuitive UI provides centralized control over all your Docker- or Kubernetes-enabled IoT environments, eliminating the need for complex, time-consuming configuration processes. -
**Visibility and control**: Portainer gives you visibility into the health and status of all your IoT fleet, allowing you to manage your containerized apps confidently. From a single dashboard, you can monitor, deploy, and update containers across all your environments, ensuring that every device is running the right version of your software. -
**Consistent, reliable deployments**: Rolling out containerized updates to thousands of devices? No problem. Portainer ensures your apps are deployed consistently and reliably, even in the most challenging environments. Whether you’re managing 10 devices or 10,000, Portainer ensures your fleet stays in sync. -
**Designed for resource-limited and unreliable environments**: Many IoT devices operate under less-than-ideal conditions—low compute power, limited bandwidth, and intermittent connectivity. Portainer is built to handle these challenges, ensuring your containerized apps are deployed efficiently, no matter the conditions. -
**Freedom from vendor lock-in**: Portainer isn’t tied to any specific vendor or device type. It works across all Docker- and Kubernetes-enabled environments, giving you the flexibility to manage a diverse fleet of IoT devices without being locked into a single ecosystem.

* *

#### Why You Should Choose Portainer for Your IoT Strategy

The truth is, many deployment tools out there weren’t designed for the realities of IoT at scale, especially when dealing with container-based applications. They weren’t built to handle thousands of Docker- or Kubernetes-enabled devices, and they’re often too complex, too rigid, or simply not scalable enough to meet the needs of a distributed IoT architecture.

**Portainer is different.** It’s purpose-built to simplify container management in IoT environments, giving you full control over your deployments without the steep learning curve or operational overhead of traditional tools. With Portainer, you can manage your containerized apps across thousands of devices with ease, gaining the consistency and visibility you need to keep your IoT strategy running smoothly.

IoT deployments can be complex—but managing containerized software across thousands of devices doesn’t have to be. If you’re tired of wrestling with over-complicated tools that weren’t built for the challenges of IoT at scale, it’s time to make the switch to Portainer.

**Portainer simplifies the deployment and management of containerized applications**, giving you the power to deploy at scale without the operational headaches. It’s the smart choice for managing your Docker- or Kubernetes-enabled IoT environments.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/the-harsh-truth-about-kubernetes-management-why-your-tools-are-failing-you
title: The Harsh Truth About Kubernetes Management: Why Your Tools Are Failing You
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/the-harsh-truth-about-kubernetes-management-why-your-tools-are-failing-you
hostname: portainer.io
description: Discover why your Kubernetes management tools are failing you and how Portainer can simplify your Kubernetes strategy, enhancing efficiency and reducing complexity.
sitename: PORTAINER.IO
date: 2024-09-26
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/Kubernetes%20complexity.jpeg
pagetype: article
filedate: 2025-01-18
-->

Kubernetes is a beast. We all know it. But somewhere along the way, the industry has fooled itself into believing that the only way to tame this beast is by introducing unnecessary complexity. Organizations are adopting over-engineered, bloated tools, or worse, tools designed for Google-scale infrastructures. And it’s killing their agility, draining their resources, and keeping their developers stuck in a loop of frustration.

The harsh truth? Your current Kubernetes management tools are failing you. They’re not making life easier, they’re making it harder. It’s time to rethink your approach, and the first step is acknowledging that *more* complexity does not equal *more* control.

#### The Overcomplication of Kubernetes Tools: Are You Overwhelmed Yet?

Let’s get real. How many of you chose your current Kubernetes management tool because it came highly recommended by some tech giant or trendy consultancy firm? How many of you *actually* need all the features you’re paying for, or worse, struggling to use?

Here’s the deal: Kubernetes doesn't have to be as hard as you've been led to believe. Yet most of you are managing it with platforms so overcomplicated, they require a dedicated team just to keep the basics running. Stop pretending you’re managing infrastructure at the scale of Google or Netflix. You’re not. Most businesses don’t need that kind of overhead, yet they’ve bought into the idea that Kubernetes has to be this difficult. What you need is a streamlined, effective management solution.

#### The Myth of the 'One-Size-Fits-All' Platform

We’ve all been sold this myth: “One tool to rule them all.” And for Kubernetes, that means opting into platforms that promise to solve every problem, but end up creating new ones instead. Heavyweight tools that claim to be “all-in-one” solutions are often just complex labyrinths of features you don’t use, integrations you don’t need, and complexity you can’t afford.

Here’s the reality: These platforms *don’t scale* for the everyday business. They’re designed for unicorns, but deployed by teams that don’t have the time or resources to learn how to ride them. What you end up with is a bloated solution that you’ve been told is ‘best-in-class,’ but in reality, it’s a sledgehammer when all you needed was a scalpel.

If your Kubernetes management platform requires a team of consultants just to keep the lights on, you’ve chosen the wrong tool.

#### The Reality Check: Your Current Setup Isn’t Sustainable

How many more sleepless nights will it take for you to realize your current Kubernetes setup just isn’t sustainable? Tool sprawl, runaway costs, and developer fatigue are the inevitable side effects of using over-complicated tools. The friction caused by these platforms is real, and the longer you keep them around, the worse it gets.

Here’s the thing: Kubernetes is supposed to be an enabler. It's supposed to give your teams the freedom to innovate faster, deliver value sooner, and manage infrastructure more efficiently. But when you’re spending more time *managing* Kubernetes than you are *using* it, there’s a fundamental problem.

Tool sprawl is killing your agility, and your developers are wasting time managing tools instead of delivering value. Isn’t it time to cut the fat?

#### What You Really Need: Portainer’s Pragmatic Simplicity

So, what’s the alternative? It’s not another heavyweight platform that promises to solve all your problems and then adds 20 new ones. It’s time to cut through the noise and adopt a management solution that does exactly what you need it to do: simplify Kubernetes without sacrificing power.

This is where Portainer comes in. Portainer gives you all the control of Kubernetes, without the complexity. It’s designed for businesses that need a streamlined solution that works, not a tool that demands an engineering degree just to operate. It’s time to stop believing the myth that you need a PhD in Kubernetes to manage containers effectively.

#### It’s Time to Rethink Your Kubernetes Strategy

Let’s be blunt. Your current Kubernetes management tools are holding you back. You’re using systems designed for a scale you don’t need, complexity you can’t afford, and operations that are dragging down your business instead of moving it forward.

It’s time for a reality check. Kubernetes doesn’t have to be this hard. Your tools don’t have to be this complicated. You don’t need an army of engineers to manage containers at scale. All you need is the right tool for the job, and that tool is Portainer.

You’re not managing Google’s infrastructure. Stop pretending you are—and start managing containers the right way.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/how-portainer-simplifies-industry-4.0-edge-device-management-overcoming-software-distribution-challenges
title: How Portainer Simplifies Industry 4.0 Edge Device Management: Overcoming Software Distribution Challenges
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/how-portainer-simplifies-industry-4.0-edge-device-management-overcoming-software-distribution-challenges
hostname: portainer.io
description: Managing Industry 4.0 edge devices can be a nightmare of complexity. Find out how Portainer can help reduce this complexity to a manageable level without sacrificing functionality.
sitename: PORTAINER.IO
date: 2024-09-05
categories: []
tags: []
image: https://www.portainer.io/hubfs/shutterstock_2114019035.jpg
pagetype: article
filedate: 2025-01-18
-->

Rolling out an Industry 4.0 transformation is full of complexities, especially when you’re talking about managing and distributing software to edge devices. It’s not just about deploying software; it’s about dealing with all the quirks and challenges that come with working at the edge. One of the first big issues is the sheer variety of devices involved. You might have devices from different vendors, all running different hardware configurations and operating systems, and many of these systems weren’t built with modern software distribution in mind. Managing all of that can quickly turn into a nightmare.

#### Simplifying Edge Management with Portainer

This is where Portainer really starts to make a difference. Portainer provides a single, unified interface that lets you manage whichever container runtime you prefer, Docker or Kubernetes. Whether your devices are running lightweight Docker setups or full-blown Kubernetes clusters, Portainer gives you the tools to handle them all from the same place. You don’t have to worry about diving into the specifics of each environment because Portainer abstracts that complexity away.

What’s really helpful is the use of **edge templates** and **edge application stacks**. These allow you to define how you want your applications to be deployed and then roll them out in a consistent way across all your devices, no matter how different they might be under the hood.

##### Overcoming Network and Update Challenges

But infrastructure isn’t the only challenge. One of the biggest headaches when working with edge devices is the **unreliable or highly secure network connections**. Many edge devices are in remote or industrial locations where network connectivity can be heavily restricted. Imagine trying to push a software update to a device in a factory or out on a wind farm, and halfway through the process, the connection drops. You’re left with an incomplete update and potentially a device that’s in an unusable state.

Portainer’s **agent-based architecture** comes to the rescue here. Each edge device runs a lightweight agent that communicates with the central Portainer instance. Even if the network cuts out, the agent can ensure that updates and changes are staged and then applied when the connection is restored. This way, you don’t have to worry about interruptions causing havoc. On top of that, Portainer gives you **granular control** over updates. You can schedule when updates are pushed, ensuring they happen when the network is stable or during off-peak hours, reducing the risk of network-related failures.

##### Ensuring Security and Role-Based Access Control

Then there’s security, which is a huge concern when dealing with edge devices. These devices are often out in the field, physically accessible, and more vulnerable to attacks compared to systems that are locked down in a data center. Securing both the software being distributed and the devices themselves is critical. Portainer makes this easier by offering **Role-Based Access Control (RBAC)**, which ensures that only authorized users can make changes to devices. This minimizes the risk of unauthorized access or accidental changes that could disrupt operations.

##### Managing Large Fleets of Edge Devices

Managing software updates across hundreds, sometimes thousands, of edge devices is a logistical challenge all on its own. These devices are often geographically dispersed, operating in completely different environments, and you need to ensure that updates are rolled out smoothly and consistently. This is where Portainer’s ability to group devices together shines. With **device grouping**, you can organize devices based on location, role, or other criteria and manage them collectively. So instead of pushing updates to devices one by one, you can deploy software in bulk across entire groups. It’s a massive time-saver and helps ensure consistency in your deployments. You can be confident that the same update is applied across all devices in a group without manual intervention.

##### Minimizing Downtime in Real-Time Operations

Real-time operations present another layer of complexity. Many edge devices are responsible for mission-critical tasks, whether in manufacturing, energy production, or transportation. You can’t afford to take these devices offline for a simple software update. Interruptions, even for a short time, can lead to costly downtime or even safety risks. With Portainer, updates are handled in a way that minimizes or eliminates downtime. You can deploy updates **locally**, directly on the edge device, which avoids the latency and potential unreliability of cloud-based updates. Portainer also allows for **partial updates**, so you only need to update specific parts of an application without disrupting the entire system. This kind of flexibility is essential in environments where uptime is crucial.

##### Compliance, Governance, and Resource Constraints

Then there’s the issue of compliance and governance, especially in industries like manufacturing, energy, or healthcare, where there are strict regulations around how software and data are managed. Portainer helps simplify this by letting you manage policies that ensure compliance across all edge devices. From one place, you can ensure proper configurations are in place, and securely distribute updates. Portainer uses encrypted communication channels, which means that all updates are securely transferred to the devices, ensuring compliance with regulations like data sovereignty or GDPR.

A less obvious but equally important challenge is the fact that many edge devices are **resource-constrained**. Some of these devices are older or embedded systems with limited CPU power, memory, or storage. They weren’t built to handle large, complex software updates, and deploying modern applications to them can be tricky. The good news is that Portainer’s **lightweight agent** is designed to run on minimal hardware without overloading the device. It’s specifically optimized to work in resource-constrained environments, so even if your edge devices are a bit outdated, they can still be managed and updated without issue. And with Portainer’s container management tools, you can monitor and optimize resource usage to ensure that applications are running efficiently without maxing out the device’s capabilities.

##### Automated Configuration Management

Finally, one of the most frustrating parts of managing edge devices is making sure they have the right configurations. Devices often have specific roles or are located in environments that require custom configurations. Keeping track of these configurations manually is a recipe for disaster. This is where Portainer’s **Edge Configurations** feature comes into play. It allows you to automatically distribute configuration files to remote devices based on their unique device IDs. You don’t have to worry about manually pushing the correct configuration to each device. Portainer handles it for you, ensuring that every device has the right settings based on its role or location. This not only saves time but also reduces the risk of human error, which is always a concern when dealing with large fleets of devices.

By addressing all these challenges, Portainer provides a comprehensive solution to managing the distribution of software and updates to edge devices, while also ensuring security, compliance, and optimized resource usage. Whether you’re dealing with network issues, real-time processing needs, or scaling across thousands of devices, Portainer brings everything together in a way that’s easy to manage and reliable.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/the-gitops-minefield-why-most-tooling-is-overcomplicated-and-how-portainer-simplifies-it
title: The GitOps Minefield: Why Most Tooling is Overcomplicated and How Portainer Simplifies It
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/the-gitops-minefield-why-most-tooling-is-overcomplicated-and-how-portainer-simplifies-it
hostname: portainer.io
description: Why GitOps tooling can complicate your life, and how Portainer can bring simplicity back to the table.
sitename: PORTAINER.IO
date: 2024-09-28
categories: []
tags: []
image: https://www.portainer.io/hubfs/Shutterstock_491363926.png
pagetype: article
filedate: 2025-01-18
-->

GitOps is supposed to make Kubernetes easier. The idea is simple: declarative configurations stored in Git, automatically applied to your cluster when changes are made. It sounds like a dream come true for developers and platform teams alike. But in reality, for many organizations GitOps tooling is a minefield. What’s promised as simplicity often devolves into a web of complexity that’s difficult to manage, prone to errors, and leaves teams scrambling to troubleshoot and maintain.

GitOps was supposed to be the answer to your Kubernetes deployment challenges, but instead it’s created new ones. The reality? Most GitOps tooling is far more complicated than it needs to be. That’s where Portainer comes in. With Portainer’s native GitOps capabilities, you get the power of GitOps without the headaches.

#### The Promise (and Pitfalls) of GitOps Tooling

On paper, GitOps is brilliant: your Git repository becomes the single source of truth for infrastructure and application deployment. By pushing changes to Git, your Kubernetes clusters automatically update to reflect those changes. Sounds simple enough, right?

But as many teams have found out, traditional GitOps tooling introduces a host of new challenges:

-
**Toolchain complexity**: Most GitOps solutions require a sprawling toolchain to work effectively. You’ll need external controllers, integrations, agents, and workflows, all of which require constant monitoring, management, and troubleshooting. Instead of simplifying deployments, you’re adding layers of complexity. -
**Learning curve**: GitOps itself is straightforward, but the tools built to enable GitOps often aren’t. From understanding how agents and controllers work to configuring automation pipelines correctly, there’s a steep learning curve. What’s sold as a “self-healing” system often ends up needing constant care and feeding from your team. -
**Fragility**: GitOps systems are highly dependent on the health of several moving parts—your Git repo, your agents, and your Kubernetes cluster. If any part of the chain breaks your GitOps pipeline can become fragile, leading to failed deployments or out-of-sync environments. Diagnosing the root cause can become a time-consuming task. -
**Security risks**: Managing secrets in a GitOps workflow can be tricky. Many teams struggle with keeping sensitive information secure while still enabling automated deployments. Some GitOps solutions leave gaps that hackers could exploit, especially if secret management isn’t properly handled. -
**Operational overhead**: Many GitOps tools require you to maintain a fleet of external controllers and agents running in your cluster. This adds operational overhead, as you need to keep these components up to date, monitor their performance, and ensure they’re properly integrated with your CI/CD pipelines.

#### Why Most GitOps Tooling Fails You

The sad reality is that many organizations dive into GitOps without fully understanding the complexity involved. They adopt popular GitOps tools only to realize that they’ve replaced one set of problems with another.

Instead of simplifying their deployment process, they’ve created new failure points. Configuration errors in Git, connectivity issues between controllers, and syncing failures between Git and the Kubernetes cluster become part of the daily grind. And when something goes wrong, it’s often not immediately clear where the failure lies—forcing teams to spend time diagnosing rather than delivering.

The bottom line? Most GitOps tools are designed with flexibility in mind, but for many businesses that flexibility comes at the cost of usability. What started as an effort to streamline operations has become a minefield of complexity.

#### Portainer’s Native GitOps: The Simpler Solution

Portainer on the other hand takes a different approach. Built with ease of use at its core, Portainer’s native GitOps capability allows you to enjoy the benefits of GitOps without falling into the trap of overcomplicated tooling. You don’t need a separate GitOps engine, external controllers, or complex pipelines. Everything you need is right there, integrated within Portainer’s platform.

Here’s why Portainer’s GitOps capability is the antidote to the GitOps minefield:

-
**No external controllers**: Unlike traditional GitOps setups that require you to manage separate controllers or agents, Portainer’s GitOps capabilities are built directly into the platform. This eliminates the need to maintain extra components, reducing your operational overhead and minimizing potential points of failure. -
**Simplicity in setup**: With Portainer, there’s no steep learning curve or convoluted configuration process. You can link your Git repository directly to your Kubernetes cluster within the Portainer UI, define how you want changes to be applied, and that’s it. You’re up and running in minutes—not days. -
**Single interface for management**: Portainer consolidates your Kubernetes management and GitOps workflows into a single interface. This means your developers, operations teams, and platform engineers can all work from the same place, reducing friction and improving visibility. No more hopping between tools to manage deployments. -
**Robust syncing**: Portainer’s GitOps implementation is designed to automatically sync your Kubernetes clusters with your Git repository, ensuring that your environments are always up to date with the latest configurations. -
**Security built-in**: With Portainer’s integrated GitOps capabilities, users can create pipelines within the safe confines of their own RBAC permissions; there is no need to maintain two discrete levels of RBAC, one in Kubernetes and one in your GitOps tooling.

#### Why Portainer’s GitOps Approach Works

At its core, Portainer’s GitOps implementation works because it doesn’t overcomplicate things. By integrating GitOps capabilities directly into the platform, Portainer eliminates the need for separate controllers, complex pipelines, and external components that only serve to make your deployments more fragile.

Portainer’s GitOps features give you everything you need to manage Kubernetes deployments efficiently, without the operational headaches that come with most GitOps tooling. It’s simple, effective, and designed for real-world teams who don’t have the time or resources to maintain bloated GitOps pipelines.

You can see in the picture below, just how simple it is to define a self-service GitOps pipeline. Simply connect Portainer to your Git repo, select the reference to use, and then select the Kubernetes manifests you wish to use for the deployment (and monitor for changes). Enable the GitOps reconciliation loop (or enable the webhook remote reconciliation trigger), and you are done. No complex configurations, controllers, or overhead.

Suppose you must ensure that what's running in your cluster is ALWAYS matching what's in Git. In that case, you can optionally enable "always apply manifest", which ensures that any local changes are reverted, even if there are no changes in the upstream repo.

#### Say Goodbye to GitOps Complexity with Portainer

GitOps was supposed to simplify Kubernetes, but for many organizations, the tooling has done the exact opposite. Instead of streamlining operations, it’s introduced new complexities, fragility, and operational overhead. But it doesn’t have to be that way.

Portainer’s native GitOps capabilities offer a simpler, more reliable approach. With no external controllers, no complicated setup, and no sprawling toolchains, Portainer brings GitOps back to its roots: easy, automated deployments that *just work*.

If you’re tired of the GitOps minefield, it’s time to make the switch. With Portainer, you get the power of GitOps without the headaches. It’s that simple.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/managing-a-swarm-with-differing-node-configs-using-the-portainer-agent
title: Managing a Swarm with differing node configs using the Portainer Agent
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/managing-a-swarm-with-differing-node-configs-using-the-portainer-agent
hostname: portainer.io
description: Learn how you can use placement constraints to deploy the Portainer Agent in a Swarm where nodes have different configurations.
sitename: PORTAINER.IO
date: 2024-08-07
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/This%20image%20shows%20a%20Docker%20daemon.jpeg
pagetype: article
filedate: 2025-01-18
-->

Portainer's support for Docker Swarm lets you manage your Swarm deployment using the Portainer Agent deployed on each node. The [installation instructions](https://docs.portainer.io/start/install/server/swarm) we provide for this work well in most cases, but they do make the assumption that all your Swarm nodes are configured in the same way. However, this might not always be the case.

First, let's look at our standard deployment on Linux.

version: '3.2' services: agent: image: portainer/agent:2.19.5 volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes networks: - agent_network deploy: mode: global placement: constraints: [node.platform.os == linux] portainer: image: portainer/portainer-ee:2.19.5 command: -H tcp://tasks.agent:9001 --tlsskipverify ports: - "9443:9443" - "9000:9000" - "8000:8000" volumes: - portainer_data:/data networks: - agent_network deploy: mode: replicated replicas: 1 placement: constraints: [node.role == manager] networks: agent_network: driver: overlay attachable: true volumes: portainer_data:

This YAML file installs Portainer Server on a manager node in your Swarm, and deploys the Portainer Agent globally (to all nodes in the Swarm).

As you can see, we assume that all of the nodes in the Swarm are configured the same way. But what if some of your nodes had differences in configuration to others?

To provide for this, we need to deploy the Portainer Agent as separate services, each with the required changes to the configuration. We can then use the [placement constraints](https://docs.docker.com/engine/swarm/services/#placement-constraints) system to define which nodes in the Swarm get which service.

#### A mixed Linux and Windows Swarm

For example, Docker installs on Windows use different path structures than on Linux to point to the Docker socket and to the volumes path, so we can't just use the same configuration for both Linux and Windows nodes. This is why we have the placement constraint in the above example restricting the deployment to nodes where the OS is Linux. To accommodate a Swarm that has a mix of Linux and Windows nodes, we'd need different configurations for each. So let's do that.

We can reuse the existing `agent`

service definition for the Linux nodes, since it's good to go. We will make a couple of changes however to make life easier for us in the future.

First, we'll rename it from `agent`

to `agent_linux`

as that's a more accurate name.

```
services:
agent_linux:
```

Next, we'll add an environment variable that will define the cluster address. This is used for internal communication between the agents. The environment variable to use here is `AGENT_CLUSTER_ADDR`

, and we'll set it to `tasks.agent`

.

```
agent_linux:
image: portainer/agent:2.19.5
environment:
- AGENT_CLUSTER_ADDR=tasks.agent
```

The `volumes`

definitions stay the same for Linux, so we can copy them straight in.

```
agent_linux:
image: portainer/agent:2.19.5
environment:
- AGENT_CLUSTER_ADDR=tasks.agent
volumes:
- /var/run/docker.sock:/var/run/docker.sock
- /var/lib/docker/volumes:/var/lib/docker/volumes
```

In the networks section we want to add an `alias`

of `agent`

to the service. This, combined with the `AGENT_CLUSTER_ADDR`

we set above, will ensure the Linux and Windows agents are able to communicate with each other and with the Portainer Server. To add the alias we need to tweak our networks section a bit:

```
agent_linux:
image: portainer/agent:2.19.5
environment:
- AGENT_CLUSTER_ADDR=tasks.agent
volumes:
- /var/run/docker.sock:/var/run/docker.sock
- /var/lib/docker/volumes:/var/lib/docker/volumes
networks:
agent_network:
aliases:
- agent
```

Everything else we can keep the same. The full `agent_linux`

definition should now look like this:

agent_linux: image: portainer/agent:2.19.5 environment: - AGENT_CLUSTER_ADDR=tasks.agent volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes networks: agent_network: aliases: - agent deploy: mode: global placement: constraints: [node.platform.os == linux]

Next we create our Windows variant. Note this should be defined within the `services:`

block but outside of the `agent_linux:`

block, as this is a separate service (the same way that the Portainer Server container is a separate service to the Agent). We'll call this one `agent_windows`

.

```
services:
agent_linux:
...
agent_windows:
image: portainer/agent:2.19.5
```

We'll set the same environment variable as we did for the Linux variant so that they can communicate with each other successfully.

```
agent_windows:
image: portainer/agent:2.19.5
environment:
- AGENT_CLUSTER_ADDR=tasks.agent
```

We now need to adjust the volume paths for Windows. Since Windows uses `npipe`

to bind to sockets, we'll use the long form syntax of the volume definitions here.

```
agent_windows:
image: portainer/agent:2.19.5
environment:
- AGENT_CLUSTER_ADDR=tasks.agent
volumes:
- type: npipe
source: \\.\pipe\docker_engine
target: \\.\pipe\docker_engine
- type: bind
source: C:\ProgramData\docker\volumes
target: C:\ProgramData\docker\volumes
```

The Portainer Agent knows what to do with the Windows paths once they are available.

The `networks`

section remains the same as in our Linux variant, as we want each service to have the same alias.

```
agent_windows:
image: portainer/agent:2.19.5
environment:
- AGENT_CLUSTER_ADDR=tasks.agent
volumes:
- type: npipe
source: \\.\pipe\docker_engine
target: \\.\pipe\docker_engine
- type: bind
source: C:\ProgramData\docker\volumes
target: C:\ProgramData\docker\volumes
networks:
agent_network:
aliases:
- agent
```

The final change we need to make is in the `deploy`

section, and this is where we define our constraint. For Windows nodes, we can simply change the `node.platform.os`

to `windows`

.

```
agent_windows:
image: portainer/agent:2.19.5
environment:
- AGENT_CLUSTER_ADDR=tasks.agent
volumes:
- type: npipe
source: \\.\pipe\docker_engine
target: \\.\pipe\docker_engine
- type: bind
source: C:\ProgramData\docker\volumes
target: C:\ProgramData\docker\volumes
networks:
agent_network:
aliases:
- agent
deploy:
mode: global
placement:
constraints: [node.platform.os == windows]
```

That's all we need to change. Your full YAML file should now look like this:

version: '3.2' services: agent_linux: image: portainer/agent:2.19.5 environment: - AGENT_CLUSTER_ADDR=tasks.agent volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes networks: agent_network: aliases: - agent deploy: mode: global placement: constraints: [node.platform.os == linux] agent_windows: image: portainer/agent:2.19.5 environment: - AGENT_CLUSTER_ADDR=tasks.agent volumes: - type: npipe source: \\.\pipe\docker_engine target: \\.\pipe\docker_engine - type: bind source: C:\ProgramData\docker\volumes target: C:\ProgramData\docker\volumes networks: agent_network: aliases: - agent deploy: mode: global placement: constraints: [node.platform.os == windows] portainer: image: portainer/portainer-ee:2.19.5 command: -H tcp://tasks.agent:9001 --tlsskipverify ports: - "9443:9443" - "9000:9000" - "8000:8000" volumes: - portainer_data:/data networks: - agent_network deploy: mode: replicated replicas: 1 placement: constraints: [node.role == manager] networks: agent_network: driver: overlay attachable: true volumes: portainer_data:

You can now deploy this on your mixed Linux and Windows Swarm and be up and running with Portainer.

Note: Depending on your setup you may also want to add an OS constraint to the `portainer`

service to ensure it lands on a Linux node. For example:

```
portainer:
image: portainer/portainer-ee:2.19.5
...
deploy:
mode: replicated
replicas: 1
placement:
constraints:
- node.role == manager
- node.platform.os == linux
```

#### Extending to custom labels

You're not restricted to `node.platform.os`

for placement constraints. As on the `portainer`

container you can use `node.role`

to restrict to node types. But you can also use custom labels to define your constraints.

A user in our [community Slack channel](https://join.slack.com/t/portainer/shared_invite/zt-21zpww5ab-mG_lA7UXbWL3HW3sPqjqEA) recently reached out as they have an interesting setup. Some of their Swarm nodes have NVMe drives, and on those nodes they redirected Docker's `data-root`

(normally `/var/lib/docker`

) to the NVMe drive. This meant a different volume path (instead of `/var/lib/docker/volumes`

) for those nodes as compared to the other, "default" nodes.

We can see how we'd solve this by looking at the above Linux and Windows examples, as they have different volume paths in each config. For example, you could create a service called `agent_default`

for the "default" nodes, and one called `agent_nvme`

for the nodes with NVMe drives (we'll use `/nvme/docker/volumes`

for the NVMe volume path):

services: agent_default: image: portainer/agent:2.19.5 environment: - AGENT_CLUSTER_ADDR=tasks.agent volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes agent_nvme: image: portainer/agent:2.19.5 environment: - AGENT_CLUSTER_ADDR=tasks.agent volumes: - /var/run/docker.sock:/var/run/docker.sock - /nvme/docker/volumes:/var/lib/docker/volumes

Note we need to ensure the right side of the volume mount is still `/var/lib/docker/volumes`

, as that's the internal path that the Portainer Agent is expecting.

But what about placement constraints? We can't use `node.platform.os`

for this, so let's create some custom labels. We'll apply a label to each node to specify which disk type it is, and then reference that label in our placement constraints.

Let's assume a 3 node cluster, where `node01`

and `node02`

have the NVMe configuration, and `node03`

has the "default" configuration. We can create a label on each node named `disktype`

and set it to `nvme`

or `default`

depending on each node. To do this, on a manager node in the Swarm you would run the following commands:

docker node update --label-add disktype=nvme node01 docker node update --label-add disktype=nvme node02 docker node update --label-add disktype=default node03

These commands set the `disktype`

label for each node, with `node01`

and `node02`

set to `nvme`

and `node03`

set to `default`

.

Now let's use those labels in placement constraints for our two Agent service configurations above.

services: agent_default: image: portainer/agent:2.19.5 environment: - AGENT_CLUSTER_ADDR=tasks.agent volumes: - /var/run/docker.sock:/var/run/docker.sock - /var/lib/docker/volumes:/var/lib/docker/volumes deploy: mode: global placement: constraints: [node.labels.disktype == default] agent_nvme: image: portainer/agent:2.19.5 environment: - AGENT_CLUSTER_ADDR=tasks.agent volumes: - /var/run/docker.sock:/var/run/docker.sock - /nvme/docker/volumes:/var/lib/docker/volumes deploy: mode: global placement: constraints: [node.labels.disktype == nvme]

We're accessing the `disktype`

label we just set using `node.labels.disktype`

, and deploying the `agent_nvme`

service *only* to the nodes labeled as `nvme`

(`node01`

and `node02`

) and the `agent_default`

service *only* to the nodes labeled as `default`

(`node03`

).

Through the use of labels and placement constraints you can see how you can deploy different Portainer Agent configurations across a custom Swarm environment depending on your needs.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/deploy-prometheus-monitoring-stack-with-portainer-part-2
title: Deploy Prometheus Monitoring Stack with Portainer - Part 2
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/deploy-prometheus-monitoring-stack-with-portainer-part-2
hostname: portainer.io
description: Part 2 - adding additional Prometheus instances to Grafana
sitename: PORTAINER.IO
date: 2022-03-06
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Mar-06-2022-06-55-57-76-PM.png
pagetype: article
filedate: 2025-01-18
-->

In [Part 1 ](/blog/deploy-prometheus-monitoring-stack-with-portainer)of this blog, I demonstrated how easy it is to deploy Prometheus and Grafrana to a cluster using Portainer.

But what if you have multiple clusters? Do you want an instance per cluster? Wouldn't you rather visualize all of them in a single Grafana dashboard?

Let me show you how.

Login to Portainer, and choose the SECOND cluster (the one that is NOT running Prometheus stack).

Click on 'Namespaces', and create a namespace called "Prometheus"

Go into Helm, select the "kube-prometheus-stack", edit the custom values, find line 641, and change true to false.

Also edit lines 2427 - 2436 if you want Prometheus persistent.

Click "Install"

In the application list, click on the prometheus application

Click "Edit this application"

Add a new "NodePort", with 9090 exposed as 32767 (or any free port), then click "update application"

*NOTE THIS EXPOSES YOUR PROMETHEUS INSTANCE TO THE PUBLIC. I STRONGLY ADVOCATE ONLY DOING THIS FOR LAN ATTACHED CLUSTERS. SEE HERE FOR MORE INFO*

Login to your Grafana instance, then click on "Configuration" then "Data Sources", then click "add data source"

Choose Prometheus..

Add in the IP address of one of your nodes, and the NodePort you set previously.

Click "save and test" and make sure you get the green tick.

Go to dashboards, select a dashboard, and change the datasource to the one you just added.

Success. You are now viewing the remote Prometheus instance from your central Grafana instance.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/deploy-and-use-argocd-with-portainer-part-2
title: Deploy and use ArgoCD with Portainer (part 2)
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/deploy-and-use-argocd-with-portainer-part-2
hostname: portainer.io
description: Portainer with ArgoCD, managing remote clusters
sitename: PORTAINER.IO
date: 2022-02-10
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Feb-10-2022-11-43-28-00-PM.png
pagetype: article
filedate: 2025-01-18
-->

In [Part 1](/blog/deploy-and-use-argocd-with-portainer) of this blog, i showed how to deploy an instance of ArgoCD in Portainer, and use it to GitOps-enable application deployments on a local cluster.

In this blog, I will show how to extend that initial Argo instance to be able to manage the other Kubernetes clusters in your central Portainer instance. At the end of the blog you will have ArgoCD running centrally, and both the local cluster and one remote cluster able to be managed from the central instance.

The first thing you need to do in Portainer is gather the authentication details for your other environments.

As the admin user, Click on the "home" page, and then click on "KubeConfig"

Select just your additional environments (in my case, Linode-LKE) and then view the config file.

Take a note of the server URL and the Token., you will need these later.

OK, so let's create a YML file that will create the required secret ArgoCD needs to import this cluster.

*apiVersion: v1*

*kind: Secret*

*metadata:*

*name: linode-lke-cluster-secret*

*labels:*

*argocd.argoproj.io/secret-type: cluster*

*namespace: argocd*

*type: Opaque*

*stringData:*

*name: linode-lke*

*server: https://kubernetes.docker.internal:9443/api/endpoints/10/kubernetes*

*config: |*

*{*

*"bearerToken": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJuZWlsIiwicm9sZSI6MSwic2NvcGUiOiJrdWJlY29uZmlnIn0.1qVJGLPDRm-UH0_nPAL7xoIfRlHR7e1Kb83VeMLMwCU",*

*"tlsClientConfig": {*

*"insecure": true*

*}*

*}*

Once you have this YAML, select the environment where ArgoCD is running (the local environment, not the remote one to be added). Then click on ConfigMaps & Secrets, then click on "+ Create from manifest"

Paste in the YAML. Don't forget to change the namespace to argocd, and set the name to match the name in the YAML, then click "deploy"

For a quick check that the secret stuck and the environment has been presented to ArgoCD, view the logs of the argocd-server pod. Look for "notifying 1 settings subscribers"

OK, so now go back into the ArgoCD UI.. and click on "settings" and then "clusters"

You now have the Linode-LKE cluster added..

OK, so now let's use it..

In the ArgoCD UI, click on "Applications", then "Create Application". Give it name, use the default project, and set the sync policy to automatic.

Use the same source as the prior blog, but this time change the URL to the remote cluster.

Click Create.

Now wait for the Sync to happen (will take seconds).

The app is now running on the remote cluster, which is not on my laptop (where the local ArgoCD is running, but is actually out at Linode.)

Let's now go into Portainer, switch our view to the Linode environment, and see what we see.

There you go, running.

You can repeat this for as many Kubernetes environments as you have defined within Portainer and you will have a single centralised ArgoCD deployment managing all of your remote Kubernetes clusters, all via Portainer's in-built Kubernetes Proxy. Safety plus convenience.

Let us know your thoughts.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/operational-maturity-framework
title: Introducing the Containerization Operational Maturity Self-Assessment
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/operational-maturity-framework
hostname: portainer.io
description: Operational maturity in containerization is a multi-faceted concept, encompassing personal, organizational, application, and technology readiness.
sitename: PORTAINER.IO
date: 2024-04-26
categories: []
tags: []
image: https://www.portainer.io/hubfs/Containerization%20Operational%20Maturity%20Framework/Containerization%20Operational%20Maturity%20-%20Landing%20Page.png
pagetype: article
filedate: 2025-01-18
-->

In the fast-paced realm of software development and IT operations, containerization stands out as a pillar of innovation. It enhances enterprise agility, scalability, and resilience, leading toward more efficient and robust systems. With predictions from Gartner indicating that 80% of all Independent Software Vendors will distribute their commercial software as containers by 2029 and 35% of all enterprise applications will run in containers, the adoption trend is clear. However, organizations must evaluate their containerization operational maturity to navigate this transformative journey successfully. Introducing a comprehensive framework designed to assess and enhance operational maturity, we aim to guide organizations through the nuances of effectively leveraging containers.

### Understanding Operational Maturity in Containerization

Operational maturity in containerization is a multi-faceted concept, encompassing personal, organizational, application, and technology readiness. This holistic approach ensures the technical alignment of tools and platforms and the preparedness of teams and processes to support a containerized environment effectively.

#### Personal Readiness

The team's competence in critical areas such as Kubernetes, Docker, and Linux is at the core of personal readiness. From essential to advanced knowledge, understanding container orchestration, architecture, and underlying infrastructure is paramount. This encompasses everything from Kubernetes constructs and CLI commands to networking concepts and data storage methodologies.

#### Organizational Readiness

Organizational structure plays a pivotal role in supporting containerized platforms. Whether embracing a Site Reliability Engineering (SRE) approach, transitioning to platform engineering, or adopting DevOps practices, the goal is to align team structures with the desired maturity levels. This ensures a supportive environment for containerization, characterized by proactive monitoring, central policy management, and a self-service platform for developers.

#### Application Readiness

The suitability of applications for containerization is another critical aspect. From container-native 12-factor applications to traditional installable software, assessing application readiness involves evaluating applications' architecture, scalability, and statefulness to determine their compatibility with container environments.

#### Technology Readiness

Lastly, technology readiness assesses the deployment of containers and tooling against the Container Management Platform standard. This ranges from advanced container service platforms featuring service mesh and geo-distributed applications to basic container experimentation. The goal is to identify the current state of technology deployment and pinpoint areas for advancement.

### The Value of Assessing Operational Maturity

"Why is it important to assess operational maturity? The advantages are numerous." Running the framework/tool against an organization's current practices sheds light on the readiness level across personal, organizational, application, and technology dimensions. It highlights gaps, provides insights, and ensures readiness before adopting containers, guiding organizations toward successful container adoption with reduced risk and optimized resources. Success stories from clients who have leveraged this assessment underscore its value in making informed decisions and aligning containerization strategies with business objectives.

### Guiding Organizations Towards Success

Our commitment extends beyond providing a framework for assessment. We offer detailed guidance through the maturity assessment process, ensuring organizations can effectively evaluate their readiness and identify actionable steps toward improvement. By engaging early and validating your strategy, you can leverage containers to their fullest potential, aligning your IT practices with your business goals for maximum impact.

#### Conclusion

Containerization represents a significant shift in how businesses deploy and manage applications, offering unparalleled agility, scalability, and efficiency benefits. By assessing and improving operational maturity, organizations can ensure they are well-equipped to leverage the full potential of containers. We encourage you to actively evaluate your operational maturity, using our framework as a guide to ensure success in your containerization efforts.

[Get the Containerization Operational Readiness Framework now.](/containerization-operational-maturity-framework)

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/cncf-project-independence
title: CNCF Project Independence
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/cncf-project-independence
hostname: portainer.io
description: Portainer wants to share their perspective on the current situation with a CNCF graduate project, amidst the noise related to LinkerD and Buoyant.
sitename: PORTAINER.IO
date: 2024-02-29
categories: []
tags: []
image: https://www.portainer.io/hubfs/Young%20Man%20Tunnel.jpg
pagetype: article
filedate: 2025-01-18
-->

Over the past week, there has been a lot of noise/upset/angst in the cloud-native ecosystem, primarily from a [change the Linkerd project](https://buoyant.io/blog/announcing-linkerd-2-15-vm-workloads-spiffe-identities) has made regarding how they provide their OSS software to the market.

If you are not aware of this, Bouyant (the company behind the Linkerd project) is saying that if you want to use "stable" versions of Linkerd, you must switch from using the binaries provided by the CNCF-backed OSS project and instead use Buoyant Enterprise for Linkerd (BEL), the commercial offering from Buoyant. Further, if you use it in production (and a company of more than 50 employees), you must pay for a license to use it beyond the 90-day grace period. The OSS project will only provide binaries for "edge" / "unstable" releases and should be deemed unsuitable for productive use.

One key thing to note here, once an OSS project is donated to CNCF, you hand over the trademark (but the donating company often retains the code copyright), and also the operational governance to the CNCF. In return, the CNCF assists (significantly) with the project's marketing, provides credits to run the systems that underpin the project's maintenance, and helps obtain external contributors and maintainers. Notably, the CNCF does NOT provide direct financial support for the ongoing development/release of the project; this is expected to be provided by the array of volunteer contributors and maintainers.

In the case of Linkerd, Bouyant has remained the primary contributor to and maintainer of Linkerd, and as a result, they can choose where to spend their time (and, therefore, their investors $). In this regard, Bouyant is entitled to say, "We want to spend our time building our commercial version." As there are no other significant contributors to the OSS project, no one else will take over the time/effort involved in shipping stable releases of Linkerd. Again, the CNCF doesn't fund anyone to develop the product and release binaries; the community supporting the project is expected to do so at their own cost. Usually, this wouldn't be an issue, but it's almost always the case for CNCF "graduated" projects.

The fact that one company is almost entirely responsible for a graduated CNCF project seems to be completely abnormal, as the [criteria](https://github.com/cncf/toc/blob/main/process/graduation_criteria.md) for becoming graduated is that the project has a healthy community of contributors. The question of "how did this happen?" should be asked of the CNCF, not Bouyant. Again, if Bouyant is in all practicality the sole contributor to Linkerd, then that is not a healthy and diverse community, and nor is it long-term sustainable. I think the key here is that while "to the letter of the law" regarding the graduated criteria, Linkerd does have more than 1 contributor, the second contributor is insignificant compared to Buoyant. The criteria should be linked to the percentage of code contributions from each contributor, not just the fact that more than one company is contributing.

Buoyant needs a way to recover its development costs, and as they are fundamentally covering all development costs of the OSS version, it's expected they would try to find ways to monetize. Should they be making the changes they have? That's up for debate, but they are within their rights. The real issue here is simply that there is insufficient diversity of maintainers. This has been left to continue for too long, and as a result, one company is carrying too much of the cost.

So, suppose you want 100% assurances that your decision to adopt a fully open CNCF-based platform won't get thrown into disarray due to decisions made by a single commercial entity. In that case, you need to check the project's maintainers and contributors and validate they come from an array of vendors. Only then will you get assurance of independence. You cannot rely on the "graduated" status alone for this indicator.

End of the day, if a CNCF project is not independently maintained, then you (as the user of that project) are no better off than if it was not a CNCF project.

These are my thoughts; what are yours?

Neil

As a side note, Portainer is a member of the CNCF, but we have not donated Portainer-CE to the foundation.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/as-a-ceo-why-do-i-still-run-a-homelab
title: As a CEO, why do I still run a homelab?
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/as-a-ceo-why-do-i-still-run-a-homelab
hostname: portainer.io
description: Learn why the CEO of Portainer runs a homelab, exploring various container runtimes and Kubernetes distributions to stay ahead in the tech market.
sitename: PORTAINER.IO
date: 2024-07-29
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/homelab%20setup.jpeg
pagetype: article
filedate: 2025-01-18
-->

As a technical guy, regardless of where I am in my career, I love to keep my hands on the tools... its what makes me able to run technical workshops, talk with engineers, and question statements made that are baseless in fact... call it my unfair advantage.

Well, here at Portainer, I also like to keep my fingers on the pulse of the tech, and so have spent the last couple of weeks rebuilding my homelab (yes, I have one). This is not your regular home setup, where you might run some PLEX or other home automation software, no, this is a homelab for me to keep my knowledge of the market sharp.

What's running in my HomeLab might you ask? A bit of everything..

The hardware I chose to run this on is an old HP Z440 Professional Workstation. It comes with a 28 Core Xeon CPU, 64GB RAM, and a 1TB SSD. I upgraded it with a 2TB NVMe disk, and have just ordered an extra 64GB RAM (because, well OpenShift uses a LOT of resources).

On this "server" I run Proxmox VE v8, which is a simply brilliant piece of open-source software (and I bought the subscription). This Proxmox environment comfortably allows me to run all my VM workloads.. well, once I added the NVMe disk anyway.

I connect to the environment remotely with a really simple OpenVPN Sever (which runs in a container - [https://dockovpn.io/](https://dockovpn.io/)) and I use PiHole as a local DNS server + Network privacy shield (for my home network). Other than that, the setup is pretty simple. I will be putting in my favorite reverse proxy, nginxproxymanager. Oh, and I run Seafile for a self-hosted "dropbox" alternate.

So, now that I have this environment, what was the intent of it?

The container space is ever-evolving. Newcomers are arriving into the space, products that flew under the radar are getting "discovered", and even for more mature products, they keep enhancing their offering.

As Portainer (the product) does not include a container runtime, nor a Kubernetes distribution, we are ALWAYS acting as a management overlay for other products. Now, in all honesty, the runtime and distro don't matter to us, as we talk to the native APIs, and as long as the distros are certified, we should have no compatibility issues. Well, that's the theory. In reality, every single distro aims to offer a "value add" over and above the standard Kubernetes capability, be that applied defaults, or just simple configurations.

I am using this environment to 1) learn how to deploy the latest versions of the container runtimes and Kubernetes distros, and 2) make sure that Portainer does actually work well with these distributions (yes, our QA team validates a subset, but I like to experiment myself, chaos engineering style).

A couple of learnings so far

Talos Kubernetes is awesome. I like the fact you can completely deploy and manage the environment from a central location, OS, and Kubernetes, without needing to SSH to the environment at all (well, you can't anyway). It's a pretty lean distro too, only needing 2-3GB of RAM per Kubernetes node. I really like that its "secure by default" too.

OpenShift is VERY involved to deploy and configure, and its a resource-consuming beast. 14GB RAM and 4 CPUs on the control-plane nodes.. just to idle (and 70 "system" namespaces once its up!!). Sure, it's probably got the widest adoption in the industry (as everyone in enterprises buys from Gartner "top right"), and RedHat is known for its awesome support, but wow. Bring your chequebook :). If you are using Portainer to manage OpenShift, then you don't need Openshift ACM (part of the Openshift Platform+ bundle). There is a lot of overlap there.

Rancher hasn't really changed in years.. and I guess, why does it need to? Getting a RKE cluster up and running was pretty easy (would be easier if they had a native Proxmox driver like they do with vSphere). Again, quite a resource-heavy distro, but a fraction of OpenShift. Rancher remains a really good way to spin up and lifecycle Kubernetes Clusters.. however, I prefer Talos.

Docker Swarm feels "old" now, but my goodness is it easy to deploy and use.. I still love it, and remain sad that it never really got to see the light of day at global scale.

K3s and MicroK8s are both pretty good for lightweight distro's, but both really need 1GB of RAM to idle, so 2GB RAM should be considered the absolute minimum to use them for any productive workload. Docker on the other hand uses almost nothing.. 340MB of RAM idle (incl OS). For the far edge, where resources are constrained, Docker (or Podman) still reigns supreme.

What else will this be used for?

I want to start learning more Kubernetes capabilities, as Portainer continues to expand its offering, I need to keep across things. OpenTelemetry, Gateway API, and good old OPA Gatekeeper are the things I have on my agenda to play with over the coming weeks.

I also want to continue my testing to ensure that Portainer central auth / RBAC works flawlessly across all these distro's.

I want to document any learnings as "reference architectures", and generally, I want to be technically able to help answer community tech questions when I can.

This is just the start of my HomeLab v2 Journey... but it's going to be an ongoing project for me... the nerd inside me loves it.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/2024-release-principle
title: Our release principle is changing in 2024, what will this mean for you?
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/2024-release-principle
hostname: portainer.io
description: Need to know which version of Portainer to use for greatest stability, read on..
sitename: PORTAINER.IO
date: 2024-01-24
categories: []
tags: []
image: https://www.portainer.io/hubfs/Business%20Woman%20Stock%20Photo.jpg
pagetype: article
filedate: 2025-01-18
-->

Nov 21, 2024: Update to this blog: We're now several releases into this scheme so we've formalized the release policy and provided some approximate dates to help you plan your Portainer deployments:

[Portainer Lifecycle Policy]. Also remember to stay up to date with the latest Portainer release -[details here.]

I would like to provide an overview of the upcoming modifications that will be implemented to our release principle in 2024.

Portainer has experienced remarkable success and customer adoption since our inception. The use cases and deployment scenarios for Portainer have been truly impressive, and the criticality level continues to grow. The increased adoption of our software has prompted us to reconsider our development and release processes. We aim to guarantee top-notch quality while aligning with our customers' expectations for product updates. In doing so, we ensure a smooth and effortless experience that our customers expect.

**What has our release principle been thus far?**

Up until now, our product release approach has followed the mantra of "ship fast, and ship often." This strategy has enabled us to innovate rapidly and address bugs along the way, knowing that the next version is always on the horizon. While this works wonderfully when users embrace the latest updates and our software is not mission-critical, issues arise when these assumptions don't hold.

**What are the shortcomings of our current release approach?**

When we prioritize fast shipping without considering the adoption rate of our customers, it can lead to support issues. Additionally, the inherent risk of breaking things when shipping quickly is typically mitigated by the ability to release fixes promptly. However, as our product has expanded its capabilities, our confidence in ensuring the stability of critical deployments through comprehensive testing of every feature, old and new, has diminished. To put it plainly, we require a much deeper level of regression testing, which is challenging to achieve with our current rapid-release schedule.

**In preparation for 2024, we have decided to revise our approach to product releases.**

In the world of open-source software (OSS), it is a prevalent practice to release a product in both Short-Term Support (STS) and Long-Term Support (LTS) versions. This approach allows for better support and maintenance management, catering to different user needs and preferences. STS releases are characterized as versions that undergo feature testing. They may include features that could potentially cause regressions and undergo limited regression testing. On the other hand, LTS versions differ because they do not contain new features and undergo comprehensive regression testing.

Looking ahead to 2024, our plan for Portainer is to adopt this model.

**How will this new release principle impact you?**

- We are introducing a couple of new image tags, the first of which is

. This tag will always point to the latest Portainer version designated as LTS (Long-Term Support). Additionally, we will point the*:lts*

tag to the latest LTS image (although it's not recommended to use the**:latest**

tag as it goes against best practices). If you prefer to use specific image versions, such as**:latest**

, make sure to review the release notes as we will now indicate whether a release is considered LTS or not.**portainer/portainer-ee:2.19.4** - According to the new definition, Portainer 2.19.x is now classified as "Short-Term Support." The upcoming release of Portainer 2.20.0 will also fall under this category, and will use our second new image tag,

. Our first "Long-Term Support" release will be Portainer 2.21, which will be based on version 2.20. We are currently undergoing regression testing and allowing ample time to address any regressions that may arise.*:sts* - If your Portainer deployments are crucial to your workflows, it is advisable to embrace the LTS versions exclusively. These versions undergo comprehensive end-to-end regression tests, ensuring their reliability and stability.
- If you appreciate quick feature innovation and are willing to tolerate occasional bugs, feel free to utilize the version tags of your preference. However, it is important to note that there may be regressions, so it is advisable to always take a complete backup of Portainer before upgrading. This ensures the preservation of your data and the smooth functioning of your system.

**What advantages will you gain from this new release principle?**

We are confident that this change will greatly benefit our valued customers by allowing them to choose their preferred release stream. Whether you seek the latest and greatest features or rock-solid reliability, we have you covered. Your needs and preferences matter to us, and we strive to deliver the best experience tailored to you.

Watch for Portainer 2.20 in the first quarter of 2024, followed by the 2.21 LTS version in the second quarter.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-community-edition-ce-vs-portainer-business-edition-be-whats-the-difference
title: Portainer CE vs Portainer BE – What’s the Difference?
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-community-edition-ce-vs-portainer-business-edition-be-whats-the-difference
hostname: portainer.io
description: Portainer exists in both Community and Business Editions. In this article we'll cover some of the key capabilities that BE provides over CE.
sitename: PORTAINER.IO
date: 2024-05-16
categories: []
tags: []
image: https://www.portainer.io/hubfs/ce-vs-be-signposts.png
pagetype: article
filedate: 2025-01-18
-->

##### Portainer exists in two different editions - our free and open source Community Edition (CE), and our premium offering: Business Edition (BE). In this article we'll cover some of the key capabilities that Business Edition provides over Community Edition.

Designed to provide a simple introduction to the complexity of container technology, the Community Edition is where a lot of users begin their Portainer journey - and is also where Portainer's own journey began. But container technology has since evolved beyond those early days. Companies from the smallest businesses to the largest enterprise corporations, government departments and other organizations have adopted containers, and have a need for a way to manage their containerized infrastructure and deployments efficiently and securely. Their needs are different to individual users and organizations that are learning about containers, and this is where the Business Edition comes in.

Portainer Business Edition focuses on adding functionality to the Community Edition that is specifically targeted at the needs of businesses and enterprises.

##### Role-based access control

A key difference between many individual and enterprise setups is the number of users that will be interacting with your environments. When using containerization in a business context you may have many different kinds of users that require varying levels of access, and simply giving everyone administrative rights isn't acceptable from a security standpoint. Portainer Business Edition extends CE's user system to implement role-based access control (RBAC), letting you define what users and teams can or cannot do on your environments and with the resources on those environments.

##### Use your existing authentication systems

Many businesses will already have an existing authentication system they use to manage their users, and Portainer can integrate with these systems to provide a centralized user management system. While this is possible in the Community Edition as well, Portainer Business Edition extends the CE functionality to include Active Directory support, as well as adding templates to the LDAP and OAuth options for popular authentication providers to accelerate the setup and management of the provider integration. With configurable automatic user provisioning and group-to-team matching, combined with our RBAC functionality, ensuring your users have the access they need is radically simplified.

##### Automate your deployments

To ensure consistency and reliability when deploying workloads on containerized environments, automating your deployments is often the best bet. Portainer Business Edition extends the basic functionality that CE provides, leveraging the GitOps approach to allow for automatic updates of your applications as your team pushes new code, either by checking periodically for updates or through the use of webhooks that can be triggered by your CI/CD pipelines. Admins can configure change windows to define when these automatic updates are allowed to occur, and developers can take advantage of relative path support and Git credential storage to make those deployments run more smoothly.

##### A single tool for your containerization infrastructure

Portainer provides the ability to manage multiple environments from a single interface, whether they be Docker Standalone, Docker Swarm or Kubernetes, large or small, local or remote. Not only that, but Portainer Business Edition also lets you manage your container registries rather than needing to switch out to a separate tool to do so. In addition, we've added notification indicators to your containers to indicate when new image versions are available, so you can keep a close eye on when you need to update your deployments without having to check another system.

##### Powerful Kubernetes support

Kubernetes environments can be significantly more complex to deploy and manage than other orchestrators like Docker Swarm. Portainer helps you to make Kubernetes management easier, and the Business Edition extends the base Kubernetes functionality available in CE to focus on the particular needs of business workloads. From Portainer Business Edition you can provision new Kubernetes clusters on a number of cloud providers, including Civo, Linode, DigitalOcean, Google Cloud, AWS and Azure, with just a few clicks. For those with their own infrastructure, BE can even install MicroK8s on bare metal or virtual servers for you, with the configuration and addons you need, right from the Portainer UI. If you have existing Kubernetes environments you want to manage with Portainer, the Business Edition accelerates the process by allowing the import of kubeconfig files to add environments.

Once you're up and running with Kubernetes, Portainer Business Edition lets you manage the essential configuration settings you'll need for an enterprise-grade Kubernetes environment. Resource quotas, quota enforcement and resource overcommitment can all be configured, and securing your clusters and workloads can be achieved by pod security constraints. From a deployment perspective, Portainer BE lets you restrict how your users can deploy applications to a code-based approach only, and BE also supports rolling restarts of your Kubernetes applications to reduce the amount of downtime your users will experience when updates are required.

##### Audit and track activity and changes

Enterprise users often have compliancy and certification requirements around the environments they run and the tooling they use, and as such need to be able to closely monitor what is going on within them. In Portainer Business Edition we provide authentication and activity logs that are viewable by administrator users within the Portainer UI, so you can see who has logged on when and what actions they have performed. We also support the exporting of these authentication and activity logs to an external log aggregator via the Syslog protocol for those that need to centralize their logging systems.

##### World-class support

Along with the additional capabilities and functionality that Portainer Business Edition provides over the Community Edition, our experienced and talented team can also provide support for your Portainer configuration as required. With SLAs including 9x5 and 24x7 support options available, Business Edition customers can feel confident that if they do run into issues or just need clarification on how to best use Portainer with their environments, we're an email or message away.

With our Business Edition we've tried to focus on functionality that is specific to businesses and enterprises wanting to manage their containerized environments. The Community Edition and our community of open source users are still of crucial importance to us and we're grateful for the support and feedback our users provide daily. Our heart remains very true to our open source roots, and we will continue to invest in both the Community Edition and Business Edition in the future.

##### For a full list of all the features and functionality in Portainer Community Edition as well as Portainer Business Edition, visit our [Portainer Features page](/features).

Try Portainer with 3 Nodes Free

If you're ready to get started with Portainer Business, [3 nodes free](/take-3) is a great place to begin. If you'd prefer to [get in touch with us](/contact-sales), we'd love to hear from you!

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/the-great-vmware-exodus
title: The Great VMware Exodus
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/the-great-vmware-exodus
hostname: portainer.io
description: Learn about the challenges of migrating from VMware to another hypervisor and explore an alternative solution: migrating VMs into containers. Find out how this strategic move can propel your business forward.
sitename: PORTAINER.IO
date: 2024-03-24
categories: []
tags: []
image: https://www.portainer.io/hubfs/Mass-Exodus.webp
pagetype: article
filedate: 2025-01-18
-->

#### Learn about the challenges of migrating from VMware to another hypervisor and explore an alternative solution: migrating VMs into containers

With the seemingly endless announcements coming out of VMware / Broadcom regarding license and product changes, it's no wonder VMware customers are worried about the future.

It's also pretty obvious that the VMware competitors are loving the opportunity to tell a story about how you can switch to their solution, with no complications at all - and some of them even have the tooling to assist with this.

So, what's the problem?

Well, a migration, like any IT project, needs two things:

- Planning; and
- Execution.

With something as critical as your hypervisor, you don't just tear in without knowing exactly what you need to do and how to do it. At least, not if you want it to go well.

Even if the replacement vendors claim to have all the tools, to complete a migration like this you should expect to spend many hours on the planning and execution. As a rule of thumb, 8 hours per VM would be a good starting point to help you estimate the overall time you might need, with actual data copy time on top of that.

When scoping out your estimate, you will need to consider:

- Completing a full VM inventory
- VM dependency mapping - which VMs rely on each other and in what ways
- Outage planning - scheduling downtime with all affected parties
- DR planning - what to do if it all goes wrong, and how will you offer DR with the new hypervisor
- Backup and Recovery planning - how will you perform VM backups with the new hypervisor
- License implication planning - for example MAC address changes and Windows reactivation
- and much more, including whether your app vendor even supports hypervisors other than VMware.

If you have just a handful of VMs, this might be a trivial process. When you get into the hundreds or even thousands of VMs, the time/cost is very real. More often than not, you will also need to engage the services of an external consultant to help you, so then the costs start to stack up fast.

Even worse, VMware has for a long time sold its software as bundles, and these bundles include a range of ancillary tools. If you are looking to eject VMware from your estate, it's not just the hypervisor you need to consider, it's the replacement of the operational management tooling that surrounds it too. Then there's your VMware-trained IT staff, who likely have a decade's worth of experience managing your platform, and who now need to be retrained in something new.

So what's the alternative?

Don't migrate from VMware to another hypervisor.

This is very much a differentiated, and maybe even a confrontational suggestion... but why not? Because it's a move sideways. Other than saving you VMware license fees (which I'm sure are significant), it doesn't move your business forward in any way.

Take this change for the opportunity it is and invest the time and money that you would need to spend on changing hypervisors and instead:

Migrate your VMs into Containers.

To be clear, this isn't saying that you should completely refactor your application to native microservices and onto a platform such as Kubernetes - although, if you can, great (and many ISVs already support their apps in containers) - instead start with something as simple as spinning up a Ubuntu container, using rsync to copy files over from your VM, install any required application components, and then use a solution like supervisord as the "PID1" process that the container runs as (and running this on plain old Docker on bare metal with shared storage). Sure, this is a derivative of a "lift and shift", but at least it gets you onto a more flexible platform and way of working.

There are even tools from cloud providers such as [Google](https://cloud.google.com/migrate/containers) and [AWS](https://aws.amazon.com/blogs/architecture/migrate-your-applications-to-containers-at-scale/) to help you to move to their platforms, but for a Linux engineer who has had some exposure to containers, it's relatively straightforward to do it yourself.

Lots of container solution vendors are trying to convince you to switch to KubeVirt (or their variant of it), which is a way of running VMs managed by Kubernetes. While that is a neat technology, it really is just a VM-to-VM migration. Don't get confused by the Kubernetes component of this. I'm talking about actually putting the contents of your VM into a container, not a VM masquerading as a container.

So, if you want to move on from the VMware ecosystem, you have a choice to make:

- Spend $$ and move sideways; or
- Spend (likely the same) $$ and move
**forward**.

As a former CIO, I know which option I would prefer.

What will you do?

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/announcing-k2d.io
title: Announcing k2d.io
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/announcing-k2d.io
hostname: portainer.io
description: Want Kubernetes on your edge devices, but not enough resources to run it and your apps? Look at this new project k2d.io
sitename: PORTAINER.IO
date: 2023-07-04
categories: []
tags: []
image: https://www.portainer.io/hubfs/K2D%20Twitter%20Image%201600x900.png
pagetype: article
filedate: 2025-01-18
-->

For a long time, we have been watching the development of “lightweight” Kubernetes distributions and their marketing towards being used at the “edge”, and claiming to be ideal for IoT deployments.

Our [own testing](/blog/comparing-k0s-k3s-microk8s) found that all 3 of the leading lightweight distributions still needed over 250MB of memory just to “idle” the Kubernetes instance. For most cases, we found that they actually needed closer to 400MB of RAM (just to deploy and sit idle, not even running any apps). 400MB is generally seen as very low memory consumption, and this is true when looked through the lens of deployment on an edge server, an Intel NUC with 8GB RAM, or even a Raspberry Pi4. But when we look at this through an Industrial IoT lens, the devices predominately being used in the field are ARM32 powered, and with only 1GB RAM. Losing almost half of that RAM just for the sole purpose of being able to be managed via a Kubernetes construct is crazy.

In addition to RAM consumption, all three of the lightweight Kubernetes distributions also require CPU cycles to maintain the Kubernetes state. This is predominantly for the scheduler reconciliation engine to run its looping process, but r'egardless, it's burning CPU cycles just to keep what's running, running. Finally, due to Kubernetes being a cluster orchestrator, even a single node deployment is treated as a cluster, and as such, requires a cluster quorum. This quorum is a database that resides on the local disk of the device, and maintaining this quorum involves disk IO. When your device is equipped with SD Cards, then this disk IO can cause early drive failures as previously discussed [in this blog.](/blog/sd-card-longevity-and-docker/kubernetes) Again, when you just need to manage a single device, this overhead is pointless.

So, what have we done about this?

The benefit of Kubernetes for the edge is actually higher order.

Kubernetes offers a universal language and consistent API for application deployments, and this universal language and API allows ISVs (and application support engineers) to consistently deploy their applications anywhere, everywhere, regardless of the underlying system configuration. Truly awesome. So Kubernetes at the edge allows engineering support staff to create a universal deployment script (YAML) for their industrial application stack (eg MQTT Broker, OPC-UA Gateway, Kafka, Node-Red, etc) and then use that stack to deploy their application on any type of hardware device, anywhere in their industrial landscape.

What's not important is actually RUNNING Kubernetes. What is important is being able to use the Kubernetes universal deployment language construct to deploy an application using the Kubernetes API. Given Kubernetes is “just” an orchestrator of container application deployments, what this actually means is being able to use the Kubernetes universal deployment language to deploy applications inside Containers.

So, Portainer has taken a different path to solving the problem of using Kubernetes at the Industrial Edge.

We are pleased to announce a new project, k2d.io (Kubernetes to Docker), a Kubernetes to Docker API translator.

K2d.io is a simple, single-container deployment that runs on either Docker or Podman-enabled Linux devices (ARM, ARM32, x86, x86-64). K2D implements a cut-down Kubernetes API server that listens for inbound Kubernetes API instructions, and then decodes the intent of the instruction, translates it (in real-time) to the corresponding Docker API commands, and then executes these Docker commands directly on the device. In effect, it allows you to control a remote Docker instance using kubectl CLI running on engineer laptops, or using Kubernetes native toolsets. K2D is NOT Kubernetes, it’s an API translator. As such, the overhead to run the translator is tiny, in the order of 22MB, really low CPU overhead

(and only when executing commands, no CPU used when not actively translating), and almost no disk IO.

Why do we think this is important?

Simple really. There are millions of Industrial Compute devices out there in the field that are capable of running Linux and Docker (often via a simple firmware update), and yet these devices are entirely unserviceable by the lightweight Kubernetes distributions. We want to get these existing assets reusable in the Industry 4 world, and that means modernizing. In the Industry 4 world, this is known as “brownfields” or “retro-fit”, and that’s exactly what we want to do. Make what was old, new, through a simple “bolt-on” accessory (in our case, a software container).

Do we think this is awesome? We sure do! We think it's going to enable a really high degree of standardization across the Industrial Edge, without having to force new hardware purchases, or accepting a massive loss of usable RAM.

Our version 0.1 alpha release (available soon on k2d.io) implements a select few Kubernetes API endpoints, but we plan to expand this based on community feedback. Remember, we are not trying to replace lightweight Kubernetes, and we still recommend these be used where the hardware is sufficient. So we will really limit the API endpoints we implement to only those absolutely needed for the specific use case intended for K2D.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/author/neil-cresswell/page/4
title: Portainer News and Blog | Neil Cresswell, CEO (4)
author: Neil Cresswell; CEO June
url: https://www.portainer.io/blog/author/neil-cresswell
hostname: portainer.io
description: Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization. (4)
sitename: Portainer.io
date: 2023-06-29
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

### Blog Post by Neil Cresswell, CEO

[
](https://www.portainer.io/blog/how-to-manage-portainer-environments-via-docker-cli)

Neil Cresswell, CEOJune 29, 20233 min read

### How To: Manage Portainer Environments via Docker CLI

Ever wanted to use the Docker CLI to access environments managed by Portainer? Here's ...

Start Reading
[
](https://www.portainer.io/blog/kubernetes-has-it-really-set-us-back-10-years)

Neil Cresswell, CEOJune 23, 20234 min read

### Kubernetes, has it really set us back 10 years?

While Kubernetes projects are often challenging, has the tech really set us back 10 ...

Start Reading
[
](https://www.portainer.io/blog/monitoring-a-swarm-cluster-with-prometheus-and-grafana)

Neil Cresswell, CEOMay 25, 20233 min read

### Monitoring a Swarm Cluster with Prometheus and Grafana

Learn how to use a simple Portainer App Template to deploy Prometheus and Grafana to ...

Start Reading
[
](https://www.portainer.io/blog/sd-card-longevity-and-docker/kubernetes)

Neil Cresswell, CEOMay 15, 20234 min read

### SD Card Longevity and Docker/Kubernetes

Using SD Cards in your Docker Hosts and want to extend the longevity, read this blog...

Start Reading
[
](https://www.portainer.io/blog/who-should-consider-portainer)

Neil Cresswell, CEOApril 6, 20233 min read

### Who should consider Portainer?

Who should consider adopting Portainer? Read if your organization should be speaking to ...

Start Reading
[
](https://www.portainer.io/blog/how-to-mount-a-cifs-share-to-a-container-in-docker-desktop)

Neil Cresswell, CEOMarch 27, 20231 min read

### How To: Mount a CIFS share to a container in Docker Desktop

How to: Mount a CIFS share to a container in Docker Desktop.

Start Reading
[
](https://www.portainer.io/blog/how-to-get-mysql-on-kubernetes-with-pvc-from-a-block-storage-device-working)

Neil Cresswell, CEOMarch 17, 20231 min read

### How To: Get MYSQL on Kubernetes with PVC from a Block Storage Device working

How to get MySQL 5.7 and newer working on a Kubernetes cluster with a block storage ...

Start Reading
[
](https://www.portainer.io/blog/kubernetes-get-logs)

Neil Cresswell, CEOFebruary 21, 20232 min read

### How to: access Logs, Shell / Console, and Stats in Kubernetes Clusters with Portainer

See how to easily get Kubernetes logs, shell/console, and stats in Kubernetes, with ...

Start Reading
[
](https://www.portainer.io/blog/why-you-should-crawl-walk-run-when-adopting-containerization-and-migrating-legacy-applications-to-containers)

Neil Cresswell, CEOJanuary 17, 20233 min read

### Why You Should Crawl, Walk, Run When Adopting Containerization and Migrating Legacy Applications to Containers

Considering adopting containerization and Kubernetes? A crawl, walk, run approach to ...

Start Reading
[
](https://www.portainer.io/blog/deploying-portainer-business-on-civo-cloud)

Neil Cresswell, CEODecember 2, 20221 min read

### Deploying Portainer Business on Civo Cloud

Portainer Business Edition, now available on the Civo Marketplace

Start Reading
[
](https://www.portainer.io/blog/managing-kubernetes-shouldnt-be-hard)

Neil Cresswell, CEOOctober 8, 20223 min read

### Managing Kubernetes shouldn't be hard!

Managing Kubernetes shouldn't be hard. This blog post delves into some of the pitfalls ...

Start Reading
[
](https://www.portainer.io/blog/pull-latest-image-feature-in-ce)

Neil Cresswell, CEOSeptember 16, 20223 min read

### "Pull latest image" feature in CE

Clarification on the "pull latest image" feature for Stacks.

Start Reading

---
<!--
URL: https://www.portainer.io/blog/how-to-use-the-digitalocean-container-registry-within-portainer
title: How to: Use the DigitalOcean Container Registry within Portainer
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/how-to-use-the-digitalocean-container-registry-within-portainer
hostname: portainer.io
description: How To: Use The DigitialOcean Container Registry with Portainer
sitename: PORTAINER.IO
date: 2024-02-11
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Feb-11-2024-12-53-13-6001-AM.png
pagetype: article
filedate: 2025-01-18
-->

Recently, we were asked, "How do I configure and use the DigitalOcean container registry in Portainer?"...

We do not have documented procedures for this, so to answer the question, we thought it was easiest to do via a blog..

First of all, you need a DO account.. then create a container registry

Give your registry a unique name, select the region, and commercial plan you need, then click "create"

Now we need to get the credentials to use this repo.

Select API in the management sidebar

then Generate a new Token

Give your token the applicable validity, and grant write access (so you can push images to the repo)

Take note of your API token, it won't be shown again.

OK, now switch to your Portainer Instance...

Click Registries, in the sidebar, and then "Add Registry"

Fill in the registry details... note the registry URL is registry.digitalocean.com, the username is the EMAIL ADDRESS used for your account, and the password is the API token.

Now let's configure this registry for browsing within Portainer.

Click the Browse button to start the configuration

Click "Configure"

Enable TLS, and disable certificate verification, then click test. See the success toaster, then click "save"

You can now see your registry (and see nothing is in it).

So let's tag an image and push it..

Go to one of your Docker environments, then navigate to images, and select an image to use to test this.. I will use fluent-bit image.

Select the DO registry from the dropdown, and in the image, add the path you want to use.. we have the portainer-demo repository, and we want to tag as fluent-bit:latest (see pic) then click tag.

Click the UP arrow to push to the registry.

See the success toaster.

OK, so now go back to registries, and browse.. you can see the image is now present.

To use this registry when running a container, just select it in the box... type-ahead should work just fine too..

So that's how easy it is to connect Portainer to your DO Container Registry.

Hope this helps all of you Portainer + DigitalOcean users out there.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/which-kubernetes-distros-does-portainer-work-with
title: Which Kubernetes distros does Portainer work with?
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/which-kubernetes-distros-does-portainer-work-with
hostname: portainer.io
description: Discover how Portainer seamlessly integrates with various Kubernetes distributions, making cluster management easier and safer. Explore the compatibility with popular distros and the advanced features available.
sitename: PORTAINER.IO
date: 2024-08-01
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/Portainer%20and%20Kubernetes%20distros.jpeg
pagetype: article
filedate: 2025-01-18
-->

For a while now, Portainer has offered a unified management control point for Kubernetes - any Kubernetes, anywhere - but recently we have been asked specifically if we know of any concerns or considerations with a few named distros such as; MicroK8s, Talos, Openshift, KOs, K3s, Rancher and Amazon EKS. I thought I would try them all out and I also tried; Azure AKS, Amazon EKS, Google GKE, Civo Kubernetes, Digital Ocean Kubernetes, Linode Kubernetes, Vultr Kubernetes.

As anyone who knows Portainer is likely aware, we do not provide any Kubernetes distribution; we focus solely on the "configuration and consumption" side of Kubernetes. By that I mean we make it really easy for Ops to configure a cluster (authentication, access, quota, security policy etc), and for Users (Devs) to consume the cluster (deploy apps, triage apps, configure GitOps pipelines etc). This has been our focus because we believe that raw Kubernetes requires too much specialist knowledge to operate, and we want to make it easier and safer. As a byproduct of that focus we are required to work on top of many different Kubernetes distributions, from the smallest to the largest, from community-supported to enterprise-supported. You name it, we likely have a customer using it.

Anyway, while we do a degree of QA against the most common distros, we cannot possibly test Portainer against all of them.

I decided it would be an interesting experiment to spin up as many of the distributions as I could, especially all of the ones our customers and/or users have mentioned to us in passing. So this is what I have done.

I now have an instance of Portainer that is managing the self-hosted distros:

- Canonical MicroK8s
- Talos Kubernetes
- K3S
- K0S
- Rancher RKE
- OpenShift OKD
- Amazon EKS Anywhere

Of course, I also spun up and connected Portainer to:

- Azure AKS
- Amazon EKS
- Google GKE
- Civo Kubernetes
- DigitalOcean Kubernetes
- Linode Kubernetes
- Vultr Kubernetes

though I tore these Cloud ones back down again after testing, because of the cost.

#### Findings

Running Portainer through its paces, I could use every single "Platform" feature, including our centralized user authentication and RBAC (creating users with corresponding roles and role bindings) in the managed clusters. I was able to enable advanced security for each cluster (which deploys and configures OPA Gatekeeper, with a number of pre-set policies). I was able to deploy and configure GitOps pipelines to each of the clusters using Portainer's integrated GitOps engine, and I was able to centrally access all of the clusters via Portainer's Kubernetes API proxy endpoint (meaning I did not need to expose the Kubernetes API externally on any of these clusters). I was able to view metrics and events, I was able to interact with the nodes to see cluster and node health, and I was able to do all of this from a single UI with a consistent UX regardless.

I would call that a win.

I plan to keep this environment running and add to the list as more distros become requested. I would also love to spin up VMware TKG, but its very big.

Are there any distros that I have not tested, and that you would like me to try out? Leave a comment and I will try it.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/help-me-pitch-portainer-to-my-business
title: Help me pitch Portainer to my business (email template)
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/help-me-pitch-portainer-to-my-business
hostname: portainer.io
description: Learn how to pitch Portainer to your business with this email template. Discover the benefits of this container management solution and how it can streamline your operations.
sitename: PORTAINER.IO
date: 2024-06-09
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/writing%20a%20business%20case%20to%20support%20a%20purchase%20of%20Portainer.jpeg
pagetype: article
filedate: 2025-01-18
-->

We're often asked if we can provide some information to help pitch Portainer to businesses or managers. So here's an email template that you can use for this purpose.

Hi [Insert Manager Name],

Some time ago, I signed up for a Portainer 3 nodes free offer [or a Portainer Free Trial, or Portainer CE].

I signed up to evaluate Portainer’s container management solution and see if it lived up to the promise of helping to simplify the adoption of containers, and in turn, achieve significantly shorter time-to-value.

After a positive evaluation of the platform and hearing excellent recommendations from my network, I would like to request a purchase of Portainer so we can deploy it for our full environment.

If you aren’t familiar with Portainer, it is a highly reputable, container management solution that will enable us to:

- Lower our overall cost to manage a container platform, through greater operational efficiency
- Save time by deploying apps rapidly and centralizing our container management
- Reduce security risks by centrally managing and securing our container environments quickly, and with pre-configured templates
- Minimize user complexity with sane defaults to keep our team on the right track as we all get familiar with this new technology.

Another reason that will make Portainer valuable to our business is that while it’s true that Portainer is just one tool amongst several tools that we require for this project, Portainer replaces the need for several of these tools, for example:

- Cluster Centralized Authentication and Role Based Access Control
- Security Policy Engine
- GitOps Pipeline Tooling
- Centralized Log Viewing and Performance Metrics visibility

Here’s four case studies from Portainer customers for your review:

[P&G partners with Portainer to containerize their legacy app](/pg-partners-with-portainer-to-containerize-their-legacy-app)[Healthcare: Software development and delivery at scale](https://www.portainer.io/customers/voc/delivery-development-at-scale)[Portainer helps San Diego Superior Court enable high availability and automation](https://www.portainer.io/san-diego-court-enabling-high-availability-and-automation)[Tech Titan: Portainer helps simplify complex infrastructure management](https://www.portainer.io/tech-titan-portainer-helps-simplify-complex-infrastructure-management)

My overarching reason for requesting this purchase is simple: I want to increase our ability to create results and help drive our business forward with this new container management technology. I’m excited to be a key part of this project and am committed to sharing what I’ve learned with my colleagues.

**Who's behind Portainer?** Portainer was created by founder Neil Cresswell to help companies access the truly transformative power of containers. The open-source version of Portainer is used by more than 900,000 users worldwide. The business edition version of Portainer which includes the critical security features we need, is used by 30,000 businesses across the globe. I believe a Portainer purchase is an important step in our container management journey, and that it will speed up our container adoption. Along with the purchase, comes support from the Portainer technical experts which will ensure that we’re well supported along the way.

For further help, please refer to our page "[Building a business case for Portainer](/building-a-business-case-for-portainer)".

If you'd like more specific information to support your business case, please [Contact Sales](/contact-sales).

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/operational-maturity-with-containers
title: Operational Maturity with Containers
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/operational-maturity-with-containers
hostname: portainer.io
description: Before you go "full steam" with containers, first ensure you know the operational impacts
sitename: PORTAINER.IO
date: 2024-04-04
categories: []
tags: []
image: https://www.portainer.io/hubfs/Red%20Sneakers%20Asphalt%20Road.jpg
pagetype: article
filedate: 2025-01-18
-->

Containerization has taken the world by storm! The number of organizations using application containers as a core component of their IT landscape continues to grow. However, fewer and fewer people truly comprehend the operational changes needed to run containers in production successfully.

Docker and Kubernetes are infrastructure components that easily allow the deployment of applications and their required networking and storage elements. This would have previously needed cross-functional team involvement (Infra Team, Network Team, Dev Team), so Docker and Kubernetes's automation is a significant efficiency gain. This behavior is one of the many benefits of containers; however, this benefit also introduces additional complications. With the introduction of new technology, there are always benefits and complications; containers follow the same pattern. Unless the operators of the container platform have a good understanding of infrastructure components, they stand a real risk of misconfigurations that may cause unreliable/unpredictable performance or, worse, insecure deployments. Sound familiar; it was the same with virtual machines.

When an organization elects to adopt containers, it should do so with "eyes wide open," by that, be fully aware that once the first container is deployed, you have started evolving your organization's IT operating model. It's impossible to conceive a critical production environment that is 100% decentralized and managed without consideration of tooling, SLA/OLAs, and ensuring that the people operating the platform have the knowledge required to operate it correctly.

In any of the hundreds of community forums, user groups, discussion channels, etc., you will read over and over again desperate cries for help from operators who are tasked with supporting a platform they are underequipped to support. Often, they need urgent help as something that was working is no longer working, and they don't know why. Or they need help because after spending days/weeks/months trying to complete a task, their time is up, and their boss is breathing down their necks. These are sure-fire signs that containers were adopted without forethought, so the teams are now struggling for survival.

Adopting containerization without concurrently training at least some of your staff in container fundamentals is a mistake. As a foundational technology, Docker should always be the starting place, and additional skills should be acquired in orchestration and observability only once the foundations are strong. But even before starting to learn Docker, the operational staff should already be very familiar with Linux, Networking, Storage (shared storage especially), and how these all play their part. We often see operators leaping straight into Kubernetes without even a hint of foundational knowledge in Docker. This is dangerous.

So, if you are on the Containerization journey, have you made the required organizational changes to support it entirely, or are you sitting on a ticking time bomb waiting for your first event?

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/secure-your-kubernetes-deployment-the-portainer-way
title: Secure your Kubernetes deployment, the Portainer way
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/secure-your-kubernetes-deployment-the-portainer-way
hostname: portainer.io
description: Our CEO Neil expands on a recent LinkedIn post on the complexities of securing a Kubernetes cluster, and how most people run with an insecure setup.
sitename: PORTAINER.IO
date: 2024-07-29
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/kubernetes%20cluster%20security%20complex-1.jpeg
pagetype: article
filedate: 2025-01-18
-->

I came across a [great LinkedIn Post](https://www.linkedin.com/posts/hijmen-fokker-b84bab63_kubernetes-security-activity-7222221540975599618-c9Tc?utm_source=share) by Hijmen Fokker on the complexities of securing a Kubernetes cluster, and how, due to complexity and a lack of understanding, most people run with an insecure setup.

This is one of the reasons we endeavor to make things simple in Portainer.

Our goal is to put complex activities within the reach of the everyday sysadmin, and when talking about Kubernetes that means critical actions like policies, security, governance, and compliance.

Let me quickly show you how Portainer helps address these issues raised.

##### Use Private Networking

By default, Kubernetes API’s and applications are all accessible publicly, over the internet. This increases the attack surface of your cluster.

Implement a private network and only expose the required endpoints.

100% agree here, unless there is a compelling reason why you need to expose your Kubernetes API to the world, don't. Ideally, you don't even expose the API outside of a dedicated "out of band" management network, and you use a secure mechanism to get into that isolated network. We kept our VMware clusters on OOB networks, we keep our network switches on OOB networks, and we keep our firewalls on OOB networks, so why oh why would it all of a sudden be a good idea to put your Kubernetes API (which equates to a management network) on the public internet? Clue: It's not.

Portainer deploys an Agent inside each managed Kubernetes cluster, and that Agent communicates with the Kubernetes API via its internal IP. When using Portainer, you can block all access to your Kubernetes API from outside the cluster, ensuring security of your management interface. Of course, if you need to access the management control of the cluster remotely, you can do this securely through Portainer's [Kubernetes API Proxy](https://docs.portainer.io/user/kubernetes/kubeconfig).

##### Set up the right RBAC

Not all engineers need administrator access to the cluster. Especially when you implement GitOps, for most engineers “Read-only” access is sufficient. This can be implemented using Kubernetes roles.

Always use the principle of least privilege.

Also, 100% agree. The amount of times I see "everyone's an admin" because configuring users, user auth, and RBAC in Kubernetes was seen as "too hard" is simply crazy. It's very common to see the default Kubernetes Admin token passed around and used by everyone in a Dev/Ops team. You cannot configure RBAC if you do not have user accounts defined, and you cannot define user accounts without some sort of user integration (eg OIDC) for Kubernetes.

Portainer acts as the centralized user authentication and authorization engine for Kubernetes. When a user is created in Portainer, and granted access to a Kubernetes cluster, we automatically create a shadow user in the cluster, and then assign an RBAC role to that user. Which RBAC role? It depends which of the [pre-defined Portainer RBAC roles](https://docs.portainer.io/admin/users/roles) have been assigned to the user. Portainer makes user authentication and RBAC assignment a very simple task, and does not require any advanced Kubernetes knowledge to achieve this.

##### Minimize Vulnerabilities

Especially when using open source software, patching vulnerabilities is critical for a secure environment.

Yes, this is good practice, and should form a core component of your CI process. Images from companies like Chainguard are always a good place to start.

Portainer lets you [define the registries that users can leverage](https://docs.portainer.io/user/kubernetes/cluster/registries) for their deployments, so you can define only your trusted internal registries, and disallow access to all others.

##### Don't use passwords

Using a central Identity and Access Management (IAM) solution is important. Passwords should not be used anywhere.

For sure, you should never use passwords stored inside an authenticator deployed in the cluster, you should always rely on an external authentication source for your user repository.

Portainer is a centralized user authentication engine, but obtains the user authentication from upstream repositories such as [LDAP](https://docs.portainer.io/admin/settings/authentication/ldap)/[MS AD](https://docs.portainer.io/admin/settings/authentication/active-directory), or any [OAuth](https://docs.portainer.io/admin/settings/authentication/oauth) source, even if this is configured with MFA and conditional access policies.

So, the [original author](https://www.linkedin.com/in/hijmen-fokker-b84bab63/) of the post is spot on - take the security of your cluster seriously. And if you want an easy way to get it done, [take a look at Portainer](/).

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/the-importance-of-keeping-your-portainer-version-up-to-date
title: The importance of keeping your Portainer version up to date
author: Rich Sharples
url: https://www.portainer.io/blog/the-importance-of-keeping-your-portainer-version-up-to-date
hostname: portainer.io
description: Keep your Portainer version updated to ensure security, performance, and support for the latest technologies. Learn about benefits and update policies for optimal deployment management.
sitename: PORTAINER.IO
date: 2024-11-21
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/Software%20updates.jpeg
pagetype: article
filedate: 2025-01-18
-->

This is a quick reminder about the importance of keeping software up to date. Whether you are using Portainer in your home lab, or managing a large fleet of Kubernetes clusters in the data center or cloud - it’s essential to ensure Portainer and other software you deploy is kept up to date.

While it may seem easier to stick with currently running versions of software, it’s nearly always more cost effective in the long run to stay current - the hidden costs of data breaches, reputational damage, and regulatory fines will significantly outweigh any perceived short-term savings or convenience.

Portainer is committed to security and as well as working with security researchers and using modern vulnerability scanning tools - we perform routine third party audits. This year alone we’ve addressed dozens of CVEs in Portainer releases. Check out the [https://docs.portainer.io/release-notes](https://docs.portainer.io/release-notes) for more information. Also check out our knowledge base article "[How does Portainer respond to CVEs?](https://portal.portainer.io/knowledge/cve)". Finally you can find a list of current CVEs in publicly available databases such as [Mitre](https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=portainer).

Aside from the additional risks of cybersecurity attacks when running unpatched software with known vulnerabilities, you should also factor in some of the other benefits:

- As customers expand their Portainer deployments, we’re constantly improving the performance, scalability, and stability of Portainer for managing business critical workloads whether in the data center or on the factory floor.
- Support for the latest versions of the products and technologies that Portainer integrates with including Kubernetes, Docker, Podman, and Identity, and cloud services.
- We’re constantly adding new features to make Portainer more powerful and make your life easier - take a look out our release notes for any version here
[https://docs.portainer.io/release-notes](https://docs.portainer.io/release-notes)

To help schedule and plan your updates, we’ve recently published [Portainer BE Lifecycle Policy](https://docs.portainer.io/start/lifecycle)[. In brief, we maintain two release “channels”:](https://www.notion.so/Portainer-BE-Lifecycle-Policy-1352d0550eae80f29271f2cc6e23f73d?pvs=21)

- Long Term Support releases (identified with an “LTS” suffix) are supported until the release of the next LTS version plus a 3 month migration window.
- Short Term Support releases (identified with an “STS” suffix) are supported until the release of the next STS or LTS version.

Older versions that fall outside of this policy are no longer maintained by Portainer and currently that includes versions prior to 2.21.

Updating couldn’t be easier - for LTS releases; the web console will notify you of available updates and allow you to update in place without having to backup and restore your settings manually.

To update to STS releases as well as information on options and best practices for updating Portainer deployments, take a look at this page [https://docs.portainer.io/start/upgrade.](https://docs.portainer.io/start/upgrade)

[With 30+ years in software, Rich brings seasoned leadership in product and technology. His expertise spans software development, product management, and fostering innovation.](https://www.portainer.io/blog/author/rich-sharples)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/sd-card-longevity-and-docker/kubernetes
title: SD Card Longevity and Docker/Kubernetes
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/sd-card-longevity-and-docker/kubernetes
hostname: portainer.io
description: Using SD Cards in your Docker Hosts and want to extend the longevity, read this blog...
sitename: PORTAINER.IO
date: 2023-05-15
categories: []
tags: []
image: https://www.portainer.io/hubfs/sdcard.jpeg
pagetype: article
filedate: 2025-01-18
-->

Docker as a technology has enabled radical changes in the world of applications; how apps are built, shipped, and supported. Containers are now the de-facto way modern applications are adopted in almost every industry and every use case.

This change enabled "edge computing" to gain rapid momentum and is the underlying deployment mechanism for Industry 4 / IOT application workloads.

Docker was initially designed to run on servers rather than lightweight devices. While it works perfectly fine on all kinds of hardware, there are unintended negative consequences when SD cards are used as the primary storage mechanism on hosts.

SD cards (well, memory cells in SD cards) have a limited number of write cycles before they become read-only; for most cards, this is 10,000 times (per cell), but there are enterprise-class ($$) cards that offer more, and pro class cards that include software features to better distribute writes across cells (TRIM / Wear Leveling). 10,000 seems like a lot, and in the photography world (where SD cards originated), it is a lot, but in the IOPS-heavy world of Linux disk IO, 10,000 can run out quickly.

When using SD Cards with containers (Docker/Podman), you need to consider all of the elements that would cause a write to occur:

- stdin/stdout/stderr - logs for containers are written to a journal file that exists on the Host FS; this means a file is being constantly written to (and deleted/recreated whenever the container is recreated)
- Image files - when pulling an image, the TAR file for each layer is downloaded to the docker host, then extracted before being placed into the image repository. This causes temporary writes for the downloaded files and then writes for the extracts.
- Container run-time FS - the docker overlay FS sets up a redirected file system for each container based on the container image (always read-only) and a writeable redirected location for any run time changes. This runtime location is destroyed and recreated whenever the container is instantiated.
- Writes from actual data being persisted - any data stored in a persistent container volume on the host has its read/write IOPS mix. Data stored temporarily (such as an MQTT queue) would significantly impact the IO write counter.
- Orchestrators, such as Kubernetes, generate disk IO; you should also be aware. Sure, lightweight Kubernetes runtimes exist, such as MicroK8s, K0s, and K3s, that use different DB engines, but still, there is a write overhead of maintaining orchestrator state in a DB. etcd as the Kubernetes database is
[IOPS heavy](https://etcd.io/docs/v3.3/op-guide/hardware/#disks)and would have a profoundly negative impact on SD card lifetime.

So, what can you do to extend the lifespan of your SD Card by removing unneeded writes?

A couple of things.

1) [disable noatime](https://opensource.com/article/20/6/linux-noatime) - atime (last accessed time) writes a timestamp into the FS every time a file is accessed. This is unnecessary for most systems, so it can be disabled. To disable, edit /etc/fstab, and add noatime to the options as per the pic below.

2) Adjust the threshold at which the Linux Kernel swaps RAM into Disk - By default Linux Swaps to disk when memory gets below 60% free. You can increase this threshold by adjusting the setting vm.swappiness to 10% (mem must get below 10% free before swapping - to be aggressive and keep everything in memory, set this to 1). To make this change, edit /etc/sysctl.conf and add [vm.swappiness=10](https://linuxhint.com/understanding_vm_swappiness/), then save and reboot.

3) Redirect docker temporary image downloads to tmpfs - by default, image files downloaded to a docker host are pre-staged into the /var/lib/docker/tmp directory before being extracted and loaded into the image repo. This is an inefficient use of the SD card, so a dedicated TMPFS mount should be added and mapped to this volume. Edit fstab and add a mount as per the below (note if you need more than 1GB temp storage space, increase this, but note it uses RAM):

4) Consider using TMPFS for your container volumes if they do not need to persist data beyond reboots (i.e., the container volume acts as a temporary cache). You can pre-create the named volume in Portainer and then use this named volume when deploying your container. Note that the size you set here uses physical RAM.

5) Use a Docker [logging driver](https://docs.docker.com/config/containers/logging/configure/) that redirects the logs of your containers to a central logging system, removing the disk IO load of the Docker built-in JSON logging driver. You can also look to use the JournalD driver, which writes container logs to the host logfile, and then configure the host with a [Log2RAM](https://github.com/azlux/log2ram) driver, keeping logs purely in RAM.

6) Final suggestion is to purchase an SD card that is a LOT larger than you need. Why? Because each memory CELL can only be rewritten a certain number of times, so to increase longevity get more cells... and that means larger capacity. Writes are spread across all cells on the SD card, so more cells, less writes per individual cell. Be aware that with MLC cards, it's not a 1:1 cell to MB mapping, but it's a good rule of thumb that a 64GB SD card has many more cells than a 16GB one.

**In Summary...**

Two of the mitigations recommended above offset SD card longevity with RAM utilization, so if you are RAM constrained, these won't apply. If you are using a resource constrained device AND have to use SD cards, just be aware that the cards will likely expire much sooner than you might think.

I hope this helps you extend the life of your SD Cards when used in the field, at the edge, or at home on RPi's.

Neil

To read more about Portainer's solution for IOT/IIOT, [click here](/edge-iiot-iot-device-management)

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/comparing-k0s-k3s-microk8s
title: Comparing Resource Consumption in K0s vs K3s vs Microk8s
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/comparing-k0s-k3s-microk8s
hostname: portainer.io
description: This blog post compares K0S, K3S, and MicroK8s, and the resources required for each.
sitename: PORTAINER.IO
date: 2022-08-22
categories: []
tags: []
image: https://www.portainer.io/hubfs/Comparing%20Resource%20Consumption%20in%20K0s%20vs%20K3s%20vs%20Microk8s%20v1.png
pagetype: article
filedate: 2025-01-18
-->

Recently I was in discussions with a client that wants to use Kubernetes on their factory floor IIOT devices (ATOM CPU, 1GB RAM), and they inquired as to which lightweight Kubernetes distribution Portainer officially recommends. I mentioned that we don't have any formal recommendations and that all three (k0s, k3s, and MicroK8s) are relatively similar, and all claim to be optimized for low-resource deployments. I recommended the client try all three themselves.

Well, the client came back to me, complaining that they couldn't get any to function reliably and that I should try them myself. So I did, and the results surprised me!

Let me show you my results ...

I deployed 3x VMs, each with 1 CPU and 1 GB RAM. This is to represent the constrained node that would often be seen in Edge Compute environments. On each of these, I deployed Kubernetes using the default settings. I then ran a simple "free -m" command on each to see how much RAM was being used to "idle" the cluster.

Note, ignore the "free" value as it's misleading. The actual free is a combination of free and reclaimable buffer cache.

K0s

K3s

MicroK8s

Whilst MicroK8s installed, i was unable to run ANY MicroKs8s commands.

I contacted Canonical to ask their advice about the above, and was told that by default, MicroK8s installs the Calico network driver and uses dqlite rather then etcd, which is not needed for single-node deployments. They recommended I disable HA (switches from Calico to Flannel and dqlite to etcd) using the command "microk8s disable ha-cluster" and then retry my tests. So I did this.

The resulting memory used dropped by 159MB :

Out of interest, I wanted to see what a standard docker deployment would use on the same VM spec. It only uses 216MB of RAM.

Base OS

Ok, but this memory usage includes the base OS... and that is correct. It's why the base OS should be running as "minimal" services as possible. My deployment was based on Ubuntu Minimal, and the VM with nothing running on it at all uses 167MB. Again though, this is a real-life scenario.

OK, so now we have our Kubernetes Single-Node Clusters up.

Let's try and deploy a simple MySQL instance.

I see the pod has started on all 3 platforms,

so how about used memory now ... up to 868MB of 971MB total.

Unfortunately, once the POD started, K0s, K3s, and MicroK8s API servers stopped responding to further API commands, so I was unable to issue any kubectl commands from this point forward. This effectively rendered the environments unusable.

I wanted to see the same thing on the Docker Node, so deployed MySQL using 'docker run mysql' and saw the used memory was only 396MB:

My Summary

None of the lightweight Kubernetes distributions (or at least, their out-of-the-box deployment) seem to be suitable to be used on devices that have 1GB of RAM or less. Not if you want to actually deploy any applications on them, that's for sure. I would recommend that lightweight hardware continues to use Docker standalone if containers are needed to be used.

Quick Table to summarise.

| Distribution | Used |
| Base OS, no Kubernetes | 167MB |
| K0s | 658MB |
| K3s | 750MB |
| MicroK8s | 685MB |
| MicroK8s (no HA) | 526MB |
| Docker | 216MB |

One other thing to note. Kubernetes API server generates a pretty decent amount of Disk I/O and so if you run on CF cards, expect them to to wear out in a relatively short space of time, and also expect to see a lot of API timeouts occuring (leading to kubernetes instability). At a minimum, you need to run on SSD storage (not even USB stick storage is fast enough).

Now, as an added bonus...

Out of pure interest, i deployed 2x more MicroK8s nodes, and configured them as workers, joining them to a standard MicroK8s cluster node (not the non-HA node), as I wanted to see what memory usage would be for a pure worker node.

Interestingly, the memory usage is substantially lower, at only 238MB. This is impressive, given the cluster is running Calico networking.

Note though, once i enabled the cluster with dns, RBAC, hostpath-storage, and metrics-server (all of which are needed in production), memory usage increased to 335MB.

So, if you absolutely have to use Kubernetes at the edge, on lightweight hardware, you "*can*" as long as you have a node with at least 2GB of RAM that will operate exclusively as the master node. Clearly this adds a single point of failure, but Kubernetes can be tuned to tolerate an extended outage of the master node without taking the cluster and all workloads offline.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/how-to-manage-portainer-environments-via-docker-cli
title: How To: Manage Portainer Environments via Docker CLI
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/how-to-manage-portainer-environments-via-docker-cli
hostname: portainer.io
description: Ever wanted to use the Docker CLI to access environments managed by Portainer? Here's how..
sitename: PORTAINER.IO
date: 2023-06-29
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Jun-29-2023-05-51-37-4881-AM.png
pagetype: article
filedate: 2025-01-18
-->

So, you have Portainer running centrally in your work (or home) network and its configured to manage multiple Docker Environments (Standalone and/or Swarm), thats awesome..

But now you want to use the Docker CLI on your laptop to interact directly with the remote Portainer managed environments. Given your only access to these environments is via Portainer, how can you achieve this?

Easy... with a tool Portainer has made available called the Portainer Authenticator.

This "run once" container, which you run on your Laptop (or wherever you will run the Docker CLI), will faciliate the creation of a docker config.json on your machine containing the authorisation headers needed.

*Now there is a pre-requisite for this to functionality to work. Your Portainer instance MUST be running with a real SSL cert. Not the self-signed certificate that Portainer generates. Why? Because we need to connect using the Docker TLS connection, and that requires us to have a CA cert, which you dont get with a self signed cert. So you need a real cert. You need to have a copy of the CA public cert too.*

Lets see how.

On your Dev machine, open the command window (either Linux Console, or WSL console).

Navigate to the ~/.docker folder (if you dont have one, create a folder)

Inside that folder, see if you have an existing config.json file. If you dont, create one with content of {} then save it.

You should now have a blank config.json in the ~/.docker/ folder.

OK, so now we need to run the portainer authenticator.

Enter the command:

docker run --rm -v ~/.docker/config.json:/config.json portainer/authenticator <PORTAINER_URL>:9443 username password

Dont forget to change the portainer URL to your real URL, and put in your portainer username and password.

The command will run, and update the config.json with the bearer token. You can cat the file to see the results.

OK, so now you have the token, how can you use it?

We need to create a docker context.

But you first need to prepare three things.. you need to tell Docker to use the config file, you need to know the endpoint ID of the Docker environment you want to manage, and you need the CA cert that the Portainer instance is using.1) Lets configure Docker CLI to use the config file.

Type the following commands to set the environment variable needed

echo export DOCKER_CONFIG=$HOME/.docker > ~/.profile

source ~/.profile

As you can see by my example below.

2) Lets get the endpoint ID.

Switch back to your Portainer screen, select one of the environments for management, and then note the ID number in the address bar. That is your endpoint ID. For my demo, its #2. Capture as many endpoint IDs as you want to manage.

3) Finally, now get your CA cert, and copy it into your host, in the path ~/.docker/ca.pem

Now we are ready to create the context.

Type the command

docker context create portainer --description "<FRIENDLY NAME>" --docker "host=[tcp://<PORTAINER_URL>:9443/api/endpoints/<ENDPOINT_NUMBER>/docker,ca=./ca.pem]"

As you can see by my example below.

Repeat for each endpoint ID that you want to add (with a different context name and friendly name).

Now we can switch to that context.

The command "docker context ls" will list your current contexts, and "docker context use <NAME>" will switch to your new context.

Now that you have that context selected, you can go ahead and run docker commands on your local laptop, and these will run in the remote Docker environment, via Portainer, which acts as an authenticated (and RBAC secured) API proxy.

From our testing, the following commands do not work via the proxy

- docker run (so you cannot deploy new containers)
- docker logs -f (follow does not work)
- docker exec
- docker attach
- docker stats

The following commands DO work as tested.

- docker stop / docker start
- docker rm
- docker image commands (all of them)
- docker network commands (all of them)
- docker volume commands (all of them)
- docker logs (just no -f)
- docker node commands (all of them)
- docker ps
- docker service commands (all of them)
- docker stack commands (all of them)
- docker cp command
- docker pull/push/tag

Give this a try and let us know what you think.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/how-to-get-mysql-on-kubernetes-with-pvc-from-a-block-storage-device-working
title: How To: Get MYSQL on Kubernetes with PVC from a Block Storage Device working
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/how-to-get-mysql-on-kubernetes-with-pvc-from-a-block-storage-device-working
hostname: portainer.io
description: How to get MySQL 5.7 and newer working on a Kubernetes cluster with a block storage device.
sitename: PORTAINER.IO
date: 2023-03-17
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Mar-17-2023-04-11-16-9973-PM.png
pagetype: article
filedate: 2025-01-18
-->

So, in MySQL 5.7 and newer, if you are deploying it on Kubernetes, and the underlying CSI driver is a "block" storage device, then its highly likely that your MySQL deployment will fail.

You will deploy a perfectly valid configuration, but the MYSQL pod will sit in a terminating loop cycle. Inspecting the logs of the POD will show you this error:

`[ERROR] --initialize specified but the data directory has files in it. Aborting.`

As per the pic below...

Now, the reason for this, is that MYSQL is expecting its persistent volume to be 100% blank (so it checks there is nothing under /var/lib/mysql), however with block storage devices, this unfortunately is not true... when block storage is formatted with EXT4, there is automatically a lost+found directory created, and this blocks MySQL from starting.

To work around this, click on the YAML editor in Portainer.. scroll down until you find the "containers" spec area..

and then paste in the following below the "image:" entry:

`args:`

- "--ignore-db-dir=lost+found"

So that it looks like this..

Then click on APPLY CHANGES (right hand side).

Wait 2 minutes, and see that MYSQL now starts.

and in the logs, you can see that the DB init completes..

Problem solved, you now have a functional MYSQL deployment.

You can read the MySQL GH issue on this here: https://github.com/docker-library/mysql/issues/186

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/author/neil-cresswell/page/5
title: Portainer News and Blog | Neil Cresswell, CEO (5)
author: Neil Cresswell; CEO September
url: https://www.portainer.io/blog/author/neil-cresswell
hostname: portainer.io
description: Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization. (5)
sitename: Portainer.io
date: 2022-09-12
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

### Blog Post by Neil Cresswell, CEO

[
](https://www.portainer.io/blog/using-the-edge-agent-on-your-local-docker-instance)

Neil Cresswell, CEOSeptember 12, 20221 min read

### Managing your local Docker instance as an edge device with Portainer

How to add your local docker instance as an edge device and use the edge agent on your ...

Start Reading
[
](https://www.portainer.io/blog/how-to-secure-the-portainer-edge-agent-comms-with-mtls)

Neil Cresswell, CEOAugust 28, 20223 min read

### How To: Secure the Portainer Edge Agent comms with mTLS

Using mTLS to secure Portainer Edge Agent to Server comms

Start Reading
[
](https://www.portainer.io/blog/portainer-edge-bulk-device-onboarding)

Neil Cresswell, CEOAugust 27, 20222 min read

### Portainer Edge - Bulk Device Onboarding

Edge Device bulk onboarding in Portainer

Start Reading
[
](https://www.portainer.io/blog/orchestrator-wars-continue)

Neil Cresswell, CEOAugust 24, 20223 min read

### Docker Swarm vs Kubernetes vs Nomad - the orchestrator wars continue?

Docker Swarm vs Kubernetes. Nomad vs Kubernetes. Which orchestrator is right for you? ...

Start Reading
[
](https://www.portainer.io/blog/comparing-k0s-k3s-microk8s)

Neil Cresswell, CEOAugust 22, 20223 min read

### Comparing Resource Consumption in K0s vs K3s vs Microk8s

This blog post compares K0S, K3S, and MicroK8s, and the resources required for each.

Start Reading
[
](https://www.portainer.io/blog/portainer-vs-rancher-vs-openshift)

Neil Cresswell, CEOJuly 28, 20228 min read

### Portainer vs Rancher vs OpenShift Blog Post

Discover how Portainer vs Rancher, and OpenShift compare and see which is the right ...

Start Reading
[
](https://www.portainer.io/blog/portainer-and-industry-4.0)

Neil Cresswell, CEOJuly 25, 20224 min read

### Enabling Industry 4.0 and IIOT Network Technology

What is Industry 4.0, how does it fit with IIOT, and how Portainer is enabling Edge ...

Start Reading
[
](https://www.portainer.io/blog/root-console-to-a-host-via-portainer)

Neil Cresswell, CEOJuly 24, 20221 min read

### Root Console to a Host via Portainer?

How to gain console access to your hosts via Portainer

Start Reading
[
](https://www.portainer.io/blog/deploying-off-the-shelf-software-in-enterprise-kubernetes-environments)

Neil Cresswell, CEOJuly 6, 20223 min read

### Deploying off the shelf software in enterprise Kubernetes environments

With developers and ISVs standardizing on containers and Kubernetes for their apps, where ...

Start Reading
[
](https://www.portainer.io/blog/choosing-the-best-kubernetes-dashboard-for-your-enterprise)

Neil Cresswell, CEOJuly 1, 20223 min read

### Choosing the best Kubernetes dashboard for your Enterprise

A short assessment of the best Kubernetes dashboards and how Portainer differs from the ...

Start Reading
[
](https://www.portainer.io/blog/portainer-a-kubernetes-management-platform-for-newbies-and-experts)

Neil Cresswell, CEOJune 28, 20223 min read

### Portainer, a Kubernetes Management Platform for newbies and experts alike.

Portainer is a tool to empower non-experts to deploy and manage container-based apps ...

Start Reading
[
](https://www.portainer.io/blog/how-to-create-kubernetes-clusters-on-azure-aks-amazon-eks-and-google-gke)

Neil Cresswell, CEOJune 27, 2022< 1 min read

### How to create Kubernetes clusters on Azure AKS, Amazon EKS and Google GKE

Learn how to easily create Kubernetes clusters inside Google GKE, Amazon EKS, and ...

Start Reading

---
<!--
URL: https://www.portainer.io/blog/how-to-mount-a-cifs-share-to-a-container-in-docker-desktop
title: How To: Mount a CIFS share to a container in Docker Desktop
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/how-to-mount-a-cifs-share-to-a-container-in-docker-desktop
hostname: portainer.io
description: How to: Mount a CIFS share to a container in Docker Desktop.
sitename: PORTAINER.IO
date: 2023-03-27
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Mar-27-2023-11-20-00-7152-AM.png
pagetype: article
filedate: 2025-01-18
-->

So I had someone ask me today, "How do i mount a remote CIFS share to a container running on Docker Desktop on Windows"... and to be honest, i had no idea... so i tested it..

First problem, Docker Desktop uses an alpine based WSL2 image, and this image is missing the cifs-utils package.. this needs to be installed

Open the Windows command prompt, and type "wsl --distribution docker-desktop"

You will then get a console into the WSL2 instance.

Then type "apk add cifs-utils" and wait for it to install

Now switch back to Docker Desktop, and using the Portainer Extension, you can define a volume that maps to the CIFS share as follows:

Note: substitute the IP address of your CIFS target (dont use dns name as that just adds complexity), and add in a username and password that has access to the CIFS share.

See the volume is created. Dont worry about the mount point location, thats just where Docker mounts the CIFS share into.

Now you can add this volume to a container..

Then click "deploy container"

Once the container is deployed, open a console into the container to validate the share..

Compare against the share itself..

Success.. works perfectly.

So this is how you attach a CIFS share to a container inside Docker Desktop for Windows (using Portainer Extension).

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/monitoring-a-swarm-cluster-with-prometheus-and-grafana
title: Monitoring a Swarm Cluster with Prometheus and Grafana
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/monitoring-a-swarm-cluster-with-prometheus-and-grafana
hostname: portainer.io
description: Learn how to use a simple Portainer App Template to deploy Prometheus and Grafana to monitor your Docker Swarm environment.
sitename: PORTAINER.IO
date: 2023-05-25
categories: []
tags: []
image: https://www.portainer.io/hubfs/Prometheus%20Monitoring%20Twitter%20Image%201600x900.png
pagetype: article
filedate: 2025-01-18
-->

This blog might seem like a "back to the future" moment, given the near all-encompassing commentary around Kubernetes, and Swarm being "dead". The reality though is that Swarm isn't dead, and its still out there solidly (and reliably) solving container orchestrator challenges for a wide range of companies who dont care for Kubernetes and its complexity/learning curve. Here at Portainer, we actually continue to see pretty consistent (and slightly growing) swarm use amongst our user community.

So for those Swarm lovers out there, how can you get similar monitoring capabilities that seem commonplace for Kubernetes? Easy..

In this article, we will explore how to use a recently added Portainer App Template to deploy Prometheus and Grafana into a Docker Swarm cluster, and then use this for advanced resource monitoring.

### How to deploy the Prometheus and Grafana stack in Portainer

First up, validate that your Portainer instance is using the Portainer provided list of App Templates, because if you have adjusted this to use a community repo, you will not see our new template. You can check this in settings, as per the below:

Now that you have checked things, navigate to one of your Docker Swarm environments, then click on "App Templates" and select the "Swarm Monitoring" Template.

Note the requirement in the information section:

**Make sure to add the monitoring == true one of your Swarm manager node before deploying this stack.**

This means that you first need to select which node(s) in your cluster will be available for the deployment of the monitoring stack. This is to ensure that the data is persisted on a selected node so that if your service needs to be redeployed, it will be redeployed on the same node.

We can do that simply from the Portainer UI by heading to the Swarm menu, then selecting the manager node that we want to use.

Just add a new label with the **name** set to **monitoring** and the **value** set to **true** and apply the changes.

You can now head back to the App Templates and deploy the Monitoring stack.

We can then inspect our newly deployed stack and wait for all of the services to be ready.

### How to USE the Prometheus and Grafana stack you just deployed...

Once all the services are ready, you can access the Grafana dashboard over the IP of one of the nodes in your Swarm cluster and port 3000: [https://swarm-node-ip:3000](https://swarm-node-ip:3000)

After logging in, you will land on the Grafana homepage. You can use the menu in the top left to access dashboards.

You will then find two dashboards under the General folder.

The Container Metrics dashboard provides an overview of the resource usage for all containers in your cluster.

The Node Metrics dashboard provides an overview of resource usage for a specific node in your cluster. You can select the node of interest using the Instance filter at the top of the dashboard.

### Conclusion

Monitoring a Swarm cluster is essential to ensure its availability and reliability. By using Prometheus and Grafana to collect and visualize the metrics of the cluster, and by using Portainer to simplify the deployment, you can effectively monitor your Swarm cluster and detect potential issues before they become critical.

You can find more information about how the monitoring stack is configured in our OSS template repository at [https://github.com/portainer/templates/blob/master/swarm/monitoring/docker-compose.yml](https://github.com/portainer/templates/blob/master/swarm/monitoring/docker-compose.yml)

To understand how the images are built, you can look at [https://github.com/portainer/templates/tree/master/images/monitoring](https://github.com/portainer/templates/tree/master/images/monitoring)

Happy Monitoring..

Try Portainer with 3 Nodes Free

If you're ready to get started with Portainer Business, [3 nodes free](https://www.portainer.io/take-3) is a great place to begin. If you'd prefer to [get in touch with us](https://www.portainer.io/contact-sales), we'd love to hear from you!

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/why-you-should-crawl-walk-run-when-adopting-containerization-and-migrating-legacy-applications-to-containers
title: Why You Should Crawl, Walk, Run When Adopting Containerization and Migrating Legacy Applications to Containers
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/why-you-should-crawl-walk-run-when-adopting-containerization-and-migrating-legacy-applications-to-containers
hostname: portainer.io
description: Considering adopting containerization and Kubernetes? A crawl, walk, run approach to these complex systems can help avoid costly mistakes.
sitename: PORTAINER.IO
date: 2023-01-17
categories: []
tags: []
image: https://contentcompany.biz/wp-content/uploads/2019/08/clipart2164340.png
pagetype: article
filedate: 2025-01-18
-->

The world of containerization is rapidly growing, and many organizations are eager to adopt this technology to improve the efficiency and scalability of their applications.

For many people, the term Kubernetes is now synonymous with containers, and when looking to adopt containers, they automatically think this means Kubernetes from day 0. However, before diving headfirst into containerization and orchestration with Kubernetes, it's important to understand that this transition should not be taken lightly.

Adopting a "crawl, walk, run" approach can ensure a smooth and successful transition for your organization.

One of the main reasons for this is that containerization and Kubernetes are complex systems that require a deep understanding of how they work. Jumping straight into Kubernetes without a proper understanding of containerization, and its specific differences from Virtual Machines can lead to confusion, frustration, and ultimately, failure. Furthermore, migrating legacy applications to containers requires a different approach than developing new applications from scratch.

The first step in the process is to "crawl." This involves getting familiar with basic containerization concepts and technologies such as Docker. Start by containerizing a simple application and running it on a single host. Destroy the container, redeploy it, update it, learn how these standard operations work, and how they impact your application. Understand what is persisted and what isn't, what changes, and what doesn't. So many mistakes are made from flawed assumptions around container persistence (or more accurately, lack thereof). Remember, a container is NOT a VM, so it doesn't behave like one.

This experimentation will give you a basic understanding of how containers work and how they can be used to ship, deploy and run applications. This step also includes understanding the impact of containerization on your existing infrastructure, such as networking, security, monitoring, etc.

This is a good point to get your hands on Portainer, to help you learn what's possible (we visually show you what is possible with Kubernetes or Docker, without you first needing to learn what's possible).

Once you have a good understanding of containerization, it's time to "walk." This involves deploying multiple containers on a single host and learning how to manage and orchestrate them as a singular cohesive unit (a stack in Docker terms). This can be done using tools such as Docker Compose or Kubernetes Minikube. This step also includes understanding the impact of distributed containers on your existing applications. For example, distributing your application across multiple containers can introduce cross-service latency, and this can negatively impact the performance of your applications.

This step also includes experimenting with different ways of migrating your legacy applications to containers, monitoring them, and managing them. Existing tools purchased for a VM-based platform likely will not be effective in the highly dynamic world of containers.

Finally, once you have a solid understanding of containerization and orchestration, it's time to "run" and move on to more advanced systems like Kubernetes. This involves deploying and managing multiple containers across multiple hosts, and learning how to handle scaling, updates, and rollbacks. Likely this will also include evaluating tools providing GitOps, observability, logging etc.

Here elements like management of the orchestrator also come into play, as you now need to actively deploy the orchestration layer (Kubernetes), update it, secure it, and grant access to it (think user access control and RBAC).

It's important to note that the process of containerization and Kubernetes adoption is never truly complete. It's a continuous process of learning and improvement. Therefore, it's essential to monitor your containerized applications and evaluate their performance, and make adjustments as necessary.

In summary, the adoption of containerization and Kubernetes should not be taken lightly, especially when migrating legacy applications. The "crawl, walk, run" approach is a proven method for gradually gaining experience and understanding of containerization before moving on to more advanced systems. By taking the time to properly understand and adopt containerization, organizations can ensure a smooth transition and successful implementation of these powerful technologies. Furthermore, migrating legacy applications requires a different approach and a good understanding of the impact of containerization on your existing infrastructure and microservices architecture."

Hope this helps to understand why you need to tread slowly and carefully.

Try Portainer with 3 Nodes Free

If you're ready to get started with Portainer Business, [3 nodes free](/take-3) is a great place to begin. If you'd prefer to [get in touch with us](https://www.portainer.io/contact-sales), we'd love to hear from you!

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/managing-kubernetes-shouldnt-be-hard
title: Managing Kubernetes shouldn't be hard!
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/managing-kubernetes-shouldnt-be-hard
hostname: portainer.io
description: Managing Kubernetes shouldn't be hard. This blog post delves into some of the pitfalls and how to avoid them with a Kubernetes management platform.
sitename: PORTAINER.IO
date: 2022-10-08
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Oct-07-2022-11-48-55-23-PM.png
pagetype: article
filedate: 2025-01-18
-->

So, you have decided that you want to adopt Kubernetes, GREAT..

But now you are reading blogs, and watching youtube videos that keep highlighting the complexity of Kubernetes, and its freaking you out! Not so great.. what do you do??

Like it or not, Kubernetes can be complicated, but for good reason.

You see **Kubernetes is considered to be the "operating system of the cloud"** and as such, **it needs to be modular, and near infinitely customizable**.

In order to be so universally accepted, it cannot impart any default settings that may impact its broad use. This translates to a default "pure upstream" installation that is extremely vanilla, and open, in its base configuration. Awesome, except it expects you to know how to take it from vanilla and adjust for your specific needs, and if you don’t, you will hit the complexity wall.

One way around this complexity is to leverage Kubernetes distributions that are released by companies that offer an "opinionated" version, which, through their install process, actually defines some sane defaults, bit still, they only go so far.

One really important thing to keep in mind; **Kubernetes alone is not sufficient for you to actually go into Production with.**

Kubernetes is no more a complete platform than a VMware ESXi Host is a Virtual Infrastructure Platform. We all know that you need far more than just a hypervisor to successfully run a Virtual Infrastructure Platform. Same is true with Kubernetes.

**To use Kubernetes in production, you need tools to facilitate monitoring, alerting, security, access, authentication, compliance, and provisioning/life cycling (UI, CI/CD, or GitOps).** There are a number of tools from (the approx 1200) CNCF members that address these needs, but again, its up to you to decide which are right for you, and its up to you to make sure each are interoperable with each other (and the underlying Kubernetes version(s) you are using). Another complexity wall. Of course, you could just follow everyone else, and use the tools they use, but is this right for your needs? Maybe they are far more advanced in their use than you are.

So what can you do?

You have a couple of choices.

**Option 1:**

You can elect to purchase your Kubernetes platform from a managed service provider, in what is best defined as a "**Kubernetes as a Service**" offering. Popular offerings are Amazon EKS, Google GKE, Azure AKS, along with Civo, DigitalOcean DoKS, and Linode Kubernetes.

For anyone deploying on-premises, we strongly recommend MicroK8s from Canonical, as its so easy to deploy, upgrade, and triage. Its also really easy, with its plugins, to adjust for your specific needs post deployment.

With this option, to get the desired simplicity, you need to be "all in" with just a single provider, and leverage their additional Kubernetes management tooling to help you setup a full Kubernetes Platform. Why? Because each provider is subtly different from the other. Sure their Kubernetes offerings are relatively standardized, but their ancillary tooling is extremely bespoke and locked to their offerings. How AWS does user authentication is very different to how Azure or Google do it.

**Option 2:**

You can deploy a **Kubernetes Management Platform** (like Portainer, but there are others too), that provides the **central, and vendor neutral, tooling** required to correctly manage and secure Kubernetes environments. The benefit of this option is that the agnostic nature of centralised tooling means you get to use any combination of backend Kubernetes as a Service providers.

These tools often include built-in capabilities that expand basic Kubernetes into a full Platform, with built-in Monitoring, CD/GitOps, Governance, and Security controls. Generally **a Kubernetes Management Platform is all you need to get started with Kubernetes** in Production. If you are looking for the easiest way to get started, then this is likely your best choice.

Clearly though, there is a degree of "lock-in" from the Kubernetes Management Platform, so you need to ensure that these platforms allow you to use any Kubernetes back end (not only their own distribution, if they offer one), and allow the use of any front end tooling (so they must provide a Kubernetes API proxy), and they should not preclude you from adopting any of the CNCF tools should your needs demand so. This is one reason why you need to look closely at the provider of the tool to ensure openness.

**So, in Summary..**

Managing Kubernetes CAN be hard, if you allow it to be... but it doesn’t have to be.

Take the easy road, and look closely at Kubernetes Management Platforms, as these will generally provide the lowest friction to getting live in production in a safe and secure way.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/pull-latest-image-feature-in-ce
title: "Pull latest image" feature in CE
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/pull-latest-image-feature-in-ce
hostname: portainer.io
description: Clarification on the "pull latest image" feature for Stacks.
sitename: PORTAINER.IO
date: 2022-09-16
categories: []
tags: []
image: https://www.portainer.io/hubfs/Feature%20explained%20Pull%20latest%20image.png
pagetype: article
filedate: 2025-01-18
-->

Over the last week there has been a fair amount of discussion online around a feature in Portainer: the "Pull latest image" functionality.

This feature appears as a toggle in the Portainer UI when recreating a container or service, and when enabled Portainer will check with the upstream registry and ensure that the latest version of the image and tag used before performing the recreate.

In version 2.12 of the Business Edition of Portainer, we added similar "pull latest image" functionality to the recreation of stacks (as per [this Github issue](https://github.com/portainer/portainer/issues/6155) - in which we mention that the feature is BE-only).

In the next Community Edition (2.13) we added the display of this toggle as an advertisement for the BE-only feature, but the feature itself was disabled. When adding this advertising toggle, we inadvertently had the toggle displaying in the incorrect state - on - when the feature itself was actually off.

In version 2.15 of Portainer CE, as part of the UI refresh, we fixed this incorrect display of the toggle to show the correct state of the feature - off. This change has caused some concern in the community that the feature was removed from the CE version of Portainer to make it a BE-only feature.

In this situation, the confusion was exacerbated by the way that Docker itself works. When recreating a container, Docker will use the latest version of the image and tag that it has locally. This could result, under certain circumstances, in stack updates appearing to pull the latest images from the upstream registry when in fact they were not. For example, if you had deployed a stack that used the nginx:latest image, then later on deployed another container using the same image (but the image upstream had updated in the meantime) and opted to pull the latest image when doing so, Docker would have an updated version of the nginx:latest image available locally, but your first stack would not be using it. When you updated the stack, Docker would recognize that you had a local version of the image that was more up to date than the one you were using, and would automatically use that version instead.

At this point I would like to make it clear: we have no plans what so ever to remove features from the Community Edition in order to make it a Business Edition exclusive feature. Doing so goes against the founding principles of Portainer and our love for open source, where Portainer was born.

The open source nature of our Community Edition means you can in fact at any point look back through our code to confirm that we have never done this.

We made a mistake here in how we displayed the toggle's true state in CE 2.13, and we're sorry that this happened and that we didn't fix this sooner. Our intent was never to deceive our users or give the appearance that we removed a feature from CE. In the future we will be ensuring that any and all toggle states as well as any other advertisements of BE-specific features in CE will accurately reflect the status of the option or feature.

This incident has caused us to do some real thinking about this feature in particular and where it should fit within our product offerings, especially considering the way that Docker itself acts and the availability of the feature for containers and services. In addition, reusing tags is actally seen as an anti-pattern and risky in production deployments (it really is a feature useful in the development phase only).

As a result, in 2.15.1 we have decided to make the "pull latest image" feature for stacks available in both CE and BE, permanently.

We hope this summary has shed some light on the events that led to where we are today. If you have any questions on what happened that haven't been answered here, please get in touch.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/who-should-consider-portainer
title: Who should consider Portainer?
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/who-should-consider-portainer
hostname: portainer.io
description: Who should consider adopting Portainer? Read if your organization should be speaking to us.
sitename: PORTAINER.IO
date: 2023-04-06
categories: []
tags: []
image: https://www.portainer.io/hubfs/Twitter%20Post%201600x900%20Considering%20Options%20.png
pagetype: article
filedate: 2025-01-18
-->

We are often asked, what types of companies stand to gain the greatest benefit from using Portainer, and that's actually a really hard question to answer.

Why?

Because we help a massively diverse range of people do things with containers that they might not otherwise be able to do... which is a very universal thing.

But in a strictly company-wide context, where the adoption of Portainer would be multi-user / multi-team, then that gets a little easier.

You see, Portainer's main goal is to make the adoption of containerization easier, by reducing the mental and operational load that generally comes with new technology. By easing organizations into containers, through our intuitive UI, and "click to configure" advanced capabilities, we generally appeal to more of one type of organization than another.

Generally speaking, organizations that have a prior investment in a large Kubernetes experienced platform engineering team likely would not appreciate the simplification that Portainer brings. Equally, organizations that are "all in" on a single cloud provider managed Kubernetes service also might not appreciate the heterogeneous multi-cluster management that Portainer brings.

So, in the interest of being 100% transparent, who would benefit from Portainer? Well, if you are an organization that fits one or more of the criteria below, then it's very likely that you will see immense value from Portainer, and we should talk.

- Limited in-house expertise: Does your company lack extensive expertise in container management or have team members who are new to Docker and Kubernetes? If so, you would benefit from Portainer's user-friendly interface and simplified management features.
- Rapid deployment requirements: Have you been thrown a project to get a new container-based application live in your environment, quick fast? You would find Portainer's ready-to-use platform advantageous.
- Resource constraints: Are you currently operating with a constrained IT budget that would hinder your ability to hire (or reassign and train) a dedicated platform engineering team? For sure you would benefit from Portainer's innate ability to enable your existing Ops teams with the skills they possess today.
- Cross-functional teams: Does your IT team have members of varying skills, technical and non-technical? Do you need to enable a wide range of people, with a wide range of skills to be effective contributors to your containerization adoption? Your team members would appreciate Portainer's intuitive interface.
- Vendor-agnostic approach: Do you want the ability to deploy your applications where it suits you, be that hybrid cloud, multi-cloud, edge, or anywhere? Don't fancy vendor lock-in? Then Portainer's vendor-neutral solution to manage containerized applications across different environments, such as Docker and Kubernetes, will be appealing.
- Security and compliance focus: Do you prioritize security and compliance? Do you need to be sure that any access to the containerized platform is safe and secure? Do you need to be sure that your applications are deployed in a secure manner? Then you would benefit from Portainer's built-in security features, such as role-based access control, integration with LDAP/Active Directory with single-sign-on, and container security policy enforcement.
- Scalability requirements: Does your containerization program need to start small and simple, but be able to scale as your adoption scales? Portainer's low resource overhead, and ability to manage large-scale deployments efficiently makes it perfect for "scale as you do".

Of course, there are always exceptions, and for sure we help even organizations that might not immediately think they need a tool like Portainer, but if you value simplicity and ease of use, we will bring you one step closer to a successful project.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/deploying-portainer-business-on-civo-cloud
title: Deploying Portainer Business on Civo Cloud
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/deploying-portainer-business-on-civo-cloud
hostname: portainer.io
description: Portainer Business Edition, now available on the Civo Marketplace
sitename: PORTAINER.IO
date: 2022-12-02
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Dec-02-2022-08-28-39-9825-PM.png
pagetype: article
filedate: 2025-01-18
-->

Portainer has been working with the Civo team for a while now, and one our earliest joint pieces of work was providing Portainer CE as a marketplace item.

Due to popular request, and off the back of the popularity of our [3 Nodes Free](/take-3) License, we are now pleased to offer Portainer Business on the Civo Marketplace.

This deployment is a BYOL (Bring your own License), but automates the deployment of the Portainer Business Server during Civo Kubernetes Cluster creation (or can be added to any existing Civo Cluster at any time).

To deploy a NEW Kubernetes cluster on Civo, equipped with Portainer Business for management, you can follow the below steps:

1) login to your Civo Account

2) From your dashboard, click "Kubernetes"

3) Click "Create new cluster"

4) Fill in your Cluster details, and then keep scrolling down to the bottom of the page. Under the "Marketplace" section, choose Portainer, and then select the "Business Edition" option (click the large Portainer box, so that you see a blue tick top right of the box - UX improvement needed there Civo!), then click "Create cluster".

Note that Portainer deploys a Civo Load Balancer, and you will access Portainer via that LB.

5) Wait for the cluster to be created and Portainer deployed...

6) Click on "Installed Apps" , and see that Portainer is already installed.

7) To get the IP of the Portainer Instance, go back to Cluster Information page. Use the Public IP address. Also ensure that you have a persistent volume provisioned and ATTACHED (as per picture).. if no PVC is attached, Portainer is not yet ready to use.

8) To access Portainer, in another browser tab, type in [https://<IP>:9443](https://<IP>:9443)

9) Apply your Portainer License (get one from [here](/take-5)) and enjoy..

Thanks to the Civo team for helping to get Portainer Business into the marketplace and up and running.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/kubernetes-has-it-really-set-us-back-10-years
title: Kubernetes, has it really set us back 10 years?
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/kubernetes-has-it-really-set-us-back-10-years
hostname: portainer.io
description: While Kubernetes projects are often challenging, has the tech really set us back 10 years? This blog post explores both sides of the debate.
sitename: PORTAINER.IO
date: 2023-06-23
categories: []
tags: []
image: https://www.portainer.io/hubfs/Shutterstock_2063436791.png
pagetype: article
filedate: 2025-01-18
-->

Whilst browsing through social media, and absorbing the plethora of information in the world of Cloud Native, we came across an [interesting post.](https://twitter.com/petecheslock/status/1671536499748118532?s=46&t=XjHKpUm6uP3kUCusyyJnOQ) In this post, the author states *"Kubernetes has single-handed set our industry back a decade. Companies are going to die because they spend more time “managing Kubernetes” than building a product."*

The commentary on this post was swift, extensive, and quite polar. You either agreed with his comment or you 100% disagreed. Generally, technologists who have spent considerable time learning Kubernetes came down on the side of "it’s not that hard, once you know how". whereas everyone else echoed the author's sentiment in that the day 1 skills ramp, and day 2 operational overhead was often greater than the benefit gained.

As always, the ever present and always insightful, Kelsey Hightower [weighed in](https://twitter.com/kelseyhightower/status/1671582240026025986), with "If you don't need Kubernetes don't use it." He followed on with all the reasons where Kubernetes is a great fit, and where it’s not, and how he keeps seeing, time and time again, people forcing Kubernetes into solutions where it just doesn’t belong.

Here at Portainer, we have some thoughts on this too...

Kubernetes is an amazing piece of technology. For sure if you have the problems that Kubernetes solves, it truly is a game changer. If you need auto-scaling, declarative deployments, a self-healing platform, and a common deployment API framework, regardless of where you are deploying, then Kubernetes is likely the best choice for your needs.

However, as an industry, where we keep going wrong, is thinking that it’s the ONLY solution to every single problem we have. Spoiler alert… it’s NOT.

Over the last 3 years, the way technology is introduced into organizations has changed. Whereas it used to be led by an enterprise architecture team, through a considered architectural design process with operational considerations, cost-benefit assessments, supportability research etc, now it’s transitioned. [Since 2020](https://www.geektime.com/fall-and-rise-of-cio/) (and maybe even earlier for innovators), technology is generally championed and introduced by the engineering team, in a “build a bespoke solution using the latest technology” construct.

The consequences of this switch are two-fold.

Engineers enjoy the challenge that adopting new technology offers, which means they have a naturally high pain threshold for technology hurdles and complexity. They are also far more likely to turn a blind eye to the ongoing management of the technology, feeling it’s just part of their job to maintain it. Whilst this is true, there is no consideration given to the cost of this maintenance PRIOR to adopting it. Sometimes the ongoing cost far exceeds what most organizations would consider acceptable.

Secondly, engineers are in high demand, and this same engineering team that bought the technology into the company, went through the pain of getting it operational, and babysat it day in, day out, well those engineers get headhunted. Then what do you do? You had better understand the risks and have a rock-solid succession plan. The problem is, most IT leaders are not aware of the risks until they manifest into pain.

So back to the original poster's point: has Kubernetes set us back 10 years?

We don’t believe so, but we do believe that there are far too many engineering teams operating without consideration for the overall cost of ownership of technology, and that once the true costs are seen by IT management, there will be a number of hard questions being asked. After all, if the development engineering team is not shipping new software features fast enough because they are too busy managing Kubernetes, then that’s not good for business. Equally, if you must retain dozens of highly trained platform engineers, just to keep the Kubernetes lights on, then that’s not good for the bottom line.

Yes, there are other options out there. Something as simple as standalone Docker Hosts offer a lot of the benefits as Kubernetes, as does the (under-represented and often mocked) Docker Swarm, Hashicorp Nomad, or even cloud services like AWS ECS (which has been around for a very long time, because, well, it just works!), and Google CloudRun. Sure, those technologies are not as “cool” as Kubernetes, but sometimes what's cool, is having a highly cost-effective and operationally efficient infrastructure platform, not just the latest and greatest tech.

Portainer purposely remains container platform neutral, and it's why we support multiple runtimes and orchestrators. Which platform is appropriate varies, depending on the need. In summary, it's a case of choosing the right tool for the right job.

Try Portainer with 3 Nodes Free

If you're ready to get started with Portainer Business, [3 nodes free](https://www.portainer.io/take-3) is a great place to begin. If you'd prefer to [get in touch with us](https://www.portainer.io/contact-sales), we'd love to hear from you!

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/kubernetes-get-logs
title: How to: access Logs, Shell / Console, and Stats in Kubernetes Clusters with Portainer
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/kubernetes-get-logs
hostname: portainer.io
description: See how to easily get Kubernetes logs, shell/console, and stats in Kubernetes, with Portainer.
sitename: PORTAINER.IO
date: 2023-02-21
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Feb-20-2023-11-58-09-6819-PM.png
pagetype: article
filedate: 2025-01-18
-->

Back in 2017, Kelsey Hightower famously quoted*:*

*"No dev actually wants to use the kubectl command line, but they are forced to due to a lack of visibility. Devs cannot fly blind. Ops, give them tools: curated dashboards that provides them insight as to what's actually happening. Devs want to see the deployment and runtime status of their app, logs, network traces, metrics."*

And whilst, under a DevOps model, Devs likely want more exposure to Kubernetes than just a dashboard, the core message remains true. Devs need tools to see what's going on with their apps once deployed.

Portainer is a centrally deployed management platform, that lets Ops provide an intuitive curated dashboard UI to Devs. Portainer allows Devs to safely engage with their applications that run within Kubernetes clusters, without specifically needing to know Kubernetes. Portainer does this by making the triage capability available at the click of a button.

Let's show you how..

One of the most fundamental pieces of functionality needed by Devs is to view the runtime logs of their deployed application, and in Kubernetes speak, this means the Pods that underpin their deployments.

The easiest way to give Devs the ability to view pod logs, without forcing them into kubectl, is via Portainer. We allow any authenticated user (that is granted access to a cluster, and is assigned the right RBAC role) to inspect the logs of running Pods, including filtering/searching within the logs, downloading the logs to their PC, and viewing logs within a certain time window.

You simply click the "Logs" quick action, and you are connected to a live stream of the Pod logs.

The second fundamental piece of capability is to open a console into a running Pod, to get a deeper understanding of what the application within that Pod is doing, and/or to inspect Pod filesystem elements.

Again, Portainer makes that easy.

You simply click the "Console" quick action, and you are connected to the console of the Pod.

And the final fundamental capability is to be able to see stats/performance of the Pod.

Portainer integrates with the Kubernetes Metrics API (either from Metrics server, or Prometheus-adapter) to pull CPU and Memory usage data for the Pod.

You simply click the "Stats" quick launch to see the metrics being generated for the selected Pod.

So as you can see, once you have Portainer installed in your environment, Devs can be given access to Pod Stats, Logs, and the Console, all without needing to install anything on their PC, or needing to know how to operate the KubeCTL CLI.

This is just the tip of the iceberg into the curated dashboard capabilities of Portainer, but as these three are the most fundamental requirements of any Dev, it's important to see how quick and easy it is for Ops to provide this safely to Devs.

Try Portainer with 3 Nodes Free

If you're ready to get started with Portainer Business, [3 nodes free](/take-3) is a great place to begin. If you'd prefer to [get in touch with us](https://www.portainer.io/contact-sales), we'd love to hear from you!

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/author/rich-sharples
title: Portainer News and Blog | Rich Sharples
author: Rich Sharples November
url: https://www.portainer.io/blog/author/rich-sharples
hostname: portainer.io
description: With 30+ years in software, Rich brings seasoned leadership in product and technology. His expertise spans software development, product management, and fostering innovation.
sitename: Portainer.io
date: 2024-11-21
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

### Blog Post by Rich Sharples

[
](https://www.portainer.io/blog/the-importance-of-keeping-your-portainer-version-up-to-date)

Rich SharplesNovember 21, 20242 min read

### The importance of keeping your Portainer version up to date

Keep your Portainer version updated to ensure security, performance, and support for the ...

Start Reading
[
](https://www.portainer.io/blog/platform-engineering-transforming-it-infrastructure-for-modern-enterprises)

Rich SharplesJune 24, 20243 min read

### Platform Engineering - Transforming IT Infrastructure for Modern Enterprises

Platform Engineering is transforming IT infrastructure for modern enterprises, ...

Start Reading

---
<!--
URL: https://www.portainer.io/blog/portainer-vs-rancher-vs-openshift
title: Portainer vs Rancher vs OpenShift
url: https://www.portainer.io/portainer-vs-rancher-vs-openshift
hostname: portainer.io
description: Compare Portainer vs Rancher and OpenShift. See how they differ and check out the feature comparison table to learn which tool is right for you.
sitename: Portainer.io
date: 2024-01-01
categories: []
tags: []
filedate: 2025-01-18
-->

## Portainer, Rancher, OpenShift

[
](#)

###### TABLE OF CONTENTS

### How does Portainer compare to Rancher? How about to OpenShift?

This is a question we get asked almost daily by people looking for a Kubernetes management platform. For a long time, the answer was "well, we are not really sure, as we don't use those tools day in, day out". So we've done the research and created a comparison table for Portainer vs Rancher vs OpenShift.

We've spent considerable time deploying and understanding Rancher and OpenShift to discover their strengths, weaknesses (or functionality they don't attempt to provide), and seeing how we compare. We took a non-biased view of this assessment, as being biased doesn't help us to learn (and we hope you appreciate the transparency).

### Key Takeaways

[Read more below](#build-environments).

[Read more below](#multi-cluster-management).

[Read more below](#platform-vs-tool).

[Read more below](#ease-of-use).

### 1. Build Environments

Straight off the bat, Portainer and Rancher/OpenShift serve two very different needs. Rancher and OpenShift are both tools that you use to CONSTRUCT yourself a Kubernetes cluster, one that is self-managed (be that on prem or in-cloud).

Portainer as a company does not provide a Kubernetes distribution, but we have partnered with Canonical, and allow you to build a MicroK8s on-premises cluster in our app.

We allow you to build Kubernetes clusters through Cloud Provider KaaS offerings, which is arguably the most operationally efficient way of using Kubernetes anyway.

**Summary: Portainer helps you deploy managed Kubernetes clusters, which is our recommended way of consuming Kubernetes unless you have a large dedicated team of Kubernetes experts.**

### 2. Multi-Cluster Management

Secondly, the biggest difference we can see between both Portainer & Rancher vs OpenShift is that OpenShift is not a multi-cluster manager.

You use the [OpenShift installer](https://docs.openshift.com/container-platform/4.10/installing/index.html) to build a (singular) OpenShift cluster against either on-premises equipment or in a select number of cloud provider IaaS offerings, and the cluster gets deployed with a Management UI for that cluster. There is no way to deploy any additional clusters and manage them from the one management UI.

Of course, RedHat offer a premium version of OpenShift, known as OpenShift Platform Plus, which bundles a cloud service that delivers multi-cluster management. If you can afford to pay for OpenShift, then paying an additional $800 per month for this premium product is probably okay.

Rancher and Portainer both let you (natively) deploy or import any number of existing environments under the one management server, which is great when you are operating at scale.

**Summary: Portainer is a multi-cluster manager that is extremely lightweight and can provide centralized access control and governance at scale.**

### 3. Platform vs Tool

It's important to note that all three products are aiming to be a complete "turn-key" platform to manage containerized applications, with the analogy "Kubernetes is the engine, we are the car" commonly used.

All three products aim to be much more than just an alternative to the Kubernetes Dashboard (or variants of it, like Mirantis Lens).

In reality, all these products aim to provide a comprehensive Kubernetes management platform that includes an intuitive UI that guides less experienced users, an integrated GitOps capability, integrated monitoring/ observability, and integrated alerting.

Because of this, all three offer either native capability or integrations with 3rd party open source components (such as ArgoCD).

Portainer made a decision to integrate with the Kubernetes Metrics API, which gives a good level of observability, rather than requiring all users to deploy the resource-heavy Prometheus and Grafana. That said, there is nothing stopping you from using [Prometheus and Grafana](https://www.portainer.io/blog/deploy-prometheus-monitoring-stack-with-portainer?hsLang=en), or [ArgoCD](https://www.portainer.io/blog/deploy-and-use-argocd-with-portainer?hsLang=en) alongside Portainer.

**Summary: if you want a quick view of resource usage of your apps, and can't spare the additional resource overhead, Portainer is your only choice here.**

### 4. Ease of Use

Really though, the most impactful difference between the products is the target user. Portainer and OpenShift both provide a management experience that applies safe/secure best practices, and does so to ensure that non-experts can operate in an environment that they might not fully understand.

With Portainer, the admin can easily disable Portainer's applied defaults and customize them to suit the skills of the team, whereas with OpenShift the defaults are enforced. If the defaults don't suit you, then OpenShift will cause friction.

Rancher however takes a very different approach. Rancher's product appears to be tailored to Kubernetes experts, who are expected to know how to secure the platform and applications correctly.

**Summary: if you want a guided, intuitive, safe-by-default experience, with the ability for the admin to adjust the defaults, then choose Portainer.**

---
<!--
URL: https://www.portainer.io/blog/author/neil-cresswell/page/6
title: Portainer News and Blog | Neil Cresswell, CEO (6)
author: Neil Cresswell; CEO June
url: https://www.portainer.io/blog/author/neil-cresswell
hostname: portainer.io
description: Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization. (6)
sitename: Portainer.io
date: 2022-06-25
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

### Blog Post by Neil Cresswell, CEO

[
](https://www.portainer.io/blog/kubernetes-the-ultimate-enabler-of-automation)

Neil Cresswell, CEOJune 25, 20225 min read

### Kubernetes, the ultimate enabler of automation

Kubernetes, the ultimate tool to enable Infrastructure as Code and GitOps

Start Reading
[
](https://www.portainer.io/blog/portainer.io-closes-us6.2-million-funding-round)

Neil Cresswell, CEOJune 22, 20222 min read

### MEDIA RELEASE: Portainer.io Closes US$6.2 Million Funding Round

Portainer.io extends its Series A funding round to further commercialize it's enterprise ...

Start Reading
[
](https://www.portainer.io/blog/media-release-portainer-extension-added-to-docker-desktop)

Neil Cresswell, CEOMay 10, 20223 min read

### MEDIA RELEASE: Portainer Extension Added to Docker Desktop

Portainer Extension Added to Docker Desktop, Brings New Functionality to Docker While ...

Start Reading
[
](https://www.portainer.io/blog/containers-a-glitch-in-the-matrix)

Neil Cresswell, CEOMay 6, 20226 min read

### Containers – a glitch in the matrix?

Why Portainer is so important in today's two-tier IT society.

Start Reading
[
](https://www.portainer.io/blog/12-steps-to-getting-started-with-portainer-in-a-production-environment)

Neil Cresswell, CEOMay 4, 20224 min read

### 12 Step Guide to Get Portainer Running in a Production Environment

This best practice guide details the 12 steps to get Portainer running in a production ...

Start Reading
[
](https://www.portainer.io/blog/sneak-peak-portainer-as-a-docker-desktop-extension)

Neil Cresswell, CEOApril 19, 20221 min read

### Sneak peak - Portainer as a Docker Desktop Extension.

Get a sneak peek into Portainer's integration with Docker Desktop

Start Reading
[
](https://www.portainer.io/blog/managing-kubernetes-roles-and-responsibilities)

Neil Cresswell, CEOMarch 24, 20222 min read

### Managing Enterprise Kubernetes: Roles and Responsibilities

Who does what when enterprise Kubernetes is in play? This blog post examines the roles ...

Start Reading
[
](https://www.portainer.io/blog/docker-desktop-kubernetes-not-enforcing-rbac-rules)

Neil Cresswell, CEOMarch 17, 20222 min read

### Docker Desktop Kubernetes NOT enforcing RBAC rules

Docker Desktop, with embedded Kubernetes, does NOT enforce any RBAC rules. It lets you ...

Start Reading
[
](https://www.portainer.io/blog/when-kubernetes-problems-strike-why-simplicity-matters)

Neil Cresswell, CEOMarch 15, 20227 min read

### With Kubernetes, be careful you dont drown in complexity..

Why a complex Kubernetes environment can bite... and why a simple environment equals a ...

Start Reading
[
](https://www.portainer.io/blog/deploy-prometheus-monitoring-stack-with-portainer-part-2)

Neil Cresswell, CEOMarch 6, 20221 min read

### Deploy Prometheus Monitoring Stack with Portainer - Part 2

Part 2 - adding additional Prometheus instances to Grafana

Start Reading
[
](https://www.portainer.io/blog/deploy-prometheus-monitoring-stack-with-portainer)

Neil Cresswell, CEOMarch 6, 20222 min read

### Deploy Prometheus Monitoring Stack with Portainer

Deploy Prometheus Monitoring Stack with Portainer, and use as a substitute for ...

Start Reading
[
](https://www.portainer.io/blog/how-to-use-kubectl-and-lens-ide-through-portainer)

Neil Cresswell, CEOMarch 4, 20223 min read

### How to use KubeCTL and Lens IDE through Portainer

Using KubeCTL and Lens to control Portainer managed Kubernetes environments.

Start Reading

---
<!--
URL: https://www.portainer.io/blog/how-to-secure-the-portainer-edge-agent-comms-with-mtls
title: How To: Secure the Portainer Edge Agent comms with mTLS
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/how-to-secure-the-portainer-edge-agent-comms-with-mtls
hostname: portainer.io
description: Using mTLS to secure Portainer Edge Agent to Server comms
sitename: PORTAINER.IO
date: 2022-08-28
categories: []
tags: []
image: https://www.portainer.io/hubfs/How%20To%20Secure%20the%20Portainer%20Edge%20Agent%20comms%20with%20mTLS.png
pagetype: blogposting
filedate: 2025-01-18
-->

So, you have decided to go into Production with Portainer for the management of remote edge devices, congratulations..

But, your security team have decided to scrutinize the configuration, and rightfully so. They are concerned about exposing Portainer's ports to the internet, and have asked what extra levels of protection can be deployed.

Your first thought is firewall ACLs, except that wont work, as your edge devices have dynamic IP addresses, so there is no way of reliably knowing what IP address they will present as... so what else?

mTLS (MutualTLS) is a mechanism that forces both the client and the server to present valid evidence that they are who they say they are, and that that evidence is issued by a trusted source (certificate authority). This is a great way to add protection to any web service that is exposed to the internet, and that only trusted people/devices should be communicating with. But how do you configure mTLS in Portainer? Let me show you.

First up, you need to configure mTLS when you are deploying Portainer, so this is going to require you to redeploy (dont worry, you can reuse your existing Portainer DB) Portainer.

To keep things simple, i will make the Portainer Server the CA for the purpose of issuing TLS certs to the remote devices, but you should use your corporate CA for this.

First step, is to generate a root CA. SSH to the Portainer server to get started.

Enter the command: *openssl req -newkey rsa:8192 -nodes -keyout ca.key -x509 -days 365 -out ca.cert -batch*

This will generate you two files, ca.cert and ca.key.

Now we need to generate the server cert.

Enter the commands:

*openssl genrsa -out server.key 4096**openssl req -new -key server.key -out server.csr -batch**openssl x509 -req -days 365 -in server.csr -CA ca.cert -CAkey ca.key -CAcreateserial -out server.cert -extfile <(printf "subjectAltName=DNS:<YOURFQDNHERE>\nextendedKeyUsage=serverAuth")*

Now we need to generate the client cert, which our edge agents will use (either 1:1 or 1:many).

Enter the commands:

*openssl genrsa -out client.key 4096**openssl req -new -key client.key -out client.csr -batch -subj "/CN=client"**openssl x509 -req -days 365 -in client.csr -CA ca.cert -CAkey ca.key -CAcreateserial -out client.cert -extfile <(printf "extendedKeyUsage=clientAuth")*

OK, you need to copy the ca.cert, client.cert and client.key files locally, using whatever tools you prefer.

Now lets deploy Portainer.

Enter the folowing (to run under Docker):

d*ocker run --name portainer -d -p 8000:8000 -p 9443:9443 --restart=always \**-v /var/run/docker.sock:/var/run/docker.sock \**-v portainer_data:/data \**-v /root:/certs \**portainer/portainer-ee:latest --sslcert /certs/server.cert --sslkey /certs/server.key --sslcacert /certs/ca.cert*

Portainer will now start, using the self-signed cert. Also note i am bind mounting /root as that is where i generated the certs into above.

OK, so onto an agent..

We will first, try to use an agent without the mTLS cert, to show what happens.

For the sake of simplicity, we will use the following command to "bulk-onboard" a device.

*PORTAINER_EDGE_ID=$(hostname) **docker run -d \**-v /var/run/docker.sock:/var/run/docker.sock \**-v /var/lib/docker/volumes:/var/lib/docker/volumes \**-v /:/host \**-v portainer_agent_data:/data \**--restart always \**-e EDGE=1 \**-e EDGE_ID=$PORTAINER_EDGE_ID \**-e EDGE_KEY=aHR0cHM6Ly8xMzguNjguNi4xMy5uaXAuaW86OTQ0M3wxMzguNjguNi4xMy5uaXAuaW86ODAwMHxkZTphYzplMzo0Mjo3ZTpjMTo4NTo2YzphNjo2Yzo4ODowNjpkZjo4ODphNjo0NHww \**-e EDGE_INSECURE_POLL=1 \**--name portainer_edge_agent \**portainer/agent:2.14.2*

and then watch the logs of the agent.. see that it fails to connect..

and in the Portainer instance, nothing shows up in the edge waiting room.

OK, so stop this agent and remove it.. it will never connect.

now, create a directory called /certs and in that directory copy in the 3x certs saved previously.

Ok, and now we can redeploy the agent using a modified version of the deployment script, as follows:

*PORTAINER_EDGE_ID=$(hostname) **docker run -d \**-v /var/run/docker.sock:/var/run/docker.sock \**-v /var/lib/docker/volumes:/var/lib/docker/volumes \**-v /:/host \**-v /certs:/certs \**-v portainer_agent_data:/data \**--restart always \**-e EDGE=1 \**-e EDGE_ID=$PORTAINER_EDGE_ID \**-e EDGE_KEY=aHR0cHM6Ly8xMzguNjguNi4xMy5uaXAuaW86OTQ0M3wxMzguNjguNi4xMy5uaXAuaW86ODAwMHxkZTphYzplMzo0Mjo3ZTpjMTo4NTo2YzphNjo2Yzo4ODowNjpkZjo4ODphNjo0NHww \**-e EDGE_INSECURE_POLL=0 \**--name portainer_edge_agent \**portainer/agent:2.14.2 --sslcert /certs/client.cert --sslkey /certs/client.key --sslcacert /certs/ca.cert*

look at the logs of the container, see it connected and has been assigned a placeholder endpointID.

and now in Portainer, go into "edge devices" and "waiting room" to see the device is pending.

Associate it, wait a few seconds, and then see the heartbeat goes green.

You now have a Portainer instance, that is connected to the Internet, ready to accept onboarding requests SOLELY from Edge devices that present the CA issued client cert. Any other requests will be rejected.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-a-kubernetes-management-platform-for-newbies-and-experts
title: Portainer, a Kubernetes Management Platform for newbies and experts alike.
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-a-kubernetes-management-platform-for-newbies-and-experts
hostname: portainer.io
description: Portainer is a tool to empower non-experts to deploy and manage container-based apps within enterprise Kubernetes (and Docker/Nomad) environments.
sitename: PORTAINER.IO
date: 2022-06-28
categories: []
tags: []
image: https://www.portainer.io/hubfs/weight%20of%20Kubernetes-1.png
pagetype: article
filedate: 2025-01-18
-->

Portainer is a tool primarily designed to empower non-experts to deploy and manage container-based applications within enterprise [Kubernetes](/kubernetes-management-platform) (and Docker/Nomad) environments.

We achieve this design goal by removing as much mental burden as possible, allowing for browser-based, no-code, or low-code deployment and management/monitoring of applications across any Kubernetes cluster managed by Portainer (on-prem, cloud, KaaS).

Our forms-based "click-ops" UI is often seen as counter to modern Infrastructure as Code principles, and this is absolutely correct. If you want to have 100% consistency, and 100% repeatability each and every time, then having humans manually defining deployment specifications for each deployment may ultimately result in discrepancies.

So, why does Portainer persist in offering and enhancing our forms-based UI, if we know it's counter to IaC?

Simple, because there are millions of developers and IT Ops people from organizations across the globe that are only just beginning to get exposure to containers. These people often have no choice to adopt Kubernetes and we want to help make their Kubernetes adoption as efficient, and fast as possible. Like it or not, a web UI is the most familiar way to achieve this (think cPanel, Plesk, vCenter).

Remember, not every company develops their software stack themselves. Many buy "off the shelf" software that needs to run in containers, and these organizations likely don't have a Development/DevOps team that is up to speed with Kubernetes.

The same is true with organizations that create web apps or business apps, that sit on top of turn-key stacks. These companies likely have developers that are not deeply familiar with infrastructure, so need help getting their app running in Kubernetes, again these are not likely to have a DevOps team either. How can companies that fit into this criteria be expected to leverage Kubernetes if they are forced to use Kube native tooling? They likely cannot. Portainer bridges the gap here.

What we aim to do, is enable a safe and secure, self-service "click to deploy" UI for these non-experts, while at the same time, allowing EXPERTS to set the rules of the game.

Every company deploying applications in containers needs access to an expert - this is a fact. The expert can be an in-house person, or an external consultant, but regardless, at least one person must be responsible for the initial configuration of the environment. This expert can then configure what their users can see and do across the managed clusters using Portainer's RBAC functionality.

From security rules (don't allow containers to run as PID1, don't allow bind mounts etc), to quotas (max CPU, RAM, Disk, load balancers, etc), to enforcing the use of namespaces (disabling the use of the default namespace), and many more. The goal is to allo

w the EXPERT to enable non-experts to self-serve in a safe and governed way.

But why does this matter? Because experts are like diamonds; in demand, hard to find, expensive, and often stolen :). When you have one, you need to make sure they

ar

e not bogged down with mind-numbing questions from non-experts. The more "101" ques

tions you can take off an expert, the happier that expert is. Experts want to focus on making the platform better, they want to focus on automation, they want to focus on the really challenging issues... they don't want to answer "help me deploy this app again" for the 50th time this week. Experts need a "force multiplier" to help them do more, without having to work every hour of the day.

So, Portainer is not a tool that experts would likely use themselves on a day-to-day basis. Portainer is a tool that experts deploy to make their life just that little bit easier. And trust me, you want happy experts as they are the drivers of innovation!

Surely though, if users interface with Portainer, what happens when they do actually need help? Does an expert have to use Portainer to assist? Not at all... Portainer is a fully-fledged API proxy for Kubernetes, and the expert can use whatever tooling they prefer to triage the resources deployed through Portainer. Of course, if preferred, the experts can use our UI to inspect and make changes too, and as admins, none of the restrictions apply, so nothing gets in their way.

I hope this helps explain why Portainer is a tool that both experts and those who are new to Kubernetes, find helpful.

If you are an expert, give Portainer a try, it might save you from going crazy supporting your users :)

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/using-the-edge-agent-on-your-local-docker-instance
title: Managing your local Docker instance as an edge device with Portainer
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/using-the-edge-agent-on-your-local-docker-instance
hostname: portainer.io
description: How to add your local docker instance as an edge device and use the edge agent on your local machine.
sitename: PORTAINER.IO
date: 2022-09-12
categories: []
tags: []
image: https://www.portainer.io/hubfs/Managing%20your%20local%20Docker%20instance%20as%20an%20edge%20device%20with%20Portainer.png
pagetype: article
filedate: 2025-01-18
-->

**** UPDATED APRIL 2022 - Confirmed still working. Note that the Agent must use the same version as the Portainer Server (at time of update, 2.18.1) ****

So you have a standalone Docker host, but you want to experiment with Portainer's Edge Compute features. Or maybe you just want to use one of the features on your local machine (eg Edge Jobs, to schedule tasks to run on the host). Read on to learn how this can be achieved.

This can be accomplished using Portainer but is a non-standard deployment. Let me show you how:

Step 1, Deploy the Portainer Server instance. Note, you do not need to bind mount the docker socket, so the install command is just:

*docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v portainer_data:/data portainer/portainer-ce:latest*

Do this, and then log into Portainer, set your initial admin password,

Now click on "Add Environments"

Click on "Docker", then "start wizard"

Click on "edge agent"

Enter a name for the environment, eg local, and then in the URL put in [https://host.docker.internal:9443](https://host.docker.internal:9443) and click "create"

Click on "Docker standalone" and then copy the script

Paste into a text editor, and adjust, adding in the text in BOLD so it looks something like this:

*docker run -d \**-v /var/run/docker.sock:/var/run/docker.sock \**-v /var/lib/docker/volumes:/var/lib/docker/volumes \**-v /:/host \**-v portainer_agent_data:/data \**--restart always \**-e EDGE=1 \**-e EDGE_ID=6e0a2378-324f-43c2-9a96-43594fcf9737 \**-e EDGE_KEY=aHR0cHM6Ly9ob3N0LmRvY2tlci5pbnRlcm5hbDo5NDQzfGhvc3QuZG9ja2VyLmludGVybmFsOjgwMDB8OTE6NzA6MjY6Zjg6ZmQ6Mzg6ZjA6Nzc6MDU6ZTU6MjY6YjY6N2I6YWY6Y2U6YmR8Mw \**-e EDGE_INSECURE_POLL=1 \**--name portainer_edge_agent \**--add-host=host.docker.internal:host-gateway \**portainer/agent:latest*

Paste this into your CLI window, and it will start the agent.

Go back into Portainer and click "close"

Note your Environment is added, and it has a green heartbeat.

You can click on it, to manage that host.

Now, if you want to use the Edge features, click on settings, Edge Compute, and enable edge compute features.

You can now use Edge Jobs to schedule tasks on that host (as an example).

That's how easy it is to deploy the Edge Agent on your local Docker-CE Instance.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-and-industry-4.0
title: Enabling Industry 4.0 and IIOT Network Technology
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-and-industry-4.0
hostname: portainer.io
description: What is Industry 4.0, how does it fit with IIOT, and how Portainer is enabling Edge technology.
sitename: PORTAINER.IO
date: 2022-07-25
categories: []
tags: []
image: https://www.portainer.io/hubfs/Enabling%20Industry%204.0%20and%20IIOT%20Network%20Technology.png
pagetype: article
filedate: 2025-01-18
-->

Industry 4.0, it's an extremely important change to how we manage the manufacture of goods (and utilities), and arguably has the largest potential for efficiency gains since the industrial revolution!

But what is Industry 4.0 anyway?

Simply put, Industry 4.0 is a way of using technology to link your people, process, and machinery for the more efficient management of your factories, production facilities, and utilities. This linking means fully connected machines, using sensors and monitors to gather real-time data, streaming the data feeds into autonomous deterministic systems which can automatically act on anomalies, whilst at the same time, presenting consolidated/enriched data to human operators, allowing smarter near instantaneous decisions to be made.

As an example of Industry 4.0 benefits:

- You can radically reduce the number of manufacturing rejects by performing quality testing through every stage of the production line, with real time adjustments to production machinery when quality begins to fall below acceptable thresholds (but before quality drops to reject levels).
- You can reduce power consumption in buildings by only lighting/heating/cooling areas of the building that are in use by humans.
- You can provide remote assistance to field engineers from specialists in HQ through the use of computer-vision, and augmented reality (thereby allowing production facilities to operate with a lower-skilled onsite engineering team).
- You can prevent costly unscheduled stoppages to the production line from equipment failure through the use of predictive failure / predictive maintenance analysis .

Industry 4.0 is based off the technology initially driven from the adoption of "Internet of things" where consumer devices were connected to the internet. IOT allowed for the monitoring and management of smart home systems (fridges, dishwashers, air-conditioners, home surveillance cameras), and then later into smart city systems (traffic control, street lighting control, rubbish monitors etc). This is all well and good, but it’s one thing to lose control of your home automation (or even have it hacked), it’s another thing all together to lose control of your critical production line, or worse, have a hacker gain control of your power station. Therefore IOT, which is consumer focussed (and generally massive scale) has been adapted for Industry and branded IIOT (Industrial IOT). The main difference is security, but also reliability, as Operational Technology (technology that operates industry) cannot tolerate downtime or compromise.

Whilst IIOT defines systems are interconnected, HOW these systems are connected is left up to equipment manufacturers and software vendors. There are now tens (or even hundreds) of thousands of solutions addressing the needs of Industry 4.0, many of which are "retrofit kits" that can be added on to existing plant and machinery. There is a lot of focus on the next generation of Programmable Logic Controllers "PLC" (now often known as Programmable Automation Controllers) and Industrial PC's being the enabler of IIOT through its ability to run software from independent software vendors, and this software is able to interact with sensors attached to the PLC.

So how is this even relevant for Portainer?

Plain and simple really.

Software is being created by software vendors, and these software vendors need to create and distribute their software in the most efficient manner for them. The most efficient manner today is in Containers. So, we have software companies creating software for Industry as Containers.

PLC (and Industrial PC) vendors need to provide the hardware that runs software to control devices. The PLC vendors are seeing increased demand for their devices to run software as containers, and so now we have PLC vendors equipping their PLC devices with a Linux OS and Docker.

Finally, we have OT engineers, who are responsible for getting hardware and software SECURELY deployed, configured, and talking to their plant and machinery. These same OT engineers are looking at Linux, Docker, and Container based software and saying "WTF is this" :). Remember Containers are first and foremost an IT technology, so they are a very very new concept to OT, and probably something that most OT engineers have never heard of before.

Portainer provides a really simple way for an OT engineer to connect to one or more PLCs to deploy & manage the container based software supplied by their ISV, and Portainer does this without the OT engineer needing to become an IT engineer overnight.

Here's another interesting thing though, for a lot of Industry 4, the devices that are needed to run the container based software, well these are very low power devices; often with ARM CPUs, and <1GB RAM (most are only equipped with 512MB!) and a measly SD card as storage. These devices are perfectly capable of running Docker (and even Docker Swarm) but they are a million miles away from being able to run even the most lightweight of Kubernetes distributions. As a result, the plethora of Kubernetes management tools that dominate the IT space have near zero applicability in the OT arena. This makes Portainer's full support for Docker a match made in heaven, and its why so many of the PLC vendors ALREADY ship Portainer as part of their base OS image. We are one of the very few fully supporting Docker.

So, if your organisation is going to embark on an Industry 4.0 project, and you are thinking "how do i empower my OT engineers" then look no further than Portainer. Get in touch and we can share some of the reference architectures we have for managing software in the OT world, we even have an OT demo lab to show you live..

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/choosing-the-best-kubernetes-dashboard-for-your-enterprise
title: Choosing the best Kubernetes dashboard for your Enterprise
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/choosing-the-best-kubernetes-dashboard-for-your-enterprise
hostname: portainer.io
description: A short assessment of the best Kubernetes dashboards and how Portainer differs from the pack.
sitename: PORTAINER.IO
date: 2022-07-01
categories: []
tags: []
image: https://www.portainer.io/hubfs/Screenshot%20for%20Kubernetes%20Dashboard%20blog.png
pagetype: article
filedate: 2025-01-18
-->

There has been a lot of fanfare in the Kubernetes community around the plethora of "dashboards" that are available, and which one is the best Kubernetes dashboard that can seemingly make the life of a Developer / DevOps Engineer monumentally easy.

By "dashboard", I mean Lens, Octant, Headlamp, Kubernetes Dashboard, and in some regards, also the Rancher Cluster Explorer as well as many others. All of these dashboards are trying to do one thing; present what's available via the Kubernetes API in a graphical way, and in a way that makes it simpler to see what's going on under the covers without actually having to remember the KubeCTL commands to do so. Most of these tools are installed locally on a user's machine, however, a few are deployed by an admin centrally and accessed by users via a browser. There are even a few SaaS dashboard offerings out there (although for something so simple, I'm not sure why you need a SaaS version).

Our assessment of these dashboards is that their UX and features are remarkably similar. Lens, with its 'plugin' architecture is probably the most advanced as it allows other ISVs to extend the base functionality to support additional dashboard operations. Unless you use this Lens feature, pretty much any of the dashboards could be swapped with another, and you wouldn't really notice any change in functionality. Sure there are slight differences between the dashboards (can see all workloads across all namespaces vs can only see workloads within a selected namespace, as an example), but materially, there are no major differences.

Make no mistake, at Portainer, we are great fans of dashboards. It's where we started life, being a Docker Dashboard (and to this day, we remain a very strong Docker dashboard), however where we diverge from the common school of thought is that we believe Kubernetes is overly complicated for a straight 1:1 abstraction of API to GUI, and that with all these dashboards, if you don't know Kubernetes (or how to write YAML files) you can't really get started.

Getting Started with Kubernetes

In Portainer, we created a higher-level abstraction in our Kubernetes UI so that as long as you know Docker (think Docker on your laptop) then you can deploy, manage and maintain your applications in Kubernetes, without first having to learn the inner workings and finer details of Kubernetes.

We call this our "getting started" or "Kubernetes onramp" experience, which you use when you deploy an app via our form-based deployment page. Of course, not everyone wants this level of abstraction, so we also have an "advanced mode" button, which lets you deploy any Kubernetes manifest of your choosing (from Git or by directly pasting in the YAML).

We realize this might not be all you want and that you may actually have your own personal preferences in regards to using one of the aforementioned dashboards, or even KubeCTL on your PC natively. This may extend to using your own CD deployment tool where DevOps have this flexibility. This is what we call "bring your own tooling", and as everyone wants to maximize the efficiency of Developers/DevOps/Ops, if BYOT is how to get this, why should we stop that?

In Portainer CE 2.9, we added the ability to use Portainer (itself) as a Kubernetes endpoint, allowing you to use ANY dashboard or CD tool to manage environments under Portainer control. We also provided access to KubeCTL directly inside Portainer, so you can run commands directly against Kubernetes endpoints (within the limits of your assigned permissions).

So, what is Portainer's value proposition here, especially if users don't actually use Portainer, and instead prefer using other dashboards? Simple, Portainer is a [Kubernetes management](/kubernetes-management-platform) platform that provides centralized management, control, and governance for enterprise Kubernetes management (as well as Docker/Swarm and Nomad).

Portainer still acts as a centralized IAM, authenticating users, assigning roles, and setting access control across all your environments, regardless of how many clusters you manage, on-prem, in the cloud, or at the edge. If you want to onboard Kubernetes (or Docker) quickly, grant users access, and specify RBAC rules centrally, then Portainer is for you. We will always retain, and continue to enhance our "getting started" experience, to make the power of containers available to everyone.

As always. comments welcome.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/root-console-to-a-host-via-portainer
title: Root Console to a Host via Portainer?
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/root-console-to-a-host-via-portainer
hostname: portainer.io
description: How to gain console access to your hosts via Portainer
sitename: PORTAINER.IO
date: 2022-07-24
categories: []
tags: []
image: https://www.portainer.io/hubfs/2.15-docker_containers_container_console_connect.png
pagetype: article
filedate: 2025-01-18
-->

So, you have Portainer running in your environment, you are remote, enjoying a long overdue holiday or something suitably glamorous, and now disaster strikes... you need to access your Docker/Kubernetes Hosts, but you forgot your SSH keys...

What can you do? You have Portainer running, you are an admin, so how can you get a console on the hosts?

Well, due to the nature of Docker (and to a lesser extent, Kubernetes) containers BY DEFAULT have near unlimited access to the host (its why security is so critical).

Let me show you what i mean.

In Portainer, click on Containers, and then click to "+ Add Container".

Use the image "busybox:latest" (or another of your preference)

In the bottom of the window, "advanced container settings" select console mode " Interactive & TTY"

Set a bind mount of /host in the container to / on the host

Set the permissions to "privileged"

Deploy the container.

Now, console into the container (for busybox, change the console to /bin/sh).

Type the command chroot /host to change your default root path to be /host (which is the bind mount to the host fs)

The container is now running as root on the host and you can run commands againt the host.

As an example, you can type "echo 3 > /proc/sys/vm/drop_caches" to flush the memory caches .. or you can reboot the host using "reboot now"

So this is a really quick and easy way to get root console access to your hosts..

Dangerous? Yes, or course, and its why (by default) in Portainer we DISABLE this capability for non-admin users.

Regardless, if you are remote, a Portainer admin, and you need to quickly gain access to your hosts, this does the trick.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-edge-bulk-device-onboarding
title: Portainer Edge - Bulk Device Onboarding
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-edge-bulk-device-onboarding
hostname: portainer.io
description: Edge Device bulk onboarding in Portainer
sitename: PORTAINER.IO
date: 2022-08-27
categories: []
tags: []
image: https://www.portainer.io/hubfs/Portainer%20Edge%20-%20Bulk%20Device%20Onboarding.png
pagetype: article
filedate: 2025-01-18
-->

So, a new feature added to Portainer business in 2022 was the ability to bulk onboard any number of edge devices into Portainer.

This feature leverages a generic "discovery" mechanism that pre-configures remote environments to announce themselves to your Portainer instance, allowing the admin to selectively "admit" devices for centralised management.

Let me show you.

First up, make sure you have a copy of Portainer running, and that its correctly configured to support edge devices (Port 9443/8000 or 30779/30776 depending on your deployment).

Once you have that, log into Portainer (make sure its a recent version, ie 2.14.2 or newer), and navigate to "Settings / Edge Compute" and scroll down until you see "Automatic Edge Environment Creation"

Note the Portainer URL, as this is the URL that the remote devices will use to connect to your Portainer instance. Make sure its correct and resolvable by the remote device. Also, make sure its HTTPS.

For security, we recommend leading the "disable edge environment waiting room" switched off, as turning this on will automatically authorise any remote environment presenting itself to this Portainer instance using the bulk-onboarding script. By default, we hold any requests in a waiting room pending Admin approval.

In the "edge ID generator" enter in a remote device environment / system variable that we can use as a unique identifier. We recommend "hostname" but you can use anything that is available as a variable on the remote device.

Copy the command applicable to your remote environment, in my case, Docker standalone. This is a generic command that can be used multiple times to onboard ANY remote device into your Portainer instance. No changes are needed regardless of the number of times used.

Now, SSH to your remote devices (or run an automated script that SSHs to each of them, and run the command copied from above.. for this blog, i am deploying onto 3x Docker Standalone Hosts.

Now, back in Portainer, navigate to "edge compute" in the sidebar, and then click on "edge devices". Note that there are no edge devices listed.

Click on "Waiting Room", and see that your devices are in there, waiting to be Assoicated.

Select one or more devices, then click on "Associate Device". Look for the success confirmation.

Now go back to "edge devices" and see the three are listed and have a green heartbeat.

You are now able to remotely manage the devices, using either the "edge stacks" option, or interactively, by navigating to them by clicking the 3 dots and selecting "browse".

This is how easy it is to use the bullk-onboarding script, and the edge waiting room to onboard remote devices into Portainer.

If you're just getting started with Portainer for Edge, you might enjoy this blog post on [Using the Portainer Edge Agent, Edge Groups, and Edge Stacks - Part 1.](/blog/using-the-portainer-edge-agent-edge-groups-and-edge-stacks-part-1)

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/how-to-create-kubernetes-clusters-on-azure-aks-amazon-eks-and-google-gke
title: How to create Kubernetes clusters on Azure AKS, Amazon EKS and Google GKE
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/how-to-create-kubernetes-clusters-on-azure-aks-amazon-eks-and-google-gke
hostname: portainer.io
description: Learn how to easily create Kubernetes clusters inside Google GKE, Amazon EKS, and Microsoft's AKS with Portainer.
sitename: PORTAINER.IO
date: 2022-06-27
categories: []
tags: []
image: https://www.portainer.io/hubfs/GKE.png
pagetype: article
filedate: 2025-01-18
-->

In [Portainer Business Edition 2.13](/blog/portainer-announces-kubernetes-provisioning-on-digitalocean-linode-and-civo) we introduced the notion of users being able to dynamically create clusters for a small number of cloud providers ([Linode, Civo and Digital Ocean](/blog/portainer-announces-kubernetes-provisioning-on-digitalocean-linode-and-civo)). As we expected, this functionality has been welcomed with open arms by the Community, which has led us to expand it in today's [2.14 BE release](/blog/portainer-ce-and-portainer-be-2.14-is-here.-download-it-now).

From today, organizations can create clusters in the 3 largest managed Kubernetes environments: [Amazon's EKS, ](https://aws.amazon.com/eks/)[Microsoft's AKS](https://azure.microsoft.com/en-us/services/kubernetes-service/#overview) and [Google's GKE](https://cloud.google.com/kubernetes-engine/?utm_source=google&utm_medium=cpc&utm_campaign=japac-NZ-all-en-dr-bkws-all-all-trial-e-dr-1009882&utm_content=text-ad-none-none-DEV_c-CRE_468768392084-ADGP_Hybrid%20%7C%20BKWS%20-%20EXA%20%7C%20Txt%20~%20Containers%20~%20Kubernetes%20Engine_Kubernetes-gke-KWID_43700033867247471-kwd-372556496315&userloc_1011036-network_g&utm_term=KW_google%20gke&gclsrc=aw.ds&gclid=CjwKCAjwh-CVBhB8EiwAjFEPGaB4zlZwpuY5w2VCXKkSmHyY0h0eToob_UZGAFHbvEtzWnegG19dcBoCQAcQAvD_BwE). This is a significant step forward for the cloud as it means organizations can get apps up and running on mainstream managed Kubernetes services with very little in-house technical expertise.

If you're new to Kubernetes and you need to get an application up and running fast, then Portainer Business Edition running in any of the main cloud providers is now your best option. If you want to know more then get in touch and we'll show you how.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/orchestrator-wars-continue
title: Docker Swarm vs Kubernetes vs Nomad - the orchestrator wars continue?
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/orchestrator-wars-continue
hostname: portainer.io
description: Docker Swarm vs Kubernetes. Nomad vs Kubernetes. Which orchestrator is right for you? This blog post examines the pro's and con's of the orchestrators.
sitename: PORTAINER.IO
date: 2022-08-24
categories: []
tags: []
image: https://www.portainer.io/hubfs/Kubernetes%20vs%20Swarm%20vs%20Nomad.png
pagetype: article
filedate: 2025-01-18
-->

So I was casually browsing Twitter this morning, and happened to get tagged on a post asking if there are any alternatives/competitors to Kubernetes, and a few people replied Docker Swarm, HashiCorp Nomad, and some even said Portainer. Interestingly, no one mentioned AWS ECS (which in my view is really the only competitor to Kubernetes).

Let me make one thing clear up front, Portainer is NOT a competitor to any of these products, for the simple reason that we are not an orchestrator. We are a centralized container management platform for all of the aforementioned orchestrators.

But here is where things get a little murky.

Docker Swarm vs Kubernetes

Docker Swarm, for all the love it STILL gets (we see +ve month on month adoption of Swarm and over 50,000 Portainer users are using it!), is really a half-finished project. It has no notion of users or RBAC, and as such, is not something enterprises (or anyone that needs granular security) should really consider. BUT Portainer on top of Swarm; well we add that missing access control layer, making it more enterprise-ready. Hence the confusion.

One thing though, Docker Swarm (or more accurately, moby swarmkit) is now massively undermaintained. There are many bugs that go unpatched (bugs on the [swarmkit repo](https://github.com/moby/swarmkit) go stale), its capabilities/features seem quite "frozen in time", and even Docker themselves dont actively promote it / talk about it.

Swarm appears to be an orphan, under the control of Mirantis, who really just wants to focus on Kubernetes. If Swarm works for you, then you will absolutely enjoy its simplicity, but be aware there is no way of officially obtaining support for it, and if you hit a bug, chances are it won't get fixed anytime soon. Thankfully, its simplicity also means that it doesn't have that many bugs, hence it's loyal following.

Kubernetes vs Nomad

So, in the enterprise space, there really are only two supportable options, Kubernetes and HashiCorp Nomad. And by far, the mindshare sits squarely with Kubernetes. Heck, the CNCF landscape shows over 1000 tools focussed on enhancing Kubernetes (Portainer is one of them), and there is probably only a handful that supports Nomad (Portainer is also one of them).

Kubernetes - the orchestrator of choice

In our view, right now, Kubernetes is the orchestrator of choice for enterprises. It's the one with all of the tooling around it. It's offered as a service by almost all of the cloud providers, and it has a complete ecosystem of professionals wanting to get certified in it.

Back onto AWS ECS, and why I think it's the only real Kubernetes competitor. ECS has been around the longest, and for good reason.. it just works. Sure it locks you into the AWS eco-system, but given AWS has a large % of cloud market share, it's interesting that it isn't seeing a resurgence of popularity as people hunt for easier solutions than Kubernetes.

My advice.. use whatever works for you. If your team is not sufficiently equipped to deal with the complexity of Kubernetes, then Docker Swarm is fine, and so too is Nomad. Heck, even standalone (non-orchestrated) Docker Hosts are a good way to start. There is nothing worse than your first experience of containerization being a negative one due to the overwhelming nature of Kubernetes. This is why Portainer is so focused on being orchestrator agnostic, so we can support any organization, across any level of maturity, and we do that with a consistent UX, so once you start using Portainer, the transition to any other orchestrator is, well, easier.

Anyway, just my 2c.

##### Try Portainer with 3 Nodes Free

If you're ready to get started with Portainer Business, [3 nodes free](/take-3) is a great place to begin. If you'd prefer to [get in touch with us](https://www.portainer.io/contact-sales), we'd love to hear from you!

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/deploying-off-the-shelf-software-in-enterprise-kubernetes-environments
title: Deploying off the shelf software in enterprise Kubernetes environments
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/deploying-off-the-shelf-software-in-enterprise-kubernetes-environments
hostname: portainer.io
description: With developers and ISVs standardizing on containers and Kubernetes for their apps, where does that leave organizations that have no Kubernetes expertise?
sitename: PORTAINER.IO
date: 2022-07-06
categories: []
tags: []
image: https://www.portainer.io/hubfs/Deploying%20off%20the%20shelf%20software%20in%20enterprise%20Kubernetes%20environments%20v2.png
pagetype: article
filedate: 2025-01-18
-->

Kubernetes is getting a lot of love in the Dev and DevOps community, and rightfully so. This [survey ](https://www.cncf.io/wp-content/uploads/2021/12/Q1-2021-State-of-Cloud-Native-development-FINAL.pdf)from CNCF found that there are now nearly 7M cloud-native software developers around the world, with larger enterprises and more experienced developers in North America and Western Europe driving the rapid adoption of these technologies.

The significant interest in Kubernetes, and its rise in adoption, is quite simply because it's highly beneficial for those that create and distribute software. This is true for both in-house developers building in-house apps, and those that work for independent software vendors (ISVs) building commercial apps.

With developers standardizing on containers as their development tooling, it's inevitable that the release teams from commercial software vendors will be recommending their management teams pivot, and solely release their products as containers. Let's face it, ISVs have a lot to gain from shipping as containers, being easier to maintain/update and easier to support.

The problem is, not every company out there develops software, in fact it's fair to say that the vast majority of companies have very little in the way of in-house software development capability.

There are literally millions of companies that BUY commercial 'off the shelf' software, install it, and get on with the job of running their business. Just think how many companies are powered by SAP, MS Dynamics (or any other ERP), Manufacturing Execution Systems, Finance Systems, and CRM systems, let alone ecommerce solutions, warehousing solutions, relational databases / BI solutions, even API/EDI Gateways, you name it. Sure some of these organizations might have one or two people creating ancillary (user-facing) apps supporting their core "systems of record", but these developers are likely web/business/mobile developers, not full stack hardcore infrastructure experts.

These same companies will likely have their own internal IT team (or outsourced IT support), who are quite used to INSTALLING software on virtual servers. These people likely have very little exposure to containers, let alone Kubernetes. So what happens to these companies when they are forced to come to grips with their software vendor mandating Kubernetes? Do these companies need to look for a new software vendor? Or do they instead need a way to get a Kubernetes platform running, their purchased app running, and be able to support this "stack" without having to go out and hire a new team of experts (talk about piling on OPEX costs).

We believe that the Kubernetes ecosystem is too focussed on Dev and DevOps, and there are not enough organizations looking to help those that need to use Kubernetes, not by choice.

[Portainer has been designed from day 1 with non-expert users in mind](/blog/portainer-a-kubernetes-management-platform-for-newbies-and-experts). We do not require Portainer users to have prior knowledge of Kubernetes to start using Kubernetes. Shocking as it might sound, there are companies out there that expect their IT systems to be easy to use and want Kubernetes to be as invisible as VMware is in their stack... it's there, but no one really cares about it.

Portainer's intuitive Kubernetes UI guides operators to deploy container-based applications (that ship either as pure standalone docker containers, as a docker compose file, as a Kubernetes Manifest, or as a HELM chart) in a really simple manner. So simple in fact that with some basic instructions (which the vendor can provide), any IT administrator could use Portainer to deploy near any application, of almost limitless complexity.

Don't for one second think that Portainer is ONLY a simple UI, we are so much more. Simplicity with massive compromise is useless, we abstract away complexity without having to give up capability, and that is an artform. In addition, as users become more familiar with Kubernetes (which is inevitable), their use of Portainer can change to being more automation centric.

How many other Kubernetes tools can you think of out there that can make this same claim? Maybe 1 or 2 at best, but for sure >95% are focused on expert Developers / DevOps engineers. This isn't a bad thing, not at all, it's just not the only need out there.

Give Portainer's Kubernetes management platform a go with [3 nodes free](/take-3) and see how easy it SHOULD be.

Neil

Keen to compare enterprise Kubernetes platforms? In this blog post we've put 3 popular options under the microscope to see how they differ, and the pros and cons of each solution. Check out the feature comparison table to learn which tool is right for you. [Compare Portainer vs Rancher vs OpenShift](/blog/portainer-vs-rancher-vs-openshift).

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/platform-engineering-transforming-it-infrastructure-for-modern-enterprises
title: Platform Engineering - Transforming IT Infrastructure for Modern Enterprises
author: Rich Sharples
url: https://www.portainer.io/blog/platform-engineering-transforming-it-infrastructure-for-modern-enterprises
hostname: portainer.io
description: Platform Engineering is transforming IT infrastructure for modern enterprises, streamlining processes, increasing efficiency, and improving developer productivity. Learn about the core responsibilities and impact of Platform Engineering in this insightful blog post by Rich Sharples.
sitename: PORTAINER.IO
date: 2024-06-24
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/Platform%20Engineering.jpeg
pagetype: article
filedate: 2025-01-18
-->

### Introduction

The interest and momentum around [Platform Engineering](/solutions/for-platform-engineering) has really grown over the last couple of years - marked by the significant bump in attendance of last month’s [Platform Con204](https://platformcon.com/talks) and research from Gartner claiming that “By 2026, 80% of large software engineering organizations will establish platform engineering teams as internal providers of reusable services, components and tools for application delivery — up from 45% in 2022”

The idea of a dedicated platform team tasked with streamlining an organization’s Internal Developer Platform has been around for over a decade but only in the last few years has it’s current meaning solidified. Over the years technology stacks have increased in complexity and the use of cloud computing services and containerization technologies (like Kubernetes and Docker) further solidified the need for dedicated teams to streamline and manage the platforms used for application development and delivery.

Matthew Skelton and Manuel Pais released their [Team Topologies](https://teamtopologies.com/) book in 2019 and while this may not have been the first formal and modern definition of Platform Engineering term, it’s probably served as the inspiration for many organizations.

### What is Platform Engineering?

In Skelton and Pais "Team Topologies," Platform Engineering is defined as the practice of building and maintaining an internal (developer) platform that provides reusable services, tools, and infrastructure and captures best practices and knowledge to support development teams. The goal is to reduce cognitive load on product teams by abstracting complexity and enabling faster delivery of value.

### Core Responsibilities of Platform Engineers

#### Automation

Problem: Manual processes are time-consuming and prone to errors.

Solution: Platform engineers implement CI/CD pipelines to automate the build, test, and deployment processes. This not only speeds up development but also ensures consistency and reduces the likelihood of human error.

#### Scalability

Problem: Applications need to handle varying loads without performance degradation.

Solution: Engineers design systems that can scale horizontally or vertically to meet demand. This involves load balancing, auto-scaling, and optimizing resource allocation to ensure applications perform well under different conditions.

#### Reliability

Problem: Downtime and performance issues can disrupt user experience and business operations.

Solution: Platform engineers establish robust monitoring and logging systems to detect and address issues proactively. They also implement redundancy and failover mechanisms to maintain high availability and reliability.

#### Security

Problem: Security vulnerabilities can lead to data breaches and compliance issues.

Solution: Engineers enforce security best practices such as encryption, role-based access control, and regular security audits. They ensure that the infrastructure complies with industry standards and regulations, protecting sensitive data and maintaining user trust.

#### Curating Golden Paths

A "golden path" refers to a set of best practices, tools, and workflows that a platform team provides to development teams to streamline and standardize the development process. It represents the optimal, recommended way to build and deploy applications, ensuring efficiency, consistency, and reduced cognitive load.

### The Impact of Platform Engineering

The work of platform engineers has a profound impact on the overall efficiency and effectiveness of an organization’s software development lifecycle. Here’s a summary of the key benefits:

- Increased Efficiency: Automation and streamlined processes reduce manual tasks, allowing developers to focus on innovation.
- Improved Reliability: Proactive monitoring and robust systems ensure high availability and performance.
- Enhanced Security: Strong security measures protect sensitive data and maintain user trust.
- Better Developer Productivity: Simplified processes and tools boost developer morale and productivity.

### Conclusion

Platform Engineering teams reduce cognitive load by abstracting complex infrastructure and providing reusable services, allowing development teams to focus on building applications and delivering features. They enforce consistency and standardization through best practices and standardized workflows (aka Golden Paths), ensuring uniformity across projects. By offering pre-built tools and services, platform engineering teams increase efficiency in development and deployment processes. They enable scalable solutions that grow with the organization’s needs. Additionally, by simplifying the development process, they improve overall developer productivity and satisfaction especially for new developers onboarding into the organization.

[With 30+ years in software, Rich brings seasoned leadership in product and technology. His expertise spans software development, product management, and fostering innovation.](https://www.portainer.io/blog/author/rich-sharples)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/deploy-prometheus-monitoring-stack-with-portainer?hsLang=en
title: Deploy Prometheus Monitoring Stack with Portainer
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/deploy-prometheus-monitoring-stack-with-portainer
hostname: portainer.io
description: Deploy Prometheus Monitoring Stack with Portainer, and use as a substitute for metric-server.
sitename: PORTAINER.IO
date: 2022-03-06
categories: []
tags: []
image: https://www.portainer.io/hubfs/Deploy%20Prometheus%20Monitoring%20Stack%20with%20Portainer.png
pagetype: article
filedate: 2025-01-18
-->

Out of the box, Portainer supports monitoring Kubernetes clusters via the metrics server/API, which gives you basic CPU and Memory stats for Pods and Nodes. But what if you want more bells and whistles?

Most people are familiar with Prometheus and Grafana, but how do you go about deploying them into Portainer managed Kubernetes Clusters? Let me show you.

First up, login to a Portainer instance that is managing one or more Kubernetes cluster.

Select the Cluster you wish to install Prometheus on,,then click on "Namespaces" and create a simple namespace.

Now click on 'HELM'.

in the "Additional Respostories" field, type in [https://prometheus-community.github.io/helm-charts, ](https://prometheus-community.github.io/helm-charts)then click "Add Repository"

Choose "Kube-Prometheus-stack".

*Note, for this to deploy, my nodes needed >4GB RAM, else OOM errors will be generated (the cluster was empty except this stack)*

Select the namespace, give the deployment a name, then click "Install".

Note that this "default" deployment does not persist the Prometheus data, so if you want to do that, you need to edit the custom values.

Alert Manager:

Grafana:

Prometheus:

Once the deployment has finished, navigate to "Applications" and check that all is good.

If your cluster does NOT have the metrics server installed ,and you would like to use Prometheus as your metrics server, go back into HELM, and deploy the chart "prometheus-adapter", which will configure Prometheus as a pseudo "metrics-server".

Edit the custom values,

1) In Line 31, Add the URL of the Prometheus instance deployed above.. in this case it is: http://prometheus-stack-kube-prom-prometheus.prometheus

2) Starting line 102 and going through to line 126, uncomment all of the "resources:" section (note, make sure to remove the {} brackets after resources:). Click "Install"

Once that is installed and running, go into "Cluster" and then "Setup" and enable features that use the metrics API. It should succeed if the HELM chart above deployed OK.

To check, click on "Cluster" and then view the stats for a node..

OK, so now Prometheus is installed, the adapter is installed to provide metrics services via the metrics API, but how do you actually access Grafana and Prometheus UI?

Go back to applications, expand the "prometheus-stack" and then click on "prometheus-stack-grafana"

Note it is only presenting itself inside the cluster, as a clusterIP

If you want to access it externally, you can just click "edit application" and add a service that suits your needs, in my case I have selected "LoadBalancer" and exposed Port 3000.

After updating the service presentation, you should now get the default admin password for Grafana. Scroll down to "config" and click on the config for admin-password

Here are the default credentials:

OK, so let's open Grafana.

And open a default dashboard, Node (Pods)

Success.

If you choose to expose the Prometheus UI, you'll not it has no authentication in front of it, so I would be hesitant mapping it to a load balancer.

So this is how you can deploy Prometheus and Grafana with Portainer, and use it as a substitute for metrics server.

For optional Part 2 of this blog, adding additional Prometheus instances to this Grafana deployment, click here ->. [https://www.portainer.io/blog/deploy-prometheus-monitoring-stack-with-portainer-part-2](https://www.portainer.io/blog/deploy-prometheus-monitoring-stack-with-portainer-part-2)

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/deploy-and-use-argocd-with-portainer?hsLang=en
title: Deploy and use ArgoCD with Portainer (Part 1)
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/deploy-and-use-argocd-with-portainer
hostname: portainer.io
description: Portainer has an excellent continuous delivery (CD) engine built-in, but what if you want to use ArgoCD with Portainer? This 2 part blog shows you how.
sitename: PORTAINER.IO
date: 2022-02-10
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Feb-10-2022-05-57-34-11-PM.png
pagetype: article
filedate: 2025-01-18
-->

Portainer already has a good continuous delivery (CD) engine built in, one that ensures applications running in Portainer managed Kubernetes clusters are consistent with their mainifest definitions stored within a Git repo.

But, what if you want to use ArgoCD? Does that mean you can't use Portainer for your centralized Kubernetes management? The answer is 'no'. This two-part blog shows you how to set it up.

Part 1 is deploying an ArgoCD management instance on a Kubernetes cluster. [Part 2](/blog/deploy-and-use-argocd-with-portainer-part-2) is connecting that management instance to additional Kubernetes clusters. This blog focuses on Part 1, with Part 2 linked at the end.

The easiest way to get ArgoCD installed is to use the helm chart provided in Portainer, under our HELM page.

Jump Into Portainer and connect to the Kubernetes environment that you want to host the ArgoCD server. In my case, it's my laptop, but for an organization, this will likely be an instance in your data center.

Click on namespaces, and create a namespace called argocd (note it has to be called this to work, else you need to modify the argo manifests)

Now, click on "HELM", and then "Argo-CD"

Select the "argocd" namespace, and give the deployment a name, argocd, then click the "show custom values".

In the web editor, scroll to lines 1041 and change the service type to NodePort, then on lines 1046/1047 and replace the " " with two free nodeports in your system. I used 30080 and 30443 (dont forget to remove the speechmarks), then click "Install"

Switch to "Applications" view, and wait for all 5 components go green.

Click on the "argocd-argo-cd-server" component and see the 2x NodePorts you assigned.

Now let's open the ArgoCD UI. In my case, its https://localhost:30443

Ah, but what's the username and password? Well that was auto-generated by ArgoCD at install time, so let's retrieve it.

Go back to Portainer, and click on ConfigMaps&Secrets. Click on the secret called "argocd-secret". Look for "clearPassword". Copy the value, as that's the password for the "admin" user.

Now, login to ArgoCD UI as admin, with that password.

ArgoCD is now installed, and ready to be used. You can use this instance to deploy applications on this local cluster. Here's how:

Click on Settings and then Repositories.

Add credentials for your Git repo. In my case, I am connecting to a repo using https. Click "Connect"

Make sure your repo has connected successfully.

Now that's done, you can deploy your first gitops app. Click on Apps, then "Create Application" and fill in the details for your Git repo.

Give your app a name, select the default project (unless you are using custom projects). Select "prune resources" and "self heal" if you want Kubernetes to ALWAYS reflect the settings you have for your app in Git.

Now select the repository URL you defined previously, set the branch revision from git (in my case, its just HEAD), and set the path to the manifest files (in my case, demo).

Set your destination cluster (we only have the local one defined at the moment), then select the target namespace. Note the namespace needs to exist first, else Argo will fail.

In my case, I selected a namespace that doesn't exist, and this is what you see in Argo UI.

So let's go back into Portainer and create the namespace.

Click on "Namespaces", then click "Add namespace from form"

Name it demoapp (as used in your Argo deployment),disable resource assignment, and then click create.

Go back into Argo UI, click Applications, find your app, and click "Refresh"

See that it now switches to "Healthy" and "Synced"

Back in Portainer, click on Applications, and see the app is deployed and running.

Now, go into Git, edit your deployment file, and then wait for the change to propagate. In my case, I will increase replicas to 2.

in a few minutes, Portainer will reflect 2 replicas.

This is how you use Portainer and ArgoCD together. Easy.

[In PART 2 of the blog](/blog/deploy-and-use-argocd-with-portainer-part-2), I will show how to add Portainer Managed Kubernetes Clusters to this ArgoCD instance.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/as-a-ceo-why-do-i-still-run-a-homelab?hsLang=en
title: As a CEO, why do I still run a homelab?
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/as-a-ceo-why-do-i-still-run-a-homelab
hostname: portainer.io
description: Learn why the CEO of Portainer runs a homelab, exploring various container runtimes and Kubernetes distributions to stay ahead in the tech market.
sitename: PORTAINER.IO
date: 2024-07-29
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/homelab%20setup.jpeg
pagetype: article
filedate: 2025-01-18
-->

As a technical guy, regardless of where I am in my career, I love to keep my hands on the tools... its what makes me able to run technical workshops, talk with engineers, and question statements made that are baseless in fact... call it my unfair advantage.

Well, here at Portainer, I also like to keep my fingers on the pulse of the tech, and so have spent the last couple of weeks rebuilding my homelab (yes, I have one). This is not your regular home setup, where you might run some PLEX or other home automation software, no, this is a homelab for me to keep my knowledge of the market sharp.

What's running in my HomeLab might you ask? A bit of everything..

The hardware I chose to run this on is an old HP Z440 Professional Workstation. It comes with a 28 Core Xeon CPU, 64GB RAM, and a 1TB SSD. I upgraded it with a 2TB NVMe disk, and have just ordered an extra 64GB RAM (because, well OpenShift uses a LOT of resources).

On this "server" I run Proxmox VE v8, which is a simply brilliant piece of open-source software (and I bought the subscription). This Proxmox environment comfortably allows me to run all my VM workloads.. well, once I added the NVMe disk anyway.

I connect to the environment remotely with a really simple OpenVPN Sever (which runs in a container - [https://dockovpn.io/](https://dockovpn.io/)) and I use PiHole as a local DNS server + Network privacy shield (for my home network). Other than that, the setup is pretty simple. I will be putting in my favorite reverse proxy, nginxproxymanager. Oh, and I run Seafile for a self-hosted "dropbox" alternate.

So, now that I have this environment, what was the intent of it?

The container space is ever-evolving. Newcomers are arriving into the space, products that flew under the radar are getting "discovered", and even for more mature products, they keep enhancing their offering.

As Portainer (the product) does not include a container runtime, nor a Kubernetes distribution, we are ALWAYS acting as a management overlay for other products. Now, in all honesty, the runtime and distro don't matter to us, as we talk to the native APIs, and as long as the distros are certified, we should have no compatibility issues. Well, that's the theory. In reality, every single distro aims to offer a "value add" over and above the standard Kubernetes capability, be that applied defaults, or just simple configurations.

I am using this environment to 1) learn how to deploy the latest versions of the container runtimes and Kubernetes distros, and 2) make sure that Portainer does actually work well with these distributions (yes, our QA team validates a subset, but I like to experiment myself, chaos engineering style).

A couple of learnings so far

Talos Kubernetes is awesome. I like the fact you can completely deploy and manage the environment from a central location, OS, and Kubernetes, without needing to SSH to the environment at all (well, you can't anyway). It's a pretty lean distro too, only needing 2-3GB of RAM per Kubernetes node. I really like that its "secure by default" too.

OpenShift is VERY involved to deploy and configure, and its a resource-consuming beast. 14GB RAM and 4 CPUs on the control-plane nodes.. just to idle (and 70 "system" namespaces once its up!!). Sure, it's probably got the widest adoption in the industry (as everyone in enterprises buys from Gartner "top right"), and RedHat is known for its awesome support, but wow. Bring your chequebook :). If you are using Portainer to manage OpenShift, then you don't need Openshift ACM (part of the Openshift Platform+ bundle). There is a lot of overlap there.

Rancher hasn't really changed in years.. and I guess, why does it need to? Getting a RKE cluster up and running was pretty easy (would be easier if they had a native Proxmox driver like they do with vSphere). Again, quite a resource-heavy distro, but a fraction of OpenShift. Rancher remains a really good way to spin up and lifecycle Kubernetes Clusters.. however, I prefer Talos.

Docker Swarm feels "old" now, but my goodness is it easy to deploy and use.. I still love it, and remain sad that it never really got to see the light of day at global scale.

K3s and MicroK8s are both pretty good for lightweight distro's, but both really need 1GB of RAM to idle, so 2GB RAM should be considered the absolute minimum to use them for any productive workload. Docker on the other hand uses almost nothing.. 340MB of RAM idle (incl OS). For the far edge, where resources are constrained, Docker (or Podman) still reigns supreme.

What else will this be used for?

I want to start learning more Kubernetes capabilities, as Portainer continues to expand its offering, I need to keep across things. OpenTelemetry, Gateway API, and good old OPA Gatekeeper are the things I have on my agenda to play with over the coming weeks.

I also want to continue my testing to ensure that Portainer central auth / RBAC works flawlessly across all these distro's.

I want to document any learnings as "reference architectures", and generally, I want to be technically able to help answer community tech questions when I can.

This is just the start of my HomeLab v2 Journey... but it's going to be an ongoing project for me... the nerd inside me loves it.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/maximize-your-openshift-investment-with-portainer-multi-cluster-management-without-the-premium-price-tag?hsLang=en
title: Maximize Your OpenShift Investment with Portainer: Multi-Cluster Management Without the Premium Price Tag
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/maximize-your-openshift-investment-with-portainer-multi-cluster-management-without-the-premium-price-tag
hostname: portainer.io
description: Learn how Portainer can work with your OpenShift environments to provide powerful multi-cluster management at a lower cost.
sitename: PORTAINER.IO
date: 2024-09-02
categories: []
tags: []
image: https://www.portainer.io/hubfs/AI-Generated%20Media/Images/multiple%20clusters%20of%20servers%20managed%20by%20a%20centralized%20system.jpeg
pagetype: article
filedate: 2025-01-18
-->

In the evolving landscape of enterprise IT, Kubernetes has emerged as the cornerstone of modern application deployment strategies. Red Hat® OpenShift® has quickly become a preferred Kubernetes distribution for enterprises, largely due to its extensive support from Independent Software Vendors (ISVs).

Many organizations choose OpenShift because their critical business applications are certified to run on this platform, ensuring reliability and support. However, as organizations scale, the complexity of managing multiple Kubernetes clusters can become a significant challenge.

This is where Portainer, a powerful multi-cluster management tool, comes into play. By integrating Portainer with OpenShift Kubernetes Engine, enterprises can manage their Kubernetes environments more efficiently and cost-effectively, without the need for the more expensive OpenShift Container Platform or Platform Plus licenses.

#### The Value of ISV Support with OpenShift

One of the primary reasons organizations adopt OpenShift Kubernetes is the broad ISV support it offers. Many leading software vendors certify their applications to run on OpenShift, making it a trusted choice for enterprises that rely on these critical applications. This certification provides assurance that the applications will perform optimally on OpenShift, with the added benefit of vendor support.

However, while OpenShift offers a solid Kubernetes foundation and ISV-backed reliability, managing multiple clusters still poses challenges. Organizations that run multiple clusters for reasons such as disaster recovery, compliance, or regional availability need robust multi-cluster management capabilities. With OpenShift, the only way to achieve this multi-cluster manager is with the premium license, Platform Plus. This is not only expensive but also relies on a cloud service, which means connecting your critical business systems to the internet for remote management.

This is where Portainer steps in as a valuable alternative.

#### Portainer: The Ideal Multi-Cluster Manager for OpenShift

Portainer is designed to simplify the management of Kubernetes environments, especially in multi-cluster scenarios. By using Portainer alongside OpenShift, enterprises can achieve a level of centralized control and simplicity that OpenShift’s basic offerings may not provide on their own. Here’s how Portainer enhances the OpenShift experience:

-
**Unified Multi-Cluster Management**: Portainer enables centralized management of multiple Kubernetes clusters from a single interface. This is particularly beneficial for organizations using OpenShift across different environments or geographic locations, providing consistency and simplifying operations. -
**Simplified Operations**: Portainer’s user-friendly interface abstracts much of the complexity involved in Kubernetes management. This means that DevOps teams can manage OpenShift clusters without needing deep Kubernetes expertise, reducing the learning curve and operational overhead. -
**Enhanced Security and Access Control**: With built-in Role-Based Access Control (RBAC), Portainer ensures that only authorized personnel can access specific clusters or resources. This is crucial for maintaining security and compliance, especially when managing clusters across different teams or departments. -
**Scalability Without the Premium Cost**: Organizations can scale their Kubernetes infrastructure using Portainer without needing to upgrade to OpenShift Platform Plus. Portainer offers essential multi-cluster management capabilities, making it a cost-effective solution that still leverages the robust OpenShift ecosystem.

#### Leveraging Portainer with OpenShift: A Strategic Advantage

By integrating Portainer with OpenShift Kubernetes Engine or OpenShift Platform Edition, enterprises can maximize their investment in OpenShift. They can benefit from the wide ISV support that OpenShift offers while also enjoying the streamlined, centralized management that Portainer provides. This combination allows organizations to:

-
**Optimize Resource Utilization**: With Portainer, enterprises can monitor resource usage across multiple clusters, identify inefficiencies, and optimize their Kubernetes deployments. -
**Maintain ISV Compliance**: Portainer’s multi-cluster management capabilities ensure that organizations can maintain compliance with ISV certifications, as applications can be managed consistently across all clusters. -
**Achieve Operational Efficiency**: By reducing the complexity of Kubernetes management, Portainer enables DevOps teams to focus on delivering value rather than managing infrastructure.

#### Achieving More with Portainer and OpenShift

Portainer provides a powerful solution for enterprises looking to enhance their OpenShift deployments. By offering comprehensive multi-cluster management without the need for a premium OpenShift license, Portainer allows organizations to scale effectively, maintain ISV compliance, and streamline operations. For enterprises invested in the OpenShift ecosystem, Portainer is the ideal companion to maximize their Kubernetes capabilities while keeping costs under control.

Below we've compared annual pricing* (in USD) for OpenShift Kubernetes Engine with Portainer, OpenShift Container Platform with Portainer, and the premium OpenShift Platform Plus products, for an example 3 cluster deployment where each cluster has 12 nodes, each with 8 vCPUs.

OpenShift Kubernetes Engine with Portainer |
OpenShift Container Platform with Portainer |
OpenShift Platform Plus |
$32,899 |
$46,435 |
$269,640 |

The price difference is immediately obvious. And remember, you only need the base OpenShift Kubernetes Engine license alongside Portainer to achieve full multi-cluster management in your organization, at one eighth the price of OpenShift Platform Plus.

Ready to enhance your OpenShift management with Portainer? [Try Portainer today](/get-started) and see how easy multi-cluster management can be. [Visit our website](https://portainer.io) to learn more or [reach out for a demo](/get-demo) to experience Portainer’s capabilities firsthand.

* Based on list pricing available from Insight.com, current as of September 2024.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer.io-closes-us6.2-million-funding-round
title: MEDIA RELEASE: Portainer.io Closes US$6.2 Million Funding Round
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer.io-closes-us6.2-million-funding-round
hostname: portainer.io
description: Portainer.io extends its Series A funding round to further commercialize it's enterprise container management platform.
sitename: PORTAINER.IO
date: 2022-06-22
categories: []
tags: []
image: https://www.portainer.io/hubfs/Neil%20Cresswell%202021%20200x400.png
pagetype: article
filedate: 2025-01-18
-->

Portainer.io today announced it has closed a US$6.2 million funding round. The round, which is an extension of its Series A that closed in May 2021, is led by Movac and backed by all the Series A investors (Sonae IM/Bright Pixel, Bessemer Venture Partners, BlackNova, AltVentures). It also adds US investor Shasta Ventures and New Zealand Growth Capital Partners to the roster as interest in the company grows.

Portainer launched in 2017 as an open source product to simplify the management of Docker and Swarm environments. In August 2020, it added support for enterprise Kubernetes, which is becoming the de facto industry standard for orchestrating containerized environments. By adding support for both Kubernetes and HashiCorp’s Nomad, Portainer has become the only universal container management system that works from the data centre to the edge and has been recognized by CRN.com as one of the [10 hottest Kubernetes startups of 2022](https://www.crn.com/slide-shows/applications-os/the-10-hottest-kubernetes-startups-of-2022-so-far-/9).

Neil Cresswell, Portainer’s chief executive said “As mainstream organizations start to adopt Kubernetes, the need for tools that simplify container management and reduce the operational complexity associated with the technology grows. We are in the middle of a near perfect storm, as organizations deploy containers to accelerate their migration to the cloud, ISVs start to ship their products as container images and containers enable applications to be deployed in edge computing environments. This funding round gives us the runway we need to execute on our commercialization strategy and set up for our Series B.”

**Media Contacts**

Tim Nichols – Head of Marketing at Portainer

**About Movac ltd.**

Movac is New Zealand's most experienced and successful venture investor, providing support to foster Kiwi founders and accelerate the growth of their tech businesses. Current portfolio companies include Author-it, ParkHelp, Mobi, TracPlus, NanoLayr, Alimetry, Auror, Dawn Aerospace, Evnex, Mint Innovation, Miruku, Myia Healthcare, Open Money Group, Osho, Portainer.io, Solve, Tectrax, Toha Foundry, Tradify and Yabble. Past portfolio companies include Aroa Biosurgery, Coretex, Unleashed Software, PowerbyProxi, Vend, Trade Me, Timely, eBus, GiveaLittle, and Greenbutton.

**About Sonae IM (Bright Pixel Capital)**

Bright Pixel Capital, (formerly Sonae IM), is a leading technology investment group focused on digital infrastructure, cybersecurity and retail technology business areas. With 50 direct investments and growing, it encompasses stakes in companies on a global scale, from early to growth stages. For more information, visit [www.brpx.com](https://aus01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.brpx.com%2F&data=05%7C01%7Ctim.nichols%40portainer.io%7C94893ecce2fc4099c22708da53386d4e%7C34d4c73d4fff43529ce2df14c8d839f5%7C0%7C0%7C637913799059140716%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=Z2drL4JK6x%2BTZUAnhaH2LILupE7SpGBnsWE5pFcWgNU%3D&reserved=0)

**About Bessemer Venture Partners **

Bessemer Venture Partners is the world's most experienced early-stage venture capital firm. With a portfolio of more than 200 companies, Bessemer helps visionary entrepreneurs lay strong foundations to create companies that matter, and supports them through every stage of their growth. The firm has backed more than 120 IPOs, including Pinterest, Shopify, Yelp, LinkedIn, Skype, LifeLock, Twilio, PagerDuty, SendGrid, DocuSign, Wix, and MindBody. Bessemer's 15 investing partners operate from offices in Silicon Valley, San Francisco, New York City, Boston, Israel, and India. Follow @BessemerVP and learn more at bvp.com.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/docker-desktop-kubernetes-not-enforcing-rbac-rules
title: Docker Desktop Kubernetes NOT enforcing RBAC rules
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/docker-desktop-kubernetes-not-enforcing-rbac-rules
hostname: portainer.io
description: Docker Desktop, with embedded Kubernetes, does NOT enforce any RBAC rules. It lets you create RBAC rules, but won't enforce them. This blog post shows how to resolve.
sitename: PORTAINER.IO
date: 2022-03-17
categories: []
tags: []
image: https://www.portainer.io/hubfs/Untitled%20design%20%283%29.png
pagetype: article
filedate: 2025-01-18
-->

So here is a little golden nugget of awesomeness that might just save you a TON of time (as it wasted hours of my time trying to triage why the RBAC rules Portainer was trying to set were being ignored).

NOTE THIS HAS NOW BEEN RESOLVED AS OF DOCKER DESKTOP VERSION 4.3.0 (Dec 2021), either update to the new version (and reset your Kubernetes instance) or follow the info below for a workaround.

If you are using Docker Desktop, and their embedded Kubernetes offering, you may not be aware but, by default it does NOT enforce any RBAC rules. It will let you create RBAC rules, but it wont enforce them.

Why?

Because Docker made a design descision (in the name of simplicity) to make ALL service accounts automatically receive cluster-admin role BY DEFAULT.

The Role Binding they set is as below:

`apiVersion: rbac.authorization.k8s.io/v1`

`kind: ClusterRoleBinding`

`metadata:`

`name: docker-for-desktop-binding`

`roleRef:`

`apiGroup: rbac.authorization.k8s.io`

`kind: ClusterRole`

`name: cluster-admin`

`subjects:`

`- apiGroup: rbac.authorization.k8s.io`

`kind: Group`

`name: system:serviceaccounts`

`If you want to reverse this design decision, you simply need to run "kubectl delete clusterrolebinding docker-for-desktop-binding" and then like magic (and like every other Kubernetes distro out there!!), it will start enforcing RBAC rules.`

Docker actually state that they "fixed" this in Aug 2019, and their technical fix was to add: *namespace: kube-system *to the end of the "subjects" line, but that didn't actually resolve the issue (hence why I still ran into this issue today).

Repeated calls from Docker Desktop users to have Docker resolve this have seemingly fallen on deaf ears (see issue 4774 referenced below).

If you want to fix this yourself, first delete the clusterrolebinding, and then add a new one (similar to Docker's, but actually correct):

`apiVersion: rbac.authorization.k8s.io/v1`

`kind: ClusterRoleBinding`

`metadata:`

` name: docker-for-desktop-binding`

`roleRef:`

` apiGroup: rbac.authorization.k8s.io`

` kind: ClusterRole`

` name: cluster-admin`

`subjects:`

`- apiGroup: rbac.authorization.k8s.io`

` kind: Group`

` name: system:serviceaccounts:kube-system`

`We have subscribed to the open github issue on the docker desktop repo where people are asking for this to be resolved, and once we see it resolved, we will delete this post.`

Hope this is helpful.

Neil

Links:

Original resported issue here (which was claimed as fixed): [https://github.com/docker/for-mac/issues/3694](https://github.com/docker/for-mac/issues/3694)

And the reopend issue that is seemingly going nowhere: [https://github.com/docker/for-mac/issues/4774](https://github.com/docker/for-mac/issues/4774)

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/media-release-portainer-extension-added-to-docker-desktop
title: MEDIA RELEASE: Portainer Extension Added to Docker Desktop
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/media-release-portainer-extension-added-to-docker-desktop
hostname: portainer.io
description: Portainer Extension Added to Docker Desktop, Brings New Functionality to Docker While Streamlining Developer Workflow. Portainer delivers unrivaled container visibility and management capability to Docker Desktop users
sitename: PORTAINER.IO
date: 2022-05-10
categories: []
tags: []
image: https://www.portainer.io/hubfs/MEDIA%20RELEASE%20Portainer%20Extension%20Added%20to%20Docker%20Desktop.png
pagetype: article
filedate: 2025-01-18
-->

**10th May 2022** – Portainer.io announced today the release of the Portainer extension on Docker Desktop, bringing ease of management and visibility to millions of Docker users. In a step towards a radically simplified and integrated container management ecosystem, the Portainer extension will bridge the gap between Docker Desktop and Kubernetes while offering unparalleled control to developers.

Docker Extensions, the new program announced today at DockerCon, brings a host of new functionalities to the Docker Desktop experience. The extensions are built with ease of use and developer familiarity in mind, ensuring developers have access to a rich suite of tools within one platform.

“We are hugely proud to join the Docker Extension program, bringing the power of Portainer to Docker Desktop users,” said Neil Cresswell, Portainer chief executive. “Since we launched Portainer in 2017, Portainer has become the most popular Docker management GUI in the world, and I’m thrilled to be able to formally integrate Portainer into Docker Desktop. Docker’s commitment to simplifying the developer experience is a perfect match for Portainer’s own obsession with humanizing container management, and Docker Desktop users are going to love the result. It is something I have dreamed of achieving and today it’s real.”

The Portainer extension allows Docker Desktop users to spin up and run a version of Portainer CE (Portainer’s free open-source product) natively inside Docker Desktop. The result is a richly functional, seamlessly integrated, and intuitive UI for managing local Docker environments. And because Portainer fully supports Kubernetes, the extension allows Desktop users to deploy images directly into any Kubernetes environment they are connected to with a few clicks and in doing so, radically simplifies the pathway from Docker Desktop to Kubernetes.

“Docker is obsessed with developer ergonomics and is committed to filling and improving the developer experience gap,” said Webb Stevens, Docker’s SVP of Secure Software Supply Chain. “We welcome Portainer to the Docker Extension marketplace, expanding the applications and capabilities available for millions of registered Docker developers.”

Docker Extensions allow developers to easily discover and integrate new functionality and additional developer tools into Docker Desktop. With Docker Extensions, they can add debugging, testing, networking, security, and other tools to their Docker Desktop installation to support development workflow and improve productivity. Docker Extensions offer a breadth of familiar experiences that integrate with Docker Desktop so they can speed up innovation without having to learn new patterns. Docker Extensions are built with the developer experience in mind and include official tools built by Docker and the company’s trusted ecosystem partners, giving developers the convenience and flexibility to create workflows that meet their individual development needs.

Docker **Resources**

- Learn more about the Docker Extensions
[https://www.docker.com/blog/docker-extensions-discover-build-integrate-new-tools-into-docker-desktop](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.docker.com%2Fblog%2Fdocker-extensions-discover-build-integrate-new-tools-into-docker-desktop&data=05%7C01%7Ctim.nichols%40portainer.io%7Cc414b899e2044ba4ece008da2fc88ef0%7C34d4c73d4fff43529ce2df14c8d839f5%7C0%7C0%7C637874835686423712%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=n97%2BEn3BEG1OoQOAEz1vSDQwmda%2B%2B%2BeDgjgHNFB%2FTW8%3D&reserved=0) - Download Docker Desktop
[https://www.docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop) - Follow Docker on Twitter @portainerio
[@docker](https://www.twitter.com/docker)

**About Portainer.io**

Portainer is the most popular universal container management platform in the world. Every day, hundreds of thousands of users rely on it to simplify the way they manage software containers. Portainer works with Docker, Kubernetes, Swarm and Nomad and is widely used to help users deploy containerized applications, triage issues secure container environments and build self-service containerized environments. Portainer is a VC-backed global company, headquartered in Auckland, New Zealand.

**About Docker, Inc. **

Docker helps millions of developers efficiently and collaboratively build, share and run applications. The Docker collaborative application development platform provides developers with an unmatched experience for an integrated, reliable and secure workflow that accelerates app delivery from code to the cloud. Through a combination of the world’s largest marketplace of components and integrations with leading tools, Docker allows teams to rapidly create innovative applications. For more information, visit [www.docker.com](https://www.docker.com)

**Media Contacts**

Tim Nichols – Head of Marketing at Portainer

+64 22 6424657

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/how-to-use-kubectl-and-lens-ide-through-portainer
title: How to use KubeCTL and Lens IDE through Portainer
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/how-to-use-kubectl-and-lens-ide-through-portainer
hostname: portainer.io
description: Using KubeCTL and Lens to control Portainer managed Kubernetes environments.
sitename: PORTAINER.IO
date: 2022-03-04
categories: []
tags: []
image: https://www.portainer.io/hubfs/lenskubectl.png
pagetype: article
filedate: 2025-01-18
-->

Portainer has a really rich management UI that aims to help Dev and Ops users navigate their way through the various deployment and configuration options for applications on Kubernetes, but what if your Devs and/or Ops staff prefer to use their CLI or a locally installed tool, rather than managing via a web browser.

Well thats easy with Portainer.

Beyond our UI, which includes an integrated KubeCTL shell, Portainer is also a full featured secure KubeAPI proxy. This proxy allows your users to pick and choose the applications they use to manage Kubernetes clusters they have been granted access to.

So how..

First up, we will assume that you have a user created in Portainer (called Bethany), and that she has been granted access to 2x Kubernetes Clusters, Prod and Dev.

When Bethany logs into Portainer she sees the following:

in the Prod Cluster, Bethany can see the default namespace, and a namespace called "webapp"

and in the Webapp namespace, she can see a single deployment, called "nginx"

and in Dev, she can see the default namespace, and a namespace called "webapp-dev"

and the app nginx-dev is running within the namespace.

OK, so how does this all translate to the CLI..

Bethany just needs to click "Home" and then click on "KubeConfig".. Select both of the clusters, then click "Download File", then open the file in notepad..

Now, on Bethany's PC (i will assume Windows here), open c:\users\Bethany\.kube and create a file called config. (or if one is there, you can replace the contents.

Copy the content of the kubeconfig.yaml file from Portainer, and paste it into the config. file. Save and Exit.

So that has configured KubeCTL, so open a command prompt and lets see..

Type "kubectl config get-contexts" and see that both clusters are listed.

the Prod cluster is the default, so lets type "kubectl get namespaces"

Dont worry about seeing the other namespaces, as whilst Bethany can list them, she has no access to them, type "kubeget get pods -n kube-system" to prove this to yourself.

Lets list the deployments in the namespace webapp, "kubectl get deployments -n webapp"

and lets list the pods in the webapp namespace.. "kubectl get pods -n webapp"

all good..

lets scale up that replicaset to 2 instances. "kubectl scale --replicas=2 deployment nginx -n webapp

and check by looking at pods..

and back in Portainer.. refresh the applications page.

Success.. so you just used the CLI to manage a deployment that was initiated in Portainer.

We can now switch contexts and do the same thing for Dev... we wont though, we will just list things, to show..

OK, so how about Lens..

Well, Lens auto-discovers any clusters that exist in your .kube\config file, so just lauch Lens (install it first if you dont already have it).

Click "Browse Clusters in Catalog", then click on the 3 dots, and click "Pin to Hotbar"

Click on one of the clusters in the left bar.. then click "Deployments" and change the namespace from default to webapp.

Note, because this user is a restricted user, Lens will generate a lot of ACL errors if you try to view namespaces for which the user has no access to (or select all namespaces), you can fix that by telling Lens which namespaces you DO actually have access to.

Click the menu in the sidebar, then the cluster, the three dots, then "settings"

Enter the two namespaces, default and webapp then click ESC

Click "disconnect", then "reconnect" to activate the changes.

Now when you navigate, you will only see the namespaces you have access to, and not a screen of errors.

OK, and now lets try a scale from Lens..

Success..

And in Portainer.. the change is seen too..

So there you have it.. you can manage your Kubernetes environments from either KubeCTL or Lens via Portainer.. simple, easy, and centralised..

Give it a go..

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/12-steps-to-getting-started-with-portainer-in-a-production-environment
title: 12 Step Guide to Get Portainer Running in a Production Environment
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/12-steps-to-getting-started-with-portainer-in-a-production-environment
hostname: portainer.io
description: This best practice guide details the 12 steps to get Portainer running in a production environment
sitename: PORTAINER.IO
date: 2022-05-04
categories: []
tags: []
image: https://www.portainer.io/hubfs/Your%2012%20Step%2c%20Best%20Practice%20Checklist%20to%20Get%20Portainer%20Implemented%20in%20a%20Production%20Environment.png
pagetype: article
filedate: 2025-01-18
-->

This guide provides a checklist to help you get up and running with, and comfortable using Portainer’s Business Edition (BE). We highly recommend our Academy course, [Best Practice Install Guide](https://academy.portainer.io/install/#/) when setting up your production environment. For a quicker start, check out our [documentation](https://docs.portainer.io/start/install)."

#### Checklist

**Prepare the environment where Portainer server will be deployed**This can be a dedicated VM running Linux and Docker (or k3s/microk8s), or it can be a dedicated management cluster (swarm or Kubernetes).- Check – Does this node have off-node persistent storage? For example, a block storage device or NFS mount. If not, provision this first.
- Check – If this is a cluster, is the storage available across all nodes? If not, provision this first.
- Check – If this is a swarm cluster, is the overlay network functional? If so, create a global service, deploying a nginx container on each node, console into each and try to curl the nginx port on the other nodes. If this fails, check firewall ports and that VXLAN is able to be used.
- Check - Ensure you have root access to the Docker host and/or cluster-admin role against Kubernetes. If not, get the correct permissions.

**Deploy Portainer using the instructions that match your environment****On first login, change the admin user to something non-standard**For example, <companyname>_admin, or <Portainer_admin>. Set a complex password for this user (you shouldn’t be logging in as the admin user anyway, so set a complex password and save it in a password safe). For more information, read “[How to correctly secure Portainer when presented on the Internet](/blog/how-to-correctly-secure-portainer-when-presented-on-the-internet)”.**Add your Portainer license**Allows you to continue with the Portainer Business deployment (or click on**Get a license**to get one).**Add environments; Docker, Swarm, Kubernetes, ACI**Take a note of all the environments you want to add. Click on**Environments**, add the environment, then add each of your remote environments. Add tags (descriptive labels) as appropriate.- Check - If you are using Docker daemon over TCP, make sure you have the TLS certs.
- Check – If you are using Docker Swarm, make sure you have tested the overlay network (see 1c).
- Check – If you are using Kubernetes, validate if NodePort or LoadBalancer is best.
- Check – If you are deploying Edge Agents, ensure Port 8000 is open on your Portainer instance and that your URL is https://.

**Configure Portainer to use trusted SSL certs**Click on Settings and scroll down to SSL Certificate. Upload your REAL SSL certs, then click on Save. Reconnect to Portainer using the FDQN specified in your SSL cert. Once you have confirmed that this works, go back to Settings and toggle Force HTTPS only on. Make sure that your HTTPS configuration is working correctly before enabling this option or you may be locked out of your Portainer installation.

- Check – If you have intermediate certs in your chain, you may need to merge root and intermediate certs.

Helpful resource:[What’s my chain cert?](https://whatsmychaincert.com/)

Docs reference: Settings[#ssl-cert](https://docs.portainer.io/v/be-2.12/admin/settings?_ga=2.89406683.1597573356.1647216954-202376916.1647216954#ssl-certificate)

- Check – If you have intermediate certs in your chain, you may need to merge root and intermediate certs.
**Configure Portainer backups**Click on Settings, scroll down to Backup Portainer, and configure scheduled backups of Portainer to S3.- Check – You will need an AWS s3 bucket for this.

Docs reference: Settings[#Backup Portainer](https://docs.portainer.io/v/be-2.12/admin/settings?_ga=2.179009380.1597573356.1647216954-202376916.1647216954#backup-portainer)

- Check – You will need an AWS s3 bucket for this.
**Create a Team structure**To prepare to connect external user directories, you should first create a team structure.- Go to Users >Teams. Create teams that best suit your operational model (these will later be mapped to groups in your directory service).

YouTube reference:[Portainer Teams & OAuth group memberships synchronization](https://www.youtube.com/watch?v=27kJzW06WlA)

Docs reference:[https://docs.portainer.io/admin/users/teams](https://docs.portainer.io/admin/users/teams?_ga=2.179009380.1597573356.1647216954-202376916.1647216954)

- Go to Users >Teams. Create teams that best suit your operational model (these will later be mapped to groups in your directory service).
**Prepare for external authentication**Now that you have teams configured, it's time to connect Portainer to your internal user directory. Go to Settings > Authentication, and configure your auth provider.- Check – Enable SSO (and hide authentication prompt) if you want to auto-login.
- Check – Enable auto user provisioning if you want users to be auto-created in Portainer on successful login.
- Check - Enable auto team membership, if you want to automatically add users into teams based on their corresponding group memberships (make sure to set the team-to-group mappings).

Docs reference:[https://docs.portainer.io/admin/settings/authentication](https://docs.portainer.io/admin/settings/authentication?_ga=2.89406683.1597573356.1647216954-202376916.1647216954)

**Set up registries**Go to Settings > Registries, and add your registries. Note you can add multiple of the same types of registries.- Check - If you are using an insecure registry, make sure you update your daemon.json configuration on each Docker host, else pulls will fail.

Docs reference:[https://docs.portainer.io/admin/registries/add](https://docs.portainer.io/admin/registries/add?_ga=2.89406683.1597573356.1647216954-202376916.1647216954)

- Check - If you are using an insecure registry, make sure you update your daemon.json configuration on each Docker host, else pulls will fail.
**Manage Access for each environment**Click on Manage Access, and then grant the appropriate teams access with the appropriate role.

Docs reference:[https://docs.portainer.io/admin/environments/access](https://docs.portainer.io/admin/environments/access?_ga=2.89406683.1597573356.1647216954-202376916.1647216954)**Set base security and config options per environment**- Click on each Docker environment, one at a time. Click on cluster or host, click on Settings, and configure base security policies

Docs reference:[Docker standalone](https://docs.portainer.io/user/docker/host/setup?_ga=2.89406683.1597573356.1647216954-202376916.1647216954)[Docker Swarm](https://docs.portainer.io/user/docker/swarm/setup?_ga=2.182001639.1597573356.1647216954-202376916.1647216954) - Click on each Kubernetes environment, one at a time. Click on cluster, click on Settings, then configure base cluster capabilities.

Docs reference:[Kubernetes](https://docs.portainer.io/user/kubernetes/cluster/setup?_ga=2.182001639.1597573356.1647216954-202376916.1647216954)

**Now you are ready to start creating apps!**😀- Click on each Docker environment, one at a time. Click on cluster or host, click on Settings, and configure base security policies

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/managing-kubernetes-roles-and-responsibilities
title: Managing Enterprise Kubernetes: Roles and Responsibilities
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/managing-kubernetes-roles-and-responsibilities
hostname: portainer.io
description: Who does what when enterprise Kubernetes is in play? This blog post examines the roles for SRE, dev and infra/ops teams.
sitename: PORTAINER.IO
date: 2022-03-24
categories: []
tags: []
image: https://www.portainer.io/hubfs/TeamValueCreation.png
pagetype: article
filedate: 2025-01-18
-->

A questions we often get asked is "who is responsible for what inside Kubernetes?" Whilst the answer really depends on your organizational structure and how segmented your teams are, I will describe the most common structure we see.

In general, there are four roles that span the operational responsibilities of managing Kubernetes: the Infrastructure Team (for on-premises deployments), the Cloud/Platform Team, the DevOps Team, and Developers.

The infrastructure team only exists if you are using on-premises hardware, as someone needs to manage the physical server/storage/networking equipment.

The Cloud/Platform team is responsible for the creation, upgrading, and scaling of Kubernetes / Docker Clusters. It is also responsible for triaging any performance or availability issues that arise with the platform (but not the applications). Fundamentally, it holds the internal OLA to ensure the system delivers acceptable SLAs.

The Cloud Platform team is responsible for:

- creating any automation for the deployment and configuration of the clusters (Infrastructure as Code),
- ensuring the platform complies with internal security requirements/policies (such as authentication, activity logging, policy agents, and configuring role-based access control).
- And, as the holders of the "cluster-admin" privilege, they also install any DevOps tooling that is required using this privilege, including tools such as Portainer, and any other observability, logging, and access tooling.

Combined, the Infrastructure Team and the Cloud Platform team are commonly known as the "Ops" Team.

The DevOps team is responsible for

- getting (and keeping) applications running in production and non-production environments. This often includes writing (or at least assisting) the dockerfiles that create container images from developer code.
- They create the application deployment manifests, and are the people that configure any CI/CD automation pipelines that ensure the application is built and deployed as expected.
- They are generally the team that is on call to support any issues with the applications in production. They need to be able to triage application performance and availability issues and so are consumers of observability and logging tools that run in the cluster.

The Dev team is responsible for

- writing the application code and testing the code works locally on their development environments,
- creating dockerfiles and local deployment manifests (compose files). They are also consumers of the CI/CD pipelines through automated image builds for their committed code.
- supporting their applications in production.

Combined, the Devs and DevOps teams are often known as the "Development" team.

For larger organisations, there is also likely an SRE team, whose sole focus is to improve the system reliability through continuous improvements, either by recommending adjustments to deployment configurations, implementing more reliable rolling update policies, monitoring load distribution and multi-geo deployments etc. When an SRE team is in play, they are the team ultimately responsible for application performance and availability.

For smaller organisations, it's common for the Infrastructure Team, the Cloud/Platform Team, and the DevOps team to be one and the same group of people.

So, this is the most common structure we see most often in organizations today... but is it a panacea? Only time will tell. One thing is for certain though, where your organization obtains differentiated value from your digital assets (customer facing software), you must have your Devs focussed on improving software, not running the platform that the apps run on.

Thoughts?

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/author/neil-cresswell/page/7
title: Portainer News and Blog | Neil Cresswell, CEO (7)
author: Neil Cresswell; CEO March 1
url: https://www.portainer.io/blog/author/neil-cresswell
hostname: portainer.io
description: Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization. (7)
sitename: Portainer.io
date: 2022-03-01
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

### Blog Post by Neil Cresswell, CEO

[
](https://www.portainer.io/blog/how-to-correctly-secure-portainer-when-presented-on-the-internet)

Neil Cresswell, CEOMarch 1, 20222 min read

### How to correctly secure Portainer when presented on the Internet

Securely accessing Portainer to the Internet

Start Reading
[
](https://www.portainer.io/blog/portainer-as-part-of-your-cicd-pipeline)

Neil Cresswell, CEOFebruary 25, 20225 min read

### Portainer as part of your CI/CD with Docker and Kubernetes GitOps

You can now use Portainer as part of your CI/CD toolset for Kubernetes GitOps. Portainer ...

Start Reading
[
](https://www.portainer.io/blog/using-env-files-in-stacks-with-portainer)

Neil Cresswell, CEOFebruary 21, 20222 min read

### Using ENV files in Stacks with Portainer

How to use ENV files in Portainer Stacks

Start Reading
[
](https://www.portainer.io/blog/deploy-a-self-hosted-registry-secured-with-x509-client-certs)

Neil Cresswell, CEOFebruary 19, 20224 min read

### Deploy a self-hosted registry secured with x509 client certs.

How to deploy a self-hosted Docker Registry, secured with x509 Client Certificates for ...

Start Reading
[
](https://www.portainer.io/blog/using-portainer-with-aws-elastic-container-registry)

Neil Cresswell, CEOFebruary 15, 20223 min read

### Using Portainer with AWS Elastic Container Registry

Want to use AWS ECR with Portainer, read how..

Start Reading
[
](https://www.portainer.io/blog/using-vscode-with-portainer-managed-kubernetes-clusters)

Neil Cresswell, CEOFebruary 15, 20222 min read

### Using VSCode with Portainer managed Kubernetes Clusters

Using VSCode with Portainer managed Kubernetes Clusters

Start Reading
[
](https://www.portainer.io/blog/wsl2-suspendresume-rtc-bug)

Neil Cresswell, CEOFebruary 14, 20221 min read

### WSL2 - Suspend Resume RTC bug

WSL2 RTC suspend resume bug getting you down?

Start Reading
[
](https://www.portainer.io/blog/deploy-and-use-argocd-with-portainer-part-2)

Neil Cresswell, CEOFebruary 10, 20222 min read

### Deploy and use ArgoCD with Portainer (part 2)

Portainer with ArgoCD, managing remote clusters

Start Reading
[
](https://www.portainer.io/blog/deploy-and-use-argocd-with-portainer)

Neil Cresswell, CEOFebruary 10, 20223 min read

### Deploy and use ArgoCD with Portainer (Part 1)

Portainer has an excellent continuous delivery (CD) engine built-in, but what if you want ...

Start Reading
[
](https://www.portainer.io/blog/portainer-ce-2.11.1-is-here-and-edge-computing-will-never-be-the-same-again)

Neil Cresswell, CEOFebruary 7, 20223 min read

### Portainer CE 2.11.1 is here and edge computing will never be the same again.

Portainer 2.11.1 brings a raft of features and functions that make managing large-scale ...

Start Reading
[
](https://www.portainer.io/blog/why-civo-and-portainer-is-like-apple-pie-and-ice-cream)

Neil Cresswell, CEOFebruary 4, 20222 min read

### Why CIVO and Portainer is like Apple Pie and Ice Cream

How do you make Kubernetes easy... with a combination of Civo and Portainer

Start Reading
[
](https://www.portainer.io/blog/should-you-expose-portainer-or-agent-to-the-internet)

Neil Cresswell, CEODecember 19, 20212 min read

### Should you expose Portainer (or Agent) to the Internet??

Exposing Portainer to the internet? Think twice...

Start Reading

---
<!--
URL: https://www.portainer.io/blog/when-kubernetes-problems-strike-why-simplicity-matters
title: With Kubernetes, be careful you dont drown in complexity..
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/when-kubernetes-problems-strike-why-simplicity-matters
hostname: portainer.io
description: Why a complex Kubernetes environment can bite... and why a simple environment equals a good nights' sleep..
sitename: PORTAINER.IO
date: 2022-03-15
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Mar-15-2022-02-54-21-69-AM.png
pagetype: article
filedate: 2025-01-18
-->

Here's a contentious topic that is sure to raise a few eyebrows....

In the current age of containerization, the need (or want) to deliver a hyper-flexible Kubernetes platform with rich functionality has seemingly caused us to overlook the benefits of a simple and intuitive, easy to understand/use, easy to triage, platform. We seem to have become obsessed by Kubernetes for the sake of Kubernetes without any consideration for how it will be used by our internal users, and supported by our internal Ops teams later.

Let me explain.

First up, ease of use..

Development teams want to use Kubernetes, right? Wrong, well kind of....

What development teams (which encompasses Devs and DevOps) want is a platform that allows them to deploy and manage their applications in a repeatable and consistent, declarative manner. They want to be able to easily enable things like auto-scaling, define the use of load balancing and reverse proxies, add monitoring and logging capability, and safely persist data in their application; and they want to be able to do all of this themselves through a simple developer experience focussed toolset, without having to open JIRA or ServiceNow tickets and waiting (potentially hours or even days) for someone to do it for them.

Development teams have latched onto the fact that Kubernetes (and Docker for more junior teams) gives them this capability, and so *development teams are often the driving force behind the adoption of Kubernetes. *That doesn't mean for one second that they want to take on the operational overhead of running a Kubernetes platform, nor do they want to exclusively use the raw Kubernetes CLI, far from it, they want its benefits, but none of its operational complexity. This is especially true when you have development teams that do not include "full stack" developers, or if you do not have the support of DevOps professionals. In this case, the development team genuinely don't want to engage with raw Kubernetes at all, but for sure they still want the benefits it brings. In this case the development team would be looking to the Ops team to provide a radically simple "Heroku" or "cPanel" style interface for Kubernetes.

When development teams are pushing for Kubernetes, its because the legacy way of deploying applications inside your organisation is not fast/flexible enough for them, and so they see Kubernetes as an enabler. The responsibility of deploying and operating the Kubernetes platform sits squarely with your internal operations/engineering team. But as an Operations team, what are you expected to provide? Simple, a Kubernetes platform that is reliable, performant, maintained, and delivers a rich developer UX to your internal users, allowing them to self-serve in a way that is safe and secure. What that doesnt allow you to do is break the real reason devs want Kubernetes in the first place, so make sure you keep self-service front of mind. Development teams should be able to deploy any applications they like; they should be able to choose how they want to expose their applications to the world (within reason); and they should be able to do this in a manner of their choosing, either using CLI, API, or a self-service UI. Remember, your job as Ops/Engineering is to enable your users, not constrain them. Sure it is your responsibility to give a reliable SLA to your users, but a 99.9% SLA is useless if its impossible to use.

Secondly, Operations..

As described above, Operations / Engineering are the team responsible for deploying and managing the Kubernetes Platform. But what liberties does that give to you? Should you have the freedom to build something that only one person can support? Surely not. You need to build a platform that is flexible and extendable, but more importantly, you need to *build something that is supportable by as many people inside your engineering team as possible*. If this means building something slightly less "cool" then thats what needs to happen. Don't fall into the trap of building something using the latest technologies just because they are trending on reddit/twitter/medium. Build something using the technology you can support.

Far too often we see Kubernetes environments built by individuals that are wanting "the best Kubernetes platform ever seen", but in doing so, create a massive risk for the organization, as the complexity makes support a nightmare. Even worse, we see engineering teams relying solely on tools that bootstrap a self-hosted Kubernetes cluster in minutes. That same team rarely have the knowledge of HOW that platform was built by the tooling, and so when (not if) it fails, they are completely in the dark on how to triage. Don't be fooled by the "bootstrap" tools, they don't help you one bit when things fail. If your team do not posses the required knowledge to deploy a Kubernetes cluster following Kelsey Hightower's "[Kubernetes the hard way](https://github.com/kelseyhightower/kubernetes-the-hard-way)" instructions, and if they don't know how to triage etc, KubeDNS, etc, then I strongly recommend adopting Kubernetes managed offerings from supported providers rather than take the risk of an unsupportable self-hosted Kubernetes platform (or one you need to pay $$$ to a 3rd party to support).

As a word of advice, I always recommend putting your Kubernetes platform through the 3am test.. "Assume it's 3am, the platform has gone offline, how many staff do you have in your organization that can start a triage process and identify the cause of the issue?" If your answer is "one person" you are almost certainly in trouble. Equally, even if you have a team of people who can jump in and start to triage, it can still take them hours to get to a fix if your environment is even slightly complex.

In IT Operations, there is a holy trinity of metrics; Mean Time to Identify (MTTI), Mean Time to Know (MTTK) and Mean Time to Fix (MTTF). This essentially translates to "how quickly do you know an issue is occurring", "how long will it take to figure out what's wrong and what to do about it", and "how long will it take to fix it". Combined these three are known as "Mean time to Resolve" (MTTR).

If your Kubernetes Platform will cause you to have an extended MTTR due to an inability to alert, rapidly triage, root cause, and remedy, then you are making a big mistake.

So, from an Operations perspective, keep ongoing supportablilty front-of-mind... unless everyone in your team can support the platform, is it really a safe bet relying on a subset of engineers?

So how does Portainer address both of these?

The answer is with simplicity. Simplicity of the platform, and simplicity of the tooling. Sure, it's possible to build a Container/Kubernetes Management Platform from a multitude of the 1051!!! products that make up the CNCF landscape, but in doing so, you are forcing yourself to remain competent in all of these tools. Good luck with that.

Do you really want your team to have to learn how to deploy, support. patch, upgrade dozens of different tools, just to deliver a Kubernetes platform? Can you imagine the research and version compatibility matrix validation needed before upgrading ANY ONE of these components? I think not.

To keep things simple and supportable (KISS), we built Portainer to provide a single tool that "just works" out of the box... We deliberately made it super simple to deploy/configure, simple to use, and simple to support.. With Portainer, there is no need to adopt other tools (but you can, as we don't lock you in!), Portainer has you covered.

Your Ops/Engineering team can deploy Portainer and use it to onboard clusters from ANY Kubernetes (or for that matter, Docker) provider, Cloud or on-premise, they can configure centralised authentication for the Clusters, they can instantly configure RBAC for all clusters, they can define resource quotas and limits, pre-configure ingress controllers to simplify the developer experience, enable metrics for simplified performance monitoring, and all of this can be done without needing any advanced Kubernetes knowledge, which combined with Cloud provide KaaS solutions is a great no-risk enabler.

Even better, whilst Portainer really helps your Ops/Engineering teams, it has an equally impressive developer UX, allowing developers with a wide array of background experience to get started with Docker, Kubernetes, and even self-serve GitOps TODAY. Your developers don't need to know how to write YAML manifests, they don't need to learn Kubernetes lingo, heck, they don't even need to know or care that the platform is Kubernetes; all your developers need to know is that they have a rich platform within which they can deploy their applications in a repeatable and consistent, declarative manner.

Portainer is the only tool you need, from Devs, DevOps, GitOps, Platform Management, Triage. We you got you covered.

Give Portainer a try today, experience simplified Kubernetes Operations today.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/sneak-peak-portainer-as-a-docker-desktop-extension
title: Sneak peak - Portainer as a Docker Desktop Extension.
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/sneak-peak-portainer-as-a-docker-desktop-extension
hostname: portainer.io
description: Get a sneak peek into Portainer's integration with Docker Desktop
sitename: PORTAINER.IO
date: 2022-04-19
categories: []
tags: []
image: https://www.portainer.io/hubfs/DockerDesktopExtension.png
pagetype: article
filedate: 2025-01-18
-->

Good things come to those who wait and this is definitely a good thing we’ve been waiting for.

If you’re a Docker Desktop user and you don’t know about Docker Extensions then you need to try harder. Docker will officially announce their launch at DockerCon 22 in early May and I’m thrilled to announce that Portainer is one of the first. We can’t reveal everything just yet, but we can give you a sneak peek at what we’ll be announcing in May.

For those not familiar, here’s the official Docker description of an Extension:

*“Docker Extensions allow users to easily discover and integrate new functionality and **additional developer tools into Docker Desktop. They offer a breadth of familiar experiences that integrate with Docker Desktop so you can speed up innovation without having to learn new patterns. Docker Extensions are built with the developer experience in mind and include official tools built by Docker and our trusted ecosystem partners.”*

We are officially a trusted ecosystem partner and that’s pretty cool IMHO. It’s testament to 5 years of hard work building awesome tools for the Docker community that make container management super simple.

The Portainer extension allows Docker Desktop users to spin up and run a version of Portainer CE (our free open source product) natively inside Docker Desktop, which gives users a far richer UI for managing their local Docker environment than what is available inside Docker Desktop.

And because Portainer now supports Kubernetes, the extension allows Desktop users to deploy images directly into any Kubernetes environment they are connected to with a few clicks and in doing so, radically simplifying the pathway from Docker (Desktop) to Kubernetes.

The video below gives you a good overview of what’s coming.

The formal announcement is at DockerCon and I can’t wait to share the story with the Docker community as it’s arguably the single most important advancement in our history and will (hopefully) see Portainer adopted by many thousands (if not millions) more developers.

Thank you Docker Community. I’m a very proud man.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/kubernetes-the-ultimate-enabler-of-automation
title: Kubernetes, the ultimate enabler of automation
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/kubernetes-the-ultimate-enabler-of-automation
hostname: portainer.io
description: Kubernetes, the ultimate tool to enable Infrastructure as Code and GitOps
sitename: PORTAINER.IO
date: 2022-06-25
categories: []
tags: []
image: https://www.portainer.io/hubfs/IaC-2.png
pagetype: article
filedate: 2025-01-18
-->

One thing is now obvious, Kubernetes has changed the IT landscape for the better. For the first time in a long time, we have a universal API for the configuration of IT infrastructure, applications, and their components. An IT “babel-fish” if you may! (sorry, 45 year old CEO here, and Hitchhikers Guide to the Galaxy is one of my all-time favs).

If you think back just 5 years, how did you deploy and manage your server and application estate?

You really only had two viable options : either manually installing and configuring every component, or for the fortunate, by investing in automation through Infrastructure as Code. Manual configuration was far and away the most common mechanism as only the most cash-flush IT teams could afford to invest the time and tooling to deliver automation.

But, for those that did embrace automation, how were those first incarnations of Infrastructure as Code delivered?

At the time, we had dozens of proprietary vendor API integrations we needed to maintain; the server hardware layer (mainly blade chassis), the virtualisation layer, the storage subsystem, the network switches, the firewalls, and the load balancers. If you were lucky enough to have a single vendor for each element, then you likely had maybe 10 discrete APIs, but if you were multi-vendor, then wow!. We also needed to maintain bash/powershell scripts for the configuration of the base operating system for each type of server provisioned, and we needed to build application silent install scripts to get apps installed and configured (remember MST files??). It was a mess. If you can you remember tools like SaltStack, Ansible, Puppet/Chef, CFEngine, and VMware Configuration Manager, then you will likely know what I'm talking about. For anyone that wanted to create and maintain these scripts, it was a substantial long-term investment. The only organizations that invested in this automation were those that had highly dynamic server and application landscapes that warranted the time savings from automation, or those that wanted the comfort of being able to rebuild their environments on-demand.

Fast forward to now, with Kubernetes’ singular consistent API format, the awesomeness of Kubernetes Operators / CRD’s, a fair bit of YAML, and a decent helping of knowhow, it's relatively straight forward to have your entire landscape declared, deployed and maintained via code. And with your landscape defined as code, you are able to deploy and maintain with 100% predictable repeatability every time. In fact, most organisations that adopt Kubernetes consider it almost mandatory that a switch to “everything as code” goes part-in-parcel with the transition.But, just like Newtons quote “what goes up, must come down”, for every positive benefit, there is a contrasting negative risk, and in the case of “everything as code”, it comes down to two things... 1) risk of errors making their way into Prod, and 2) the skills required to automate.

- If you automate something, then your automation had better be perfect. Unlike humans, code is not able to dynamically adapt to unexpected changes. Code expects to do the same thing every time and get the same result every time. Automation needs error handlers to be created in order to be relied upon, and these error handlers need to be thorough. With automation, it is incredibly easy to inadvertently apply a defective configuration and take an entire system offline (here’s looking at you CloudFlare, oh and most of the other Cloud Native enterprises that have outages due to automation gone awry). So whenever automation is deployed, you would be negligent not to invest in development and pre-prod environments in which to test the automation. Also, if you have a fully automated deployment, then you need to ensure that you have an equally significant investment in writing health checks, which are used to automatically rollback any changes if there are unintended consequences.
- Whilst Kubernetes has made “everything as code” possible, you cannot just take any Windows or Linux admin, and make them into automation experts overnight. It takes time to learn YAML constructs, it requires a certain ‘finesse’ to write a YAML file from a standing start. And in order to automate Kubernetes, you need to know how the API works, what each API call does, and what the valid inputs (and expected outputs) are for each. You also need to be monitoring Kubernetes API deprecation notices, and ensure your automation continues to function correctly across releases. This all translates into the need for your automation (DevOps/Platforms) team to be Kubernetes experts, nothing less will provide the required quality (at least, not initially).

So, how can you unlock the benefits of Kubernetes without having to dive headfirst into code?

Easy. With Templates, commonly implemented via HELM charts, or the more “in vogue” Kustomize files.

But to take it a step even further, how do you enable the non-container-native developer or engineer to use these? If there is one thing that Apple and Google can claim fame for, it's their App Stores, and the simplicity of deploying any application with just a single action. This consumerization of application deployments is what Kubernetes needs, a “click to deploy” marketplace, that does not require any knowledge of adjusting HELM values.yaml files, or how to manipulate Kustomize.

There are a number of vendors trying to deliver this marketplace capability, under the guise of an “Internal Developer Platform”. Each vendor bringing their own unique solution for this requirement, and for Portainer, we do this using our “Templates” function.

Portainer Templates allow an internal expert to completely define the state of an application, and then to publish that configuration state to other internal users to simply “Click to Deploy”. The users deploying their applications from the template do not need to customize anything. This is the ultimate in simplicity and usability.

OK, so that’s well and good, but what about those organizations that want to get on the “everything as code” bandwagon? Does Portainer stop them from doing this? Is Portainer just a click-ops UI? Not at all. Portainer has a built in GitOps engine, and that engine can be configured to source all application definitions from Git, and then to deploy applications based on these definitions. Deploying in this way removes the UI from the equation, ensuring that applications can be redeployed at any time, and they will always be deployed in exactly the same way.

So, regardless of where you are on your internal journey, Portainer can help you to standardize deployments, either using Templates, or through our native GitOps engine, and with the magic of Kubernetes, the breadth of scope for configuration is vast.

Here at Portainer, we love what Kubernetes enables, we just think that it should be easier to experience the benefits of Kubernetes, and that any IT team, of any size/maturity should be able to fully exploit the power of Kubernetes.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/containers-a-glitch-in-the-matrix
title: Containers – a glitch in the matrix?
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/containers-a-glitch-in-the-matrix
hostname: portainer.io
description: Why Portainer is so important in today's two-tier IT society.
sitename: PORTAINER.IO
date: 2022-05-06
categories: []
tags: []
image: https://www.portainer.io/hubfs/Matrix.jpeg
pagetype: article
filedate: 2025-01-18
-->

Anyone that has been around a while knows IT typically flows in 7-10 year waves. Normally, these waves make perfect logical sense and everything gets better for everyone as a result, but sometimes there’s a glitch in the matrix and it all makes a bit less sense. There’s an argument Containers represent one such glitch.

As an industry, we’re out of the VM wave, in the later stages of the cloud wave and driving deeper into the container wave as every month passes. Whilst the cloud enabled freedom from managing on-premises platforms, and the inevitable never ending asset replacement cycle, it ended up causing “pay as you go” hell. It was (and still is) a very common occurrence to hear stories of organisations being unable to forecast their monthly bills, and worse, not even be able to afford them as their growth in adoption increased. Unfortunately, many were often stuck with their provider (and the costs) due to technology lock-in. Containers, and specifically Kubernetes, was seen as a layer of technology abstraction that commoditised the cloud providers, allowing organisations to deploy their application in a consistent and portable way, that was completely free of any lock-in.

As a technology, containers definitely delivered on the promise of commoditising IT platforms, being able to offer a singular consistent API/framework regardless of where the platform was deployed; cloud (any), on-premises, or even a combo; but at the same time they’re causing a world of pain for organizations who are just trying to keep up with digital innovations.

Like it or not, containers are creating a two-tier society, one tier that can afford the rockstar engineers who know how to build and manage complex containerized environments, and everyone else. In a wildly resource-constrained market, the ‘haves’ are getting richer and the ‘have-nots’ are getting left behind and out-competed. In a global ecommerce world, where competitors can come from anywhere, not just in your country (think “sheen” as a perfect example of a fashion industry disrupter that is a pure-play ecommerce engine ONLY), this is a problem for everyone, as unless everyone gets to ride the container wave, things start to go very wonky very quickly.

We know containers are awesome, but they are hard to manage (shock-horror), particularly when they are deployed at scale and where some level of orchestration is needed. To be valuable, developers who historically were focussed purely on writing code, now need to be “full stack” and understand a raft of new concepts. In fact, for the teams involved in delivering software inside an organization, containers represent a whole new organizational design, language, way of working, and set of principles and paradigms.

Container, unfortunately, change everything. And when everything changes there are always casualties.

**So, how does Portainer fit in?**

Portainer is designed for the ‘have-nots’ who know they have no choice but to ride the container wave (because the software applications they are either buying or building all run in containers) but don’t want to / can’t afford to invest in a team of rockstars to build and manage a container environment. They simply want a ‘turnkey solution’ to the container management problem.

Curiously, the ‘haves’ in this mash-up don’t want a turnkey solution at all as it represents an existential threat to the rockstars who are making lots of money creating long-term very expensive chaos for early adopter organizations. This is the glitch in the matrix at work….

It’s becoming increasingly clear that there is simply no competitive advantage to be had by organizations in becoming experts in containers. The real competitive advantage comes from being able to exploit the power of containers __without__ incurring the insane costs associated with learning and managing them.

As a Container Management Platform, Portainer does something really important. __It makes containers accessible to the have-not__s. Without Portainer, the have-nots will find it really hard – if not impossible - to get on the container wave, which has potentially far reaching implications for them and the IT teams that support them. There’s an argument that in the case of the have-nots, Portainer is almost priceless, but that’s for them to tell us, not the other way around.

In the crazy dev resource constrained world that we now live in, any tooling that allows existing developers to spend more time developing and less time working on things that don’t add any value (like infrastructure) has huge value. Developer Hours Saved is the new currency of the IT vendor community and Portainer saves a LOT. Like really, a LOT.

With Portainer,

- Platform Managers without deep knowledge of containers or Kubernetes can set up and configure a container platform that developers can use to deploy their code themselves 24x7 without actually knowing how Kubernetes works. That in of itself represents a massive cost/time saving to organizations as it means existing ops teams can be re-purposed rather that turned-over.
- ‘Normal’ Developers (ie the sort that write .net, .js, .php applications) can deploy their own code into test, dev or prod environments on prem or in the cloud through a simple point and click interface (with guardrails in the background defined by the Platform team in place to ensure they don’t break anything along the way). They can just point and click, which makes triage and troubleshooting infinitely easier. There simply is no CLI.
- DevOps teams can set up CI/CD workflows deploying directly into Kubernetes without having to know the intricacies of the orchestrator.

We’ve spent years (literally) making the underlying technologies (Docker/Kube etc) nearly invisible to the end user so they can focus on delivering higher value functions. We firmly believe the goal of a software delivery team should be delivering more code, not to become experts in Kubernetes for the sake of it!

So, can you actually quantify the time savings associated with Portainer? Probably, but anyone that has ever lifted the hood on Kubernetes and had a look underneath will know instinctively that whatever the price point associated with Portainer, it’s a quantum less than the cost of trying to reskill an entire organization in the art of Kubernetes.

The other side of the Portainer value proposition relates more to security / compliance and represents another one of those matrix glitches. The container wave has essentially standardized on Kubernetes, which is a wildly complicated piece of software in its own right. However not only is it complicated it’s also relatively insecure in many ways which is a problem for have-nots who don’t have the expertise on staff to know how to secure it. There are now thousands of known exploits in the wild targeting poorly configured Kubernetes systems, and many masquerade as harmless pieces of software that then get deployed by devs without realising their ulterior motives.

With Portainer in place, users only have access to the tools, features, capabilities they need, and with the lowest level of privilege that they need to get their job done. Many/most compliance obligations are met as a result. This is super important as the use of Containers grow inside the organization, and organizations expand from a few nodes to a few clusters.

Time will show there’s nothing wrong with being a have-not. In fact, as far as containers are concerned, there’s actually a whole lot of benefits to come from being a have-not. As a have not (with Portainer) you won’t ever have to dig your way out of the Kubernetes hole the early adopters have dug for themselves and pay the Kubernetes tax that the matrix has imposed on us!

If you’re a have-not and you’re ready for a turnkey container solution then come and talk to Portainer. You’ll be glad you did.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/using-the-portainer-edge-agent-edge-groups-and-edge-stacks-part-1
title: Using the Portainer Edge Agent, Edge Groups, and Edge Stacks - part 1
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/using-the-portainer-edge-agent-edge-groups-and-edge-stacks-part-1
hostname: portainer.io
description: Using the Portainer Edge Agent, Edge Groups, and Edge Stacks - part 1
sitename: PORTAINER.IO
date: 2021-02-19
categories: []
tags: []
image: https://www.portainer.io/hubfs/undefined-Feb-19-2021-07-09-59-42-AM.png
pagetype: article
filedate: 2025-01-18
-->

Portainer has an amazing feature that lets you manage remote edge compute devices from a single centralized instance. You can manage for up to 25,000 x86 or ARM based edge devices running on unreliable or highly latent networks with support for Windows and Linux Operating Systems.

In this How-To we are going to learn how to enable the edge compute feature of Portainer that I have split into two parts:

- The first part will show how simple it is to add edge devices via the Edge Agent and the importance of using tags for endpoints;
- in the second part I show how to enable the Edge Compute features of Portainer and how to manage edge devices with this feature.

**Adding Tags**

- Start by logging in your
**Portainer**instance and selecting the**Endpoint -> Tags**menu option:

Tags help you organize your endpoints based on criteria. So for instance let's say we have 4 different categories that you may want to group your endpoints in: architecture, geography, image and function - You can add your
**tags**freely as these are simple text inputs: - Considering the criteria I mentioned item #1 I added:
- Architecture:
**x86**and**arm64** - Geography:
**north**and**south** - Image:
**mysql**,**redis**and**prometheus** - Function:
**metrics**and**db**

You can use whatever criteria you prefer. As you can see**Tags**are very easy to add.

- Architecture:

**Adding Endpoints with the Edge Agent on Portainer**

- Start by clicking on
**Endpoint -> Add endpoint**: - Select
**Edge Agent**: - You can name your endpoint accordingly. One very important detail is to make sure that the IP address of the
**Portainer server URL**matches the one of the machine where the endpoint is going to be added: - Add the tag or tags that you want for this endpoint using the criteria you believe is appropriate for the device:
- On the
**Endpoint details**page make sure to select**Docker Swarm**for the agent. For now the**Edge Compute**feature of**Portainer**only supports docker swarm nodes:

Make sure to click on the**Copy command**button in order to deploy the portainer agent on the edge device. - Add the IP address of the edge device and click on
**Update endpoint**: - On a terminal application, login to the device that you will add as an endpoint on you
**Portainer**instance asuser:*root* - If you haven't already make sure to convert the standalone docker node to a swarm node by typing
`docker swarm init`

: - Paste the command copied earlier on step #5:
- In a matter of seconds the
**Edge Agent**will be installed. You can check if the edge agent has started successfully by typing`docker ps`

on the terminal: - You can now go back to
**Portainer**, click on**Home**and you should see your endpoint associated to your instance and with the tags you selected when you added the endpoint: - You can click on the endpoint to manage it with
**Portainer**:

Hope that worked well for you, and you're up and running with Portainer. If you have any questions or comments, please drop them into the comments section below, or join us on our [Slack channel](https://portainer.slack.com/join/shared_invite/enQtNDk3ODQ5MjI2MjI4LTcwNGYxMWQ5OGViYWZkNDY2ZjY4YTMwMTgzYmU4YmNiOTU0MDcxYmJjNTIyYmQ0MTM5Y2QwNTg3NzNkMTk5MDg#/).

Video walk through available here:

See for yourself, with a demo or free trial

Let us introduce you to a world of fast and easy app deployment, governance, and management in Docker/Swarm and Kubernetes. Join a group demo to see how Portainer Business helps to make Engineering and DevOps teams more accurate and efficient in container management.

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-announces-kubernetes-provisioning-on-digitalocean-linode-and-civo
title: Portainer announces Kubernetes provisioning on DigitalOcean, Linode and Civo
author: James Carppe
url: https://www.portainer.io/blog/portainer-announces-kubernetes-provisioning-on-digitalocean-linode-and-civo
hostname: portainer.io
description: Learn how to spin up a Kubernetes cluster on Digital Ocean, Linode or CIVO using Portainer Business Edition.
sitename: PORTAINER.IO
date: 2022-05-16
categories: []
tags: []
image: https://www.portainer.io/hubfs/Digital%20Ocean.png
pagetype: article
filedate: 2025-01-18
-->

Portainer [Business Edition 2.13](/blog/portainer-ce-and-be-2.13-are-here) is now live and brings with it a very important feature that our customers have been asking for. Portainer users can now provision Kubernetes environments on cloud providers directly from within Portainer. In the latest release, provisioning is supported on DigitalOcean, Linode and Civo.

For organizations using Kubernetes, Portainer’s value proposition has crystalized. It removes huge amounts of operational complexity and reduces the time to value on Kubernetes investments. In practical terms, that means organizations don’t need to hire rafts of experts to maintain their Kubernetes environments, instead they can empower existing teams with Portainer, which is much faster and much cheaper than almost any other alternative.

And that all makes perfect sense, other than the fact that, up until now, Portainer users have not been able to create clusters, they’ve only been able to manage them. This has been a frustration for some Portainer users as it meant they still needed access to experts with the skills to create clusters, which at least partially undermined the overall Portainer value proposition.

However, that’s no longer a problem.

If you’re a managed Kubernetes cloud customer of Digital Ocean, Linode or Civo, you can now use [Portainer Business Edition](/) to spin up clusters at will. This means that anyone with the appropriate permission / role can use a GUI-based tool they are intimately familiar with to spin up clusters at the drop of a hat __without needing to use any other tooling or commands__. This makes the process of cluster creation quick, reliable, safe, secure, auditable and almost fool proof!

See how easy it is to create a cluster on each of the 3 providers.

For organizations getting started on their containerization / Kubernetes journey, this removes yet another barrier to Kubernetes adoption. With a single tool that can do both creation and management it’s even easier to get up and running.

Obviously these 3 providers represent a small proportion of the managed cloud market and we’ll be adding more partners in 2.14 with a focus on the gorillas!

[A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.](https://www.portainer.io/blog/author/james-carppe)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-ce-and-portainer-be-2.14-is-here.-download-it-now
title: Portainer 2.14 - now with Kubernetes provisioning on EKS, GKE, and AKS
author: James Carppe
url: https://www.portainer.io/blog/portainer-2.14-now-with-kubernetes-provisioning-on-amazon-eks-google-gke-and-azure-aks
hostname: portainer.io
description: Portainer 2.14 is here. It includes a raft of new features including the ability to create Kubernetes clusters in Amazon EKS, Google GKE, and Azure AKS.
sitename: PORTAINER.IO
date: 2022-06-29
categories: []
tags: []
image: https://www.portainer.io/hubfs/Portainer%20new%20release%20.png
pagetype: article
filedate: 2025-01-18
-->

Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our [Portainer Features page](/features)*. *

Portainer version 2.14 is now available in both Community Edition and Business Edition. It includes a number of changes and updates as well as some new Business Edition-specific features. For a full list of changes, please refer to our [release notes](https://docs.portainer.io/release-notes).

**New Kubernetes-as-a-Service providers**

In 2.13 we introduced support for provisioning Kubernetes clusters directly from Portainer on [Civo, Linode and DigitalOcean](/blog/portainer-announces-kubernetes-provisioning-on-digitalocean-linode-and-civo). In this release, we've expanded that even further to include Amazon EKS, Google GKE, and Azure AKS. We've also refreshed the cloud credentials interface as part of this work, as well as updated our documentation with examples of how to retrieve the necessary credentials for specific providers.

**Import your existing Kubernetes environment**

We've long supported deploying the Portainer Agent to existing Kubernetes environments, but with 2.14 we've made this even easier with the ability to import your kubeconfig file directly into Portainer, and have Portainer automatically configure access and deploy the agent for you. This works with both cloud providers and on-premise Kubernetes installations.

**Add Environment Wizard**

When you first install Portainer you're presented with the environment wizard, allowing you to add the environments you wish to manage, but after that you'd use our traditional interface to add more. In 2.14 we've improved the environment wizard and brought it in to be used at any point to add new environments.

**Out of date image indicators**

Version 2.14 adds a new column to the containers, stacks and services listings which will let you know whether an image used is up to date or if there's a new version available. This lets you easily tell which containers, stacks or services you need to update.

**Improvements to custom templates**

App Templates are a powerful feature for system administrators, letting you set up templated applications for users to easily deploy. In 2.14 we've extended our custom templates to let you easily create tags within your templates that a user can later fill in when deploying the template, allowing for much more customization of the individual deployment.

**Environment variable support for webhooks**

Along the same lines as the custom templates changes, we've also added support for environment variables to be passed over webhooks in 2.14. Using this, you can customize your triggers to provide custom information to Portainer that it can use alongside the redeployment.

**Reworking the Team Leader role**

We've spent some time reworking our existing Team Leader role in 2.14, fixing a few bugs and expanding the capabilities of the role. Team Leaders can now add and remove members from teams as well as promote members to co-team leaders.

**Adjustable password length requirements**

In 2.13 we introduced password strength requirements to Portainer. In this version, we've taken on the feedback that you've provided and made these requirements adjustable by administrators. An admin can now set the minimum length required for a password, and users that don't meet the requirements will be asked to update the passwords when they next log in, with the option to defer the change a couple of times before being required to make the change. We also removed the complexity requirements and just restrict on length.

**Dependency updates**

We've updated a number of our third-party dependencies in this release, including docker, docker-compose, helm and kubectl. One specific thing to note is that this adds docker-compose version 2 support to Portainer.

[A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.](https://www.portainer.io/blog/author/james-carppe)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/how-to-correctly-secure-portainer-when-presented-on-the-internet
title: How to correctly secure Portainer when presented on the Internet
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/how-to-correctly-secure-portainer-when-presented-on-the-internet
hostname: portainer.io
description: Securely accessing Portainer to the Internet
sitename: PORTAINER.IO
date: 2022-03-01
categories: []
tags: []
image: https://www.portainer.io/hubfs/Untitled%20design%20%287%29.png
pagetype: article
filedate: 2025-01-18
-->

So, you have Portainer running; you got it up pretty quickly using our standard deployment scripts, and that's neat..

But now you've decided you want to allow access to Portainer from the public internet, so you are either port forwarding the Portainer UI ports (http:9000/https:9443) from a public IP to Portainer, or you're deploying a reverse proxy, and presenting Portainer through a subdomain.

Remember, Portainer is an exceptionally privileged piece of software, and it has near root-level access to your Container infrastructure, so first up, are you really sure you want to expose it to the internet directly, and not via a VPN?

Assuming you're happy to expose it, you absolutely must must must make sure the "admin" user (the one you setup when you deployed Portainer) has a seriously complicated password, as this is the most trusted account in Portainer. It should NEVER have a dictionary-based password. If this isn't the case, change the password for that account RIGHT NOW.

Next, you need to make sure you have configured our authentication system to use a suitably secure external mechanism, such as "LDAP" or "OAuth" (the latter of which supports 2FA/MFA)..

Contrary to some opinions, both of these authentication sources are included in the free open-source version of Portainer. Portainer Business Edition, (our premium offering) has "click to configure" convenience buttons that help you do this quicker, but the raw authentication capability is in available in both versions (LDAP and Custom OAuth).

For the documentation (and examples) on how to configure LDAP authentication in Portainer CE, click here: [https://docs.portainer.io/admin/settings/authentication/ldap](https://docs.portainer.io/admin/settings/authentication/ldap)

For the documentation (and examples) on how to configure OAuth authentication in Portainer CE, click here:[ https://docs.portainer.io/admin/settings/authentication/oauth](https://docs.portainer.io/admin/settings/authentication/oauth)

Portainer Business Edition customers, please contact us for guidance on how to configure authentication correctly.

Portainer's internal authentication system should never be used when presenting Portainer to the internet, either directly or via a reverse proxy. This is for non-production/demo purposes only. For those of you that still want to use Portainer's internal authentication AND present Portainer on the internet, PLEASE ensure you set complicated (non-dictionary) passwords for ALL of your users. Portainer helps to protect against dictionary based brute force hacks through an authentication rate limiter, but with enough time, a dictionary word password WILL be compromised.

Portainer added support for HTTPS in mid 2021 (Port 9443) and we recommend that no one uses Port 9000 any longer, so please upgrade to a Portainer version that supports 9443 (or just use the most recent version of Portainer, which is currently 2.11.1).

Additionally, if you are presenting Portainer publicly on the internet, we strongly recommend network ACLs on your firewall, so you only allow access from known trusted IP addresses (or geoblock all countries were you don't need access). We wouldn't ever recommend allowing access from any/0.0.0.0 as this doesn't provide you any defence against "drive-by" brute force attacks.

And finally, you should already be aware that Portainer needs to persist its data, and as such requires a persistent volume. If you are running Portainer on a cluster, make sure that volume is available across the cluster, as if its not, and Portainer restarts on another node, it will not be configured, and will leave you vulnerable.

Be safe out there, and always secure your Portainer instance.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-ce-2.11.1-is-here-and-edge-computing-will-never-be-the-same-again
title: Portainer CE 2.11.1 is here and edge computing will never be the same again.
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-ce-2.11.1-is-here-and-edge-computing-will-never-be-the-same-again
hostname: portainer.io
description: Portainer 2.11.1 brings a raft of features and functions that make managing large-scale edge / IoT deployments easy and secure.
sitename: PORTAINER.IO
date: 2022-02-07
categories: []
tags: []
image: https://www.portainer.io/hubfs/Unknown-jpeg.jpeg
pagetype: article
filedate: 2025-01-18
-->

Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our [Portainer Features page](/features)*. *

Every day an unfathomable amount of data is created at the edge of the network, much of it transient, but all of it created for a reason. As data is created, it generally needs processing for it to become valuable. With the sheer quantity of data now in play, it is increasingly uneconomical to transfer it from the edge into the datacenter for processing, which is driving the exponential growth of edge computing.

As an example, take a series of surveillance cameras deployed in a city; if you want to look for a crime, you could either send all the feedback to a central location for processing, or you can run the AI engine on or near the camera, where the feed can be processed locally (and then discarded), with only “action” intel being transported back to the operator. Processing at the edge massively reduces the amount of data in motion and can dramatically speed up business processes.

Having simplistic devices at the edge that run single-purpose applications and send their data to a central processor is a simple setup. You just need a way to centrally control the device and somewhere to receive the data. However, if you want to move up the value chain you are likely going to want to run multiple applications, be able to update the applications, and have sufficient processing power for the application to do what is needed. In effect, you need the edge devices to operate as minicomputers.....

But how do you securely manage 20,000 minicomputers that are all connected to the public internet from a central location? There are so many examples of common IoT devices on the market today (home surveillance as an example) that are easily compromised. To operate at scale, security of remote device management must be a key consideration.

At Portainer, we see the edge as super important, and we foresee a future where managing massively distributed applications/containers running at the edge is as easy as running containers in the datacentre/cloud. It should be possible for anyone to do it, from anywhere without the need for a PHD. Managing edge-based devices, however, comes with a truly unique set of engineering challenges that have led us to build some truly remarkable tech we’re very proud of.

2.11.1 builds on the existing edge functionality embedded in Portainer. However, rather than building on top, it builds underneath – delivering unique capability that allows devices running at the edge to be FULLY managed.

This release addresses the 2 key weaknesses associated with edge devices

- Today’s Intel architectures make it impossible to install an OS onto a device without physically connecting to it. This is hugely limiting from an operational standpoint as it requires devices to be physically handled to be upgraded.
- Once a device is in the field it’s impossible to ‘remote’ into the device to triage issues and resolve issues, particularly when the device is offline.

These two factors have proven operationally limiting and have limited the rollout of edge devices due simply to the physical cost of managing the software running on the devices.

Portainer 2.11.1 changes all that. It allows users of Portainer to:

- Zero-Touch device onboarding to install an OS directly onto a remote machine (first install and upgrade)
- Power on and restart a remote machine anywhere in the world, even if the device is off
- Remotely access the devices KVM from within Portainer
- Shut a remote device down remotely

And, of course, users of 2.11 can continue to leverage all the existing edge functionality in Portainer to remotely start/stop containers, install images etc etc etc. Portainer now provides a complete end-to-end, soup to nuts management solution for remote devices – something that up to now simply has not been possible.

Up to 20,000 edge devices can be connected to a single instance of Portainer which makes it suitable for use in everything from smart grids to industrial plant management situations.

See the functionality in action here:

If you’d like to see Portainer in action or you’ve got a use case you’d like to explore with us, please [get in touch](/contact).

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/should-you-expose-portainer-or-agent-to-the-internet
title: Should you expose Portainer (or Agent) to the Internet??
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/should-you-expose-portainer-or-agent-to-the-internet
hostname: portainer.io
description: Exposing Portainer to the internet? Think twice...
sitename: PORTAINER.IO
date: 2021-12-19
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Dec-19-2021-10-45-42-05-PM.png
pagetype: article
filedate: 2025-01-18
-->

This is a question we get asked over and over, and its likely that for the 10 that ask the question, there are another 1000 that dont ask, and just do..

So, should you expose Portainer (or our agent) to the Internet..

Well, if you want the short answer, its NO... but for the longer answer, read on.

Portainer is an administrative tool with a very high degree of privilege and access to your container environent; as a result, access TO Portainer itself should be strictly controlled. If you are familiar with VMware, ask yourself, would you expose vCenter direct to the internet? I think not. How about your Cloud Provider portals, would you expect the cloud provider to allow logins without some form of 2 factor authentication in front of their UI or API? Nope..

Its with shock that we note the Shodan.io tool lists 5,710 instances of the Portainer Agent exposed to the internet, and a staggering 31,677 instances of Portainer itself. Remember this tool also shows the IP addresses listening on these Ports, so think long and hard as to whether you want/need your instances public.

Portainer has two agents; our standard agent, and our edge agent (as shown below).

The standard Agent is designed for use WITHIN YOUR LAN/WAN, and the Edge Agent is designed to manage container environments connected to the public internet. If you are using our standard agent, and you have exposed it to the internet (by publishing port 9001 publically), then might we suggest that you rethink this strategy. If nothing else, you should have a firewall ACL in place that only allows access to port 9001 from trusted IPs (namely, the public IP of your Portainer instance). If you have 9001 exposed to the internet without any form of protection, you need to reconsider.

The Edge agent does not require ANY inbound ports, as it connects back to Portainer over the internet using a secure tunnel.. This is why its recommended whenever you have container environments remote that you need to connect to over the internet.

Now, in regards to exposing Portainer (HTTP:9000 / HTTPS:9443); please make sure you are using our External Authentication capability and integrate Portainer with a trusted authentication provider that includes 2FA (eg Github Auth, Google Auth, Azure Auth).. you should never rely on JUST a password for something as critical as Portainer. This external auth is included for free in Portainer CE (oAUTH, Custom) - see docs.portainer.io if you need guidance on how to configure this.

In an upcoming version of Portainer (2.11.1) we will be making (likely breaking) changes to the regular agent to bolster its security, as we need to provide additional protection for those not following the above recommendations.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/wsl2-suspendresume-rtc-bug
title: WSL2 - Suspend Resume RTC bug
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/wsl2-suspendresume-rtc-bug
hostname: portainer.io
description: WSL2 RTC suspend resume bug getting you down?
sitename: PORTAINER.IO
date: 2022-02-14
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Feb-14-2022-06-26-33-17-PM.png
pagetype: article
filedate: 2025-01-18
-->

Another little annoying bug that hit us, and we just found a fix for..

[A little known bug](https://github.com/microsoft/WSL/issues/5324) with WSL2 is that it does not correctly handle resuming from a suspended state. When it does resume, the RTC clock simply continues from where it left off.. which is a problem if your machine is suspended for a few days..

No biggie, right... wrong... with so much of the internet (and Kubernetes) forcing the use of TLS/SSL, all communications are checking x509 Certificate validity dates. For that check to work reliably, it requires that devices are kept in sync with actual date / time..

a common error seen would be:

error: Post \"https://x.x.x.x:6443/api/v1/namespaces\": x509: certificate has expired or is not yet valid: current time 2022-02-12T13:17:04Z is before 2022-02-14T08:53:54Z]

So, what to do...

Well, its actually already fixed by MS, but for some reason, its not updated as part of Windows Update (no idea why).. to fix it, simply open a PowerShell windows as admin, and then type wsl --update

Then either restart WSL as it says, or reboot your PC...

No more RTC issues after this.. lovely.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/deploy-a-self-hosted-registry-secured-with-x509-client-certs
title: Deploy a self-hosted registry secured with x509 client certs.
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/deploy-a-self-hosted-registry-secured-with-x509-client-certs
hostname: portainer.io
description: How to deploy a self-hosted Docker Registry, secured with x509 Client Certificates for Authentication
sitename: PORTAINER.IO
date: 2022-02-19
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Feb-19-2022-10-13-56-32-PM.png
pagetype: article
filedate: 2025-01-18
-->

We were recently approached by a user and asked if Portainer supported self-hosted registries that implemented authentication through x509 client certs, and NOT with username/password credentials.

In order to give them an answer, we first wanted to replicate the setup and test it. We found that the process to setup this environment isnt well documented on the internet, so are publishing our steps here, just in case you want to do this too..

Most of this work is executed via the CLI on your host environments, so bear with us..

OK, you need at least 2 VMs for this to work.. one that will host the registry, and one that will act as your client.

Step 1, On the REGISTRY VM (in my case, its Ubuntu). Install Docker.

Follow the instructions here: [https://docs.docker.com/engine/install/ubuntu/](https://docs.docker.com/engine/install/ubuntu/)

- apt-get install ca-certificates curl gnupg lsb-release
- curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
- echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
- apt-get update
- apt-get install docker-ce docker-ce-cli containerd.io
- systemctl enable docker
- docker info (just to check all started ok)

Step 2, create the self-signed SSL cert that will be used for the registry server instance (will actually be used by the nginx proxy). Note you need to have a FQDN for the registry, so make sure you register one accordingly, and then use in the line 4 below. For this blog, i will use registrydemo.portainer.io

- mkdir -p /opt/registry/
- cd /opt/registry/
- mkdir -p certs
- openssl req -nodes -newkey rsa:8192 -days 365 -x509 -keyout certs/server.key -out certs/server.cert -batch -addext "subjectAltName = DNS:<YOUR FQDN HERE>"

Step 3, create the client CA certificate (the one we will use to generate all client certs that will be used for authentication).

- cd /opt/registry/
- openssl req -nodes -newkey rsa:8192 -days 365 -x509 -keyout client-ca.key -out certs/client-ca.cert -batch -subj "/commonName=docker-registry-client-ca"

Step 4, generate a client cert using the CA cert above.

- openssl genrsa -out client.key 4096
- openssl req -new -key client.key -out client.csr -batch -subj "/commonName=docker-registry-client"
- openssl x509 -req -days 365 -in client.csr -CA /opt/registry/certs/client-ca.cert -CAkey /opt/registry/client-ca.key -set_serial 01 -out client.cert
- rm -f client.csr

Step 5, Configure and start the Docker Registry Container

- create a config file in /opt/registry/config.yml
- version: 0.1

http:

secret: randomsecretgoeshere

addr: 0.0.0.0:80

storage:

filesystem:

rootdirectory: /var/lib/registry

maxthreads: 100

delete:

enabled: true - docker run -d --restart=always --name registry -v /opt/registry/config.yml:/etc/docker/registry/config.yml registry:2

Step 6, Configure and start the nginx proxy Container

- create a nginx config file in/opt/registry/nginx-registry.conf
- server {

listen 443 ssl;

keepalive_timeout 70;

client_max_body_size 0;

ssl_protocols TLSv1 TLSv1.1 TLSv1.2;

ssl_ciphers ECDH+AESGCM:ECDH+AES256:ECDH+AES128:DH+3DES:!ADH:!AECDH:!MD5;

ssl_session_cache shared:SSL:10m;

ssl_session_timeout 10m;

ssl_certificate /etc/nginx/ssl/server.cert;

ssl_certificate_key /etc/nginx/ssl/server.key;

ssl_client_certificate /etc/nginx/ssl/client-ca.cert;

ssl_verify_client on;

location / {

proxy_pass http://registry;

}

} - docker run -d --restart=always --name nginx --publish 443:443 --link registry:registry -v /opt/registry/nginx-registry.conf:/etc/nginx/conf.d/default.conf -v /opt/registry/certs:/etc/nginx/ssl nginx

Step 7, make sure nginx and registry are working.

curl -v -k --cert ./client.cert --key ./client.key https://localhost:443/v2/

Step 8, now we need to generate the instructions to be used on the Docker Client machines..

- Change <YOURFQDNHERE> to your registry URL, then Run the following:
- HOST=registrydemo.portainer.io

SERVER_IP="$(wget -q -O- curlmyip.org)"

cat << __EOF__

set -xe

SERVER_CERT="$(cat /opt/registry/certs/server.cert)"

CLIENT_KEY="$(cat client.key)"

CLIENT_CERT="$(cat client.cert)"

mkdir -p /etc/docker/certs.d/$HOST:443

echo "\$SERVER_CERT" > /etc/docker/certs.d/$HOST:443/ca.crt

echo "\$CLIENT_CERT" > /etc/docker/certs.d/$HOST:443/client.cert

echo "\$CLIENT_KEY" > /etc/docker/certs.d/$HOST:443/client.key

echo "\$(cat /etc/hosts | grep -v '$HOST')" > /etc/hosts

echo "$SERVER_IP $HOST" >> /etc/hosts

__EOF__ - Copy the results to your clipboard and take a note of it.

Step 9, OK, so now SWITCH to your Docker Host VMs (repeat this on every docker host that you want to access this registry).

run the script output from before on the host.

Step 10, Switch to the /etc/docker/certs.d/ directory, and check you have a directory for the FQDN of your registry, and inside that directory are 3x certificate files.

Step 11, you should now be able to use the registry. Test it as follows:

- docker pull nginx
- docker tag nginx registrydemo.portainer.io:443/nginx:latest
- docker push registrydemo.portainer.io:443/nginx:latest
- docker rmi registrydemo.portainer.io:443/nginx:latest
- docker rmi nginx
- docker run -d registrydemo.portainer.io:443/nginx:latest
- docker image ls

You now have a private registry, that is secured with HTTPS, and authenticated with client certificates.

Step 12, In Portainer, you simply need to add the registry with no authentication, and Docker will take care of the rest.

For proof, try to open your registry FQDN from a browser, and see you cannot access it.

Done.

Hope this is of use to you.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/using-env-files-in-stacks-with-portainer
title: Using ENV files in Stacks with Portainer
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/using-env-files-in-stacks-with-portainer
hostname: portainer.io
description: How to use ENV files in Portainer Stacks
sitename: PORTAINER.IO
date: 2022-02-21
categories: []
tags: []
image: https://www.portainer.io/hubfs/Using%20ENV%20files%20in%20Stacks%20with%20Portainer.png
pagetype: article
filedate: 2025-01-18
-->

Note: The following only applies to Docker Standalone and does not work for Docker Swarm.

OK, so a little confession.. our documentation, whilst already pretty comprehensive, doesn't cover every single detail of Portainer features... why? Because we are still a startup, and its only in the last 12 months that we have had the ability to fund people to start to focus on our documentation... so there are times when things are just, well, not documented.

We were recently [called out](https://twitter.com/aroah/status/1495665904373354498?s=21) for a particular piece of functionality in Portainer that is not documented (it will be now), in regards to using ENV files when deploying Stacks with Portainer. As a way to first apologize to the reporter (and to thank you for highlighting the missing docs), and to start the process to get this documented, I figured a blog would make sense.. so here goes.

So, you have a compose/stack file that has a lot of environment variables, and you want to load these into Portainer via an ENV file, and then make these available to the stack as a file (negating the need to define each one manually). How do you do that?

Well there is a nifty little button in Portainer "load variables from env file", and if you click that button, and select a ENV file on your PC, we auto-populate Portainer with these variables.

Cool, but how do you actually use them in your stack?

Well this where the documentation issue arises... we don't actually mention anywhere how to use these as a file... so you would naturally think that you need to reference these one by one, such as below:

and this would work... as shown in the resulting deployment.

But that's annoying.. what about just referring to the values as a file.. an ENV file even..

Well, you just need to reference the env file we create in the service definition. We call the file "stack.env" and it contains all of the variables read in from the external env file.

and that auto-creates the variables in the container without you having to manually enter them in via Portainer or 1:1 in the stack definition.

OK but that specifies a singular ENV file, how do I use that with multiple services in a stack?

well, you need a ENV file that contains all of the variables your stack needs; take this example..

then in Portainer, you use the "load from file" which loads them into the stacks page like so..

and then you reference them in your stack file like so..

But be aware, the ENVs are populated to BOTH of the services as they share a single file. This may cause you concern (or not).

So, this is how you use an external ENV file with Portainer Stacks.. expect to see this in the docs very soon.

Oh, and if you find features that are undocumented (or not clearly documented), please let us know.

Try Portainer with 3 Nodes Free

If you're ready to get started with Portainer Business, [3 nodes free](https://www.portainer.io/take-3) is a great place to begin. If you'd prefer to [get in touch with us](https://www.portainer.io/contact-sales), we'd love to hear from you!

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/why-civo-and-portainer-is-like-apple-pie-and-ice-cream
title: Why CIVO and Portainer is like Apple Pie and Ice Cream
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/why-civo-and-portainer-is-like-apple-pie-and-ice-cream
hostname: portainer.io
description: How do you make Kubernetes easy... with a combination of Civo and Portainer
sitename: PORTAINER.IO
date: 2022-02-04
categories: []
tags: []
image: https://www.portainer.io/hubfs/__opt__aboutcom__coeus__resources__content_migration__serious_eats__seriouseats.com__recipes__images__2013__03__20130323-anna-apple-pie-vanilla-ice-cream-slice-00fec96e95174030a50888954a95718b.jpg
pagetype: article
filedate: 2025-01-18
-->

Another day, another survey – this one from our good friends at CIVO. Unlike many, this one is worth taking a moment to review as it surfaces some important issues.

Unsurprisingly, the survey headlines are entirely consistent with many of the things we now know to be true.

- Containers are here to stay and they’re gradually eating away at the legacy IaaS/VM landscape
- The world is slowly but surely moving from on-premises to public cloud
- Kubernetes is the big dog in the orchestration fight, but it’s hard to drive
- Spinning up Kube clusters in the cloud is way slower than it should be.

But look a bit deeper into the survey and there are some nuggets that are worth exploring and thinking about a little more deeply.

Firstly, the survey highlights the Kubernetes adoption challenges faced by organizations, with 57% of developers pointing to the steep learning curve associated with Kubernetes. And secondly, 47% of those surveyed indicated that Kube complexity is ‘holding back their company’s use of containers’. These are big numbers.

Basically, 50% of responders are saying Kubernetes is getting in the way of business, which is a big deal. As an industry, we’ve managed to standardize on a platform / technology that is beyond the cognitive capabilities of * most* developers which means, in its current incarnation, it simply won’t make it into the early majority and that’s going to be a problem.

Unsurprisingly, 85% of survey responders “would be more inclined to use the tech if adopting the platform was easier”.

So, what does ‘make the platform easier to adopt’ actually mean?

At the highest level, there are 2 elements to a Kube implementation, the ‘infrastructure’ component (essentially the clusters) and the control plane. For Kube to be easy to adopt, you need both elements to be ‘easy’. Fixing one without the other is like serving apple pie without icecream. You just don’t do it.

CIVO is super smart and have built the most intuitive hosted Kube platform on the market and it’s totally awesome. Users can spin up clusters and manage their environment near instantly BUT, at the end of the days it’s still Kubernetes. To make it useful, developers still have to know the low level CLI commands for deploying apps into containers etc.

So, how do you simplify the Kube control plane so any developer can use it?

Well, there’s a reason that more than 500,000 developers use Portainer and there’s a reason why we’ve spent 2 years lifting and shifting our Docker capability so it works seamlessly with Kubernetes. The industry NEEDS a tool – any tool – to make Kubernetes accessible to the mainstream developer.

So…if you’re looking for a truly innovative hosted Kubernetes service then you should look no further than CIVO, their stuff rocks. However if you’re looking for an amazing, integrated top Kube solution that’s usable by everyone then put Civo and Portainer together. Then you’ve really got Apple Pie and Ice Cream.

Read the survey in full here: [https://www.civo.com/kubernetes-report-2021](https://www.civo.com/kubernetes-report-2021)

Deploy Portainer on a Civo Cluster here: [https://www.civo.com/marketplace/Portainer](https://www.civo.com/marketplace/Portainer)

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/using-vscode-with-portainer-managed-kubernetes-clusters
title: Using VSCode with Portainer managed Kubernetes Clusters
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/using-vscode-with-portainer-managed-kubernetes-clusters
hostname: portainer.io
description: Using VSCode with Portainer managed Kubernetes Clusters
sitename: PORTAINER.IO
date: 2022-02-15
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Feb-14-2022-11-04-48-89-PM.png
pagetype: blogposting
filedate: 2025-01-18
-->

VSCode is without a doubt, the most commonly used developer IDE worldwide (Stackoverflow state more than 50% of devs use it), but how can you use Portainer to maximize developer productivity with it?

One of the coolest features of VScode is its "extensions", which provide developers with embedded capabilities, such as the ability to directly deploy container based applications to Docker and/or Kubernetes. It also has extensions that can create a direct network tunnel from the developers workstation into private network spaces in remote clusters.

But what if you are already using Portainer and you want to use some of VSCode's Kubernetes-native extensions?

The answer is EASY.

If you were not already aware, Portainer implements a full Kubernetes API proxy into our architecture. This proxy provides for centralised access control and entry into any Kubernetes Cluster managed by Portainer. You users do not need to have TCP access to your cluster API endpoints, as connectivity is exclusively between your users and the Portainer sever. Portainer first validates that the user attempting to access the Kube proxy is authenticated and has suitable permissions, and if allowed, they are transparently connected to the relevant backend cluster. Because Portainer is a full Kubernetes API proxy, you can just treat Portainer like any other Kubernetes API endpoint, and let Portainer take care of the rest.

Let me show you...

First up, you need a Portainer instance with at least one Kubernetes cluster defined. In my example, I have Portainer running on my laptop, but in reality, this would be in your datacenter.

From within Portainer, you need to generate your kubeconfig file, so click on the button "kubeconfig", and save the file into your working path for your locally installed kubectl util (in my case its c:\users\neil\.kube\config)

if you want to validate this config file works, open a command window, and type "kubectl config get-contexts" and you should see them listed.

Now, open up your VSCode instance, click on the "manage" gear in the bottom left, then click "extensions"

In the search box, type in "Kubernetes", select the first result (as per my picture) and click "Install"

Once installed, click the little gear icon, and the "extension settings" to configure the extension.

In the input box "kubectl path", put in the exact path to your kubectl binary (in my case, as I'm using Docker Desktop, its C:\Program Files\Docker\Docker\resources\bin. Close the settings to save them.

Now this is installed and configured, in the sidebar of VSCode, you should see a new Kubernetes logo icon. Click on that.

You can now directly navigate and view the resources in the cluster, via Portainer, using VScode. Navigate around to see what you can see..

OK, but how do you actually deploy something?.. Well you can directly open a YAML manifest if you have one locally, so do that now. Click "File", then "Open File", and select a manifest.

Once you have it opened, click on "view" and then "Command Palette"

Type in "Kubernetes Create" and press enter, that will deploy the manifest.

Look for the Success status in the bottom right.

Switch to Portainer, and you can see it deployed.

This is a simplistic demonstration, but now that you have the extension installed, there are no limits to what you can do against the clusters using VSCode.

Give it a try and let us know your results

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/using-portainer-with-aws-elastic-container-registry
title: Using Portainer with AWS Elastic Container Registry
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/using-portainer-with-aws-elastic-container-registry
hostname: portainer.io
description: Want to use AWS ECR with Portainer, read how..
sitename: PORTAINER.IO
date: 2022-02-15
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Feb-15-2022-06-47-32-96-PM.png
pagetype: article
filedate: 2025-01-18
-->

Portainer has full support for communications with container image registry providers, including DockerHub (authenticated and anonymous), Azure Container Registry, Quay.io, ProGet, GitLab, AWS ECR, and pretty much every other Docker Registry v2 API registry provider.

But how do you use AWS ECR within Portainer? Let me show you.

We will start at step zero, creating the credentials in AWS Console (you can skip this if you already have valid creds)

Login to the AWS Management Console as an Admin User, go into IAM and 'Create a group'

Give the group a name, such as ECR_Admin

Scroll down to "Attach permissions policies" and assign the permission "AmazonEC2ContainerRegistryFullAccess", then click "Create Group"

Because Portainer's access to ECR cannot be based off a user with MFA enabled, you should create a specific user for this purpose. In the IAM console, click "Users" and then "Add Users".

Give the user a meaningful name, such as "portainer_registry_access", and set the credential type to "Access Key - Programmatic Access"

Add the user to the group you created, in my case, ecr_admin, then complete the creation of the user (no need for any other settings)

Take a note of the credentials provided, you will need these inside Portainer.

Next open the ECR page on AWS so we can create our first ECR Repository.

ECR will generate a FQDN for your private registry, but you need to create the specific repository you want to use. Note that unlike other registry providers, ECR requires you to pre-create ALL repos before you can push to them (or the push will fail). For this example, we will use "portainertesting" as our repository.

Take a note of the URL, we will need that later. Click "create" to complete.

You should now see your repository.

Ok, now switch to Portainer.

As an admin user, click on "Registries" in the sidebar, and then click "Add Registry"

Choose "AWS ECR" as the registry type.

Complete the details using the information previously captured. Note that registry URL is just the FQDN, it does not include the repository. Make sure to add your correct region. Click "add registry"

It's worth noting, that after adding this information, Portainer will automatically (in the background) keep regenerating an [AWS session key/token](https://docs.aws.amazon.com/cli/latest/reference/ecr/get-authorization-token.html), so as to ensure the authentication continues to work beyond the initial 12 hour session validity. You do not need to do anything but add these credentials, Portainer handles the rest.

If you are using Portainer Business Edition, you can verify commuications, by clicking the "browse" button.

At the moment, the registry doesn't have anything in it, so as long as your see "No repository available" you are good to go (no red warnings).

Ok, so let's push an image to the repo.

After selecting a Docker Environment (Note, this ONLY works with Docker, as Kubernetes has no native way to push images to a Repo), click on "images" in the left sidebar, then find the image you want to push, and tag it with the AWS registry. In my case, I'm just using the NGINX image.

Once you have added the repository name and tag, click the "tag" button, and then click the "up" arrow to push to the registry.

Once the push is completed, you should see a green success indicator.

OK, so now go back to the registries page, and browse again (assuming business edition), or use the AWS ECR UI to see inside the registry to validate the image was pushed.

OK, so the image is successfully in the Repo.

So now how do we use it?

Easy, if you are deploying a container using a Docker environment, you simply change the registry when you are in the create screen, and enter the repository and tag.

And you will see the container running with the private image from ECR.

To do this in Kubernetes, you can only "use" the images from the ECR registry. In Kubernetes, the "image pull secret" needs to be propagated into each namespace, which Portainer does for you.

As the admin, in a Kubernetes environment, click on "cluster" and then "registries". Select "manage access" next to the AWS ECR registry you created.

Select the namespace(s) that you wish to create the pull secrets within, then click "create access"

In the left sidebar, click "Applications" and then "Add application using form"

Select the namespace, and then you can select the AWS registry from the drop down list.

This is how easy it is to use AWS ECR Registry within Portainer.

Give it a try.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-as-part-of-your-cicd-pipeline
title: Portainer as part of your CI/CD with Docker and Kubernetes GitOps
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-as-part-of-your-cicd-pipeline
hostname: portainer.io
description: You can now use Portainer as part of your CI/CD toolset for Kubernetes GitOps. Portainer has easy CD functionality to make automated deployment a breeze.
sitename: PORTAINER.IO
date: 2022-02-25
categories: []
tags: []
image: https://www.portainer.io/hubfs/CICD%20Twitter%20Post%201600x900.png
pagetype: article
filedate: 2025-01-18
-->

Historically, Portainer has been a pure "ClickOps" tool, due to its rich UI, however that is no longer the case.

As of Portainer CE 2.11 and Portainer Business 2.12, we now have comprehensive, built-in GitOps for Docker and Kubernetes. This functionality covers 80% of use cases where you need a GitOps solution that "just works". It's perfect if you don't have a solution already in place, and/or don't want to spend weeks or months learning something that should be invisible!

But how does Portainer's GitOps engine fit into your development pipeline?

Below is a pretty typical flow that most organizations aspire to, when looking to embrace a CI/CD pipeline incorporating multiple developers or teams.

Getting code into Production starts with developers, who physically write the code. Developers almost always develop locally, on their laptops, using IDEs of their choosing. More often than not, these same developers want to see their code changes running locally, to iterate before they commit their code back to the company repo for testing. To accommodate their need to run code locally, developers build their own scripts/tooling, likely leveraging VSCode, bash scripts, and Docker.

The Dev (or their DevOps teammate) would generally write a Dockerfile which is used by their scripts to build a container instance of their app, and then run that container (and any supporting services) inside their local docker instance. At this level, developers are running standalone Docker instances (likely Docker Desktop) on their machines, and are expected to know how to use Docker to inspect and triage the containers. Portainer can help developers get the visibility they need to triage their applications locally, seeing logs, performance, crash states/reasons etc.

Once developers are confident in their work, they commit their changes back to the centralized code repo which is where Continuous Integration (CI) toolsets normally kick into life.

A CI tool (like Azure DevOps, or GitHub Actions) will trigger the automated build of an image (using Dockerfiles created by the developers or DevOps team) and will push the image (plus any image artifacts) to a combination of an image registry, and a Git repo that holds the manifest for the application deployment. The CI tool then notifies either a CD tool that a deployment needs to take place or the CI tool can wait for a deployment to occur outside of its control (eg via GitOps tooling), before executing automated unit tests against the built environment. Once the automated tests have successfully been completed, the CI will typically notify the CD tool that the deployed environment is no longer needed and should be destroyed.

At the next stage, generally triggered by the automated tests, but sometimes by a human, the successfully tested branch is merged back into a release trunk/branch which initiates the second cycle of CI automation. Again, CI builds an image, the image and manifests are pushed to a repo, and then the CI notifies CD (or waits) for deployment to a staging environment to occur. Once the staging environment is running, automated integration tests are executed by the CI, and often these are supplemented with manual tests executed by a QA team. Once all integration tests are completed, the CI would typically notify the CD tool that the deployed environment can be destroyed. The CI tool then retags the built image with the production tags, and pushes the tags and manifests to a repo.

At the final stage, the CI either initiates the update of Production by notifying a CD tool to deploy the new production build, or exits if there is a GitOps tool polling for changes.

So, how does Portainer fit into the flow?

Portainer is not a CI tool, it is not even a CD tool (although, as our GitOps tooling can be configured to pull or be triggered by a webhook we can be thought of as a CD). Portainer is a GitOps tool. If you are not aware of the definition of GitOps, it means all deployment configuration manifests that describe the "desired state" are held in Git, automation is triggered by changes that occur in Git, and as a result, this dramatically reduces developer tool context switching as they can trigger deployment updates from within the tool they use every day.

From a CI perspective, you simply need to configure your pipeline to create images, push manifests, and then wait for Portainer to detect the changes, and deploy the environment based on the changes (at the very least, a manifest would change with a new image version tag, Portainer would detect that and update the running deployment with the new image tag).

But how is Portainer's GitOps engine different from others in the market? Simple, Portainer's capability exists for Docker, Docker Swarm, and Kubernetes, so if you run a hybrid environment, we are the obvious choice.

Secondly, Portainer runs the GitOps capability inside Portainer, not inside your clusters, so there is ZERO load on your clusters, and nothing to install or maintain. Portainer polls for changes, and then executes the changes against the clusters on your behalf, regardless of where they may be hosted or what version of Kubernetes they run.

Portainer Business has additional capabilities, such as an "enforce" mode, which overrides the running deployment with what's defined in Git, and also a "change window" option, which disables automation outside of a preset time window (which is brilliant if your apps are not fully capable of rolling updates, but you still want the benefit of GitOps).

Portainer Business Edition also adds support (on Docker Standalone and Docker Swarm environments) for storing your files in your Git repository alongside your stack YAML, and automatically deploying those files to your environments when you deploy the stack. We call this relative path support, and you can read more about how it works [in our documentation](https://docs.portainer.io/advanced/relative-paths).

Given our GitOps is native to Portainer, and it's so simple to use, give it a try, you will be surprised how easy it is to get started.

Try Portainer with 3 Nodes Free

If you're ready to get started with Portainer Business, [3 nodes free](/take-3) is a great place to begin. If you'd prefer to [get in touch with us](https://www.portainer.io/contact-sales), we'd love to hear from you!

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/author/neil-cresswell/page/8
title: Portainer News and Blog | Neil Cresswell, CEO (8)
author: Neil Cresswell; CEO December
url: https://www.portainer.io/blog/author/neil-cresswell
hostname: portainer.io
description: Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization. (8)
sitename: Portainer.io
date: 2021-12-15
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

### Blog Post by Neil Cresswell, CEO

[
](https://www.portainer.io/blog/portainer-release-cadence-for-2021)

Neil Cresswell, CEODecember 15, 20211 min read

### Portainer release cadence for CE and Portainer Business in 2021

Portainer Release Cadence for 2021

Start Reading
[
](https://www.portainer.io/blog/portainer-statement-re-log4j-cve-2021-44228)

Neil Cresswell, CEODecember 14, 2021< 1 min read

### Portainer statement re Log4J CVE-2021-44228

Portainer response to CVE-2021-44228

Start Reading
[
](https://www.portainer.io/blog/container-service-delivery-platforms-to-build-or-to-buy-and-why-thats-not-really-a-question)

Neil Cresswell, CEONovember 29, 20213 min read

### Container service delivery platforms - to build or to buy? And why that’s not really a question

Learn why you should consider deploying Portainer as your service delivery platform ...

Start Reading
[
](https://www.portainer.io/blog/why-kubernetes-should-be-like-a-vending-machine)

Neil Cresswell, CEONovember 8, 20214 min read

### Why Kubernetes should be like a vending machine

Vending machines are simple platforms for self-service delivery of just about anything. ...

Start Reading
[
](https://www.portainer.io/blog/talking-stateful-kubernetes-neil-cresswell-interviewed-on-the-cncf-data-for-kubernetes)

Neil Cresswell, CEONovember 1, 20211 min read

### Persistent Disk or StatefulSet? The right way and the wrong way to make apps persist state inside a K8s cluster- Neil Cresswell Interviewed on the CNCF 'Data for Kubernetes

From this talk delegates will learn the difference between persistent disk and ...

Start Reading
[
](https://www.portainer.io/blog/portainer-2.9-takes-kubernetes-mainstream-with-gui-templates-and-api)

Neil Cresswell, CEOOctober 12, 20212 min read

### Portainer 2.9 Takes Kubernetes Mainstream with GUI, Templates, and API

Portainer CE version 2.9 brings Kubernetes to the mainstream with a host of new features, ...

Start Reading
[
](https://www.portainer.io/blog/reclaim-disk-space-by-compacting-the-docker-desktop-wsl-disk-image)

Neil Cresswell, CEOSeptember 26, 20211 min read

### Reclaim disk space by compacting the Docker Desktop WSL disk image

Docker Desktop WSL2 taking up lots of disk space

Start Reading
[
](https://www.portainer.io/blog/why-everyone-is-an-admin-is-a-bad-idea)

Neil Cresswell, CEOSeptember 26, 20217 min read

### Why 'everyone is an admin' is a bad idea for Kubernetes and Docker

Learn how to secure your Kubernetes and Docker environments correctly with Portainer.

Start Reading
[
](https://www.portainer.io/blog/containers-vs-vms)

Neil Cresswell, CEOSeptember 25, 20217 min read

### Containers vs VMs - What's the Difference?

Containers vs VMs - this blog post examines how they are different, and why one is not a ...

Start Reading
[
](https://www.portainer.io/blog/portainer-now-with-helm-support)

Neil Cresswell, CEOSeptember 24, 2021< 1 min read

### Portainer, now with Helm Support

Portainer Business, now with Helm support

Start Reading
[
](https://www.portainer.io/blog/why-are-stateful-containers-so-confusing)

Neil Cresswell, CEOSeptember 23, 20214 min read

### Why are stateful containers so confusing in Kubernetes?

StatefulSets vs Deployments, when you should use each.

Start Reading
[
](https://www.portainer.io/blog/kubernetes-is-complex-scare-mongering-or-reality)

Neil Cresswell, CEOSeptember 9, 20213 min read

### Kubernetes is complex; scare-mongering or reality?

Kubernetes is hard, but are we scare mongering unnecessarily.

Start Reading

---
<!--
URL: https://www.portainer.io/blog/author/adolfo-delorenzo
title: Portainer News and Blog | Adolfo Delorenzo
author: Adolfo Delorenzo February
url: https://www.portainer.io/blog/author/adolfo-delorenzo
hostname: portainer.io
description: Latest news and updates from the Portainer team
sitename: Portainer.io
date: 2024-02-29
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

### Blog Post by Adolfo Delorenzo

[
](https://www.portainer.io/blog/restore-portainer-k8s-running-the-api)

Adolfo DelorenzoFebruary 29, 20245 min read

### How to Restore a Portainer instance running on Kubernetes using the API

How to Restore a Portainer instance running on Kubernetes using the API

Start Reading
[
](https://www.portainer.io/blog/manage-software-running-at-the-far-edge-with-nomad-and-portainer-webinar)

Adolfo DelorenzoSeptember 22, 2022< 1 min read

### Manage software running at the far edge with Nomad and Portainer - Webinar

Discover how HashiCorp's Nomad and Portainer can help solve the challenge of managing ...

Start Reading
[
](https://www.portainer.io/blog/portainer-community-edition-2.11-release)

Adolfo DelorenzoDecember 9, 20211 min read

### Portainer Community Edition 2.11 Release

Portainer CE 2.11 makes Portainer compatible with AWS Registry and adds a range of other ...

Start Reading
[
](https://www.portainer.io/blog/how-to-secure-your-portainer-installation)

Adolfo DelorenzoNovember 25, 20211 min read

### How to secure your Portainer installation

Securing your Portainer Installation is really important. This blog explains what you ...

Start Reading
[
](https://www.portainer.io/blog/portainer-business-edition-version-2.10)

Adolfo DelorenzoNovember 14, 20213 min read

### Portainer Business Edition version 2.10 - the container service delivery platform you've been waiting for

Portainer Business Edition 2.10 is here and brings with it all of the great functionality ...

Start Reading
[
](https://www.portainer.io/blog/2.9.1-release)

Adolfo DelorenzoOctober 10, 20213 min read

### New Portainer CE 2.9.1 Release - now with support for Dark Mode, HTTPS, HELM and Kube Proxy

Portainer Community Edition Open Source Docker Kubernetes Update Upgrade RBAC Helm ...

Start Reading
[
](https://www.portainer.io/blog/how-to-run-portainer-behind-a-wireguard-vpn)

Adolfo DelorenzoSeptember 29, 20213 min read

### How-To run Portainer behind a Wireguard VPN

How-To run Portainer behind a Wireguard VPN

Start Reading
[
](https://www.portainer.io/blog/portainer-business-charm-launched-for-canonicals-charmed-kubernetes)

Adolfo DelorenzoSeptember 23, 20212 min read

### Portainer and Canonical Expand Partnership Launching Business Charm for Charmed Kubernetes

Charmed Kubernetes is Canonical's 'enterprise' Kube distro. Portainer Business turns ...

Start Reading
[
](https://www.portainer.io/blog/2.7.0-release)

Adolfo DelorenzoJuly 30, 20212 min read

### New Portainer Business 2.7.0 Release - now with support to pull and redeploy a Docker stack from Git, Kubernetes app deployment from Git and Group membership mapping from OAuth.

Check out our latest release, Portainer Business 2.7.0. Now with support to pull and ...

Start Reading
[
](https://www.portainer.io/blog/new-portainer-ce-2.6.0-release)

Adolfo DelorenzoJune 25, 20212 min read

### New Portainer CE 2.6.0 Release - now with support for Git repository deployment, and single sign-on support for OAuth

2.6 release notes for Portainer CE, specifically addressing a number of points relating ...

Start Reading
[
](https://www.portainer.io/blog/installing-portainer-to-the-raspberry-pi-piday-raspberrypi-raspberry_pi)

Adolfo DelorenzoJune 21, 2021< 1 min read

### Installing Portainer to the Raspberry Pi #piday #raspberrypi @Raspberry_Pi

In this guest post from Emmet at pimylifeup.com, you can follow the easy guide to install ...

Start Reading
[
](https://www.portainer.io/blog/from-zero-to-production-with-fedora-coreos-portainer-and-wordpress-in-7-easy-steps)

Adolfo DelorenzoMay 7, 202131 min read

### From Zero to Production with Fedora CoreOS, Portainer, and WordPress in 7 Easy Steps

From Zero to Production with Fedora CoreOS, Portainer, and WordPress in 7 Easy Steps

Start Reading

---
<!--
URL: https://www.portainer.io/blog/author/james-carppe
title: Portainer News and Blog | James Carppe
author: James Carppe October 3
url: https://www.portainer.io/blog/author/james-carppe
hostname: portainer.io
description: A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.
sitename: Portainer.io
date: 2024-10-03
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

### Blog Post by James Carppe

[
](https://www.portainer.io/blog/portainer-2.22-sts-release)

James CarppeOctober 3, 20242 min read

### Portainer 2.22 STS is now available

Portainer version 2.22 STS is now available - find out more about the STS release type ...

Start Reading
[
](https://www.portainer.io/blog/portainer-2.21-release)

James CarppeAugust 27, 20245 min read

### Portainer 2.21 LTS is now available

Portainer version 2.21 LTS is now available - the first LTS release we've done. Find out ...

Start Reading
[
](https://www.portainer.io/blog/portainer-agent-vs-edge-agent)

James CarppeAugust 16, 20243 min read

### Portainer Agent vs Edge Agent

Struggling to understand the difference between the Agent and Edge Agent? This excerpt ...

Start Reading
[
](https://www.portainer.io/blog/persistent-storage-docker-bind-mounts-and-named-volumes)

James CarppeJune 12, 20244 min read

### Persistent Storage: Docker Bind Mounts and Named Volumes

In this first post in an ongoing series we look at persistent storage in Docker, ...

Start Reading
[
](https://www.portainer.io/blog/portainer-and-docker-26)

James CarppeMarch 28, 20242 min read

### Portainer and Docker 26

On 20 March version 26 of Docker was released. There are a number of changes in this ...

Start Reading
[
](https://www.portainer.io/blog/portainer-2.20-release)

James CarppeMarch 19, 20247 min read

### Portainer 2.20 STS is now available

Portainer version 2.20 STS is now available - the first in our new STS and LTS release ...

Start Reading
[
](https://www.portainer.io/blog/portainer-2.19-release)

James CarppeAugust 31, 20234 min read

### Portainer Latest Version - 2.19 is now available

Portainer Latest Release - 2.19 is now available, with improved performance and update ...

Start Reading
[
](https://www.portainer.io/blog/portainer-2.18-release)

James CarppeApril 18, 20233 min read

### Portainer 2.18 is now available with improved performance, MicroK8s cluster creation, and more.

Portainer 2.18 is now available. Discover improved performance, MicroK8s cluster ...

Start Reading
[
](https://www.portainer.io/blog/portainer-2.17-release)

James CarppeFebruary 7, 20235 min read

### Portainer 2.17 is now available

Portainer 2.17 and 2.17.1 (patch) are now available. This version includes backup to ...

Start Reading
[
](https://www.portainer.io/blog/portainer-2.16-release)

James CarppeOctober 31, 20223 min read

### Portainer 2.16 is now available

Portainer 2.16 is now available. It includes improvements to ingresses, git creds ...

Start Reading
[
](https://www.portainer.io/blog/portainer-2.15-release)

James CarppeSeptember 5, 20224 min read

### Portainer 2.15 - a new UI, GPU support, pod security policies and more

Portainer 2.15 is now available. It includes a brand new UI, support for GPUs in Docker, ...

Start Reading
[
](https://www.portainer.io/blog/portainer-2.14-now-with-kubernetes-provisioning-on-amazon-eks-google-gke-and-azure-aks)

James CarppeJune 29, 20223 min read

### Portainer 2.14 - now with Kubernetes provisioning on EKS, GKE, and AKS

Portainer 2.14 is here. It includes a raft of new features including the ability to ...

Start Reading

---
<!--
URL: https://www.portainer.io/blog/portainer-ce-and-be-2.13-are-here
title: New Portainer CE and BE 2.13 - with Kubernetes provisioning
author: James Carppe
url: https://www.portainer.io/blog/portainer-ce-and-be-2.13-are-here
hostname: portainer.io
description: Learn what's new in Portainer CE and Portainer BE 2.13 - including Kubernetes provisioning on Digital Ocean, Civo, and Linode.
sitename: PORTAINER.IO
date: 2022-05-08
categories: []
tags: []
image: https://www.portainer.io/hubfs/Portainer%20new%20release%20%20-%20CE%20and%20BE%202.13.png
pagetype: article
filedate: 2025-01-18
-->

Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our [Portainer Features page](/features)*. *

Portainer version 2.13 includes a number of changes and updates from previous versions as well as some new Business Edition-specific features. For a full list of changes, please refer to our release notes.

**Provisioning Kubernetes in the Cloud**

One of the most exciting new features in 2.13 is the ability to provision Kubernetes environments on cloud providers directly from within Portainer. With a couple of clicks, you can spin up a Kubernetes environment in the cloud right from Portainer itself, automatically deploying the Portainer Agent to the new cluster ready for you to manage.

In this release, we're supporting provisions on Civo, Linode and DigitalOcean, with more providers to come in the future. [You can learn more about provisioning in this blog post.](/blog/portainer-announces-kubernetes-provisioning-on-digitalocean-linode-and-civo)

**Concurrent release of Community and Business Editions**

Version 2.13 marks the first time we are releasing both Business Edition and Community Edition at the same time. This is part of us streamlining our release process, and you can expect to see concurrent releases like this going forward.

To go along with this, we're also combining our documentation into a single release, rather than the split between the Business Edition and Community Edition that has been done previously. Any features that are Business Edition specific will be noted in the documentation.

**Home page filtering**

As you add more environments to Portainer, the list on the home page may grow. To help with this, we've added filtering options to the home page. With these you can filter the list of environments displayed by platform, status, tags and groups, making things a lot easier to find.

**Registry browsing for non-admins**

- Edge Agent Waiting Room

The Edge Agent Waiting Room functionality lets you pre-load Edge devices with a script to deploy the Edge Agent and connect back to the Portainer Server without having to pre-configure the environments in Portainer. Newly connecting devices go into a "waiting room", where an admin user would approve or deny those devices connecting to the environment. This is extremely powerful if you're deploying a large number of devices and aren't able to manually configure each one when they're connected for the first time.

You can read more about this feature in our [accompanying blog post.](/blog/pre-staging-edge-environments-with-portainer)

**Private registries for Edge Stacks**

BE 2.13 adds support for private registries to our Edge Stacks functionality. This lets you deploy stacks on Edge devices from sources other than Docker Hub, including your own company registries set up within Portainer.

- Environment variables from the local system available in Edge Stacks

**Enforcing strong passwords**

On the security front, we've improved security for Portainer's internal authentication method by requiring that you use strong passwords for your users. Passwords will need to be at least 12 characters, and include at least three of the following four character types:

- Lower case letters

- Upper case letters

- Numeric characters

- Special characters

If you're upgrading Portainer and your existing passwords don't meet this requirement, you'll be prompted to change your password when you first log in after the upgrade.

This feature only applies to those using Portainer's internal authentication - if you're using an external authentication provider like Active Directory or OAuth, this won't apply to you.

- Dependency updates to resolve CVEs

We've also spent some time updating our third-party dependencies within the Portainer image to resolve some reported CVEs, and we'll continue to keep an eye out for these in the future, updating the dependencies as needed.

[A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.](https://www.portainer.io/blog/author/james-carppe)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/reclaim-disk-space-by-compacting-the-docker-desktop-wsl-disk-image
title: Reclaim disk space by compacting the Docker Desktop WSL disk image
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/reclaim-disk-space-by-compacting-the-docker-desktop-wsl-disk-image
hostname: portainer.io
description: Docker Desktop WSL2 taking up lots of disk space
sitename: PORTAINER.IO
date: 2021-09-26
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Sep-26-2021-11-14-25-69-PM.png
pagetype: article
filedate: 2025-01-18
-->

For those of you that run Docker Desktop on Windows with WSL2 integration, this is for you..

Have you wondered where all your hard drive space is going? Have you seen that the folder c:\users\<yourname>\AppData\Local\Docker\WSL\Data is growing and never shrinking?

Well in that folder sits a virtual hard disk called ext4.vhdx, and its the virtual disk that the Docker Desktop WSL2 instance uses. This is a "thin provisioned" disk image that grows as data is created, but its never compacted again, even if the data is removed from within the virtual disk itself (so doing docker system prune commands wont actually get you back any space).

Just this morning my own laptop ran out of disk space (as in 0 bytes free), and a quick check showed me that my docker desktop VHDX was at 41GB.

A quick google search lead me to this blog: [https://nickjanetakis.com/blog/reclaiming-tons-of-diskspace-by-compacting-your-docker-desktop-wsl-2-vm](https://nickjanetakis.com/blog/reclaiming-tons-of-diskspace-by-compacting-your-docker-desktop-wsl-2-vm) which saved my bacon.

I ran the commands he recommended (shown below), and managed to reclaim 5GB of space. Not a lot, i know, but got me out of a hole.

The root cause isnt actually Docker's issue (its WSL2), but no idea why Docker dont make this quick fix a "right click" option off their task bar icon, or even an option in their settings menu. It seems like a pretty important thing to do, especially with highly dynamic environments like local developers using Docker Desktop (the target market..

Anyway, thought this might be a useful piece of info, and thanks to Nick Janetakis for making this fix easy to find.

Neil

Here is the root cause if its of interest.. note its been open since Nov 2019. [https://github.com/microsoft/WSL/issues/4699](https://github.com/microsoft/WSL/issues/4699)

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-now-with-helm-support
title: Portainer, now with Helm Support
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-now-with-helm-support
hostname: portainer.io
description: Portainer Business, now with Helm support
sitename: PORTAINER.IO
date: 2021-09-24
categories: []
tags: []
pagetype: article
filedate: 2025-01-18
-->

Do you have a favorite Helm chart or repository that you deploy from? With our new Helm support, you can now deploy Helm charts from Bitnami or other favorite Helm repositories.

As an admin you can set the default repository for your users, and as a user you can add must have repositories to your personal view.

For ease of use, to narrow down the list you can select categories of charts to view or type in the search box. With ability to edit the values.yaml of your Helm chart, customizing and deploying just got easier.

Once deployed you’ll be redirected to our new look applications page view. Here we have reworked our view to accommodate Helm charts with multiple workloads being nested under the Helm Chart deployment. This brings new and quick access to you for things like secrets and ports.

This is our first step into supporting Helm charts and we welcome feedback on how we can tweak things to better cater for everyone’s workflow. Please let us know what you think (good or bad). You can provide feedback on this feature here: [https://github.com/portainer/portainer/issues/5350](https://github.com/portainer/portainer/issues/5350)

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/why-kubernetes-should-be-like-a-vending-machine
title: Why Kubernetes should be like a vending machine
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/why-kubernetes-should-be-like-a-vending-machine
hostname: portainer.io
description: Vending machines are simple platforms for self-service delivery of just about anything. For IT team, the goal is to make Kube look like a vending machine.
sitename: PORTAINER.IO
date: 2021-11-08
categories: []
tags: []
image: https://www.portainer.io/hubfs/Untitled-png.png
pagetype: article
filedate: 2025-01-18
-->

A vending machine is the ultimate self-service device for selling stuff. They have a self-explanatory user experience, which makes it easy for users to get exactly what they want, when they want it, securely; all without having to talk to anyone about anything.

As the owner of a vending machine, you’ve got two jobs: make sure it’s stocked and make sure it works. That’s it. The concept of a vending machine is simple and there’s a lot we should learn from them as we think about how best to deploy containers and Kubernetes.

Why?

As an IT team, our mission is to create a reliable and resilient ‘self-service’ operating environment that allows our customers (typically developers, but sometimes an ‘apps’ team) to deploy software and resolve problems quickly and easily without talking to us. We did this quite well in the past with IaaS based environments; deploying automation tools that offered service catalogs, letting users self-serve and deploy pre-configured VMs on-demand. So…surely, we can just do the exact same thing with Kubernetes, right?

Out of the box, Kubernetes is about as far from a vending machine as you can get. Kube’s claim to fame is it can be made to do anything, in any way, and it does this by being near infinitely configurable. However, it’s this vast flexibility that makes it so difficult for IT teams to offer a predictable, self-service, catalog-based service offering for their customers.

**If you want the transformative power of Kubernetes to be adopted widely across your organization, you need to remove a lot of this configurability and get back to offering a standardized set of services that are easy to understand and easy to consume. By overlaying a third-party Service Delivery Platform, Kubernetes can start to look a lot like the vending machine we’re looking for.**

A Service Delivery Platform turns your Kubernetes implementation into a Containers-as-a-Service (CaaS) environment. It gives users secure self-service access to the functionality they need through a simple GUI that negates the need for them to learn the intricacies of Kubernetes. It also gives Platform Managers the ability to set up and configure the rules by which developers play, which puts them firmly in control of how the ball game is played.

A well configured service delivery platform enables users to:

- Instantly deploy vanilla “turnkey” fully functional landscapes (picked from a catalogue), equipped with all the supporting services their application needs to run
- Easily deploy their application into that landscape
- Keep their application up to date as they develop new features (CD)
- Facilitate the easy promotion of their application across environments through a simple “click to promote” process
- Provide a simple means to triage their application should it not function as expected
- Scale their application to support increasing production loads
- Easily configure the reverse proxies and load balancers needed to run their application successfully in production
- Easily consume storage when they need to make applications persistent
- Provide a “secure by default” behavior, removing the burden from the user to ensure this is done right.

All without having to write a single line of YAML or know any CLI.

The concept of a Service Delivery Platform isn’t new – there are a number of fairly well-known examples around already (not necessary called SDPs) and no doubt plenty of start-ups in the wings chomping at the bit to enter the space. However, not all platforms are equal and there are at least 2 important things to think about before selecting a vendor.

- Some SDPs come tied to a full stack of Kubernetes capability underneath them (K8s distro, Managed Service etc) which starts to look a lot like vendor lock-in. If you get hooked on a particular SDP, and it’s tied to a particular K8s distro, then there’s no easy way out of that distro. That might be OK in a mature market, but the Kubernetes market is moving fast and today’s ‘distro-of-the-day’ might not be tomorrows (it won’t be) and right now you need to not lose your ability to be agile.
- The SDP’s interface can be as hard to learn as Kubernetes itself. We’ve played with a lot of SDPs and whilst they might be easier to use than Kubectl, they are definitely not simple, straightforward and intuitive. Interestingly, many of today’s SDPs have been designed to surface every last piece of Kube functionality, which is good in theory, but as we’ve established already, large parts of Kubernetes simply aren’t relevant or necessary for ‘mainstream’ implementations and can create more problems than the solve.

Portainer differs from other SDPs on the market in 3 important ways

- It works with any / all distros and can be used to provide a single consolidated view of clusters running in different environments. This is unique and as organizations spread their clusters across different environments a critical piece of capability
- Assuming your team is familiar with containers and have come from a Docker background (most have) then there’s a good chance they will already be familiar with Portainer’s interface as Portainer cut its teeth in the Docker world
- Portainer is moving forwards at a pace and by hitching your wagon to Portainer you won’t need to change or retrain your team as the market moves and changes (think serverless) as we’re already working on what’s coming next….

So, if you’re heading into Production with your Kubernetes implementation and you can see the value in a vending machine then give Portainer Business a try with [3 free nodes](/take-3).

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/containers-vs-vms
title: Containers vs VMs - What's the Difference?
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/containers-vs-vms
hostname: portainer.io
description: Containers vs VMs - this blog post examines how they are different, and why one is not a replacement for the other.
sitename: PORTAINER.IO
date: 2021-09-25
categories: []
tags: []
image: https://www.portainer.io/hubfs/Virtual%20Machines.png
pagetype: article
filedate: 2025-01-18
-->

When newcomers are taking their first steps into container adoption, one of the common areas of confusion is understanding the difference between a container and a virtual machine.

In this blog, I will explain the differences in the technical architecture, and why one is not a direct replacement for the other. Note that this information applies regardless of the orchestrator you may decide to use (Docker or Kubernetes), as it's more about the foundational differences between a VM and a Container.

It's important for newcomers to understand that [containers](/hybrid-cloud) are not automatic replacements for VMs. One of the easiest ways to think of a container is "*that a container is just as an application process that runs WITHIN a VM, so how can a container be anything like a VM".* This thinking helps to cement the reality that a container is not a replacement for a VM.

But what are the actual differences?

1) Containers are not statically assigned hardware resources, which means you don't need to think about how many CPUs, RAM, disk your application needs to be physically assigned. In a VM, you need to decide upfront, is this a VM with 1,2,4 + CPUs, does it need 1,2,4,8,16+ GB of RAM, do I need 100GB or more disk? And once you deploy your app, to upsizing or downsizing takes a bit of a manual process (how hard/easy depends on your hypervisor / cloud provider).

Containers, by default, have access to ALL of the resources of the VM (host) they are running upon. Sure, you can apply a resource limit, but that's just a software constraint, and requires no downtime.

2) Containers are just a SINGLE process. A container cannot (natively) contain both your front-end application AND your backend DB, unless you knowingly set it up to run this way. Containers also do not run background tasks (such as CRON). When you build your container image, you specify the command (CMD) that the container will run as its PID1 (primary process). As you can see from the MYSQL container image below, the command assigned to PID1 is mysqld.

And you can see when the container is running, that mysqld is in fact running as PID1.

From a mechanical perspective. PID1 is what keeps the container alive. Should PID1 die (or be stopped), the container dies/stops. So whatever process runs as PID1 MUST be a long-running process if you want the container to start and stay running.

If you have a container image that does NOT specify a long-running CMD (PID1), then you must manually specify additional CMD information at container runtime, or else the container will start and then immediately stop (example here is busybox); if you just run it without any other inputs, it starts, executes SH, and then exits. You can make SH wait for inputs by marking the container as being "interactive and TTY" bypassing the -it flags when starting.

If you deploy as interactive, you can then "attach" to the PID1 instance, and execute commands directly.

You need to be exceptionally careful here though, as if you happen to send Ctrl Break to this console, you actually kill the SH session, thereby stopping the container (Ctrl C works OK though).

3) Containers are NOT persistent by default. Any changes you make inside the container, are NOT persisted (retained) unless you have knowingly pre-configured the container to run this way at creation time. Inside a container image, the original author would have defined persistent volume requirements, using the VOLUME statement. These are the areas the image creator requires you to make persistent, as this is where the application holds all of its configuration information. If we go back to the MYSQL image example, you can see that the image creator wants you to persist /var/lib/mysql.

When you deploy your container, you must specify a persistent volume for that container as shown below:

Now, if you happened to console into the container, and run, for example, an apt-get upgrade, to upgrade the software elements inside the container, then this is NOT persisted should the container be updated/redeployed. The only data that is retained is data that resides in the /var/lib/mysql directory.

4) Containers use NAT networking. Containers are, by default, connected to your network by bridging (NAT routing) THROUGH the Docker network interface, so a container itself does not have a "real" IP address on your network. If you deploy a container, it will automatically attach to the "bridge" network, which is the docker network component that implements a NAT router. When you deploy your container, it will get an IP address assigned by the Docker IPAM engine, which by default is in the 172.17.0.0/16 subnet as shown below.

The container I deploy, in my example below, mySQL, has been assigned IP address 172.17.0.6. On my LAN, my networking is 192.168.1.0/24, and I have no way to reach 172.17.0.6, so how do I? By accessing the container using the host's IP address (in my case, my host is 192.168.1.253). This is why, when you deploy a container, you are asked which "ports to publish" as this tells Docker what NAT publishing to automatically configure for you, and its why you cannot have more than one container using any one port (eg just a single container can be assigned Port 80).

So the four points above should highlight why a container is NOT a VM, and how it differs, but what if you want to have your container act like a VM/Virtual Appliance?

Whilst we do not recommend this, the information below may give you some guidance:

1) You CAN run more than one process at a time...

If you want to run something like Wordpress and MYSQL in the same container, you need something to act as PID1, and that something can start and manage the Wordpress and MYSQL processes. This "something" can be as simple as a bash script, that includes an indefinite loop, or a sleep. As you can see from the "Single container Wordpress" image example below (where it's trying to emulate a single VM), they have set a bash script "/run.sh" as their CMD, and that will start a supervisor process to operate as PID1, and then that supervisor starts all of the processes needed, and then sleep.

and you can see that supervisord is now PID1 by running a ps -ef

Now, what IS a supervisor process; it's just that, it's a binary/process that runs, stays running, and starts/keeps-alive other processes as defined by its configuration.

In the example above, it's starting MYSQLD and APACHE2 processes (these are what make up the MSQL app). You can see that by manually running ./supervisorctl from /usr/bin directory in the container console.. You can read more about [Supervisord here.](https://skarnet.org/software/s6/s6-supervise.html)

2) You can give your containers a real IP address if you need. Docker (but not Kubernetes) has this awesome network driver called MACVLAN, and basically its a Layer2 pass-through bridge, so that your container can operate on your real network directly. There are some complications here as containers cannot DHCP from your network DHCP server, and your docker host network must be allowed to enter into promiscous mode (most cloud providers explicitly block this, as do some hypervisors). But with MACVLAN your container can be directly routable. To use MACVLAN, you need to configure your Docker Host for it first. Portainer helps you with the process (go into networking, create a network, and select MACVLAN).

3) You can use background task schedulers, like CRON, but you must either make crond your CMD (PID1) or configure your supervisor process to also start crond.

4) Unfortunately there is NO way to make the entire contents of a container persistent, so you either need to manually specify multiple directories to be persisted, or ensure all of your configuration data is stored in a single place, and do not make changes to the container contents directly in the container console.

I hope this helps explain the difference between a container and a VM, and some potential workarounds to get your legacy VM app into a container if you need to do so with minimal changes.

Neil

Try Portainer with 3 Nodes Free

If you're ready to get started with Portainer Business, [3 nodes free](/take-3) is a great place to begin. If you'd prefer to [get in touch with us](https://www.portainer.io/contact-sales), we'd love to hear from you!

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/why-everyone-is-an-admin-is-a-bad-idea
title: Why 'everyone is an admin' is a bad idea for Kubernetes and Docker
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/why-everyone-is-an-admin-is-a-bad-idea
hostname: portainer.io
description: Learn how to secure your Kubernetes and Docker environments correctly with Portainer.
sitename: PORTAINER.IO
date: 2021-09-26
categories: []
tags: []
image: https://www.portainer.io/hubfs/Why%20everyone%20is%20an%20admin%20is%20a%20bad%20idea.png
pagetype: article
filedate: 2025-01-18
-->

Did you know, Docker and Kubernetes are, by default, insecure? It's a confrontational statement i know.. but let me explain what I mean by asking a few simple questions:

- How many of you have allowed your users to access your production Docker environment directly, either by providing TLS keys for Docker API remote access, or by letting them SSH onto the hosts directly?
- How many of you out there have deployed Kubernetes, and think it's "just easier" to share the KubeConfig file created during the deployment (cluster-admin) with your users?
- How many of you are aware of the inherent insecurity of containers and allow users to bind mount local directories, or run a container in privileged mode, or run containers as host PIDs, and what about letting them mount host devices into containers? Are you aware that by allowing these things to happen the containers your users deploy could give them access to the underlying host and all other containers?
- And in Portainer, how many of you have defined all your users as 'Admins'? how many of you use Admin accounts for day to day use? How many are still running with our "Internal Authentication" and allowing users to have simple passwords? how many of you have increased the session timeout so as to not prompt users to login daily?

The inconvenient truth is, 'too many. Engineering leaders are forced to make a conscious decision: do I focus on ease-of-use for my team, or do I focus on security? The reality is that in the majority of cases, ease-of-use wins out. There is, however, often a middle ground.

In this blog, i will quickly describe some of the issues that the above questions spring from, and why you really SHOULDNT do/allow any of these for your users.

Docker

Docker has no notion, whatsoever, of users or roles. With Docker (and Docker Swarm) you either have access to the environment, or you don't. If you have access, you have access to EVERYTHING. You can see every container, every volume, you can stop things, you can delete things, you can even purge (delete) all stopped containers and unused images. Letting all of your users have this level of access in a shared platform (here we are assuming a production environment, not private/local docker instances) is seriously dangerous and borderline negligent. The actions of one user could negatively impact the services managed by another, and that is simply unacceptable. Sure, you can work around this by having multiple clusters and segment your users to their own cluster, but that is hugely inefficient.

Kubernetes

Kubernetes, by default, is not configured with any external authentication, so also has no notion of users. To add users to Kubernetes either means adding them locally per cluster, or by installing an authentication plugin to synchronise user access from 3rd party sources. In addition, once you start adding users, you need to also define what those users can do, which is done with roles and role bindings and is really hard. It's all too common for IT to simply give out the primary cluster admin credentials in order to save the time/complexity associated with configuring users and roles. This, like the above with Docker, is insane.

Privileged Actions

Not many people know, but it would take only take a few seconds to completely compromise a Docker or Kubernetes environment that is not configured with the appropriate security policies. If all your users are Admins, these controls are impossible to enforce, so before you can even consider these risks, you must first address the first two.

If I wanted to gain access to a Container host, I simply need to deploy a container, bind mount the hosts / as /host in the container, and I'm off and running. I have access to the hosts root FS and can access anything and everything. Same goes with allowing users to deploy containers as host PIDs, when you do this, the container can access (and kill) all other processes running on the host, thereby destroying any process isolation. Same with allowing access to devices, there is nothing stopping a user from mapping the device /dev/sd1 into their container, and running fdisk and removing all partitions on that disk. These activities, whilst requiring malicious intent to be dangerous, should be blocked at all times, and only allowed for a specific reason, and under specific approvals.

Portainer Configuration

Portainer is designed to be used from the most simplistic home-lab deployment right through to large enterprise environments, so we leave a lot of configuration options up to the Portainer Admin to set up. If you, as the IT Admin, chose NOT to secure Portainer adequately you will get a platform that allows your users to do things they shouldn’t, either maliciously, or through an accident. That's bad.

So, what should you do?

Portainer has the notion of users, and users can be defined either as 'Admin' or 'Regular Users'. Admins have access to everything, deployed everywhere, and can do anything. Regular users have access only to environments they are authorised to manage, to create and manage deployments they create, or that are shared with them by other users.

As we have determined, you don't want everyone having access to everything, and as such, you really shouldn't have more than one or two Admins. Remember, if all users are Admins, then NONE of the Portainer security controls to limit privileged actions or manage access take effect.

When hackers are trying to gain access to a system, they often look for a way in as "Admin" as this makes their life so much simpler. Having too many users assigned the admin role is a recipe for disaster. Even admins should not login with their admin account on a day to day basis.. [Here is a great article](https://www.lbmc.com/blog/why-you-should-not-use-an-admin-account/) (external) that explains why this is important.

Please, please, please don't make all users Admins

If the Portainer CE Admin/User split is not granular enough for you, then we have RBAC capability in Portainer Business ([five nodes free](/take-5) or [paid](/pricing)) which allows you to have granular access control to who can do what.

For example, you may want to let some of your users have complete control over just one cluster, but not any others (we call this our "endpoint admin" role), or you may want some of your users to be able to see EVERYTHING across a cluster, but be read-only so as not be able to change anything (we call this our "helpdesk" role), maybe you want some users to be able to start/stop running containers, but not be able to create new or delete (thats our "operator" role).

These roles should not be seen as adding complexity, rather they should be seen as a way to correctly assign "principle of least permission" to your environment, because in all honesty, if everyone can do anything, how can you track/audit who does what?

Portainer has its own internal authentication, but its very limited and only designed for non-critical use cases. In critical/business environments, where you need password policies, lockout policies, or to enable multi-factor authentication, you should configure our external authentication, either against LDAP/AD, or by using our OAuth capability to link to your corporate directory. And yes, Portainer CE does let you configure OAuth to ANY provider, and no, we are not "forcing" you to buy Portainer Business for this feature. The "custom" OAuth provider lets you configure against anything. Portainer Business OAuth includes a "click to configure" UI element that makes configuring OAUTH a 2 minute task.

One other thing around authentication, we made a contentious decision to remove a feature we had (no-auth) which as its name implied, allowed you to run Portainer with NO authentication. We did so because many people abused this, and were therefore vulnerable to external compromise. In making this change, we added a new feature to help ease the transition, and that’s a "session lifetime", which defaults to 8 hours. This setting tells Portainer how long a logged in session can remain logged in; some users wanted to make this 1 year, and so we allowed this to be set by the admin, but in all honesty, for a control system like Portainer, we really do recommend against this, and ideally you have your system auto-logout every day (the default).

Always set the Portainer "per host/cluster" security controls (below), so you can remove privileged actions from your users. Unless there is a specific reason for them to use this capabilities, they should be removed.

Its crucial for IT governance and security to know who does what in Portainer, and that’s why, in Portainer Business, we added authentication and activity logs. The logging function records, in a read only journal, who logs in (and who tries but fails) to Portainer, and what activities they perform whilst logged in. This is crucial for IT governance, so for those of you that need this feature, give the Portainer Business free trial a go.

I hope this helps to clarify:

- why you need to secure your environment,
- the danger of all users having "admin" rights, and
- why you should use the security settings we provide in Portainer

Happy containering.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/author/neil-cresswell/page/9
title: Portainer News and Blog | Neil Cresswell, CEO (9)
author: Neil Cresswell; CEO August
url: https://www.portainer.io/blog/author/neil-cresswell
hostname: portainer.io
description: Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization. (9)
sitename: Portainer.io
date: 2021-08-28
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

### Blog Post by Neil Cresswell, CEO

[
](https://www.portainer.io/blog/how-to-manage-docker-kubernetes-concurrently-with-portainer-in-docker-desktop)

Neil Cresswell, CEOAugust 28, 20213 min read

### How To: Manage Docker & Kubernetes concurrently with Portainer in Docker Desktop

Use Portainer to manage both Docker and Kubernetes in your Docker Desktop environment

Start Reading
[
](https://www.portainer.io/blog/why-restricting-access-to-the-default-namespace-is-key-to-running-a-secure-kubernetes-environment)

Neil Cresswell, CEOAugust 22, 20213 min read

### Why restricting access to the default namespace is key to running a secure Kubernetes environment

Restricting access to the default namespace and using namespaces to manage resources is ...

Start Reading
[
](https://www.portainer.io/blog/containers-as-a-service)

Neil Cresswell, CEOAugust 19, 20214 min read

### Why you need Containers-as-a-Service for your Kubernetes environment

Containers-as-a-service is the difference between having a large Kube implementation and ...

Start Reading
[
](https://www.portainer.io/blog/rbac-for-kubernetes)

Neil Cresswell, CEOAugust 19, 20213 min read

### RBAC for Kubernetes. Why is it so hard to provide secure user access into Kubernetes?

RBAC for Kubernetes. How to remove the complexity and get RBAC for Kubernetes the easy ...

Start Reading
[
](https://www.portainer.io/blog/congratulations-to-forbes-rising-stars)

Neil Cresswell, CEOAugust 13, 20211 min read

### Congratulations to Forbes' rising stars.

Congratulations to Forbes' other rising stars in the 2021 list of cloud computing giants.

Start Reading
[
](https://www.portainer.io/blog/portainer.io-recognized-as-rising-star-in-forbes-2021-cloud-100-list)

Neil Cresswell, CEOAugust 10, 20212 min read

### Portainer.io recognized as 'rising star' in Forbes' 2021 CLOUD 100 list

Portainer recognized as rising star in Forbes' 2021 Cloud 100 ListForbe

Start Reading
[
](https://www.portainer.io/blog/portainer-your-docker-gui-for-your-ubuntu-linux-desktop)

Neil Cresswell, CEOAugust 6, 20212 min read

### Portainer, an awesome GUI if you run Docker on your Ubuntu Linux Desktop

Docker GUI for Ubuntu Linux

Start Reading
[
](https://www.portainer.io/blog/migrating-from-mirantis-to-portainer-business.-in-the-words-of-a-happy-portainer-business-customer)

Neil Cresswell, CEOJuly 14, 20215 min read

### Migrating from Mirantis to Portainer Business. In the words of a happy Portainer Business customer

Migrating from Mirantis to Portainer in the words of a very happy Portainer Business ...

Start Reading
[
](https://www.portainer.io/blog/stacks-docker-compose-the-portainer-way)

Neil Cresswell, CEOJuly 14, 20217 min read

### Stacks = docker-compose, the Portainer way

Learn how you can use Portainer and its stacks feature to use docker-compose files, as ...

Start Reading
[
](https://www.portainer.io/blog/portainer-vs-mirantis)

Neil Cresswell, CEOJuly 8, 20213 min read

### Portainer vs Mirantis: A Users Point of View in 2021

Compare Mirantis vs Portainer for container management. Discover the features, community, ...

Start Reading
[
](https://www.portainer.io/blog/portainer-versions-why-were-matching-the-agent-with-the-portainer-release)

Neil Cresswell, CEOJune 4, 20211 min read

### Portainer Versions - Why we're matching the Agent with the Portainer Release

Ready to upgrade Portainer? To make it easier to manage, we are matching the agent ...

Start Reading
[
](https://www.portainer.io/blog/portainer-on-microk8s-openebs-metallb-and-ingress)

Neil Cresswell, CEOMay 27, 20213 min read

### Portainer on MicroK8S + OpenEBS, MetalLB and Ingress

The blog post shows how to deploy Portainer on MicroK8s with OpenEBS and MetalLB with ...

Start Reading

---
<!--
URL: https://www.portainer.io/blog/why-are-stateful-containers-so-confusing
title: Why are stateful containers so confusing in Kubernetes?
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/why-are-stateful-containers-so-confusing
hostname: portainer.io
description: StatefulSets vs Deployments, when you should use each.
sitename: PORTAINER.IO
date: 2021-09-23
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Sep-23-2021-05-50-02-94-AM.png
pagetype: article
filedate: 2025-01-18
-->

The Portainer team spend a lot of time in online communities related to Kubernetes, and one of the most frequent questions we see relates to data persistence for apps.

There seems to be general confusion as to when you should use a Deployment with a PVC and when you should use a StatefulSet with a PVC. There is also a real lack of understanding when it comes to disk access policies, what RWO/RWX mean and what they allow you to do.

Let me try and explain what all this means.

First things first, both a Deployment with a PVC and a StatefulSet with a PVC **will** allow you to persist data for your container-based application. However, the decision as to which is best for your app comes down to a couple more things...

- does your application expect to have more than its disk state retained?
- does it need its hostname retained too?
- does the start-up and shutdown order of the replicas matter?

Perhaps an easier way of thinking about this is to ask yourself "was my app originally designed to run in its own VM with its own disk storage?", if the answer is 'yes', then its likely StatefulSet is a better choice for you.

With a Deployment, the corresponding Pods that get created have a hostname that matches the deployment name + a random system defined value, eg myapp-576cd55d5f-dwp8q.

Should the Pod be rescheduled on another node (due to node maintenance) or, if you update/redeploy the application, then the hostname will change. Can your application accommodate its hostname change?

If you have a Deployment with multiple replicas and these replicas start in a random order, can your application handle that, or does one pod need to start before another, and does the order they are stopped matter also?

If you have a Deployment with multiple replicas, do all of these replicas need to access the same underlying persistent volume, or do they each expect their own unique volume?

While we are here, let’s quickly talk about disk access policy, RWO/RWX (read write from a single pod or read/write from multiple pods) and the lesser used ROX (read only from multiple pods). These policies tell Kubernetes if you can create Deployments with multiple replicas using the SAME underlying persistent volume. Generally, this is a BAD idea unless you know what you are doing, as unless your application supports this, you can end up in a world of pain (think, last changed wins).

We regularly see questions from Kubernetes engineers asking, "my storage is NFS, so I set my access policy to RWX, but why can’t i get the MYSQL deployment to scale up to 3 replicas?". Well, it’s simple... sure, your storage driver allows you to present the same volume to multiple pods, but the application running within the pod (MySQL in this example) requires an exclusive lock on the files contained within the volume. The first pod starts, MySQL starts, and locks the DB file, the second pod starts, MySQL starts, and crashes as it is unable to open the DB file.

The real answer here is there is no way you can "share" a volume unless your app is designed to handle it, MySQL (and all other DBs out there) are NOT. You need to configure each with its own persistent volume and then configure DB replication (either multi-master, or master/worker).

When you get a more simplistic application, like NGINX or WordPress, you potentially can share a volume, as neither of these want to exclusively lock backend files, so these could be deployed as a deployment with multiple replica's and with persistence, but again, you need to be careful.

Generally, we would advise against using multi-replica deployments with persistence as you really need to know what you are doing in these types of setups.

OK, so back to Deployment with PVC or StatefulSet with PVC..

If you need Pods to have their own persistent volume, then use StatefulSets. Its just not worth the risk to see if your app supports concurrent writes, so dont guess.

If you need the pods that make up your application to have consistent, and predictable hostnames, then use StatefulSets. Hostnames for pods are ALWAYS <application name>-<numerical increment>. This does not change regardless of where they are rescheduled, or when they are redeployed

If you need the pods that make up your application to start in a specific order, then use StatefulSets. Pods are always started in their increment order (0,1,2,3,4,5...). Pod 1 will only start once pod 0 is online and ready.

If you need the pods that make up your application to stop in a specific order, then use StatefulSet. Pods are always stopped in the reverse increment order (5,4,3,2,1,0).

I hope this helps clarify when to use StatefulSets vs Deployments.

If you elect to deploy an application with persistence through Portainer we will DEFAULT to StatefulSet as the alternative can lead you to some very dark places unless you know exactly what you are doing.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/kubernetes-is-complex-scare-mongering-or-reality
title: Kubernetes is complex; scare-mongering or reality?
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/kubernetes-is-complex-scare-mongering-or-reality
hostname: portainer.io
description: Kubernetes is hard, but are we scare mongering unnecessarily.
sitename: PORTAINER.IO
date: 2021-09-09
categories: []
tags: []
pagetype: article
filedate: 2025-01-18
-->

We have recently seen some criticism about the wider Kubernetes dev-tools market using messaging such as "Kubernetes is complex" and how its trite and misleading...

Well, we tend to disagree, but not just because Portainer is likely one the very tools being criticising for harping on about the complexity of Kubernetes... but because Kubernetes IS complex, at least for many (if not most) people that are being made to use it.

Let me give my perspective.

- Kubernetes is not "follow your nose" it IS hard for someone nett-new to the technology; it takes time and patience to learn. How long? well that depends on the person, it could be 6 weeks, it could be 6 months".. how much do they need to learn? well that depends too, it could be very little, or it could be an extreme amount as the person needs to be a Swiss-army-knife inside their org, supporting everything.
- Don't forget, if you decide to embrace Kubernetes, there is also the need to learn all of the ancillary tools required to support the platform (Prometheus, Alert Manager, Graphana, Logging Systems, CICD tooling, container registries, service-meshes etc etc)... without these you are flying blind.
- If you don't have the luxury of time to get up to speed on all of this (your boss is telling you that they just bought this new core business application, which so happens to run on Kubernetes, can you get it into prod right now) then what do you do? Do you contract an external expert to do it? Do you do your very best and hope its done properly and securely, do you go hire a new member into your team with prior experience (if you can afford one), or do you say "sorry boss, i need a few months to learn the tech first"... either way, its not good
- What about when you outgrow doing simple stateless deployments of apps on a single cluster (likely using Helm), and enter the realm of managing multiple clusters, external authentication, RBAC roles, deploying stateful containers with persistent storage, load balancers, ingresses, quotas etc.. can you only embrace these more advanced technologies at the speed you and your team can learn them, or do you want to embrace them at a pace that makes sense for your organisation ? Ideally the latter, right?
- And what about when you want to mature into GitOps/DevOps paradigms, are you ready for that new learning curve? that takes Kubernetes to another level altogether..

This is where products like Portainer come into play.. the job of Portainer is to get your team up and running on this new technology NOW, with the skills they have NOW, and without exposing the organization to undue risk, or being forced to use expensive consultants or hiring new expert staff.

Portainer is not meant to STOP you learning, its there to bootstrap your knowledge and simplify your onboarding into this technology, until such a point as you master it sufficiently to start using native tools (and Portainer supports native tooling proxying through it, so your users can choose to either stay using Portainer's UI or transition to native tooling, or use a mix of both).

This is the value of products like Portainer, to take away the shock of the new tech, to help newbies get started quicker, with a lower barrier to adoption, and to help them learn good practices through embedded controls. At least, this is the ethos behind Portainer.

Is Portainer there yet with Kubernetes, no we are not, we are still building out our vision of simplicity, but we have now cemented our foundations for what's to come.. expect to see major innovations from us in the coming months.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-release-cadence-for-2021
title: Portainer release cadence for CE and Portainer Business in 2021
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-release-cadence-for-2021
hostname: portainer.io
description: Portainer Release Cadence for 2021
sitename: PORTAINER.IO
date: 2021-12-15
categories: []
tags: []
image: https://www.portainer.io/hubfs/reelase_cadence_2021.png
pagetype: article
filedate: 2025-01-18
-->

Please note that this blog is now out of date.

With 2020 now drawing to a close, we are wanting to advise the community on our release plans for both Portainer Community (CE) and Portainer Business (PB) for 2021.

Its fair to say that the historical release cadence for Portainer CE has been somewhat random, and this was predominately related to the fact that we had grand aspirations that were at times grander than the size of our development team. This meant we chose to have larger gaps between releases so as to fit in more features.

Now that our team is growing, we are able to lock in a more predictable cadence and will have a relatively simple and transparent approach to feature additions vs bug fixes. Moving forward, “dot” releases of Portainer CE will contain only bug fixes and “non-breaking” trivial new features.

Major releases will occur every two months, and will contain both new features and bug fixes, some of which may introduce breaking changes. Regardless, every month we will be releasing a new version of Portainer CE. Release will be targeted on or around the second to last day of each month.

For Portainer Business (PB), we need a slightly longer release cycle due to the increased depth of testing we have committed to our business users. There will be a major release once every 4 months, and a “dot” release midway between the major releases. The dot releases for BE will ONLY include bug fixes; there will be NO new features added in the mid-releases. The upgrade to a “dot” release is only recommended if you have a bug that has been fixed, or if we recommend you upgrade due to a security issue. Release will be targeted on or around the last day of the first week of the month of release.

You will note that the release numbering for Portainer Business differs from Portainer CE, and that is because whilst Business is derived off CE, it runs a different development cycle. Portainer PB 2.2 may contain some features from CE 2.3 or CE 2.3.1 as we determine applicability.

We hope this new release schedule will assist with your internal planning, and as always, I'm happy to take questions.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-2.9-takes-kubernetes-mainstream-with-gui-templates-and-api
title: Portainer 2.9 Takes Kubernetes Mainstream with GUI, Templates, and API
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-2.9-takes-kubernetes-mainstream-with-gui-templates-and-api
hostname: portainer.io
description: Portainer CE version 2.9 brings Kubernetes to the mainstream with a host of new features, including dark mode.
sitename: PORTAINER.IO
date: 2021-10-12
categories: []
tags: []
image: https://www.portainer.io/hubfs/undefined-Oct-06-2021-10-24-09-95-PM.png
pagetype: article
filedate: 2025-01-18
-->

**October 12, Los Angeles, CA** — Portainer.io today announced the release of the latest version of its Portainer Community Edition (CE) open-source container management tool, making Kubernetes accessible to everyone for the first time. Version 2.9 includes a much-requested DarkMode, support for HTTPS mode, and lightweight Gitops with webhooks support, as well as Kubernetes-specific enhancements, including custom templates, support for HELM, and better support for registries.

Portainer.io CEO Neil Cresswell said, “Kubernetes is so rich in functionality that it overwhelms most users. It can do so many things, many of which simply aren’t necessary for everyday usage. This new version of Portainer makes it easy for users to see what’s important and get apps up and running in production without getting caught in an endless trial and error loop.”

He continues, “Four years ago we did exactly this for Docker. Kubernetes has won out as the orchestrator of choice, so it’s natural for us to do what we did for Docker, for Kube. I’m incredibly proud of what the team has achieved. We really have succeeded in making Kubernetes accessible to anyone with a basic understanding of containers.”

The new release allows Kubernetes Platform Managers, as well as end users (typically developers), to accomplish a huge range of tasks without having to know how to use the CLI or write YAML. The Portainer GUI has been redesigned to align with Kubernetes workflows and logic and is now smoother and more elegant. The in-built logic (expert defaults) which made Portainer so popular in the Docker world have been updated to make Kubernetes sing.

With Portainer, Kubernetes can now be configured and used by anyone, for free. The new release is available to download today and is being showcased at KubeCon North America (Booth S90).

Portainer CE version 2.9 brings with it four significant enhancements:

- Enables users with a rudimentary understanding of Kube to be able to pick up and deploy complex applications quickly and easily using HELM or community created manifest files.
- Enables cluster administrators to configure the Kube cluster with mandatory quotas, applying sane secure defaults (such as disabling access to default namespace, disabling resource over-commit), and enabling disabling the use of external load balancers and storage classes.
- Enables platform managers to set up centralized Identity and Access management, including external authentication and RBAC for multi-cluster environments.
- Incorporates a Kubernetes compatible API which allows organizations to connect third-party deployment tools and dashboards, such as Jenkins, Headlamp and Lens, to their clusters via the Portainer platform, giving them full RBAC/policy control over their environments, and removing the need to expose their cluster APIs externally.

Portainer CE 2.9 is available for free immediately. Visit [www.portainer.io](//www.portainer.io) to learn more.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-statement-re-log4j-cve-2021-44228
title: Portainer statement re Log4J CVE-2021-44228
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-statement-re-log4j-cve-2021-44228
hostname: portainer.io
description: Portainer response to CVE-2021-44228
sitename: PORTAINER.IO
date: 2021-12-14
categories: []
tags: []
pagetype: article
filedate: 2025-01-18
-->

You will no doubt be aware of the recent Log4j RCE 0-day vulnerability being actively exploited in systems and services that use the Java logging library, Apache Log4j between versions 2.0 and 2.14.1 (CVE-2021-44228).

This message is to advise you we have actively checked our code and dependencies, and can confirm we have no exposure to log4j vulnerability in any element of Portainer nor our software supply chain. Portainer does not use the Java language in our development, and so are not vulnerable to this CVE.

We will continue to monitor the situation but wanted to let you know that Portainer is safe and sound.

Please feel free to get in touch if you have any concerns or further questions.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/container-service-delivery-platforms-to-build-or-to-buy-and-why-thats-not-really-a-question
title: Container service delivery platforms - to build or to buy? And why that’s not really a question
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/container-service-delivery-platforms-to-build-or-to-buy-and-why-thats-not-really-a-question
hostname: portainer.io
description: Learn why you should consider deploying Portainer as your service delivery platform rather than building your own solution from best-of-breed providers.
sitename: PORTAINER.IO
date: 2021-11-29
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Nov-29-2021-03-12-01-01-AM.png
pagetype: article
filedate: 2025-01-18
-->

In the [first part of this blog series](/blog/why-kubernetes-should-be-like-a-vending-machine), I argued organizations looking to deploy containers at scale need to remove IT Ops from the developer experience and put a self-service environment in place that allows developers to deploy apps into containers whenever they want, however they want. I likened the idea to that of a vending machine, which is the purest expression of ‘self-service’ I can think of.

In this blog I explore the different elements that make up a self-service container management platform, which we, at Portainer, now call a ‘Container Service Delivery Platform’ and look at the classic ‘build v’s buy’ paradox.

At the most basic level, a Service Delivery Platform needs to do 4 things:

- Allow end users to deploy (and update) applications unaided, in a manner that suits their experience and knowledge,
- Allow end users to monitor and troubleshoot their application,
- Allow admins to set the rules within which the end users can operate,
- Overlay a governance layer that protects the platform for rogue agents.

And of course, ideally it should be able to do this across any hosting environment and across any orchestrator – otherwise it’s lock-in central.

Now, with enough developer time, you can build all of this yourself with scripts, various open-source tools, and a whole heap of labor. But unless building infrastructure platforms is your thing, why would you? Wouldn’t you be better off focusing your team’s efforts on building software that helps drive your business forward?

A few years back, there was no “out of the box” tooling that made Kubernetes self-service capable, however in a CNCF year, a lot has changed. Now there are any number of tools, like Portainer, that can be deployed in minutes which negate the need for you to spend months building your own.

To help make my point, look at the diagram below. To deliver a container management platform, you need at least 6 different components.

- The tooling to remotely manage the container hosts that underpin the platform
- The tooling required to build, update, and triage the container orchestrator/cluster
- The tooling to provide secure and govern the platform
- The tooling that provides the self-service portal that the end users need
- The tooling that provides the observability that the end users, and operations, both need
- And finally, the integration APIs that allow the platform to inter-connect with external tooling/services

Again, this can all be built in-house using an array of “best-of-breed” tools, most of which likely possess capability far in excess of anything you actually need.

Here’s as an example of a “self-rolled” architecture:

- Terraform / Ansible scripts can be created to manage the deployment of container engine nodes and/or deploy a Kubernetes as a Service offering from Cloud providers
- KubeADM, KubeSpray (or other similar tools such as Kops, Sidero, Charmed Kubernetes, or even Rancher) can be used to create and manage the build of a self-built Kubernetes Cluster.
- Prometheus and Grafana (or Datadog, Dynatrace etc) can be used to help operations teams monitor, manage, and triage the platform,
- ELK or Loki (or Splunk, Graylog etc) can be used for log analytics,
- KeyCloak, StrongDM, Okta or Auth0 can be used to federate authentication,
- OpenPolicy Agent to control what actions can be performed,
- Kubernetes RBAC to ensure Devs can only complete allowed tasks,
- Integration with an internal service management tool (such as ServiceNow or even github PRs) to deliver
[developer self-service](/developer-self-service)capability. - Any DevOps/GitOps tooling, such as ArgoCD or Flux to provide code release automation.

Alternatively, there is Portainer.

Portainer is designed as a “T-shaped” platform tool (to align with T-shaped engineers), which means it is capable across a range of functionality, but expert in a few. **In our case, we are expert at environment management, and highly capable across everything else. **

By deploying Portainer you negate the need to deploy a lot of additional 3rd party complicated tooling just to get started. Portainer lets you get started today.

Obviously, there will be times when you need the capability only an expert specialist tool provides, and with Portainer’s integration API, this is easy to do. You can either transparently deploy tools directly into the clusters already managed by Portainer, or you can connect Kubernetes native tools TO Portainer, and we will manage the communications to the underlying environment for you. We call this “growing with you”.

So, if you want to get started with Containers in general or delve into the world of Kubernetes, Portainer is the only place to start.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/talking-stateful-kubernetes-neil-cresswell-interviewed-on-the-cncf-data-for-kubernetes
title: Persistent Disk or StatefulSet? The right way and the wrong way to make apps persist state inside a K8s cluster- Neil Cresswell Interviewed on the CNCF 'Data for Kubernetes
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/talking-stateful-kubernetes-neil-cresswell-interviewed-on-the-cncf-data-for-kubernetes
hostname: portainer.io
description: From this talk delegates will learn the difference between persistent disk and StatefulSet. They will learn when to use each (and when not to) and what are the pitfalls they should be aware of when deploying multi replica apps. They will also learn what is disk access policy, what is RWO and how RWX disk access changes the equation in regards to persistence
sitename: PORTAINER.IO
date: 2021-11-01
categories: []
tags: []
image: https://www.portainer.io/hubfs/Kubernetes-NeilCresswell%202.png
pagetype: article
filedate: 2025-01-18
-->

Portainer CEO Neil Cresswell joined the Data for Kubernetes Livestream and Podcast last week to discuss working with persistent states inside of Kubernetes.

Watch the full [interview here](https://www.youtube.com/watch?v=mDDHiQSRdFo) or listen via [Anchor podcasts](https://anchor.fm/dokcommunity/episodes/DoK-Talks-96--Persistent-Disk-or-StatefulSet--The-right-way-and-the-wrong-way-to-make-apps-persist-state-inside-a-K8s-cluster--Neil-Cresswell-e19d9s0). While you're here check out this incredible drawing/note taking from a member of the [DOK community](https://dok.community/) below.

ABSTRACT OF THE TALK

There is confusion amongst Kubernetes users as to when you should make a Deployment with a PVC and when you should use a StatefulSet with a PVC. There is also a general lack of understanding when it comes to disk access policies, what RWO/RWX mean and what they allow you to do. These concepts are complicated and require a deep level of understanding in order to avoid users making bad decisions that they come to regret later.

In this talk we will explore when you should use each type and what things you need to think about before making a decision. We'll also explore in detail how to safely deploy a multi-replica application with persistence using Portainer.

As part of the talk we will explore disk access policy, understand what RWO really is and how RWX disk access changes the equation in regards to persistence.

TAKE-AWAYS

From this talk delegates will learn the difference between persistent disk and StatefulSet. They will learn when to use each (and when not to) and what are the pitfalls they should be aware of when deploying multi replica apps. They will also learn what is disk access policy, what is RWO and how RWX disk access changes the equation in regards to persistence

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/2.7.0-release
title: New Portainer Business 2.7.0 Release - now with support to pull and redeploy a Docker stack from Git, Kubernetes app deployment from Git and Group membership mapping from OAuth.
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/2.7.0-release
hostname: portainer.io
description: Check out our latest release, Portainer Business 2.7.0. Now with support to pull and redeploy a Docker stack or Kubernetes app deployment from Git.
sitename: PORTAINER.IO
date: 2021-07-30
categories: []
tags: []
image: https://www.portainer.io/hubfs/undefined-Jul-30-2021-02-18-13-02-AM.png
pagetype: article
filedate: 2025-01-18
-->

Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our [Portainer Features page](/features)*. *

Today, we have released Portainer Business 2.7.o. This new release comes with several features and fixes addressing feedback and enhancement requests, including the ability to deploy a manifest from a git repository for Docker and Kubernetes.

We've highlighted the most significant changes below, and at the end of the blog post, you'll find a link to our tips and tricks for upgrading, as well as the release notes.

**Deploy a manifest from a git repository for Docker and Kubernetes**

This brings the ability to deploy a docker-compose or YAML Manifest from a git repository when using Stacks deployment on Docker or Advanced Application deployment with Kubernetes. This is specially useful if you use a Git server to store deployment Manifests.**Group membership mapping from OAuth**Discover how you can easily manage access control in Portainer when you have a large number of users and you're using OAuth.**Summary of the Kubernetes actions**

Portainer will now generate a*Summary*block with all the actions and changes being applied to a Kubernetes endpoint. So before confirming an action on the Kubernetes cluster like for instance deploying an Application or creating a Namespace via the Summary tab you have cleary each step that will be performed by Portainer.**Advanced deployment available for all users**

Previously Advanced Deployment was only available to Endpoint Administrators. Now with this new feature Standard Users also have access the Advanced Deployment option in Portainer when deploying applications:**Real-time container and node performance**

You can now monitor in real-time the performance of your Pods and Nodes in your Kubernetes cluster with a graphical representation of hardware resources that these components are using.**Rename the “Resource pools” to Namespaces**

Previously namespaces were created using the Resource Pool option that could cause some confusion. We decided to change this to the standard Namespace Kubernetes nomenclature for clarity.**Single Sign-on support for OAuth with the ability to skip the Authentication Prompt.**

Portainer 2.7.0 has support for SSO on the OAuth authentication method. You can now configure SSO with your favorite provider (GitHub for example) and seamlessly login into your Portainer instance. With this you don’t have to provide a password with Portainer if your OAuth session is still valid.**Proget Registry support**

Portainer 2.7.0 now supports adding Inedo Proget Private Registry so you can deploy private images via Portainer easily with this new integration.

We would like to thank all of our business customers and community members that help us improve **Portainer**. We are continuously open to suggestions and enhancements.

**Tips and tricks for Upgrading**

See upgrade instructions for Docker, Docker Swarm and Kubernetes [here](https://documentation.portainer.io/upgrade/).

Any questions or comments, don't hesitate to drop me a line. Or join our [Slack channel](https://portainer.slack.com/join/shared_invite/enQtNDk3ODQ5MjI2MjI4LTcwNGYxMWQ5OGViYWZkNDY2ZjY4YTMwMTgzYmU4YmNiOTU0MDcxYmJjNTIyYmQ0MTM5Y2QwNTg3NzNkMTk5MDg#/) here.

See for yourself, with a demo or free trial

Let us introduce you to a world of fast and easy app deployment, governance, and management in Docker/Swarm and Kubernetes. Join a group demo to see how Portainer Business helps to make Engineering and DevOps teams more accurate and efficient in container management.

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/2.9.1-release
title: New Portainer CE 2.9.1 Release - now with support for Dark Mode, HTTPS, HELM and Kube Proxy
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/2.9.1-release
hostname: portainer.io
description: Portainer Community Edition Open Source Docker Kubernetes Update Upgrade RBAC Helm Security HTTPS
sitename: PORTAINER.IO
date: 2021-10-10
categories: []
tags: []
image: https://www.portainer.io/hubfs/undefined-Oct-06-2021-10-24-09-95-PM.png
pagetype: article
filedate: 2025-01-18
-->

**Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our Portainer Features page . **

**2.9.1 Portainer Community Edition Release**

This is a significant release that builds on 2.9 with a number of new features and enhancements for Kubernetes in particular..

**Improved UI**

Let's start with the new UI which has been redesigned to reduce clutter and is now more intuitive. It is now much easier to navigate inside Portainer and Kubernetes users should start to feel more at home.**Kubectl Shell**

We've integrated Kubectl into Portainer natively to help users troubleshoot Kubernetes applications without having to leave the Portainer UI, This also allows expert users to use advanced Kubernetes features and functions not yet supported inside Portainer.**Portainer as a proxy for third-party container environments**

We’ve introduced the ability for Portainer to be used as a secured authenticated proxy into third-party container environments in CE 2.9.1. This allows Platform and DevOps engineers to integrate Portainer seamlessly with third-party CI/CD tools and build secure, end-to-end automated delivery workflows.

The new API proxy also allows Portainer users to retrieve the configuration files they need to connect the deployment/observability tools they like while reflecting the access and permissions set by their administrator. This unlocks a new 'Bring Your Own Tool' paradigm that we're particularly excited about.**Lightweight GitOps**

We’re continuing the work we started in CE 2.6 around deploying applications from Git and bringing more controls (manual and automated) to the application deployment process..

With CE 2.9.1, we’ve introduced a lightweight GitOps engine that enables users to employ 'entry level' CD automation without needing to be an expert in the area. The functionality allows a user to configure automatic updates for their application, poll-based (with Portainer polling for changes at a specific interval) or push-based (via webhooks).**Helm Charts support**

In CE 2.9,1 we've bought an easy way for the DevOps and Platform teams to deploy software provided by their ISV or any tool vendor inside a Kubernetes environment.

By supporting Helm, which is the de-facto packaging system for applications on Kubernetes, we allow users to easily register application repositories inside Portainer and deploy any application listed under these repositories.**Custom Templates**

We’ve bought a custom template feature for more convenience when it comes to share and re-use application manifests across Kubernetes environments. This will enable advanced Kubernetes users to create application packages they will be able to share with their less Kubernetes savvy teammates.**Private registry support for Kubernetes**

Here we’ve bought a long-time missing feature for Kubernetes, allowing users to deploy applications that are hosted on any private registry supported by Portainer.

This also introduces a revamp of the registry access management experience to make it more consistent across Docker and Kubernetes.**HTTPS support**

As most administration tools are exposed over HTTPS by default and with the massive number of Portainer instances exposed over the Internet, support for HTTPS was long due for Portainer. HTTPS support goes hand in hand with our container environment proxy to make sure that communications between any 3rd party or external tools and Portainer are secured.**Removal of 'Advanced Mode'**

** 10. Dark Mode**

And last but not least....one of the Portainer community's most requested features: dark mode for Portainer. We’re bringing support for user themes that can be set by each user through their account settings. In this release, Portainer will ship with experimental support for a dark theme and a high-contrast theme.

See for yourself, with a demo or free trial

Let us introduce you to a world of fast and easy app deployment, governance, and management in Kubernetes or Docker/Swarm. Request a trial or join a group demo to see how Portainer Business helps to make Engineering and DevOps teams more accurate and efficient in container management.

Find the release notes for 2.9.1 [here](https://github.com/portainer/portainer/releases/tag/2.9.1):

Find the documentation for 2.9.1 [here](https://docs.portainer.io/v/ce-2.9/)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/restore-portainer-k8s-running-the-api
title: How to Restore a Portainer instance running on Kubernetes using the API
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/restore-portainer-k8s-running-the-api
hostname: portainer.io
description: How to Restore a Portainer instance running on Kubernetes using the API
sitename: PORTAINER.IO
date: 2024-02-29
categories: []
tags: []
image: https://www.portainer.io/hubfs/Internet%20Technology%20Business.jpg
pagetype: blogposting
filedate: 2025-01-18
-->

If you want to understand the ease and speed of restoring a Portainer instance on a Kubernetes cluster using the Portainer API, then this post is for you. This post will demonstrate via a simple script called portainer_hb.sh and the Portainer API to restore a Portainer Instance: A Simple, Fast, and Efficient Process.

The magic of Portainer lies in its simplicity. This bash script checks if the main Portainer server is up and running. The script accomplishes this task by executing an API call that doesn't require authorization. If no response matches the standard pattern of an API call, the script takes the initiative and deploys a new Portainer instance. Post-deployment, it restores a backup from an S3-compatible server—in our case, MinIO.

#### Pre-reqs

For this blog, the main pre-requisites are:

- Portainer is backing up to an S3 bucket
- Portainer is running on Kubernetes
- Make sure your Portainer instance is accessible via a FQDN.

*After the restore process, your new Portainer instance IP address has to be updated on your DNS server to ensure no disruption of services. This is especially important if you have Endpoints connected to Portainer via Edge Agents.*## Backing up to S3

The backup process to S3 in Portainer is simple and powerful. You can follow our documentation page, [Backing up to S3](https://docs.portainer.io/admin/settings#backing-up-to-s3). which explains how to perform S3 bucket backups on any S3-compatible server like Amazon, Wasabi, MinIO, etc.

### The portainer_hb.sh script

#### Is it alive?

Let's start with checking if the main Portainer server is alive. This is a simple 'ping' using an HTTP call with `curl`

that; depending on the response, we can determine if Portainer is up or not. The ping interval is 5 seconds. If Portainer goes down, the script carries on to the next steps. Otherwise, it'll stay on an endless loop.

```

## Check if the main Portainer server is running using an API call. An 'Unauthorized' reply means it is. No authentication is needed.

while true
do
portainer_up=`curl --silent --insecure -X GET | jq -r '.details'`
if [ "$portainer_up" = "Unauthorized" ]; then
echo -ne '⚡ Portainer is up\\r'
else
break
fi
sleep 5
done
```

#### Create a new instance of Portainer on the secondary site

The following step of the process deploys a Portainer server on Kubernetes if the main server goes down. The publishing method adopted for the Portainer deployment is NodePort. For more details, you can check our documentation page, [Install Portainer BE on your Kubernetes environment](https://docs.portainer.io/start/install/server/kubernetes/baremetal).

```

## Deploy a new Portainer instance

kubectl apply -n portainer -f
echo
echo 'Deploying Portainer server'
echo
```

##### Is the Portainer running?

This step makes sure the Portainer server is running correctly on the Kubernetes cluster before starting the restore process.

```

## Check if Portainer is running before applying the restore

while true
do
portainer_running=`kubectl get po -n portainer | tail -1 | awk '{print $3}'`
if [ "$portainer_running" != "Running" ]; then
echo -ne ' ⚡ Portainer is Not Running yet\\r'
else
break
fi
sleep 1
done
```

#### Restoring the main Portainer server from an S3 bucket

Now that Portainer is up and running, it is ready to be deployed with a backup file stored in an S3 bucket. Ensuring the variables below are set correctly in this next step is crucial. These are:

- ACCESSKEYID
- This is the access key for your S3 bucket

- BUCKETNAME
- This is the bucket name where your backup of Portainer is stored

- FILENAME
- For example, this is the file name you'd like to use to restore Portainer.
`portainer-backup_2024-02-27_00-55-00.tar.gz`

- For example, this is the file name you'd like to use to restore Portainer.
- FILEPASSWORD
- If you defined a password for your backup file, make sure to place it here

- REGION
- This is the region where your S3 server is located, for example,
**us-east-1**

- This is the region where your S3 server is located, for example,
- SERVER:PORT
- This is the hostname or IP address of the S3 bucket server along with the port where it is running, for example,
**192.168.10.45:9001**

- This is the hostname or IP address of the S3 bucket server along with the port where it is running, for example,
- SECRETKEY
- Finally, this is the password that enables access to the S3 bucket server

*Change the variables above in the script to match your setup. Once the restore process finishes, remap the IP address of the secondary Portainer server to the original FQDN.*

```

## Restore the Portainer backup from an S3 bucket

echo
echo 'Restoring Portainer backup'
ACCESSKEYID="portainer"
BUCKETNAME="portainerbkp"
FILENAME="portainer-backup_2024-02-27_00-55-00.tar.gz"
FILEPASSWORD="restore1234"
REGION="us-east-1"
SERVER="s3server.example.com"
PORT="9001"
SECRETKEY="changeme"
curl -X POST \\
--insecure \\
--header 'Content-Type: application/json' \\
--url '' \\
--data '{"accessKeyID": "$ACCESSKEYID", "bucketName": "$BUCKETNAME", "filename": "$FILENAME$", "password": "$FILEPASSWORD", "region": "us-east-1", "s3CompatibleHost": ":$PORT", "secretAccessKey": "$SECRETKEY"}'
echo
echo 'Portainer restored'
```

##### The Complete Script

```

## Check if the main Portainer server is running using an API call. An 'Unauthorized' reply means it is. No authentication is needed.

while true
do
portainer_up=`curl --silent --insecure -X GET | jq -r '.details'`
if [ "$portainer_up" = "Unauthorized" ]; then
echo -ne '⚡ Portainer is up\\r'
else
break
fi
sleep 5
done

## Deploy a new Portainer instance

kubectl apply -n portainer -f
echo
echo 'Deploying Portainer server'
echo

## Check if Portainer is running before applying the restore

while true
do
portainer_running=`kubectl get po -n portainer | tail -1 | awk '{print $3}'`
if [ "$portainer_running" != "Running" ]; then
echo -ne ' ⚡ Portainer is Not Running yet\\r'
else
break
fi
sleep 1
done

## Restore the Portainer backup from an S3 bucket

sleep 5
echo
echo 'Restoring Portainer backup'
ACCESSKEYID="portainer"
BUCKETNAME="portainerbkp"
FILENAME="portainer-backup_2024-02-27_00-55-00.tar.gz"
FILEPASSWORD="restore1234"
REGION="us-east-1"
SERVER="s3server.example.com"
PORT="9001"
SECRETKEY="changeme"
curl -X POST \\
--insecure \\
--header 'Content-Type: application/json' \\
--url '' \\
--data '{"accessKeyID": "$ACCESSKEYID", "bucketName": "$BUCKETNAME", "filename": "$FILENAME$", "password": "$FILEPASSWORD", "region": "us-east-1", "s3CompatibleHost": ":$PORT", "secretAccessKey": "$SECRETKEY"}'
echo
echo 'Portainer restored'
```

What makes this process genuinely remarkable is continuity. The restore process carries across all of the pre-configured settings of Portainer, ensuring no disruption when the application is redeployed on the backup Kubernetes cluster. In a real-world production environment, this would include all aspects like endpoints, registry settings, and authentication, among others, configured on the Portainer server. The implication here is clear – there are minimal interruptions to your operations.

To provide a more precise and more practical understanding, below is a video demonstrating the automated restore process. In this example, we used the `portainer_hb.sh`

bash script.

In the video, the main Portainer server runs on IP address 192.168.10.171, while the backup operates on IP address 192.168.10.176. The MinIO S3 server, tasked with storing the backups, runs on IP address 192.168.10.1.

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/how-to-run-portainer-behind-a-wireguard-vpn
title: How-To run Portainer behind a Wireguard VPN
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/how-to-run-portainer-behind-a-wireguard-vpn
hostname: portainer.io
description: How-To run Portainer behind a Wireguard VPN
sitename: PORTAINER.IO
date: 2021-09-29
categories: []
tags: []
image: https://www.portainer.io/hubfs/How-To%20run%20Portainer%20behind%20a%20Wireguard%20VPN.png
pagetype: article
filedate: 2025-01-18
-->

**How-To run Portainer behind a Wireguard VPN**

In this blog post you will learn how to **Portainer** behind a Wireguard VPN. This will be based on a point-to-point connection between two machines. You can also watch this how-to as a video below.

**Pre-reqs**

- A
*server*machine that will either have a fixed IP or a DDNS hostname where Portainer is running - If the machine running Portainer is running on a cloud-base virtual, access to the network security console in order to be able to open UDP port 51820
- If the machine running Portainer is on-prem, admin access to the operating system in order to be able to open UDP port 51820
- Wireguard installed on the host running Portainer and a second host that will connect via the VPN. Please refer to
[https://www.wireguard.com/install/](https://www.wireguard.com/install/)on how to install Wireguard.

#### Prepare the Portainer machine

- The first step is to generate the wireguard keys for both the main host and the client host that will connect to Portainer via the VPN by running the following:
`wg genkey | tee srv.privatekey | wg pubkey > srv.publickey`

We will use these on the*Portainer*host`wg genkey | tee clt.privatekey | wg pubkey > clt.publickey`

We will use these on the*client*host

- After running the key generation commands above you can continue by running the following commands on the host running Portainer.
**Please make sure to copy&paste the entire code block below**:

`server_priv=`cat srv.privatekey``

server_publ=`cat srv.publickey`

client_priv=`cat clt.privatekey`

client_publ=`cat clt.publickey`

cat <<EOF> server.conf

[Interface]

## Name: server

Address = 192.168.10.10/24

PrivateKey = $server_priv

ListenPort = 51820

[Peer]

## Name: client

PublicKey = $client_publ

AllowedIPs = 192.168.10.11/32

EOF

cat <<EOF> client.conf

[Interface]

## Name: client

PrivateKey = $client_priv

Address = 192.168.10.11/24

[Peer]

## Name: server

PublicKey = $server_publ

EndPoint = [SERVER IP]:51820

AllowedIPs = 192.168.10.10/32, 192.168.10.0/24

PersistentKeepalive = 25

EOF

rm *.privatekey

rm *.publickey

This script will generate two wiregaurd configuration the base files that will be used by the wireguard clients to connect to each other:

- server.conf - make sure to replace
**[SERVER IP]**with the hostname or IP of the host that is running Portainer - client.conf - there is no need to change anything on this file

The VPN subnet chosen for this example is 192.168.10.0

#### Wireguard configuration

- On the Portainer host install wireguard according to the linux version you are running. Please following the instructions on the Wireguard documentation page:
[https://www.wireguard.com/install/](https://www.wireguard.com/install/) - Move/Copy the
**server.conf**file to the**/etc/wireguard**folder. - On the client host move/copy the
**client.conf**file to the same**/etc/wireguard**folder if it is a linux machine or use the**Import**option if you are running Wireguard on MacOS or Windows.

#### Start Wireguard and access Portainer

- On the Portainer host you can start wireguard by running:
`wg-quick up server`

- On the client host you can start wireguard by running:
`wg-quick up client`

if it is a linux machine or use the corresponding Activate option on MacOS/Windows clients.

You should be able to ping from the client host the Portainer machine by running`ping 192.168.10.10`

- Finally you can open your browser on the client machine using the following address:
[https://192.168.10.10:9000](https://192.168.10.10:9000)- if you deployed Portainer on Docker or[https://192.168.10.10:30777](https://192.168.10.10:30777)- if you deployed Portainer on Kubernetes

See for yourself, with a demo or free trial

Let us introduce you to a world of fast and easy app deployment, governance, and management in Docker/Swarm and Kubernetes. Join a [group ](/cs/c/?cta_guid=470f4e07-4b3f-4aeb-a46e-170652130c1c&signature=AAH58kGTR-0Mfc_4_pR2qHe4wpKAPYU5tA&pageId=35556045556&placement_guid=3208c32b-0a64-4902-94bc-008cdee13feb&click=565ceb1c-ea2b-4eb8-be0b-662a68511e6b&hsutk=381ab94f13bd88bff0428d99baabeefa&canon=https%3A%2F%2Fwww.portainer.io%2Ffree-trial&utm_referrer=https%3A%2F%2Fwww.portainer.io%2Fblog%2Frbac-for-kubernetes&portal_id=4731999&redirect_url=APefjpEKKtwXn5Yo3j0NxpLoIm1D4HFX2y-TV2BbS0-qXjdg82eDpRK0orn6c2K-0F6g6etL-VrIJFxpqmQ5SccrNFtNTHIBdAtsmkrCHs8-WSaROonx2vuL48e7TKabBGnIIJbhelxTGzN0FC7o479kK_F7c8z8amJ_eayUsFf1Gf9X6_UilB7muthj48yz1EzKCa03v_STlCRFsgiMHXBGk--0JNoQ7YrRqygk2BQP5a9PrTw0vsM7Q8sKvP-IdCCZGo_1kbq06KykZxIb-kZ9vIpp4RUlIS1N6r1R5DQmUgia_YM7lpE&__hstc=146943656.381ab94f13bd88bff0428d99baabeefa.1632160309475.1632947859881.1632955013749.15&__hssc=146943656.15.1632955013749&__hsfp=658372124&contentType=standard-page)[demo](/cs/c/?cta_guid=470f4e07-4b3f-4aeb-a46e-170652130c1c&signature=AAH58kGTR-0Mfc_4_pR2qHe4wpKAPYU5tA&pageId=35556045556&placement_guid=3208c32b-0a64-4902-94bc-008cdee13feb&click=565ceb1c-ea2b-4eb8-be0b-662a68511e6b&hsutk=381ab94f13bd88bff0428d99baabeefa&canon=https%3A%2F%2Fwww.portainer.io%2Ffree-trial&utm_referrer=https%3A%2F%2Fwww.portainer.io%2Fblog%2Frbac-for-kubernetes&portal_id=4731999&redirect_url=APefjpEKKtwXn5Yo3j0NxpLoIm1D4HFX2y-TV2BbS0-qXjdg82eDpRK0orn6c2K-0F6g6etL-VrIJFxpqmQ5SccrNFtNTHIBdAtsmkrCHs8-WSaROonx2vuL48e7TKabBGnIIJbhelxTGzN0FC7o479kK_F7c8z8amJ_eayUsFf1Gf9X6_UilB7muthj48yz1EzKCa03v_STlCRFsgiMHXBGk--0JNoQ7YrRqygk2BQP5a9PrTw0vsM7Q8sKvP-IdCCZGo_1kbq06KykZxIb-kZ9vIpp4RUlIS1N6r1R5DQmUgia_YM7lpE&__hstc=146943656.381ab94f13bd88bff0428d99baabeefa.1632160309475.1632947859881.1632955013749.15&__hssc=146943656.15.1632955013749&__hsfp=658372124&contentType=standard-page) to see how Portainer Business helps to make Engineering and DevOps teams more accurate and efficient in container management.

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-business-charm-launched-for-canonicals-charmed-kubernetes
title: Portainer and Canonical Expand Partnership Launching Business Charm for Charmed Kubernetes
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/portainer-business-charm-launched-for-canonicals-charmed-kubernetes
hostname: portainer.io
description: Charmed Kubernetes is Canonical's 'enterprise' Kube distro. Portainer Business turns Charmed Kubernetes into a worldclass Containers-as-a-Service solution.
sitename: PORTAINER.IO
date: 2021-09-23
categories: []
tags: []
image: https://www.portainer.io/hubfs/Image%20from%20iOS.png
pagetype: article
filedate: 2025-01-18
-->

23rd September, Auckland, New Zealand. Portainer announced the launch of its Portainer Business Charmed Operator, allowing for seamless integration with Canonical’s Charmed Kubernetes distribution.

The new Portainer charm allows users of Canonical’s Charmed Kubernetes distribution to automatically install and integrate Portainer Business as part of the Kubernetes cluster deployment process, using Juju, the [Charmed Operator framework](https://juju.is/).

Portainer Business is a powerful operating platform that transforms any Kubernetes implementation into a ‘containers-as-a-service’ solution. With Portainer Business at the core, Platform Managers can use Portainer’s simple GUI to configure a range of security and governance policies –such as Role Based Access and resource quotas - that control how end users (typically Developers) interact with the environment.

Developers working in a Portainer-managed environment benefit from an easy-to-use GUI to deploy, manage, and monitor their applications or, equally, can connect any dashboard or CI/CD tool they like via Portainer. Without Portainer, Developers must use complex CLI commands to deploy and monitor their apps, which is hard and a major inhibitor in the overall K8s adoption trend.

[Charmed Kubernetes](https://ubuntu.com/kubernetes) is Canonical’s pure upstream, composable Kubernetes distribution. It is powered by Juju and allows users to build Kubernetes clusters from the ground up and tailor them to their needs, by selecting the specific networking, storage, observability, and other cloud-native components they want to use. Charmed Kubernetes supports a multitude of cloud platforms from AWS, Azure, and GCE, to VMware, Openstack, LXD, and bare metal. With Portainer managing Charmed Kubernetes, businesses have an easy way to design *and *manage their Kubernetes deployments at scale.

Neil Cresswell, CEO of Portainer.io, said “Portainer Business makes managing, configuring and using the services of Charmed Kubernetes super easy for everyone involved. I’m delighted to offer the Charm to users looking for governability and security across their organization within the integrated ecosystem of Charmed Kubernetes.”

“Canonical prioritizes user choice while offering fully integrated and automated operations, which is why the Portainer Business Charm makes so much sense as part of Charmed Kubernetes. We’re huge fans of the security Portainer Business brings to companies using a wide range of CI/CD tools”, commented Alex Chalkias, Project Manager at Canonical.

The Charm is available to Charmed Kubernetes users immediately on [Charmhub](https://charmhub.io/portainer). Portainer and Canonical will be showcasing the charm at KubeCon North America on the 12th and 13th of October

**About Canonical**

Canonical is the publisher of Ubuntu, the OS for most public cloud workloads as well as the emerging categories of smart gateways, self-driving cars, and advanced robots. Canonical provides enterprise security, support, and services to commercial users of Ubuntu. Established in 2004, Canonical is a privately held company

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/author/adolfo-delorenzo/page/2
title: Portainer News and Blog | Adolfo Delorenzo (2)
author: Adolfo Delorenzo April 9
url: https://www.portainer.io/blog/author/adolfo-delorenzo
hostname: portainer.io
description: Latest news and updates from the Portainer team (2)
sitename: Portainer.io
date: 2021-04-09
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

### Blog Post by Adolfo Delorenzo

[
](https://www.portainer.io/blog/portainer-as-alternative-to-synology-docker-gui)

Adolfo DelorenzoApril 9, 2021< 1 min read

### Portainer as an alternative to Synology Docker GUI

Why Portainer instead of Synology Docker GUI? Using Portainer offers access to all Docker ...

Start Reading
[
](https://www.portainer.io/blog/deploy-applications-on-kubernetes-with-portainer-stateless-stateful-or-daemon)

Adolfo DelorenzoApril 3, 20211 min read

### Deploy Applications on Kubernetes with Portainer - Stateless, Stateful or Daemon

Deploying applications on Kubernetes can be done using at least 3 methods, Stateless, ...

Start Reading
[
](https://www.portainer.io/blog/how-to-install-portainer-on-a-synology-nas)

Adolfo DelorenzoMarch 31, 20211 min read

### How to Install Portainer on a Synology NAS

Today we are going to take a look at how you can install Portainer on a Synology NAS.

Start Reading
[
](https://www.portainer.io/blog/deploy-and-manage-traefik-with-portainer-on-a-charmed-kubernetes-cluster)

Adolfo DelorenzoMarch 18, 20211 min read

### Deploy and Manage Traefik with Portainer on a Charmed Kubernetes cluster

In this post you will learn a basic deployment of the Traefik ingress controller on a ...

Start Reading
[
](https://www.portainer.io/blog/3-reasons-you-need-portainer-in-your-life)

Adolfo DelorenzoMarch 17, 20211 min read

### 3 Reasons you need Portainer in your life

Why you need Portainer to help manage Kubernetes

Start Reading
[
](https://www.portainer.io/blog/secure-your-portainer-setup-with-security-controls)

Adolfo DelorenzoMarch 5, 20212 min read

### Secure Your Portainer Setup with Security Controls

Discover the security controls available within Portainer to secure your setup.

Start Reading
[
](https://www.portainer.io/blog/using-the-portainer-edge-agent-edge-groups-and-edge-stacks-part-1)

Adolfo DelorenzoFebruary 19, 20212 min read

### Using the Portainer Edge Agent, Edge Groups, and Edge Stacks - part 1

Using the Portainer Edge Agent, Edge Groups, and Edge Stacks - part 1

Start Reading
[
](https://www.portainer.io/blog/swarm-on-azure-with-terraform)

Adolfo DelorenzoFebruary 15, 2021< 1 min read

### Creating a Docker Swarm on Azure with Terraform

Part 2 of the super helpful series on Creating a Docker Swarm on Azure with Terraform (in ...

Start Reading
[
](https://www.portainer.io/blog/multi-cluster-management-with-portainer.io)

Adolfo DelorenzoFebruary 9, 20215 min read

### Easy Multi Cluster Management for Kubernetes, Docker/Swarm and Edge

Manage multiple remote clusters simultaneously from a single instance of Portainer – ...

Start Reading
[
](https://www.portainer.io/blog/portainer-release-2.1.1)

Adolfo DelorenzoFebruary 5, 20212 min read

### New Portainer CE 2.1.1 Release - now with support for Compose >3 in standalone hosts, and Compose 3.8 for Swarm

Announcing Portainer CE Release 2.1.1. Discover the new features, fixes and tips for ...

Start Reading
[
](https://www.portainer.io/blog/how-to-deploy-portainer-on-microk8s)

Adolfo DelorenzoJanuary 26, 20212 min read

### How to Deploy Portainer on MicroK8s

Discover how easy it is to deploy Portainer in Kubernetes with the latest version of ...

Start Reading
[
](https://www.portainer.io/blog/portainer-access-control-setup)

Adolfo DelorenzoDecember 7, 2020< 1 min read

### Portainer Access Control Setup via the API

You can in fact very easily allow users or teams access. Assuming that we have a team ...

Start Reading

---
<!--
URL: https://www.portainer.io/blog/installing-portainer-to-the-raspberry-pi-piday-raspberrypi-raspberry_pi
title: Installing Portainer to the Raspberry Pi #piday #raspberrypi @Raspberry_Pi
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/installing-portainer-to-the-raspberry-pi-piday-raspberrypi-raspberry_pi
hostname: portainer.io
description: In this guest post from Emmet at pimylifeup.com, you can follow the easy guide to install Portainer on your Raspberry Pi.
sitename: PORTAINER.IO
date: 2021-06-21
categories: []
tags: []
image: https://www.portainer.io/hubfs/Installing%20Portainer%20to%20the%20Raspberry%20Pi%20%23piday%20%23raspberrypi%20.png
pagetype: article
filedate: 2025-01-18
-->

In this guest post from Emmet at [pimylifeup.com](https://pimylifeup.com/), you can follow the easy guide to install Portainer on your Raspberry Pi.

Portainer is a lightweight and open-source container management tool. Using this tool, you can create, manage and delete your Docker containers running on your Raspberry Pi with ease.

Not only is the software straightforward to use, but it is also dead easy to install as it runs entirely within a [Docker container](https://www.docker.com/resources/what-container).

As [Portainer](https://www.portainer.io/) is built to have relatively low overhead, there isn’t much of a performance impact to using the software.

It is a perfect way of managing your docker containers without having to fiddle around with the command line.

Equipment

You can use our list of parts below to see what we used when setting up Portainer on our Raspberry Pi. [Read more](https://pimylifeup.com/raspberry-pi-portainer/).

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/new-portainer-ce-2.6.0-release
title: New Portainer CE 2.6.0 Release - now with support for Git repository deployment, and single sign-on support for OAuth
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/new-portainer-ce-2.6.0-release
hostname: portainer.io
description: 2.6 release notes for Portainer CE, specifically addressing a number of points relating to Kubernetes.
sitename: PORTAINER.IO
date: 2021-06-25
categories: []
tags: []
image: https://www.portainer.io/hubfs/Screen%20Shot%20Git%20Repository%20CE%202.6%20undefined-Jun-24-2021-04-58-03-03-AM.png
pagetype: article
filedate: 2025-01-18
-->

Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our [Portainer Features page](/features)*. *

Today, we have released Portainer CE 2.6.0. This release comes with several features and fixes, specifically addressing feedback regarding Kubernetes management.

We've highlighted the most significant changes below, and at the end of the blog post, you'll find a link to our tips and tricks for upgrading.

**Deploy a manifest from a git repository**

This brings the ability to deploy a manifest from a git repository when using advanced deployment of an Application on Kubernetes. This is especially useful if you use a Git server to store deployment Manifests that can be written as a YAML Manifest or as a Compose format.**Summary of the Kubernetes actions****Portainer**will now generate a*Summary*block with all the actions and changes being applied to a Kubernetes endpoint. So before confirming an action on the Kubernetes cluster (like for instance deploying an Application or creating a Namespace via the Summary tab), you have cleary each step that will be performed by**Portainer**.**Advanced deployment available for all users**

Previously Advanced Deployment was only available to Endpoint Administrators. Now with this new feature, Standard Users also have access to the Advanced Deployment option in**Portainer,**when deploying applications:**Real-time container and node performance**

You can now monitor in real-time the performance of your Pods and Nodes in your Kubernetes cluster. This feature provides you with a graphical representation of hardware resources that these components are using.**Rename the “Resource pools” to Namespaces**

Previously namespaces were created using the Resource Pool option (which caused some confusion). After listening to feedback from the community, we decided to change this to the standard Namespace Kubernetes nomenclature for clarity.**Single Sign-on support for OAuth**

Portainer 2.6.0 has support for SSO on the OAuth authentication method. You can now configure SSO with your favorite provider ([GitHub](#GitHub)for example) and seamlessly login into your Portainer instance. With this feature, you don’t have to provide a password with Portainer if your OAuth session is still valid.

We would like to thank all of our community members that help us improve **Portainer**. We are continuously open for suggestions and enhancements.

**Tips and tricks for Upgrading**We have tested and validated Portainer version upgrades from 1.24.0 to the latest (2.6.0). Although un-tested, it is possible an upgrade path that has not been validated might work. We recommended that you test any upgrade path on a non-critical system before applying it to your active production systems.

See upgrade Instructions for Docker, Docker Swarm and Kubernetes [here](https://documentation.portainer.io/upgrade/).

You can pull the latest CE image by command:

docker pull portainer/portainer-ce:latest

Any questions, don't hesitate to drop me a line. Or join our [Slack channel](https://portainer.slack.com/join/shared_invite/enQtNDk3ODQ5MjI2MjI4LTcwNGYxMWQ5OGViYWZkNDY2ZjY4YTMwMTgzYmU4YmNiOTU0MDcxYmJjNTIyYmQ0MTM5Y2QwNTg3NzNkMTk5MDg#/) here.

Request a Demo of Portainer Business

Let us introduce you to a world of fast and easy app deployment, governance, and management in Docker and Kubernetes. [Request a 1:1 demo](https://www.portainer.io/portainer-demo-request-kubernetesgui-dockergui) to see how Portainer Business helps to make teams more accurate and efficient in a business environment.

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-business-edition-version-2.10
title: Portainer Business Edition version 2.10 - the container service delivery platform you've been waiting for
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/portainer-business-edition-version-2.10
hostname: portainer.io
description: Portainer Business Edition 2.10 is here and brings with it all of the great functionality delivered in CE 2.9 plus a number of BE specific features
sitename: PORTAINER.IO
date: 2021-11-14
categories: []
tags: []
image: https://www.portainer.io/hubfs/undefined-Nov-14-2021-09-45-20-81-PM-1.png
pagetype: article
filedate: 2025-01-18
-->

Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our [Portainer Features page](/features)*. *

2.10 is a game-changer for organizations that want to use Portainer to manage their containerized environments. It adds impressive Kubernetes functionality as well as GitOps integration and dark mode, which is one of our most requested features.

This 2.10 release also coincides with our [Take 3 Program](/take-3), which gives anyone (with a valid business email address) access to 3 free nodes of Portainer Business Edition for as long as they want, so now there's no reason not to use Portainer Business Edition!

**Improved UI**

Let's start with the new UI, which has been redesigned to reduce clutter and be more intuitive. It's now much easier to navigate inside Portainer and Kubernetes users should start to feel much more at home.**Lightweight GitOps integration**

We’re continuing the work we started earlier in the year around deploying applications from Git and bringing more controls (manual and automated) to the application deployment process..

With BE2.10 we’ve introduced a lightweight GitOps engine that enables users to employ 'entry level' CD automation' without needing to be an expert in the area. The functionality allows a user to configure automatic updates for their application, poll-based (with Portainer polling for changes at a specific interval) or push-based (via webhooks).

There are two additional features in PBE 2.10 that enhance the GitOps capabilities of Portainer:

**Forced Redeployment -**This feature allows our users to enable an enforcement setting when deploying an application from Git to make sure that any external change to the application is always over-ridden by the definition stored in Git.

**Change Window Settings -**We’re introducing the ability to specify a change window on specific environments to prevent automatic updates from happening outside of the changes window.

**Kubectl Shell**

We've integrated Kubectl into Portainer natively to help users troubleshoot Kubernetes applications without having to leave the Portainer UI, This also allows expert users to use advanced Kubernetes features and functions not yet supported inside Portainer.**Portainer as a proxy for container environments**

We’ve introduced the ability for Portainer to be used as a secured authenticated proxy into third-party container environments. This allows Platform and DevOps engineers to integrate Portainer seamlessly with third-party CI/CD tools and build secure, end-to-end automated delivery workflows.

The new API proxy also allows Portainer users to retrieve the configuration files they need to connect the deployment/observability tools they like while reflecting the access and permissions set by their administrator. This unlocks a new 'Bring Your Own Tool' paradigm that we're particularly excited about.**Helm Charts support**

In BE2.10 we've bought an easy way for the DevOps and Platform teams to deploy software provided by their ISV or any tool vendor inside a Kubernetes environment.

By supporting Helm, which is the de-facto packaging system for applications on Kubernetes, we allow users to easily register application repositories inside Portainer and deploy any application listed under these repositories

**Custom Templates**

**Private registry support for Kubernetes**

Here we’ve bought a long-time missing feature for Kubernetes, allowing users to deploy applications that are hosted on any private registry supported by Portainer.

This also introduces a revamp of the registry access management experience to make it more consistent across Docker and Kubernetes.

**HTTPS support**

As most administration tools are exposed over HTTPS by default and with the massive number of Portainer instances exposed over the Internet, support for HTTPS was long due for Portainer. HTTPS support goes hand in hand with our container environment proxy to make sure that communications between any 3rd party or external tools and Portainer are secured.

**Removal of 'Advanced Mode**'

We've realigned the UI around Form vs Manifest deployment to make more sense of the deployment workflow.

**Dark Mode**

One of the Portainer community most requested feature: dark mode for Portainer. We’re bringing support for user themes that can be set by each user through their account settings. In this release, Portainer will ship with experimental support for a dark theme and a high-contrast theme.

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/from-zero-to-production-with-fedora-coreos-portainer-and-wordpress-in-7-easy-steps
title: From Zero to Production with Fedora CoreOS, Portainer, and WordPress in 7 Easy Steps
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/from-zero-to-production-with-fedora-coreos-portainer-and-wordpress-in-7-easy-steps
hostname: portainer.io
description: From Zero to Production with Fedora CoreOS, Portainer, and WordPress in 7 Easy Steps
sitename: PORTAINER.IO
date: 2021-05-07
categories: []
tags: []
image: https://www.portainer.io/hubfs/From%20Zero%20to%20Production%20with%20Fedora%20CoreOS%2c%20Portainer%2c%20and%20WordPress%20in%207%20Easy%20Steps.png
pagetype: article
filedate: 2025-01-18
-->

In this guest blog post from [James Reynolds](https://www.magnusviri.com/)[ames Reynolds](http://www.magnusviri.com/), he delves into using Fedora CoreOS, Portainer, and WordPress in 7 Easy Steps. The magic of Fedora CoreOS is that it configures itself at install time, including installing Portainer and enabling the host firewall. Once configured, you can quickly and repeatedly set up this server without logging into it. Then you can use Portainer to run any container or docker-compose file like WordPress. By firewalling Portainer you protect your admin interface from possible attacks while leaving the services rendered by your other containers accessible.

You need somewhere to install Fedora CoreOS, either bare metal hardware or a virtual environment, which could include the cloud. Before deploying, you'll want to perfect your configuration and it's easiest to do that in a test environment. So I'll show how to install it on your own computer using VirtualBox, which is free to download. This is essentially the same thing as installing on a bare metal server.

The [FCOS documentation](https://docs.fedoraproject.org/en-US/fedora-coreos/getting-started/) includes examples showing how you would create a FCOS instance on AWS and locally on a Linux computer using libvert. The documentation has provisioning instructions for Alibaba Cloud, AWS, Azure, DigitalOcean, Exoscale, GCP, IBM Cloud, libvirt, OpenStack, QEMU, VMware, and Vultr. Please see the documentation for more information on the provisioning method of your choice.

To follow along, you will need [VirtualBox](https://www.oracle.com/virtualization/technologies/vm/downloads/virtualbox-downloads.html), [Docker](https://www.docker.com/products/docker-desktop), a text editor, and a local web server to host a config file. I'll use a simple Python 3 command. If you need to install Python 3, please do a web search on how to install Python 3. I'm doing this on macOS but there is nothing platform specific.

I'll refer to 2 host names, host.example.com and fcos.example.com. Your computer running VirtualBox is host.example.com. Your VM running FCOS is fcos.example.com. Change these names to the IP's of each before running any commands.

If you're already familiar with Fedora CoreOS, Butane (formerly the Fedora CoreOS Config Transpiler, FCCT), Ignition files, and provisioning, go ahead and skip to Step 5. Add Portainer, Step 6. Add WordPress, or Step 7. Add a Host Firewall. If you're new to Fedora CoreOS, Butane, and Ignition, keep reading.

### Motivation

[Portainer](https://www.portainer.io/) is lightweight, simple to deploy, and makes it easy to use containers. Portainer CE is open source and runs in a container itself, so installing it is a `docker`

command and uninstalling it is as simple as removing the container. It works with Kubernetes, Docker, Docker Swarm and Azure ACI.

Portainer is powerful. It can control all of my containers. Before I was willing to put it on a production server I needed to firewall the Portainer port so that the login page can't be accessed from non-approved IPs. I don't control the network firewall that my server will be running on so I need to configure this firewall on the host. Unfortunately, at this time the FCOS documentation doesn't explain how to setup a host firewall. It took searching and trial and error to figure it all out.

Also, FCOS does not come with docker-compose. Adding WordPress is my way of showing how Portainer enables you to use docker-compose files with FCOS without having to install docker-compose in the OS.

### About Fedora CoreOS

[Fedora CoreOS](https://getfedora.org/coreos) is a secure, minimal, production-ready container operating system that aims to be one of the best platforms for both cloud computing clusters and single node deployments. It is optimized for Kubernetes and for stand alone operations.

FCOS is an immutable operating system that automatically updates itself. Although you can install software into FCOS using [rpm-ostree](https://coreos.github.io/rpm-ostree/), the documentation strongly discourages doing so because automatic updates may have difficulty with extra packages installed. If you are interested in doing this, there is a good article on [the Red Hat developer's blog](https://developers.redhat.com/blog/2020/03/12/how-to-customize-fedora-coreos-for-dedicated-workloads-with-ostree/) that discusses rpm-ostree.

FCOS is customized when it's installed by an Ignition config file. Ignition can re-partition disks, format filesystems, create users, and write files, including systemd services. Most of the work to setup FCOS is making your Ignition configuration file and making sure the provisioning method can read it at install time.

Being immutable just means everything is read-only. However, the directories /etc and /var are mounted as read-write which lets users write and modify files there. But all of those changes should be considered ephemeral, that is, disposable. Your long-term infrastructure should be encapsulated in your Ignition config file and your containers.

After going through all the steps below, you might need to login to FCOS and edit configuration files until it is setup for your environment. If you do that, you'll need to use `vi`

since there are no other text editors installed in FCOS. If you've never used `vi`

before you'll need to search the web for instructions on how to use it.

Once you have figured out everything you want, you'll want to save all of those changes to the Ignition file, throw away your install, then start over. This is why it's good to do this virtually on your own computer first before installing for production. Once you have your Ignition file you can recreate your entire server from scratch without having to login, which is the goal.

On a production server you need a persistent storage method. You could configure your containers to store their data in the cloud, or you could save to disk. This is a big enough topic that depends so much on your environment that I can't cover it here. The FCOS documentation has a [page devoted to storage](https://docs.fedoraproject.org/en-US/fedora-coreos/storage/). My examples will be storing the container data in the default location, /var/lib/docker/containers. If you do the same thing, you need to move the container data off of the server before starting over if you want to save it.

I mentioned earlier that FCOS does not include docker-compose. You can install it by running `sudo rpm-ostree install docker-compose`

, but as I've said, the official documentation discourages installing anything outside of containers. Portainer's stacks accept docker-compose files. This makes Portainer a great addition to FCOS.

FCOS includes both docker and podman. The Portainer developers are aiming to [add podman support in the second half of 2021](https://github.com/portainer/portainer/issues/2991). For this reason, I will only cover setting up FCOS with docker.

### Step 1. Butane Configuration

The first step is to create a Butane file. Butane config files are formatted as YAML. We will convert this to an Ignition file in step 2. The goal of the Butane/Ignition config file is to set up the server when FCOS installs. That way you don't have to login to the server after you install it.

However, when starting out, it's a good idea to login and look around. You can login by either setting up ssh or setting a login password.

#### Set Up ssh

Here is a basic Butane file that enables ssh login.

`variant: fcos`

version: 1.3.0

passwd:

users:

- name: core

ssh_authorized_keys:

- ssh-rsa AAAAB3NzaC1yc...

Replace the ssh-rsa portion with your public key file. If you don't have one and don't know how to get one, search the web for "create ssh public key".

Note, the big advantage of ssh is that you can copy and paste commands. If you interact with FCOS using VirtualBox's window, you can't copy and paste commands.

#### Set a Password

The core user can run sudo without asking for a password, so you don't have to set a password. But in case you want a password, just add "password_hash" to your Ignition file.

`passwd:`

users:

- name: core

password_hash: $y$j9T$kWrG97KL0ouB3d3VdtBrA.$10OyjrSU7C5tlnHcNxaQD531aFTq4/gNwFovW5Yp/90

There are a few ways you can get a password hash. The Fedora CoreOS documentation recommends you use the mkpassword command and specify the yescrypt hash. Windows users can use the [Cygwin mkpasswd utility](https://cygwin.com/cygwin-ug-net/mkpasswd.html). On Linux or macOS you can even run it in a container.

Note, I'm pretty sure there are containers on Docker Hub with this pre-installed but I made a rule for myself that I don't use unofficial images.

`docker run --rm -it fedora`

Then, inside of the container, run this.

`dnf -y install mkpasswd ; mkpasswd --method=yescrypt`

It will take a minute to install and then it will ask for a password. Enter the password you want. It will print the password hash. Copy it and use it in the Butane file.

If you want to login to ssh using a password, you have to configure that also.

`storage:`

files:

- path: /etc/ssh/sshd_config.d/20-enable-passwords.conf

mode: 0644

contents:

inline: |

## Fedora CoreOS disables SSH password login by default.

## Enable it.

## This file must sort before 40-disable-passwords.conf.

PasswordAuthentication yes

#### Silence Console Messages

This code silences many console messages that print out while logged into FCOS and is optional.

`storage:`

files:

- path: /etc/profile.d/systemd-pager.sh

mode: 0644

contents:

inline: |

## Tell systemd to not use a pager when printing information

export SYSTEMD_PAGER=cat

- path: /etc/sysctl.d/20-silence-audit.conf

mode: 0644

contents:

inline: |

## Raise console message logging level from DEBUG (7) to WARNING (4)

## to hide audit messages from the interactive console

kernel.printk=4

#### Set the hostname

Setting a hostname makes it easier to tell one server from another when you end up having a dozen or so of these VM's booted up.

`storage:`

files:

- path: /etc/hostname

mode: 0644

contents:

inline: |

1-basic

#### All of the Above

If you add all of the options above this is what your Butane file will look like. Remember, you only need one way to login, and ssh is probably the best way to go for a production server.

Don't forget to put in your own ssh-rsa key and password hash.

`variant: fcos`

version: 1.3.0

passwd:

users:

- name: core

ssh_authorized_keys:

- ssh-rsa AAAAB3NzaC1yc...

password_hash: $y$j9T$kWrG97KL0ouB3d3VdtBrA.$10OyjrSU7C5tlnHcNxaQD531aFTq4/gNwFovW5Yp/90

storage:

files:

- path: /etc/ssh/sshd_config.d/20-enable-passwords.conf

mode: 0644

contents:

inline: |

## Fedora CoreOS disables SSH password login by default.

## Enable it.

## This file must sort before 40-disable-passwords.conf.

PasswordAuthentication yes

- path: /etc/profile.d/systemd-pager.sh

mode: 0644

contents:

inline: |

## Tell systemd to not use a pager when printing information

export SYSTEMD_PAGER=cat

- path: /etc/sysctl.d/20-silence-audit.conf

mode: 0644

contents:

inline: |

## Raise console message logging level from DEBUG (7) to WARNING (4)

## to hide audit messages from the interactive console

kernel.printk=4

- path: /etc/hostname

mode: 0644

contents:

inline: |

1-basic

You can see the full [Butane file](https://github.com/magnusviri/fcos_portainer_fw/blob/main/1_basic.bu) on GitHub.

### Step 2. Convert Butane to Ignition

The `butane`

command line tool (formerly the Fedora CoreOS Config Transpiler, FCCT) converts Butane files into Ignition files. Ignition files are formatted as JSON and are not meant to be edited by hand.

Run the following command to convert the Butane file to an Ignition file.

`docker run -i --rm quay.io/coreos/butane:release --strict < 1_basic.bu > 1_basic.ign`

The converted file should look something like this.

`{"ignition":{"config":{"replace":{"source":null,"verification":{}}},"security":{"tls":{}},"timeouts":{},"version":"3.0.0"},"passwd":{"users":[{"name":"core","sshAuthorizedKeys":["ssh-rsa ssh-rsa AAAAB3NzaC1yc..."]}]},"storage":{},"systemd":{}}`

### Step 3. Create the VM in VirtualBox

Now let's create a VM in VirtualBox and connect it up to our Ignition file. The hardware requirements for FCOS is 2 CPU's, 4096 MB of RAM, and 8 GB of hard disk.

First download the [fedora-coreos Bare Metal ISO from the web](https://getfedora.org/en/coreos/download?tab=metal_virtualized&stream=stable) or you can use this command to download the ISO.

`docker run --privileged --pull=always --rm -v $PWD:/data -w /data \`

quay.io/coreos/coreos-installer:release download -s stable -p metal -f iso

Open VirtualBox and click the "New" button.

Name your virtual machine something like "fcos-portainer-1", set the type to "Linux" and version to "Red Hat (64-bit)". Give it 4096 MB of RAM. Make sure "Create a virtual hard disk now" is selected and then click "Create".

Next, set the hard disk size to 9 GB. 8 GB is the recommended minimum but I got warnings it wasn't big enough so I use 9 GB. Choose the VDI and Dynamically allocated. Any type will work, but Dynamically allocated VDI uses little hard disk space. Click "Create".

Once the virtual machine is created, click the "Settings" button.

#### 2 CPU's

In Settings, click on "System", then the "Processor" tab and set CPU to 2.

#### Set Up Networking

Your environment will dictate what you do here. Your VM needs to be able to talk to the host computer (to download the Ignition file) and to the internet (to download Portainer). If you have a DHCP server on your network you can use Bridged Networking.

In Settings, click "Network", and then set "Attached to" to "Bridged Adapter". Then click "Ok".

#### Set the virtual optical disk file at first boot

Click the "Start" button.

The first time you start a VM VirtualBox asks you to set the virtual optical disk.

Click the folder icon and then click the "Add" button. Find and select the Fedora CoreOS iso you downloaded earlier. Then click "Start".

#### Manually set the virtual optical disk file

This is how you manually set the virtual optical disk file (e.g. you clicked cancel instead of setting a optical disk file).

In Settings, click "Storage". Click on "Empty" under "Controller: IDE". On the right in the "Attributes" section, click the blue disk icon next to "IDE Secondary Device 0".

In the pop-up select "Choose a disk file..." then find and select the iso you downloaded earlier. It should look like this.

Click "OK".

#### Start Fedora CoreOS

Click the "Start" button to start up the VM if you haven't already.

When the VM boots from the ISO it will auto login as the core user and you'll have a terminal prompt. Nothing is installed yet. This is what it looks like when it boots to the live installer.

If you've never used VirtualBox before you should know a few things. The VM window will "capture" your mouse. That means you wont be able to move your mouse out of the window until you press the "Host" key, which on the Mac is usually the left command key.

Another thing about Macs with retina displays is that the window will be small. You can make it bigger by selecting "Scaled-Mode" in the "View" menu.

#### Set the FCOS IP

If you don't have DHCP, you'll have to set a static IP on the VM. You'll need the VM network interface.

`nmcli connection`

You should see something like this.

`Wired connection 1 df07b92a-4319-3ae7-8ebd-3920b2ac15b3 ethernet enp0s3`

The correct interface for this output is enp0s3. Yours may be different depending on how you configured the networking.

Change the interface and the IP in the following like to match what will work on your subnet.

`sudo ip addr add 192.168.0.200/24 dev enp0s3`

This IP will only last while booted to the Live CD. To change it permanently check out the [FCOS network documentation](https://docs.fedoraproject.org/en-US/fedora-coreos/sysconfig-network-configuration/). You can set the networking at the install step, you can set it with the ignition file, or you can set it with other methods.

### Step 4. Download the Ignition Config and Install

#### Host the Ignition File on a Web Server

Now you need to set up a web server with your Ignition file. It's easy to do this if you have Python3 installed. If you don't have it installed, you can run it in Docker. On your host computer, in the Terminal, cd to the directory that contains your Ignition file. If you have Python3 installed run the following command. It will print feedback when it's running.

`python3 -m http.server`

To run Python3 with Docker, type the following command.

`docker run -p 8000:8000 -v $PWD:/data -it --rm python`

Then type these commands in the container. Note, you wont get feedback after the last line.

`import os`

os.chdir("/data")

from http.server import HTTPServer, SimpleHTTPRequestHandler

HTTPServer(('', 8000), SimpleHTTPRequestHandler).serve_forever()

By default the web server is running on port 8000. You should also find the IP of your host computer. The Ignition file URL will be something like host.example.com:8000/1_basic.ign. Change "host.example.com" to your host computer IP.

#### Download the Ignition File

On the VM download the Ignition file.

`curl -O host.example.com:8000/1_basic.ign`

You should verify it downloaded by typing the following.

`cat 1_basic.ign`

After it's downloaded, quit the Python web server. Press cntl-c in the host Terminal window running the Python web server. If you ran the web server with Docker you'll need to press cntl-d or type "exit()" to quit.

#### Install Fedora CoreOS

Now install Fedora CoreOS. Type this in to the VM console. Change "1_basic.ign" to the name of the file you downloaded.

`sudo coreos-installer install /dev/sda --ignition-file 1_basic.ign`

If you have any trouble installing, please read the [Installing CoreOS on Bare Metal] ([https://docs.fedoraproject.org/en-US/fedora-coreos/bare-metal/](https://docs.fedoraproject.org/en-US/fedora-coreos/bare-metal/)).

After it's installed, you'll see the text "Install complete." Turn off the VM with the following command.

`poweroff`

The VM will boot to the installer until you remove the live CD. Go back into "Settings", "Storage", and right-click on "fedora-coreos" and select "Remove Attachment". Click "Remove" in the confirmation dialog, and then click "OK".

#### Login and Test

Start up the VM again. Now you get to see if the login methods you configured work. If you set a password then login to the console with the username "core" and the password you created with the mkpasswd command. If you set up ssh, FCOS will display the IP immediately after it boots on the console. Remotely connect using `ssh core@fcos.example.com`

(change fcos.example.com to your VM IP).

Once you're logged in, try starting a container.

`sudo docker run hello-world`

Now check to see if you can run a web server from your VM.

`sudo docker run -d -p 80:80 docker/getting-started`

On your host, see if you can connect to the VM's container with a web browser.

Hopefully you see the Docker "Getting Started" webpage. If not, check to see if the container is running on the VM by typing `docker ps`

. Also check to make sure you are using the correct IP by typing `ip a`

in the VM.

Note, by default the core user isn't in the docker group, but you can add it to the Butane file like so.

`variant: fcos`

version: 1.3.0

passwd:

users:

- name: core

groups:

- docker

### Step 5. Add Portainer

#### Manually

Installing Portainer is easy. To install it with Docker, run these 2 commands.

`sudo docker volume create portainer_data`

sudo docker run --privileged=true -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce

On your host you should be able to open up a web browser to http://fcos.example.com:9000/ (change fcos.example.com to your VM IP). You'll see the Portainer initialization page. For more information on setting up Portainer check out the [quick start documentation](https://documentation.portainer.io/quickstart/). Or you can just wing it. You can just delete the container and volume and start over if you mess it up.

#### At First Boot

Now, to add Portainer to our Ignition file. Add the following to your Ignition file.

`systemd:`

units:

- name: docker.portainer.service

enabled: true

contents: |-

[Unit]

Description=Portainer Admin Container

After=docker.service

Requires=docker.service network.target network-online.target

[Service]

Type=oneshot

RemainAfterExit=yes

TimeoutStartSec=0

ExecStartPre=-/usr/bin/docker stop %n

ExecStartPre=-/usr/bin/docker rm %n

ExecStartPre=/usr/bin/docker pull portainer/portainer-ce

ExecStart=-/usr/bin/mkdir -p /mnt/shared_nfs/portainer_data

## Privileged mode is required for binding to local socket to work due to SELINUX (https://github.com/portainer/portainer/issues/849)

ExecStart=/usr/bin/docker run --privileged=true -d -p 9000:9000 --name %n --restart always -v /var/run/docker.sock:/var/run/docker.sock -v /var/portainer_data:/data portainer/portainer-ce

ExecStop=/usr/bin/docker stop -t 15 %n

[Install]

WantedBy=multi-user.target

You can see the full [Butane file](https://github.com/magnusviri/fcos_portainer_fw/blob/main/2_portainer.bu) on GitHub.

#### Start Over

Because FCOS reads the Ignition file only at install time, you need to reinstall the OS if you change the Ignition file.

Ok, I know the title of this article has the words "7 Easy Steps", but I didn't say how many times you'd repeat each step. I could've told you to do everything all at once, but if something went wrong, it would be difficult to figure out what is wrong. By setting up the server in steps, you make sure you don't move on to the next part without making sure the previous parts work.

This is especially important when you turn on the firewall. Debugging firewalls is hard enough. You can't debug it if you don't even know if ssh or http is working. So before turning on your firewall, make sure everything else is working.

Think of it this way. This will be easy for you by the time you get your server setup. You might even have some of it memorized.

Shutdown your VM by typing `poweroff`

. Go to VirtualBox and right click on your VM and select "Remove". In the confirmation dialog select "Delete all files".

Now go back to Step 2 and repeat. To make it easier, I've condensed the steps below.

Set up VM

- Linux
- Red Hat (64-bit)
- 4096 MB RAM
- Create a virtual hard disk now
- 9 GB Dynamically allocated VDI

VM Settings

- 2 CPU's
- Set up networking
- Start VM

Set IP if you need to

`sudo ip addr add 192.168.0.200/24 dev enp0s3`

On host type:

`butane < 2_portainer.bu > 2_portainer.ign`

python3 -m http.server

VM:

`curl -O host.example.com:8000/2_portainer.ign`

cat example.ign

sudo coreos-installer install /dev/sda --ignition-file example.ign

poweroff

Remove Live CD Start VM

If everything worked right, you wont need to login after you install it. Wait a minute for Portainer to start. Then open up a web browser to http://fcos.example.com:9000/ (change fcos.example.com to your VM IP). Note, your new VM might have a different IP if you have DHCP.

Don't go to Step 6 until you have Portainer working without having to login.

### Step 6. Add WordPress

Enter a username and password at the Portainer initialization page and click "Create user". On the next screen, connect Portainer to Docker and click "Connect". Click on the "local" endpoint.

Click on "Stacks" and then click the "Add stack" button. Give it a name.

Open a new webpage to the github.com/docker/awesome-compose repository and copy the contents of the [WordPress-MySQL docker-compose.yaml](https://github.com/docker/awesome-compose/blob/master/wordpress-mysql/docker-compose.yaml) file.

As of today, this is what that file looks like.

`version: '3.7'`

services:

db:

image: mysql:8.0.19

command: '--default-authentication-plugin=mysql_native_password'

volumes:

- db_data:/var/lib/mysql

restart: always

environment:

- MYSQL_ROOT_PASSWORD=somewordpress

- MYSQL_DATABASE=wordpress

- MYSQL_USER=wordpress

- MYSQL_PASSWORD=wordpress

expose:

- 3306

- 33060

wordpress:

image: wordpress:latest

ports:

- 80:80

restart: always

environment:

- WORDPRESS_DB_HOST=db

- WORDPRESS_DB_USER=wordpress

- WORDPRESS_DB_PASSWORD=wordpress

- WORDPRESS_DB_NAME=wordpress

volumes:

db_data:

In Portainer, make sure "Web editor" is selected. Paste the text into the web editor. At the bottom click "Deploy the stack". The button text will change to "Deployment in progress". Wait for it to start up. Open up a new webpage to http://fcos.example.com (change fcos.example.com to your VM IP). You should see the following.

Now you are ready to add a firewall. But don't start over yet. You need to Get the Network Interface if you haven't already. So leave this VM running.

### Step 7. Add a Firewall

#### About Docker's Firewall

Firewalls work by creating a list of rules, called chains. When a network packet reaches the computer, the packet is compared to the rules. Depending on the rule, the packet could be accepted or dropped. If that happens no more rules will be examined.

If the packet isn't accepted or dropped, then the next rule will be examined. If no rules accept or drop the packet, then the last rule decides the packets fate. A "default deny" policy will deny all packets that reach the last rule. A "default allow" policy will accept all packets that reach the last rule. Docker uses a "default allow" policy.

Docker is tightly coupled with the system firewall. It creates it's own rules for containers that have higher precedence than other rules. To allow administrators to create rules for containers Docker added the DOCKER-USER chain. You'll be making all of your container rules in DOCKER-USER. Your OS rules, like for ssh, go in the INPUT chain.

If you want to simulate default deny behavior, you have to drop all traffic from the external network interface in the DOCKER-USER chain. This allows the internal network traffic to pass through so that Docker still works. The iptables command to create a rule to drop external network traffic looks like this.

`/usr/sbin/iptables -A DOCKER-USER -i enp0s3 -j DROP`

This has to be the last rule in DOCKER-USER or else your other rules wont be evaluated.

All of the following rules assume there is only one external network interface and that it is enp0s3. If your server has a different network setup, you're going to have to modify all of these rules to make sure they work with your setup.

#### nftables vs iptables

Nftables remedies many problems with iptables such as ease of use, scalability, and performance. Nftables has been included in the Linux kernel since 2014. You can read more about [moving from iptables to nftables](https://wiki.nftables.org/wiki-nftables/index.php/Moving_from_iptables_to_nftables) from the nftables wiki.

Unfortunately, Docker is tightly coupled with iptables. And at the time of this writing, I couldn't get nftables to work correctly with Fedora CoreOS. I'm not sure if it didn't work because of my configuration, Docker, or Fedora CoreOS.

So this article will just cover iptables.

#### Get the Network Interface

Before you can create a firewall you need to know your network interface. This will be different depending on the type of network adapter the VM is configured with. The easiest way to find the interface is to boot the VM and check. Hopefully, you didn't remove your previous VM. If you did, you'll need to create a quick VM so you can get the interface. Make sure it has the same network interface that you plan on using.

Login and type this command to get the interface.

`nmcli connection`

You should see something like this.

`Wired connection 1 df07b92a-4319-3ae7-8ebd-3920b2ac15b3 ethernet enp0s3`

docker0 ac84b147-bab5-489a-8168-883462a9bbed bridge docker0

The correct interface for this output is enp0s3. I use enp0s3 in the following examples, but yours may be different. Because the interface may change I try to keep the interface defined as a shell script variable.

#### Adding iptables to the Butane file

Add the following to your Ignition file in the correct places.

`storage:`

files:

- path: /etc/sysconfig/iptables-post-docker

mode: 0755

contents:

inline: |

######

interface=enp0s3

admin_net=192.168.0.15

/usr/sbin/iptables -A INPUT -i lo -j ACCEPT

/usr/sbin/iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT

/usr/sbin/iptables -A INPUT -p tcp --dport 22 -s $admin_net -j ACCEPT

/usr/sbin/iptables -P INPUT DROP

/usr/sbin/iptables -D DOCKER-USER 1

/usr/sbin/iptables -A DOCKER-USER -p tcp --dport 80 -j RETURN

/usr/sbin/iptables -A DOCKER-USER -p tcp --dport 443 -j RETURN

/usr/sbin/iptables -A DOCKER-USER -p tcp --dport 9000 -s $admin_net -j RETURN

/usr/sbin/iptables -A DOCKER-USER -i $interface -j DROP

systemd:

units:

- name: iptables-post-docker.service

enabled: true

contents: |

[Unit]

Description=Post docker iptables firewall rules

After=docker.service

[Service]

Type=oneshot

ExecStart=/etc/sysconfig/iptables-post-docker

[Install]

WantedBy=basic.target

You can see the full [Butane file](https://github.com/magnusviri/fcos_portainer_fw/blob/main/3_iptables.bu) on GitHub.

Be sure to change the admin_net variable to use the IP's for your network. 192.168.0.15 is my administrator computer.

You can change the firewall after it's been installed by remotely logging in and editing /etc/sysconfig/iptables-post-docker.

However, doing this is what causes configuration drift. To avoid configuration drift, you'll make the change in your Butane file and create a new FCOS VM with the new config and remove the old VM with the old config. If you're using a network storage volume, this isn't such a hard task.

#### iptables rules

You probably want to change the rules a little so I will explain what the rules do.

These lines open up web access.

`/usr/sbin/iptables -A DOCKER-USER -p tcp --dport 80 -j RETURN`

/usr/sbin/iptables -A DOCKER-USER -p tcp --dport 443 -j RETURN

If you have any other ports that your containers need opened put them here.

This next line gives the admin computer access to Portainer.

`/usr/sbin/iptables -A DOCKER-USER -p tcp --dport 9000 -s 192.168.0.15 -j RETURN`

All of the other lines must look exactly like they are and if you change any of them without knowing what you're doing you will likely stop the firewall from working correctly.

Warning!

I noticed that changing ports doesn't work. In the next line I changed Portainer from port 9000 to 9001.

`sudo docker run --privileged=true -d -p 8000:8000 -p 9001:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce`

I also changed the firewall.

`/usr/sbin/iptables -A DOCKER-USER -p tcp --dport 9001 -s $admin_net -j RETURN`

I couldn't get this to work.

#### Start Over Again

Now that you have your firewall rules, you'll need to start over again. That includes converting your new Butane configuration file, putting the Ignition file on a web server, shutting down your VM, throwing it away, recreating it, starting the VM, downloading the Ignition file, installing, and restarting.

I will be honest. Developing immutable operating systems means you will be repeating this step over and over. Because of this, you need to come up with a way of making this quick and easy. Here's a script that will convert the butane file, create a VirtualBox VM, and set it up. It does not start the VM though.

Edit the first few lines to make sure it works in your environment.

`#/bin/sh`

vmname="3_iptables"

vm_path=~/"VirtualBox VMs"

iso_path=`ls "$vm_path"/fedora-coreos-*-live.x86_64.iso | tail -n 1`

cd ~/butane_files

if [ ! -e $vmname.bu ]; then

echo "Edit this script so it changes to the directory with $vmname.bu"

exit

fi

docker run -i --rm quay.io/coreos/butane:release --strict < $vmname.bu > $vmname.ign

VBoxManage createvm --name $vmname --ostype RedHat_64 --register

VBoxManage storagectl $vmname --name IDE --add ide

VBoxManage storageattach $vmname --storagectl IDE --port 0 --device 0 --type dvddrive --medium "$iso_path"

VBoxManage createmedium --filename "$vm_path/$vmname/$vmname.vdi" --size 9216

VBoxManage storagectl $vmname --name SATA --add SATA --controller IntelAhci

VBoxManage storageattach $vmname --storagectl SATA --port 0 --device 0 --type hdd --medium "$vm_path/$vmname/$vmname.vdi"

VBoxManage modifyvm $vmname --nic1 bridged --bridgeadapter1 en0

VBoxManage modifyvm $vmname --memory 4096 --vram 16

VBoxManage modifyvm $vmname --cpus 2

VBoxManage modifyvm $vmname --audio none

VBoxManage modifyvm $vmname --usb off

VBoxManage modifyvm $vmname --usbehci off

VBoxManage modifyvm $vmname --usbxhci off

echo "Next steps:"

echo "Type 'python3 -m http.server'"

echo "Power on the VM"

echo "In VM type the following:"

echo " curl -O host.example.com:8000/$vmname.ign"

echo " cat $vmname.ign"

echo " sudo coreos-installer install /dev/sda --ignition-file $vmname.ign"

echo " sudo poweroff"

echo "Remove the live installer iso then restart the VM"

This [script](https://github.com/magnusviri/fcos_portainer_fw/blob/main/create_vbox_vm.sh) is also on GitHub.

I could've given this script to you earlier, but the script isn't the greatest, and you'll likely need to fiddle with it to get it to work for you. So it's best to tackle one hurdle at a time.

For example, you'll probably need to change the next line so it works in your network environment.

`VBoxManage modifyvm $vmname --nic1 bridged --bridgeadapter1 en1`

If you can't get the script to work, then just create the VM manually like you have been and start it up.

#### Testing the Firewalls

First, test the obvious. Make sure you can ssh in to your VM and access the Portainer url from your administrative computer. Then make sure you can't access those from a different IP. If this works, then move to the next round of tests.

Add WordPress. Now check to make sure you can access WordPress from any computer.

Lastly, if you want to be thorough, open a port that should be closed, like 8888, and then make sure you can't access it from any IP. You will have to ssh in and run the following code on the command line.

`sudo docker run -p 8888:8888 -v $PWD:/data -it --rm python`

Then type these commands

`import os`

os.chdir("/data")

from http.server import HTTPServer, SimpleHTTPRequestHandler

HTTPServer(('', 8888), SimpleHTTPRequestHandler).serve_forever()

If you can't access port 8888 from any IP, that's great, it works.

However, make sure it's working. Open a new window and ssh in and type this to make sure the web server is running on port 8888.

`curl localhost:8888`

You should see lots of html.

To exit the docker container type control-c, then control-d.

#### Troubleshooting

If you find that the rules don't work, instead of recreating the VM over again and again, it's best to ssh in and change the firewall rules in the virtual machine. You'll need to use `vi`

to edit those rules. If you don't know how to use `vi`

, do a web search for "vi tutorial".

`vi /etc/sysconfig/iptables-post-docker`

After changing the rules, you can either reboot the VM, or you can stop docker, restart iptables, then start docker.

`sudo reboot`

Or

`systemctl stop docker`

systemctl restart iptables

systemctl start docker

You have to do this because docker modifies the firewall rules when it starts up and if you restart iptables without stopping docker first, you'll just have a mess.

When you have the firewall rules that you want, modify your Butane and other files on your host computer and start over yet again. You should never change the configuration on the VM and then leave it running in production. This is how it's been done in the past, but the whole point of having an immutable and ephemeral operating system is to have all of your configuration saved outside of the server's file system.

You should never make a last minute change without testing it thoroughly and completely. Last minute untested changes will always lead to a mistake, maybe not this time, but eventually it will happen.

### Last steps

After you have made all the changes and verified they will work, then you are ready to move on from VirtualBox and try to provision your Fedora CoreOS server on bare metal, in your virtual environment, or the cloud. Read the [FCOS documentation](https://docs.fedoraproject.org/en-US/fedora-coreos/getting-started/) to find a provisioning method of your choice and get familiar with all of the features of FCOS.

Other things you will want to do include [enable ssl for Portainer](https://documentation.portainer.io/v2.0/deploy/ssl/) and WordPress, set the [Fedora CoreOS update policy](https://docs.fedoraproject.org/sq/fedora-coreos/auto-updates/), and set up [external storage](https://docs.fedoraproject.org/en-US/fedora-coreos/storage/).

### Final words

Things are changing quickly. I had to modify this article several times while writing it because things changed while I was writing it.

FCOS is currently migrating their firewall backend from iptables to nftables. When this happens, the firewall rules should still work but there is a chance something could break, especially if you have a complex firewall. You can tell when the change has occurred when running iptables -V no longer displays "legacy".

`iptables -V`

iptables v1.8.5 (legacy)

Hopefully the FCOS documentation will soon include official firewall documentation. And hopefully the problems with nftables will be fixed. And I look forward to Portainer working with podman.

I hope you were able to follow along and get this working for you. I am excited about the Fedora CoreOS and containers and I hope to pass that excitement on to others.

Good luck and happy sailing.

Request a Demo of Portainer Business

Let us introduce you to a world of fast and easy app deployment, governance, and management in Docker and Kubernetes. [Contact our sales team](/contact-sales) to discuss how Portainer Business helps to make teams more accurate and efficient in a business environment.

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/manage-software-running-at-the-far-edge-with-nomad-and-portainer-webinar
title: Manage software running at the far edge with Nomad and Portainer - Webinar
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/manage-software-running-at-the-far-edge-with-nomad-and-portainer-webinar
hostname: portainer.io
description: Discover how HashiCorp's Nomad and Portainer can help solve the challenge of managing software at the far edge.
sitename: PORTAINER.IO
date: 2022-09-22
categories: []
tags: []
image: https://www.portainer.io/hubfs/Webinar%20-%20Nomad%20and%20Portainer.jpg
pagetype: article
filedate: 2025-01-18
-->

Discover how HashiCorp's Nomad and Portainer can help solve the challenge of managing software at the far edge.

Nomad has proven itself to be a hugely powerful scheduling tool, particularly for software running in containers at the far edge, however managing really big deployments, potentially consisting of thousands of clusters, comes with a unique set of challenges that demand specialist tooling.

In this webinar, we’ll discuss the challenges associated with managing Nomad clusters with a particular focus on deploying applications en-masse to thousands of clusters simultaneously.

Hear from Adolfo Delorenzo (Portainer) and Kerim Satirli (HashiCorp), how Portainer has solved the problem and is helping organizations manage not only software running at the edge, but also the remote (hardware) devices.

#### What you'll learn

- The challenges of managing software at scale at the far edge
- Different software options for solving the problem
- How Portainer uniquely addresses the challenges

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/how-to-secure-your-portainer-installation
title: How to secure your Portainer installation
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/how-to-secure-your-portainer-installation
hostname: portainer.io
description: Securing your Portainer Installation is really important. This blog explains what you need to do and how to do it.
sitename: PORTAINER.IO
date: 2021-11-25
categories: []
tags: []
image: https://www.portainer.io/hubfs/How%20to%20secure%20your%20Portainer%20installation.png
pagetype: article
filedate: 2025-01-18
-->

**Creating the first administrator user**

- The first thing you need to do when accessing Portainer for the first time is set up your primary
**admin**user. - It's good practice
**not**to use the default*admin*as a username - you can set it to anything you like. - Make sure to use a secure password that has a combination of letters, numbers and characters.

**Enabling HTTPS access to Portainer**

- Under Settings scroll down until you are on the SSL Certificate section:
- Enable the
**Force HTTPS only**option and click on**Apply changes**: - Portainer now will only be available on port
**9443**with*https*.

Let's say for example the ip address of your Portainer instace is 192.168.10.50, you will now have access via the following address:[https://192.168.10.50:9443](https://192.168.10.50:9443) - You can upload your own certificates if you so prefer via the Settings->SSL Certificate section.

**Access Portainer via a VPN using Wireguard**

If you want to avid exposing your Portainer instance on the Internet, we suggest you check our blog post that shows how to use an end-to-end connection with Wireguard here: [https://www.portainer.io/blog/how-to-run-portainer-behind-a-wireguard-vpn](https://www.portainer.io/blog/how-to-run-portainer-behind-a-wireguard-vpn)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-community-edition-2.11-release
title: Portainer Community Edition 2.11 Release
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/portainer-community-edition-2.11-release
hostname: portainer.io
description: Portainer CE 2.11 makes Portainer compatible with AWS Registry and adds a range of other important new features that make Portainer easier to use.
sitename: PORTAINER.IO
date: 2021-12-09
categories: []
tags: []
image: https://www.portainer.io/hubfs/Portainer%20Community%20Edition%202.11%20.png
pagetype: article
filedate: 2025-01-18
-->

**Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our Portainer Features page . **

**Portainer Community Edition 2.11 Release**

This update to Portainer CE brings with it a number of enhancements, fixes and features.

**Support for AWS ECR**

We have added support to AWS ECR registry to the registry list within Portainer. You will now be able to add and browse private registries hosted on AWS ECR. Public registries can also be added but they do not have the browse ability.**Introduce the ability to create and use API Access Tokens**

With the introduction of Portainer API Access Tokens, users can integrate automation systems more easily. API Access Tokens remove the time expiry issue from having to log in as a specific user that then had a session expiry related to it, then requiring logging in again. The access token allows you to call specific Portainer actions.**Allow tags to be defined when importing a Docker image**

Introduced the ability to set image tags at the time of import**Provide a simple way to get access to all your environment contexts**

Kubconfig download was a first step implementation in[2.9](/blog/portainer-2.9-takes-kubernetes-mainstream-with-gui-templates-and-api)allowing you to download the config for a specific environment. With the interest it gained, we have expanded its function by moving the Kubeconfig Download button to the Homepage view. When clicking on this it now allows you to select and download all your environments that you have access to.**Do not invalidate Kubeconfig upon Portainer restarting**

Every time a portainer instance got restarted the kubeconfigs got invalidated. With this change upon restarting your portainer, it will retain your existing kubeconfigs valid.

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-2.21-release
title: Portainer 2.21 LTS is now available
author: James Carppe
url: https://www.portainer.io/blog/portainer-2.21-release
hostname: portainer.io
description: Portainer version 2.21 LTS is now available - the first LTS release we've done. Find out more about this and the release itself.
sitename: PORTAINER.IO
date: 2024-08-27
categories: []
tags: []
image: https://www.portainer.io/hubfs/Portainer%20YT%20Thumbnail%20%28release%20videos%29.png
pagetype: article
filedate: 2025-01-18
-->

Portainer version 2.21 includes a number of new features, fixes, and updates. It is also our first LTS release. Read on for more about this and the release itself.

### Long Term Support (LTS)

2.21 is our first Long Term Support, or "LTS", release of Portainer. LTS releases are meant to be production-ready versions that you can safely run on your mission-critical infrastructure. Generally, LTS releases won't have any new features as compared to the Short Term Support, or "STS", releases that came before - in this case 2.20 - but will be focused on making sure those features are rock solid.

You can read more about our new release principle in our CEO Neil's [blog post](/blog/2024-release-principle).

### New Features

**New menu structure (BE/CE)**

The first change you're likely to notice in 2.21 is an update to the menu structure within Portainer. In order to streamline the user experience for people that are new to containerization, as well as those more experienced, we've updated the names of some menu items, moved others into new subsections, and generally made it easier to understand where to find the functionality you're after. This is particularly evident for Kubernetes environments, but applies to Portainer as a whole as well.

**More performance improvements (BE/CE)**

Our ongoing efforts to improve the performance of Portainer continue in this release. Along with the updated menu structure we have implemented additional caching to improve page load times as well as moved more of our pages and page components to the React framework. We've also added more background population of page contents so that rendering the crucial information comes first with additional longer-to-retrieve information being loaded asynchronously.

For Kubernetes users, we've added a per-user toggle to enable front-end data caching for Kubernetes environments that can also help with page load times. This is configurable through the My account page.

**Support for streaming Portainer activity and auth logs to external systems (BE)**

When deploying Portainer within your organization you may have the desire or perhaps compliancy need to ship your log files to an external log aggregator. In 2.21 BE we've added the ability to push Portainer's activity and authentication logs in syslog format to an external Security Information and Event Management (SIEM) system without having to write a custom wrapper around the Portainer API.

At present this feature is considered experimental and is configurable via CLI options, but we're intending to expand this feature further in the future based on customer feedback.

**Buttons to reload image update indicators (BE)**

Our new image indicator feature has been quite popular since we released it way back in 2.14, and we've made a few adjustments to it in subsequent versions. In 2.21 we've added in buttons on the Containers, Stacks, and Services list pages, as well as the details page for each, that will perform an on-demand reload of the image status for the page you're on.

Image indicators are cached for 24 hours after they are loaded for performance reasons, but with these buttons you can force a check at any time you need one.

**List and manage more Kubernetes object types (BE)**

We've expanded the types of Kubernetes objects you can list and manage through Portainer in 2.21. In this version, admins will see new pages for Service Accounts, Cluster Roles and Cluster Role Bindings, and Roles and Role Bindings under the new More Resources menu item.

**Enforce admin-only Kubernetes secret viewing in the UI (BE)**

As a cluster administrator you may want to restrict the viewing and editing of secrets within the cluster to administrator users. In 2.21 we've added a toggle that allows you to do just that.

Note that due to limitations within Kubernetes itself, this feature does not hide secrets from viewing through other tools outside of Portainer.

**Templates for Edge (BE)**

Template functionality has existed in Portainer for non-Edge environments for some time, and in 2.21 we're bringing that functionality to Edge Stacks. With Edge Compute enabled, you'll find a new Edge Templates option in the left-hand menu. Here you can deploy an Edge Stack from our pre-provided templates, or create and manage your own custom Edge Stack templates for your applications.

Edge Templates support the same functionality as our non-Edge templates, including variables and Git repository deployments, and can also be deployed from the Create Edge stack page.

**New Edge Administrator role (BE)**

2.21 also introduces a new Edge administrator role for Edge Compute users. This role lets you give users full control over resources in Edge environments without giving them full administrative access to all of Portainer.

### Enhancements and Fixes

**Updated third-party binaries and libraries (BE/CE)**

As we do with every release, we've updated the versions of the third-party binaries and libraries that we use within Portainer to newer versions. This resolves a number of reported CVEs as well as providing improved performance and functionality in some cases.

**Support for new Kubernetes versions (BE/CE)**

Along with updated binaries and libraries, we've also updated our Kubernetes version support in 2.21. We now support deploying to Kubernetes 1.30 environments in all cases, including through our supported cloud providers in our Kubernetes as a Service feature as well as our Kubernetes cluster creation tools for on-premise infrastructure.

**Consolidate Helm functionality into Applications (BE/CE)**

As part of our menu restructuring and general usability improvements, in 2.21 we moved the Helm functionality for Kubernetes environments into the Applications system proper, rather than the separate system we had before.

You can now provision applications from Helm charts via the standard Create from manifest option under Applications, and Helm deployments will appear in the Applications list alongside other non-Helm deployments. We've also made some improvements to how you can configure and manage your Helm chart repositories within Portainer.

**Allow stopping a Kubernetes app by scaling to 0 (BE/CE)**

Docker Swarm users have for a long time been able to scale their services to 0, but this wasn't possible in Portainer for Kubernetes deployments. With 2.21, now it is. Scaling a deployment to 0 replicas will result in the application being stopped, and you can then scale it back up at a later date to start it again.

**Added option to disable stacks for Kubernetes (BE/CE)**

When deploying an application on Kubernetes, we provide the ability to define a “stack” that your deployment belongs to, which can be useful for grouping deployments. However, this functionality may not always be ideal for everyone’s workflow, so in 2.21 we’ve added the option to disable stack functionality for Kubernetes environments.

These are the major new features and changes in 2.21. For a full list of changes, please refer to our [release notes](https://docs.portainer.io/release-notes).

[A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.](https://www.portainer.io/blog/author/james-carppe)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-2.17-release
title: Portainer 2.17 is now available
author: James Carppe
url: https://www.portainer.io/blog/portainer-2.17-release
hostname: portainer.io
description: Portainer 2.17 and 2.17.1 (patch) are now available. This version includes backup to S3-compatible providers, rolling restarts for Kube, remote updates for Edge devices, and more.
sitename: PORTAINER.IO
date: 2023-02-07
categories: []
tags: []
image: https://www.portainer.io/hubfs/2.17-featured.jpg
pagetype: article
filedate: 2025-01-18
-->

Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our [Portainer Features page](/features)*. *

Portainer version 2.17 includes a number of new features, fixes and updates. I've outlined the big ones below.

Top 10 Reasons to Upgrade to 2.17.1

[Relative path support for Git stacks](#relative-path-support-for-git-stacks)[Back up Portainer to S3-compatible providers eg. MinIO](#back-up-to-s3-compatible-providers)[Log viewer improvements](#log-viewer-improvements)[GitHub Container Registry (GHCR) support](#github-container-registry-support)[Rolling restart for Kubernetes applications](#rolling-restart-for-kubernetes-apps)[Direct YAML editing in Portainer](#direct-yaml-editing-in-portainer)[Enforce code-based deployment on Kubernetes clusters](#enforce-code-based-deployment)[Edge devices moved to home page](#move-edge-devices-to-home-page)[Remote update of Edge Agents](#remote-update-of-edge-agents)[Browse Edge devices that are deployed in async mode](#browsing-async-environments)

**Back up Portainer to S3-compatible providers (BE)**

Portainer Business Edition has long provided the ability to back up your Portainer config to an AWS S3 bucket. In 2.17 we've [expanded this support](https://docs.portainer.io/admin/settings#backup-portainer), by popular demand, to S3-compatible providers such as MinIO. As long as your provider is S3-compatible, you should now be able to use them with Portainer.

**Log viewer improvements (BE)**

[log viewer interface](https://docs.portainer.io/user/docker/containers/logs), improving the usability of the viewer as well as the search and filter capabilities, ANSI color support, full screen viewing and more. You'll find this updated interface wherever the log viewer is used in Portainer.

**Relative path support for Git stacks (BE)**

Often when deploying a stack you'll want to pre-populate your container's file system from your Git repository into pre-defined relative paths. 2.17 adds support for this with [a toggle on your stack deployment](https://docs.portainer.io/user/docker/stacks/add#relative-path-volumes), letting you spin up a stack and copy the necessary files into directories on your host automatically.

**Upgrade from CE to BE (CE)**

Upgrading from the Community Edition of Portainer to the Business Edition has in the past needed you to jump into the command line and redeploy your Portainer installation, but now in 2.17 you can do this [right from the Portainer UI](https://docs.portainer.io/start/upgrade/tobe/inapp). You can bring your own license key or sign up for a free trial, and Portainer will handle the upgrade for you automatically, getting you up and running on BE without any hassle.

**GitHub Container Registry (GHCR) support (BE)**

We've now added the GitHub container registry to our list of supported registry providers in 2.17. This lets you [connect to and browse your GitHub registry](https://docs.portainer.io/admin/registries/add/ghcr) directly from within Portainer, as well as deploy containers from images stored there.

**Kubernetes Management - new features in 2.17**

**Rolling restart for Kubernetes applications (BE)**

In the Kubernetes realm, we've added a [rolling restart](https://docs.portainer.io/user/kubernetes/applications/inspect#actions) option to your deployments. Instead of terminating all your pods and restarting them from scratch when doing an update, you can now instead do a rolling restart of your application, reducing downtime. This is available via the Portainer UI as well as via an option [on your application webhook](https://docs.portainer.io/user/kubernetes/applications/webhooks), which means it can be used in your deployment automation.

**Improved Kubernetes defaults (BE/CE)**

We've made some changes to the default [cluster configuration](https://docs.portainer.io/user/kubernetes/cluster/setup) in version 2.17 to more align with sensible standards. This includes automatically detecting new ingress controllers and the presence of the metrics API, as well as auto enabling storage options set as default in the cluster. These apply only clusters that you've newly added to Portainer - your existing clusters won't have their settings changed.

**Direct YAML editing in Portainer (BE)**

Since the beginning, you've been able to view the YAML for your Kube deployments in Portainer, but in 2.17 you can now make changes to that YAML straight from the UI. Portainer uses the Kubernetes patch mechanism to apply these changes, so if you need to make a quick adjustment to a deployment you can jump straight into the YAML and get it done.

**Enforce code-based deployment (BE)**

In 2.17 we've added the option, by popular demand, for cluster admins to [enforce code-based deployment](https://docs.portainer.io/admin/settings#deployment-options) on their Kubernetes clusters, disabling the use of the form-based deployment approach. This restriction can be applied globally or on a per-cluster basis. This is to help provide admins with greater control over how applications are deployed and managed on their clusters.

**Enforce admin-only ingress creation (BE)**

Along the same vein, 2.17 adds an option to [restrict ingress creation](https://docs.portainer.io/user/kubernetes/cluster/setup#only-allow-admins-to-deploy-ingresses) to admins only. With this option on, non-admin users will still be able to use ingresses configured in the cluster, but won't be able to deploy new ones.

[Edge Device Management](/iiot-edge) - New features in 2.17

**Move Edge Devices to the home page (BE/CE)**

In the Edge sphere, one of the big changes in 2.17 is moving of Edge Devices to the [home page](https://docs.portainer.io/user/home) view alongside the traditional Portainer environments. This gives you a more unified view of your infrastructure than before, making it easier to use and manage your setup no matter what type it is.

**Browsing async environments (BE)**

Now that Edge Devices are on the home page, we've also added the ability to browse Edge devices that are deployed in async mode as you would a traditional environment. You can [browse your environment](https://docs.portainer.io/admin/settings/edge/devices#browsing-your-edge-device) as you would any other in Portainer. This is based on the use of snapshots, so what you're seeing will depend on how recent your snapshot is.

**Remote update of Edge Agents (BE)**

2.17 also introduces the ability to remotely update your Edge Agent deployments from within Portainer, removing the need to connect to each environment individually when a new version comes out. You can [schedule an update](https://docs.portainer.io/admin/environments/update) across multiple devices at a time that suits you, and Portainer will handle the rest. There are some limitations with this feature at the moment and it is considered a beta, so bear that in mind when trying it out.

**Pre-pull images on Edge devices (BE)**

When deploying an Edge stack across a number of devices, you may want to pre-pull your images to the device to make sure they get there before you deploy. In 2.17 we've added the [option to pre-pull images](https://docs.portainer.io/user/edge/stacks#pre-pull-images) on Edge stack deployments, and when enabled Portainer will pull all the needed images to the remote environment and ensure they have been pulled successfully before starting the stack, and will let you know if it wasn't able to do so. This should improve the reliability and stability of your Edge stack deployments.

These are the major new features and changes in 2.17. For a full list of changes, please refer to our [release notes](https://docs.portainer.io/release-notes).

Need more than 3 nodes?[Talk to our friendly sales team](/contact-sales) to ask about pricing for your use case.

Ready to Upgrade?

Follow the [instructions in our documentation](https://docs.portainer.io/start/upgrade) to upgrade Portainer.

[A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.](https://www.portainer.io/blog/author/james-carppe)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-2.15-release
title: Portainer 2.15 - a new UI, GPU support, pod security policies and more
author: James Carppe
url: https://www.portainer.io/blog/portainer-2.15-release
hostname: portainer.io
description: Portainer 2.15 is now available. It includes a brand new UI, support for GPUs in Docker, Kubernetes pod security policies and other features and fixes.
sitename: PORTAINER.IO
date: 2022-09-05
categories: []
tags: []
image: https://www.portainer.io/hubfs/Portainer%202.15%20-%20a%20new%20UI%2c%20GPU%20support%2c%20pod%20security%20policies%20and%20more.png
pagetype: article
filedate: 2025-01-18
-->

Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our [Portainer Features page](/features)*. *

Portainer version 2.15 includes a number of new features, fixes and updates. For a full list of changes, please refer to our [release notes](https://docs.portainer.io/release-notes).

**New look UI**

The first thing you'll see when using 2.15 is that things look a bit different. Our design and frontend teams have been working hard to make the UI more organized across the board, with a modern, more consistent style and behavior, so that it's easier for you to learn, use, and master Portainer.

While this is a big change, we've made sure to keep most things where they are, so you won't have trouble using Portainer with the new look.

This is the first step of many UI improvements that are on the way, so keep an eye out for those in future releases. We'd also love to get your feedback on the new look, so let us know what you think.

**GPU support for Docker**

2.15 brings support for GPUs to our Docker implementation. Now using Portainer you're able to attach GPUs to containers to take advantage of their processing power for workloads like machine learning. You can make GPUs available to your environments and then select the GPUs to attach to a container and configure the capabilities you require.

At the moment this is only available to Docker Standalone installations, but we're hoping to expand this to other platforms in the future.

It's also worth noting that much of this particular feature came about because of a community contribution to Portainer, so if you'd like to see a feature in an upcoming version and you have some development skills, have a look at how you can [contribute to Portainer](https://docs.portainer.io/contribute/contribute).

**Kubernetes per-environment security constraints**

When you're sharing an environment between teams, you might want to restrict the access each pod has to limit risks. In Kubernetes you can achieve this using pod security policies, and now with 2.15 you can apply and manage these policies directly in Portainer. For example, you can restrict running containers as privileged, define the allowed host ports, volume types, file system paths, and much more.

Policies are applied on a per-environment basis using the popular and trusted [Open Policy Agent](https://www.openpolicyagent.org/) engine using the [OPA Gatekeeper](https://github.com/open-policy-agent/gatekeeper), which Portainer will install and configure for you if it doesn't already exist.

**Improved Edge Agent async functionality**

There's more improvements to our async functionality for Edge Agents in 2.15. You're now able to list the containers and their running status for Edge Stacks within Portainer, as well as get log files for your Edge Stacks.

**Nomad live browsing**

In 2.15 we've extended our Nomad support further by adding live browsing of your Nomad environment in Portainer. Before this, your view in Portainer was based on the latest snapshot and not live data, but now in 2.15 you're seeing up to date information in the UI while the tunnel between the Nomad Edge Agent and the Portainer Server is open.

**New image notification for private registries**

2.14 added the new image notification feature for public registries, which has been hugely popular. In 2.15 we've expanded this feature to cover private repositories as well, so as long as Portainer knows how to connect to your registry you'll be able to see at a glance whether your containers are running up to date images.

**More usability improvements**

Along with the new look, we've made some usability changes to the home page. You can now filter your environments by connection type, for example Agent, Edge Agent, or API, and you can also see the version of the Portainer Agent running on each environment - a good way to tell if all your environments are running the latest version of the agent.

We've added search to all our Web Editor fields in this release - hit Ctrl-F (or Cmd-F if you're on a Mac) and you're able to search the contents of the field. The search also supports regular expressions. This also came about from a community contribution.

You can now also click the version number in the bottom left of the Portainer UI to show more details about the version of Portainer you're running. We'll often ask for this when trying to troubleshoot an issue, so we've made it easier for you to find when you need it.

**Dependency updates and Kompose deprecation**

We've updated a number of our third-party dependencies in this release for new functionality and bug fixes. We're also looking at deprecating our Kompose support in a future release, so if you're using that you might want to look at moving to YAML manifests instead.

Ready to Upgrade?

Follow the [instructions in our documentation](https://docs.portainer.io/start/upgrade) to upgrade Portainer.

[A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.](https://www.portainer.io/blog/author/james-carppe)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-2.16-release
title: Portainer 2.16 is now available
author: James Carppe
url: https://www.portainer.io/blog/portainer-2.16-release
hostname: portainer.io
description: Portainer 2.16 is now available. It includes improvements to ingresses, git creds storage, notification logs, async browsing and other features and fixes.
sitename: PORTAINER.IO
date: 2022-10-31
categories: []
tags: []
image: https://www.portainer.io/hubfs/2.16-featured.jpg
pagetype: article
filedate: 2025-01-18
-->

Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our [Portainer Features page](/features)*. *

Portainer version 2.16 includes a number of new features, fixes and updates. I've outlined the big ones below.

**Improvements to ingresses**

Ingresses in Kubernetes can be complicated to set up, especially when you consider the different types of ingresses available. In version 2.16 of Portainer we've done a lot of work around our ingress support, adding auto detection of ingress controllers, support for types other than nginx and traefik, as well as support for TLS. We've also moved the setting of hostnames and annotations out of the namespace level, making it easier to configure and manage these for IT admins.

**Git credential support**

If you're deploying your applications from private Git repositories, you might have found it frustrating to have to enter your credentials for each stack or app you deploy. In 2.16 we've added a Git credential manager, letting you save credentials and use them when adding deployments. These credentials are only available to the user that added them, so there's no issues with other users having access to your creds.

**Notification log**

Sometimes when you do things like deploy a container or make a config change in Portainer, you'll get a notification pop up in the top right corner. In case you miss the notification or you want to go back and see the notifications you've had, we've now added a notification log in Portainer Business Edition. You can either select Notifications from the left hand menu, or click the bell icon in the top right of any page to see the log.

**Remote commands on async Edge devices**

When you're running your Edge devices in async mode, before now you haven't had the ability to run remote commands on the individual devices. In 2.16 we've added this functionality, letting you browse your device as well as run commands like start, stop, restart, and delete on your containers, stacks and volumes.

**Uploading local files when building images**

When you're building a new container image, sometimes you might need to include custom files such as a config file. When building from a Git repository or a tar file you can just include that file along with it, but if you're writing the Dockerfile directly in Portainer you haven't had the option before. In 2.16 we've added the ability to upload local files to use in your image builds. Just click the Select files button in the Upload section to add your files, then you can reference them in your Dockerfile.

**Logging standardization**

We've made some changes to how we do logging in Portainer in 2.16. In this version, we've moved to using the [zerolog](https://github.com/rs/zerolog#zero-allocation-json-logger) standard for Portainer's logs, as part of larger standardization work we're doing. For the most part this won't affect you much, but this should make it easier to identify issues with your installation.

**Kubernetes secret types**

We've expanded the types of secrets that can be created through Portainer in version 2.16. Before now we only supported the Opaque secret type, but we've now got support for the built in secret types as well as the ability to create your own custom type. When you're creating a secret, simply choose the type from the dropdown menu.

**Shared memory size support**

In 2.16 we've added the ability to define the shared memory size for individual Docker containers through the Portainer UI. You can set this through the Advanced container settings section when creating or editing a container.

**Login screen message**

When you're using Portainer in a larger organization you might have a requirement to display a message to all users at the login screen before they log in. In 2.16 we've added a field to let admins set this message through the Portainer UI.

**Context-sensitive help**

On each page of the Portainer UI you'll find a question mark icon in the top right. In 2.16, clicking on this icon will take you to the documentation for the page you're currently on, making it easier to find the answers you're looking for. This is the first step of improvements we're making to our in-app documentation, so look out for more of this in future releases.

These are the major new features and changes in 2.16. For a full list of changes, please refer to our [release notes](https://docs.portainer.io/release-notes).

Ready to Upgrade?

Follow the [instructions in our documentation](https://docs.portainer.io/start/upgrade) to upgrade Portainer.

[A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.](https://www.portainer.io/blog/author/james-carppe)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-2.19-release
title: Portainer Latest Version - 2.19 is now available
author: James Carppe
url: https://www.portainer.io/blog/portainer-2.19-release
hostname: portainer.io
description: Portainer Latest Release - 2.19 is now available, with improved performance and update processes, GitOps for Edge, MicroK8s cluster management and more.
sitename: PORTAINER.IO
date: 2023-08-31
categories: []
tags: []
image: https://www.portainer.io/hubfs/Portainer%20YT%20Thumbnail%20%282-19%20release%20video%20-v1%29.png
pagetype: article
filedate: 2025-01-18
-->

Portainer version 2.19 includes a number of new features, fixes and updates. I've outlined the big ones below.

**Improved page load performance (BE/CE)**

We've made more improvements to page load performance in this release, in particular around the Kubernetes applications page. We've also split the [ConfigMaps & Secrets](https://docs.portainer.io/user/kubernetes/configurations) page into two tabs that load separately, which should reduce load time when you have a large amount of either. There's still more work to be done here, so you can expect more improvements in the future.

**Update Portainer from within Portainer (BE)**

Having to drop out to the command line to update Portainer when a new version comes out has always been a bit of an annoyance, and in 2.19 we've got rid of that for BE users by letting you [update to the latest version](https://docs.portainer.io/start/upgrade#from-within-portainer) right from within the Portainer UI. Admin users will see a notice and a link they can click on to upgrade Portainer to the latest version, without needing to do it manually.

**Stack versioning and rollback (BE)**

When using stacks in Portainer, you may sometimes make a change that doesn't quite work as you expect. With 2.19, we've added [stack versioning](https://docs.portainer.io/user/docker/stacks/edit#editing-a-stack) to Portainer, which lets you keep a record of your previous stack configuration when deploying an update.

If you run into issues, you can roll back to the previous stack configuration that Portainer kept for you. This is available for both Docker Standalone and Docker Swarm stacks.

**GitOps for Edge Stacks (BE)**

Way back in version 2.10 of Portainer we added GitOps support for stacks, letting you deploy from a Git repo directly onto your environment. In 2.19, we've brought that support to Edge Stacks as well, meaning you can [use Git as the source of truth](https://docs.portainer.io/user/edge/stacks/add#gitops-updates) for your Edge Stack deployments. This includes support for webhooks to trigger updates on your Edge Stacks, relative path support, and support for environment variables.

As part of this we've also introduced an [Edge Configurations](https://docs.portainer.io/user/edge/configurations) section. This feature lets you pre-deploy configuration files to your Edge devices, either by group or by specific device identifier, to a location that your stacks will be able to refer to. This means you can keep your Edge stack repos thin and performant, while still letting you provide the necessary config files to get your app up and running.

**Staggered deployment for Edge Stacks (BE)**

If you've got a large number of Edge Devices you're deploying to, you might not always want to push an update to every one of them at once, in case something goes wrong. With 2.19 you can now [stagger your Edge Stack deployments](https://docs.portainer.io/user/edge/stacks/add#update-configurations) to suit your needs.

You can either choose a static number of devices to update concurrently, or update your deployment exponentially in growing groups. You can set the timeout and delay for your deployments, and choose how to act if the update fails, including whether to roll back to the previous version.

**Edge Stack status improvements (BE)**

Alongside the staggered deployment functionality, we've also put some work into improving the way we display the [status of your Edge Stacks](https://docs.portainer.io/user/edge/stacks).

We've moved to using progress bars to display the amount of deployments at each status, letting you clearly see the state of your Edge Stack across your devices. We've also added a record of when each device reached each status through the Environments tab on the Edge Stack's details page, as well as the target and deployed versions of the Edge Stack as part of the new stack versioning feature.

**Improved MicroK8s cluster management (BE)**

In version 2.18 we added provisioning of MicroK8s directly on to fresh machines from within Portainer. In 2.19 we've extended the functionality around [managing MicroK8s environments](https://docs.portainer.io/user/kubernetes/cluster#microk8s-cluster-management) deployed this way, adding support for upgrading, scaling and deleting nodes in the cluster, the enabling and disabling of addons after provisioning, as well as being able to customize arguments for your addons.

You can also now specify which nodes should be control planes when provisioning, and we've refreshed the provisioning workflow to take advantage of the new functionality.

**Annotation support for services (BE)**

Portainer now supports [configuring annotations for Kubernetes services](https://docs.portainer.io/user/kubernetes/applications/add#publishing-the-application) from the UI, alongside the other areas that already supported annotations in previous versions.

Annotations are particularly useful when configuring service meshes and other tools.

**Auto deploy a manifest to new environments (BE)**

When you're deploying a new Kubernetes environment, you may want to run an "initial setup" manifest on the environment to get it configured the way you want it. With 2.19 you can now specify a manifest to automatically deploy when you [provision](https://docs.portainer.io/admin/environments/add/kaas) or [create](https://docs.portainer.io/admin/environments/add/kube-create) a new Kubernetes environment or [add the Portainer Agent](https://docs.portainer.io/admin/environments/add/kubernetes/agent) to an existing Kubernetes cluster.

This lets you pre-configure things like namespaces, secrets and anything else you need automatically.

**Support requiring notes on applications (BE)**

In larger organizations (and even smaller ones), if you have a lot of deployments it might be hard to keep track of what each one is for. In 2.19 we've added a configuration option to [enforce the setting of notes](https://docs.portainer.io/admin/settings#deployment-options) on new deployments.

Using this you can require that your team adds a description to every deployment they push out, making it easier to find detail on the deployment down the line.

These are the major new features and changes in 2.19. For a full list of changes, please refer to our [release notes](https://docs.portainer.io/release-notes).

Start your Journey Today

Our [Getting Started Page](/get-started) is the best place to start.

Ready to Upgrade?

Follow the [instructions in our documentation](https://docs.portainer.io/start/upgrade) to upgrade Portainer.

[A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.](https://www.portainer.io/blog/author/james-carppe)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-2.18-release
title: Portainer 2.18 is now available with improved performance, MicroK8s cluster creation, and more.
author: James Carppe
url: https://www.portainer.io/blog/portainer-2.18-release
hostname: portainer.io
description: Portainer 2.18 is now available. Discover improved performance, MicroK8s cluster creation, expanded snapshot functions and more.
sitename: PORTAINER.IO
date: 2023-04-18
categories: []
tags: []
image: https://www.portainer.io/hubfs/2.18-featured.jpg
pagetype: article
filedate: 2025-01-18
-->

Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our [Portainer Features page](/features)*. *

Portainer version 2.18 includes a number of new features, fixes and updates. I've outlined the big ones below.

**Improved page load performance (BE/CE)**

One of the first things you might notice in 2.18 is a snappier UI. We've made a number of changes to the Portainer interface in this version to improve load times across the board, with some specific changes around the number of notifications displayed, adding the ability to disable GPU functionality on environments where it isn't needed, and streamlining the environment API calls made throughout the app, in particular for Kubernetes environments.

We'll be continuing to look for areas where we can improve performance, so look out for more of this in future releases.

**MicroK8s cluster creation (BE)**

In the Kubernetes space, 2.18 brings the ability to [provision and configure a MicroK8s Kubernetes cluster](https://docs.portainer.io/admin/environments/add/kube-create) directly onto fresh machines, straight from the Portainer interface. All you'll need is SSH access to the machines and you're good to go. Provide one or more IP addresses of your servers, choose the version of MicroK8s to install and select any addons you require, and optionally select a custom application template to deploy once your cluster is created.

Portainer will install MicroK8s, configure the cluster and deploy the Portainer Agent for you, getting you up and running on Kubernetes as painlessly as possible.

**Expanded annotation support (BE)**

In 2.18 we've expanded our support for adding Kubernetes annotations to resource types through the UI. You can now add annotations through the Portainer interface for namespaces, application deployments, ConfigMaps and secrets, with support for services coming in a future release.

**Kubernetes services view (BE/CE)**

In this release we've added a new [Services](https://docs.portainer.io/user/kubernetes/services) page to Kubernetes environments, which lists the services deployed on your cluster along with detail about each service, for example the application and namespace the service belongs to, the type of service, and any ports and IPs assigned to the service.

**Edge Agent Standard and Async (BE/CE)**

In the Edge arena, we've continued on from the work in 2.17 to bring Edge Devices in alongside standard Edge Agent deployments. In 2.18 we've split Edge Agent provisioning into two types - Edge Agent Standard for the traditional Edge Agent environment deployment, and Edge Agent Async for asynchronous deployments.

When [adding an environment](https://docs.portainer.io/admin/environments/add) you'll be able to choose between the two options so you can be sure you're deploying the configuration you need.

**Expanded snapshot functionality (BE)**

In more expansion of 2.17's features, Portainer's [snapshot functionality](https://docs.portainer.io/user/home/snapshot) for async Edge Agents now lets you browse even more of your environment from the snapshot, including container status, volume, image and stack listing, and the ability to stop, start, restart and kill containers as needed. You'll also be able to see more detail including which images and networks are in use as well as environment variable details.

**mTLS specific certificate support (BE)**

Previously when deploying Edge Agents using mTLS you were restricted to using the same TLS certificate for both the Portainer user interface and your mTLS deployment. In 2.18, you can now [choose a specific set of certificates for mTLS use](https://docs.portainer.io/admin/settings/edge#mtls-certificate), separate from the one used for Portainer itself. This is particularly useful when you have separate domains for access to Portainer and for your Edge Agent communications.

**Edge Stack retry policy (BE)**

2.18 sees the addition of a [retry policy](https://docs.portainer.io/user/edge/stacks#retry-deployment) for your Edge Stacks. With retry deployment enabled, Portainer will keep trying to redeploy your stack if it runs into deployment errors. This helps to avoid failed deployments when a connection to the edge device may be unstable or unreliable.

These are the major new features and changes in 2.18. For a full list of changes, please refer to our [release notes](https://docs.portainer.io/release-notes).

Need more than 3 nodes?[Talk to our friendly sales team](/contact-sales) to ask about pricing for your use case.

Ready to Upgrade?

Follow the [instructions in our documentation](https://docs.portainer.io/start/upgrade) to upgrade Portainer.

[A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.](https://www.portainer.io/blog/author/james-carppe)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-2.14-now-with-kubernetes-provisioning-on-amazon-eks-google-gke-and-azure-aks
title: Portainer 2.14 - now with Kubernetes provisioning on EKS, GKE, and AKS
author: James Carppe
url: https://www.portainer.io/blog/portainer-2.14-now-with-kubernetes-provisioning-on-amazon-eks-google-gke-and-azure-aks
hostname: portainer.io
description: Portainer 2.14 is here. It includes a raft of new features including the ability to create Kubernetes clusters in Amazon EKS, Google GKE, and Azure AKS.
sitename: PORTAINER.IO
date: 2022-06-29
categories: []
tags: []
image: https://www.portainer.io/hubfs/Portainer%20new%20release%20.png
pagetype: article
filedate: 2025-01-18
-->

Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our [Portainer Features page](/features)*. *

Portainer version 2.14 is now available in both Community Edition and Business Edition. It includes a number of changes and updates as well as some new Business Edition-specific features. For a full list of changes, please refer to our [release notes](https://docs.portainer.io/release-notes).

**New Kubernetes-as-a-Service providers**

In 2.13 we introduced support for provisioning Kubernetes clusters directly from Portainer on [Civo, Linode and DigitalOcean](/blog/portainer-announces-kubernetes-provisioning-on-digitalocean-linode-and-civo). In this release, we've expanded that even further to include Amazon EKS, Google GKE, and Azure AKS. We've also refreshed the cloud credentials interface as part of this work, as well as updated our documentation with examples of how to retrieve the necessary credentials for specific providers.

**Import your existing Kubernetes environment**

We've long supported deploying the Portainer Agent to existing Kubernetes environments, but with 2.14 we've made this even easier with the ability to import your kubeconfig file directly into Portainer, and have Portainer automatically configure access and deploy the agent for you. This works with both cloud providers and on-premise Kubernetes installations.

**Add Environment Wizard**

When you first install Portainer you're presented with the environment wizard, allowing you to add the environments you wish to manage, but after that you'd use our traditional interface to add more. In 2.14 we've improved the environment wizard and brought it in to be used at any point to add new environments.

**Out of date image indicators**

Version 2.14 adds a new column to the containers, stacks and services listings which will let you know whether an image used is up to date or if there's a new version available. This lets you easily tell which containers, stacks or services you need to update.

**Improvements to custom templates**

App Templates are a powerful feature for system administrators, letting you set up templated applications for users to easily deploy. In 2.14 we've extended our custom templates to let you easily create tags within your templates that a user can later fill in when deploying the template, allowing for much more customization of the individual deployment.

**Environment variable support for webhooks**

Along the same lines as the custom templates changes, we've also added support for environment variables to be passed over webhooks in 2.14. Using this, you can customize your triggers to provide custom information to Portainer that it can use alongside the redeployment.

**Reworking the Team Leader role**

We've spent some time reworking our existing Team Leader role in 2.14, fixing a few bugs and expanding the capabilities of the role. Team Leaders can now add and remove members from teams as well as promote members to co-team leaders.

**Adjustable password length requirements**

In 2.13 we introduced password strength requirements to Portainer. In this version, we've taken on the feedback that you've provided and made these requirements adjustable by administrators. An admin can now set the minimum length required for a password, and users that don't meet the requirements will be asked to update the passwords when they next log in, with the option to defer the change a couple of times before being required to make the change. We also removed the complexity requirements and just restrict on length.

**Dependency updates**

We've updated a number of our third-party dependencies in this release, including docker, docker-compose, helm and kubectl. One specific thing to note is that this adds docker-compose version 2 support to Portainer.

[A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.](https://www.portainer.io/blog/author/james-carppe)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-2.20-release
title: Portainer 2.20 STS is now available
author: James Carppe
url: https://www.portainer.io/blog/portainer-2.20-release
hostname: portainer.io
description: Portainer version 2.20 STS is now available - the first in our new STS and LTS release process. Find out more about this and the release itself.
sitename: PORTAINER.IO
date: 2024-03-19
categories: []
tags: []
image: https://www.portainer.io/hubfs/2.20-release-meta.png
pagetype: article
filedate: 2025-01-18
-->

Portainer version 2.20 includes a number of new features, fixes, and updates. It also signals the beginning of our new STS and LTS release process. Read on for more about this and the release itself.

**Portainer and STS / LTS**

As discussed in the [blog post](https://www.portainer.io/blog/2024-release-principle) from our CEO Neil, we're moving to a new release process for Portainer. In short, we now intend to ship two different types of releases: Short-Term Support (STS) and Long-Term Support (LTS) releases. Portainer version 2.20 is the first of our Short-Term Support releases.

A Short-Term Support release can be considered as "bleeding-edge" as it will contain the latest features and functionality we've developed. The STS releases (including this one) will go through a significant amount of pre-release testing, but there may be changes that could cause regressions and features that might see further iterations. As such, if stability is a crucial concern for your setup we wouldn't recommend deploying STS releases on production environments.

Long-Term Support releases, on the other hand, will not contain new features and will be focused on stability. We'll be taking what we added in the previous STS release, comprehensively testing for issues and regressions, and supplying what we consider production-ready LTS images. The LTS images will be our recommended images, and version 2.21 is planned to be our first LTS release.

As part of this we're also changing the way we tag our images. The `:latest`

tag will now only be updated with LTS releases instead of every release. Since 2.20 is a STS release, the `:latest`

tag will remain pointing to 2.19.5.

#### How do I deploy 2.20 STS on my environment?

To deploy 2.20, you will need to use the version-specific `:2.20.3`

tag. As above. `:latest`

will remain pointing to 2.19.5 so you'll want to adjust your commands accordingly. For specific instructions on installing or updating Portainer on your environments, refer to our [documentation](https://docs.portainer.io/v/2.20/start/upgrade). You can also use the new `:sts`

tag to use 2.20 and upcoming STS releases.

When you do update to 2.20 however, make sure you take a backup first! If you run into issues and need to drop back to 2.19.5, you'll need this to restore your installation, so note any changes you make to your setup if rolling back.

#### Feedback encouraged

Lastly, we want your feedback on this release! Releasing 2.20 as a STS release lets you get in there, test out the changes, and let us know your thoughts on them. The more feedback we have on 2.20, the better our 2.21 LTS release will be, so if you run into any issues or have any thoughts about the new features, get in touch through our normal feedback channels: [GitHub issues](https://github.com/portainer/portainer/issues) for bug reports, [discussions](https://github.com/orgs/portainer/discussions) for general feedback and help, and for our commercial customers [via our success team](https://share.hsforms.com/1CGApq5VOSaO8WI8rtqVeEA2tf8f).

Now that we have that covered, let's talk about what's new in 2.20!

### New Features

**New menu structure (BE/CE)**

The first change you're likely to notice in 2.20 is an update to the menu structure within Portainer. In order to streamline the user experience for people that are new to containerization, as well as those more experienced, we've updated the names of some menu items, moved others into new subsections, and generally made it easier to understand where to find the functionality you're after. This is particularly evident for Kubernetes environments, but applies to Portainer as a whole as well.

**More performance improvements (BE/CE)**

Our ongoing efforts to improve the performance of Portainer continue in this release. Along with the updated menu structure we have implemented additional caching to improve page load times as well as moved more of our pages and page components to the React framework. We've also added more background population of page contents so that rendering the crucial information comes first with additional longer-to-retrieve information being loaded asynchronously.

For Kubernetes users, we've added a per-user toggle to enable front-end data caching for Kubernetes environments that can also help with page load times. This is configurable through the My account page.

**Support for streaming Portainer activity and auth logs to external systems (BE)**

When deploying Portainer within your organization you may have the desire or perhaps compliancy need to ship your log files to an external log aggregator. In 2.20 BE we've added the ability to push Portainer's activity and authentication logs in syslog format to an external Security Information and Event Management (SIEM) system without having to write a custom wrapper around the Portainer API.

At present this feature is considered experimental and is configurable via CLI options, but we're intending to expand this feature further in the future based on customer feedback.

**Buttons to reload image update indicators (BE)**

Our new image indicator feature has been quite popular since we released it way back in 2.14, and we've made a few adjustments to it in subsequent versions. In 2.20 we've added in buttons on the Containers, Stacks, and Services list pages, as well as the details page for each, that will perform an on-demand reload of the image status for the page you're on.

Image indicators are cached for 24 hours after they are loaded for performance reasons, but with these buttons you can force a check at any time you need one.

**List and manage more Kubernetes object types (BE)**

We've expanded the types of Kubernetes objects you can list and manage through Portainer in 2.20. In this version, admins will see new pages for Service Accounts, Cluster Roles and Cluster Role Bindings, and Roles and Role Bindings under the new More Resources menu item.

**Enforce admin-only Kubernetes secret viewing in the UI (BE)**

As a cluster administrator you may want to restrict the viewing and editing of secrets within the cluster to administrator users. In 2.20 we've added a toggle that allows you to do just that.

Note that due to limitations within Kubernetes itself, this feature does not hide secrets from viewing through other tools outside of Portainer.

**Templates for Edge (BE)**

Template functionality has existed in Portainer for non-Edge environments for some time, and in 2.20 we're bringing that functionality to Edge Stacks. With Edge Compute enabled, you'll find a new Edge Templates option in the left-hand menu. Here you can deploy an Edge Stack from our pre-provided templates, or create and manage your own custom Edge Stack templates for your applications.

Edge Templates support the same functionality as our non-Edge templates, including variables and Git repository deployments, and can also be deployed from the Create Edge stack page.

**New Edge Administrator role (BE)**

2.20 also introduces a new Edge administrator role for Edge Compute users. This role lets you give users full control over resources in Edge environments without giving them full administrative access to all of Portainer.

### Enhancements and Fixes

**Updated third-party binaries and libraries (BE/CE)**

As we do with every release, we've updated the versions of the third-party binaries and libraries that we use within Portainer to newer versions. This resolves a number of reported CVEs as well as providing improved performance and functionality in some cases.

**Support for new Kubernetes versions (BE/CE)**

Along with updated binaries and libraries, we've also updated our Kubernetes version support in 2.20. We now support deploying to Kubernetes 1.27 and 1.28 environments in all cases, and 1.29 where it is available for particular platforms. This is for our supported cloud providers in our KaaS feature, our Kubernetes cluster creation tool for on-premise infrastructure, and for connecting of your existing environments.

**Consolidate Helm functionality into Applications (BE/CE)**

As part of our menu restructuring and general usability improvements, in 2.20 we moved the Helm functionality for Kubernetes environments into the Applications system proper, rather than the separate system we had before.

You can now provision applications from Helm charts via the standard Create from manifest option under Applications, and Helm deployments will appear in the Applications list alongside other non-Helm deployments. We've also made some improvements to how you can configure and manage your Helm chart repositories within Portainer.

**Allow stopping a Kubernetes app by scaling to 0 (BE/CE)**

Docker Swarm users have for a long time been able to scale their services to 0, but this wasn't possible in Portainer for Kubernetes deployments. With 2.20, now it is. Scaling a deployment to 0 replicas will result in the application being stopped, and you can then scale it back up at a later date to start it again.

**Added option to disable stacks for Kubernetes (BE/CE)**

When deploying an application on Kubernetes, we provide the ability to define a “stack” that your deployment belongs to, which can be useful for grouping deployments. However, this functionality may not always be ideal for everyone’s workflow, so in 2.20 we’ve added the option to disable stack functionality for Kubernetes environments.

These are the major new features and changes in 2.20. For a full list of changes, please refer to our [release notes](https://docs.portainer.io/v/2.20/release-notes).

[A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.](https://www.portainer.io/blog/author/james-carppe)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/author/james-carppe/page/2
title: Portainer News and Blog | James Carppe (2)
author: James Carppe May
url: https://www.portainer.io/blog/author/james-carppe
hostname: portainer.io
description: A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets. (2)
sitename: Portainer.io
date: 2022-05-16
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

### Blog Post by James Carppe

[
](https://www.portainer.io/blog/portainer-announces-kubernetes-provisioning-on-digitalocean-linode-and-civo)

James CarppeMay 16, 20221 min read

### Portainer announces Kubernetes provisioning on DigitalOcean, Linode and Civo

Learn how to spin up a Kubernetes cluster on Digital Ocean, Linode or CIVO using ...

Start Reading
[
](https://www.portainer.io/blog/pre-staging-edge-environments-with-portainer)

James CarppeMay 8, 20222 min read

### Pre-staging Edge environments with Portainer

Learn how to pre-load edge devices with a startup script to deploy the Portainer Edge ...

Start Reading
[
](https://www.portainer.io/blog/portainer-ce-and-be-2.13-are-here)

James CarppeMay 8, 20223 min read

### New Portainer CE and BE 2.13 - with Kubernetes provisioning

Learn what's new in Portainer CE and Portainer BE 2.13 - including Kubernetes ...

Start Reading

---
<!--
URL: https://www.portainer.io/blog/portainer-2.22-sts-release
title: Portainer 2.22 STS is now available
author: James Carppe
url: https://www.portainer.io/blog/portainer-2.22-sts-release
hostname: portainer.io
description: Portainer version 2.22 STS is now available - find out more about the STS release type and the release itself.
sitename: PORTAINER.IO
date: 2024-10-03
categories: []
tags: []
image: https://www.portainer.io/hubfs/2.22-sts-release-meta.jpg
pagetype: article
filedate: 2025-01-18
-->

Portainer version 2.22 STS includes a number of new features, fixes, and updates as part of our Short Term Support (STS) program. Read on for more about this and the release itself.

**Short Term Support (STS)**

2.22 is a Short Term Support, or "STS", release of Portainer. STS releases intended to be an introduction of new features and functionality in Portainer, and while we do perform significant testing prior to release are not recommended for production use. For production, we recommend staying with the Long Term Support (LTS) releases. The features that appear in STS releases will, once refined and stable, be implemented in the next LTS release.

You can read more about our release principles in our CEO Neil's [blog post](https://www.portainer.io/blog/2024-release-principle).

### New Features

**Podman support (BE/CE)**

Version 2.22 brings official Podman support to Portainer for the first time. While Podman has partially worked in previous versions, there have been some functionality and compatibility issues that we've worked to resolve in this release.

At present we support Podman 5.x on CentOS 9. While other versions of Podman on other Linux distributions may work, we have not fully tested outside of the above options as of yet.

**More performance improvements (BE/CE)**

Our ongoing efforts to improve the performance of Portainer continue in this release. In particular we've focused on the Kubernetes UI experience in 2.22, with all-around improvements to the snappiness of the Kubernetes-related functionality within Portainer.

**Two new Kubernetes security options (BE)**

In some circumstances an administrator may want to restrict access to certain functionality within Portainer from regular users, but still retain that functionality for administrator and environment administrator users if needed. In 2.22 we've added the option for administrators to disable the Kubernetes Config download option and/or the Kubernetes Shell functionality for non-admin users.

### Enhancements and Fixes

**Expanded ACI support (BE)**

This release brings improvements to our Azure Container Instance (ACI) support functionality. During creation you can now select a private virtual network, add tags, volumes, and GPUs. We've also expanded the management capabilities for your ACI workloads by adding stopping and restarting of ACIs as well as viewing of events related to those ACIs.

**Updated third-party binaries and libraries (BE/CE)**

As we do with every release, we've updated the versions of the third-party binaries and libraries that we use within Portainer to newer versions. This resolves more than 20 reported CVEs as well as providing improved performance and functionality in some cases.

These are the major new features and changes in 2.22. For a full list of changes, please refer to our [release notes](https://docs.portainer.io/v/2.22/release-notes).

[A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.](https://www.portainer.io/blog/author/james-carppe)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-and-docker-26
title: Portainer and Docker 26
author: James Carppe
url: https://www.portainer.io/blog/portainer-and-docker-26
hostname: portainer.io
description: On 20 March version 26 of Docker was released. There are a number of changes in this release to be aware of especially with older versions of Portainer.
sitename: PORTAINER.IO
date: 2024-03-28
categories: []
tags: []
image: https://www.portainer.io/hubfs/shutterstock_1394052911.jpg
pagetype: article
filedate: 2025-01-18
-->

On the 20th of March 2024, version 26.0.0 of Docker was released. There are a number of changes in this release to be aware of, with one in particular causing issues with older versions of Portainer. Version 2.20.3 of Portainer, [now available](https://docs.portainer.io/v/2.20/release-notes), includes fixes for the known incompatibilities with Docker 26 and above, and we plan to add full support for Docker 26+ in our next LTS release (2.21), due in mid-August.

#### What's the issue?

The specific issue manifests in being unable to view image details or access the container console when running Portainer on a Docker 26 and above environment. This is a result of the removal of the `Container`

and `ContainerConfig`

fields from the response of Docker's `GET /images/{name}/json`

API endpoint. Portainer's implementation relies on these fields existing in the response it receives from the Docker API, and as such an error is returned.

#### Why wasn't this prepared for?

These fields were flagged as deprecated in the previous Docker release (25.0.0), which was released in January 2024. Portainer 2.19.4 was released in December 2023, so before the deprecation notice was flagged in Docker 25. Because of this, we were unaware the fields were going to be deprecated and therefore were unable to prepare for it. For our 2.20 STS release, we based this off the 2.19.4 codebase so it is affected the same way.

It is worth noting that we publish a list of the supported versions of Docker (and Kubernetes) for each release on our [Requirements and Prerequisites](https://docs.portainer.io/start/requirements-and-prerequisites) page in the [Portainer documentation](https://docs.portainer.io). The versions we list there are versions we have tested Portainer against and can verify are functional. We recommend sticking to our supported versions where possible, especially in production environments.

#### Should I upgrade Docker?

Docker 26.0.0 was only a week old at the time of this initial post, and we would highly advise against upgrading to such a new version so quickly. However, we recognize that you will eventually need to upgrade, and we are working on fixes to resolve these errors. Portainer version 2.20.3, part of our [STS](/blog/portainer-2.20-release) release, contains fixes for the errors we've so far identified, and is available now. It is important to note that this patch does not provide certified complete support for Docker 26 and above - it is focused on resolving the breaking issues as described above. Full Docker 26+ support will be available in our next LTS release, 2.21 LTS, which we expect to release in mid-August.

If you have any questions around these issues or find other problems with Docker 26 and above you can reach out through our various [support channels](/get-support-for-portainer).

[A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.](https://www.portainer.io/blog/author/james-carppe)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/persistent-storage-docker-bind-mounts-and-named-volumes
title: Persistent Storage: Docker Bind Mounts and Named Volumes
author: James Carppe
url: https://www.portainer.io/blog/persistent-storage-docker-bind-mounts-and-named-volumes
hostname: portainer.io
description: In this first post in an ongoing series we look at persistent storage in Docker, specifically the difference between bind mounts and named volumes.
sitename: PORTAINER.IO
date: 2024-06-12
categories: []
tags: []
image: https://www.portainer.io/hubfs/shutterstock_1394052911.jpg
pagetype: article
filedate: 2025-01-18
-->

Persistent storage in containerization can be a complex topic to cover. In this first post in a series of blog posts, we'll be looking at persistent storage concepts in Docker, specifically the difference between bind mounts and named volumes.

### What is Persistent Storage?

Before we dive into the Docker specifics, let's look at what we mean by persistent storage.

Containers are intended to be "idempotent" - that is, you should be able to destroy a container and create a replacement without any data loss. When you have a basic container that performs an action, you often don't need to worry too much about persistent storage. However, once you start working with containers that *do* need to have data persistency (for example, a database), the idempotency of a container will start to become a problem. If you want to save entries to a database in your container, without persistent storage that data would be lost when the container is recreated.

Persistent storage provides an option to keep that data outside of the container, but still accessible by it, so that it can survive a container recreation.

### Docker and Volumes

In Docker, a volume is a way for a container to be given persistent storage for files that are outside of the image itself but need to remain through restarts of the container.

There are two primary types of volumes available in Docker: bind mounts and named volumes. Each type has it's own benefits and drawbacks, functioning in different ways externally but both appearing in the same way to the container's internal file system.

### Bind mounts

A bind mount is fairly straightforward - it is a way to mount a directory from the host machine into your container. You simply define the directory on your host system (for example, `/mnt/nginx`

) and the path where you'd like it to appear within your container's filesystem (for example, `/usr/share/nginx/html`

). That's it.

While simple, there are certain considerations you should keep in mind when using bind mounts. Because you are mounting your host filesystem into your container, your container has access to that filesystem. This could be a security issue if you're running an insecure or malicious container image. A bind mount is also managed outside of the Docker orchestrator, so you would need to ensure that the directory stays at that path, has the right permissions, and isn't modified unexpectedly by other processes on the host system.

### Named volumes

Named volumes, often simply referred to as "volumes", are Docker's answer to managed persistent storage. When you create a named volume, Docker builds a virtual file system that can then be attached to a container (or multiple containers) to serve as persistent storage. This virtual file system, while existing on the host, is managed by Docker itself. As such, you're not mounting the host filesystem directly into your container at all, unlike with a bind mount.

Named volumes are generally created independently of a container, as after all they are a separate object. In Portainer, this can be done through the Volumes page by clicking Add volume and filling in the details. You can find more information on this [in our documentation](https://docs.portainer.io/user/docker/volumes/add).

Once a named volume has been created, you can mount it to a container by selecting the volume and the path where you'd like it to appear within your container's filesystem (much like a bind mount above). Because the volume is referenced by a name rather than a path, this makes it more portable especially when you consider how different paths may work on different OSes and deployments.

Named volumes can also be created as part of a stack definition through the use of a separate `volumes`

section alongside the `services`

section you would use to define your containers. They can then be referenced in the `volumes`

subsection of your service definitions in the same YAML file.

There are of course cases where a named volume might not make sense - for example, if you had a directory with a large amount of files that you wanted to make available to other services outside of your container, but in many situations using a named volume can provide you with benefits that a bind mount cannot.

### What about network volumes?

Docker also supports the mounting of network volumes (such as NFS or CIFS shares) within a container, and these essentially work in a similar way to a bind mount in that you provide the source path (and often in the case of a network mount the necessary access credentials) and the path to mount within the container file system. Also much like bind mounts, network volumes are managed outside of Docker so don't have the benefits of named volumes.

### Learning more

For a more in-depth dive into persistent storage in Docker, have a look at our [Deploying on Docker with Portainer](https://academy.portainer.io/deploy/docker) course in the [Portainer Academy](/academy). There we work through the concepts of Docker including volumes, along with example deployments to get you understanding the concepts by employing them directly.

In the next post in this series we'll be building upon the basic concepts we've covered here for Docker and looking at how persistent storage applies to the world of Kubernetes.

[A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.](https://www.portainer.io/blog/author/james-carppe)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-agent-vs-edge-agent
title: Portainer Agent vs Edge Agent
author: James Carppe
url: https://www.portainer.io/blog/portainer-agent-vs-edge-agent
hostname: portainer.io
description: Struggling to understand the difference between the Agent and Edge Agent? This excerpt from our Best Practice Install Guide explains what each means and when to use each.
sitename: PORTAINER.IO
date: 2024-08-16
categories: []
tags: []
image: https://www.portainer.io/hubfs/Red%20Sneakers%20Asphalt%20Road.jpg
pagetype: article
filedate: 2025-01-18
-->

The following is an excerpt from the [Best Practice Install Guide](https://academy.portainer.io/install/) from the Portainer Academy which outlines the differences between the Portainer Agent and the Portainer Edge Agent. You can read the [full guide](https://academy.portainer.io/install/) and more in the [Portainer Academy](https://academy.portainer.io).

Portainer supports a number of different connection methods for adding environments, but in a production setup we highly recommend the use of the Portainer Agent to connect. The Portainer Agent is a lightweight container that runs on your environment and facilitates the communication between the environment and the Portainer Server instance. The Portainer Agent can be deployed in two different configurations: Agent and Edge Agent, with the primary difference being how they communicate with the Portainer Server instance.

#### Agent

In Agent mode, the Portainer Server instance initiates communication from itself to the Portainer Agent container. With this method you are interacting with your environment in real time.

This requires that the Agent listen on a specific port for connections so that the Server can connect. As such, we generally recommend the use of Agent mode only in private networks where exposing a port on the Agent is acceptable within your organization's security posture.

#### Edge Agent

In Edge Agent mode, the opposite occurs. The Agent periodically connects back to the Portainer Server instance to check if there are pending tasks to perform. As a result, there is no need to expose any ports on the Agent end, making the Edge Agent mode ideal for remote environments outside of your network, and requiring only that your Portainer Server be accessible from the Agent.

Because the Agent initiates the communication in Edge Agent mode, you don't necessarily have instant access to your environment initially. You can however use a reverse tunnel initiated by the Agent to provide this access. When you select an Edge environment to manage through the Portainer UI, behind the scenes the Portainer Server logs a request for a tunnel to be opened. When the Edge Agent next connects to the Portainer Server to check for updates, it will see the pending tunnel request and initiate the tunnel, providing you access to the remote environment. Because of this check in process, you may need to wait for your tunnel to establish. The check-in interval for Edge Agents defaults to every 5 seconds, but this can be adjusted to suit your needs.

#### Edge Agent Async

The Edge Agent can also be configured to run in Async mode. For the most part this mode works the same as the standard Edge Agent configuration, with the notable exception that the reverse tunnel functionality is not available. Environment status is available through the use of "snapshots" sent periodically from the remote environment to the Portainer Server. This means that Async mode is best suited for IoT and IIoT devices where direct interaction with the environment is not required, and instead there is a desire for very small amounts of data to be transmitted, which is helpful when there may be limited or intermittent connectivity with the remote device, or when your remote devices are connected over unreliable network connections.

As we've covered above, there are pros and cons for each deployment option. To summarize, your Agent deployment options are as follows:

Agent Type |
Comm. direction |
Pros |
Cons |
Best for |
|---|---|---|---|---|
| Agent | Server -> Agent |
Instant access |
Requires exposing port at the Agent | Environments on local / private networks |
| Edge Agent Standard | Agent -> Server | No exposed ports at the Agent Real-time management (on demand) |
Delayed real time access | Environments on remote networks |
| Edge Agent Async | Agent -> Server | No exposed ports at the Agent Low data usage |
No real time access | Remote IoT / IIoT devices |

You can have a mix of agent types across your setup, but each environment should only be added once and with one agent type.

For more guides on how to set up and use Portainer, have a look at the [Portainer Academy](https://academy.portainer.io).

[A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.](https://www.portainer.io/blog/author/james-carppe)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/pre-staging-edge-environments-with-portainer
title: Pre-staging Edge environments with Portainer
author: James Carppe
url: https://www.portainer.io/blog/pre-staging-edge-environments-with-portainer
hostname: portainer.io
description: Learn how to pre-load edge devices with a startup script to deploy the Portainer Edge Agent on first boot.
sitename: PORTAINER.IO
date: 2022-05-08
categories: []
tags: []
image: https://www.portainer.io/hubfs/2-13-blog-edge-waitingroom-script-png.png
pagetype: article
filedate: 2025-01-18
-->

Computing at the edge is a rapidly growing field, and something we've supported with Portainer for some time now via the Portainer Edge Agent. Using our Edge Agent, your edge devices can be managed from a centralized Portainer server installation, even when the connectivity from an edge device to the server is intermittent and changing, or limited by security requirements. But as your stable of edge devices grows, the logistics of deploying the agent to the devices becomes more difficult, especially in the world of IIoT devices and the distribution of these devices in multiple physical locations.

To help make this easier, we're introducing a couple of new features to our Edge device support in [Portainer version 2.13:](/blog/portainer-ce-and-be-2.13-are-here) device pre-staging and the Edge environment waiting room. By combining these two features, you're now able to pre-load edge devices with a startup script to deploy the Portainer Edge Agent on first boot, and have those newly deployed agents connect to a Portainer management environment to be approved by an administrator - all without any user intervention at the edge device.

To prepare a device, within the Portainer server you can create a generic script that will install the Portainer Edge Agent with the necessary settings in order for it to communicate back to the Portainer server. You can customize this script with environment variables as well as create scripts for the platforms we support, such as Kubernetes, Docker Swarm, Docker Standalone and Nomad. This script can be run without changes on any number of devices, meaning you can roll this out to as many devices as you need to run as part of their initial boot sequence.

This takes care of the pre-loading aspect, but we don't necessarily want every single device to automatically connect to and associate with your Portainer server without your approval. This is where the second concept comes in: the waiting room. With this feature, any new edge device that connects to your Portainer server using the script that you generated will go into a waiting room, visible within the Portainer UI. An administrator user can then choose on a per-device basis whether to allow the associating of the edge device with the Portainer server.

Once the device is approved to associate with Portainer, it will become listed in your Edge Devices and can be used as part of Edge Groups to deploy Edge Stacks.

Combining these two features means larger-scale deployments of remotely manageable edge devices becomes a lot easier thanks to Portainer. You can find more information as well as usage examples in our documentation.

[A former web developer, operations manager, and radio announcer, James is a big fan of technology in all forms. When not making videos and helping Portainer customers out, you'll often find him watching films and television, pretending to be a photographer, and tinkering with the latest gadgets.](https://www.portainer.io/blog/author/james-carppe)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-your-docker-gui-for-your-ubuntu-linux-desktop
title: Portainer, an awesome GUI if you run Docker on your Ubuntu Linux Desktop
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-your-docker-gui-for-your-ubuntu-linux-desktop
hostname: portainer.io
description: Docker GUI for Ubuntu Linux
sitename: PORTAINER.IO
date: 2021-08-06
categories: []
tags: []
image: https://www.portainer.io/hubfs/Portainer%2c%20an%20awesome%20GUI%20if%20you%20run%20Docker%20on%20your%20Ubuntu%20Linux%20Desktop.png
pagetype: article
filedate: 2025-01-18
-->

Note: As this is an older blog post, the installation instructions below are out of date. We recommend using our [official documentation](https://docs.portainer.io) to ensure that you are installing the latest version of Portainer.

According to the 2021 StackOverflow Survey (of 80,000 respondents), 25% of all developers out there use Linux as their primary desktop Operating System, yet Docker Desktop, which is a combination of Docker Engine and Graphical UI, is only able to be deployed on Windows or MacOS (as of August 2021).

So, for all you Linux lovers out there, let's see how easy it is to get Docker Engine plus Portainer UI running on your Ubuntu Development workstation. Dont forget though, Portainer also works on Windows and MacOS, so we have you covered regardless.

First things first, lets install Docker (skip this step if you already have Docker installed).

On your Ubuntu Desktop, open a terminal window, and enter the command:

s*udo curl -fsSL https://get.docker.com |bash*

This will install Docker Engine to your PC.

Once the installation succeeds (as below), you can move on to the next step

Now lets install Portainer.

run the command: *sudo docker volume create portainer_data*

then run the command: *sudo docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce*

This will deploy Portainer CE, on your local Docker instance, and listen for UI requests via Port 9000 (you can omit port 8000 if you won't ever be adding additional environments to this instance).

You can now open your prefered browser, in my case its Firefox, and connect to [https://localhost:9000](https://localhost:9000)

Then create your initial username and password (dont use "admin" for your username, use your own name).

Finally, select "Docker" as the endpoint type, then click "connect"

You can now manage your local Docker instance in a nice friendly GUI.

Lets see what Portainer can do for you..

You are able to:

- Deploy applications via App Templates (Click to Deploy)
- Deploy and Manage Stacks (compose files), including deploying direct from git
- Deploy & Manage Containers, including the ability to edit a running container
- Pull/Push/Build Images
- Create Networks
- Create/Delete Volumes
- See a log of Docker Events
- See docker engine (Host) information, and apply security controls should you desire

So, as you can see, Portainer is a powerful graphical UI that can be used to manage your Docker-CE instance running on your Linux Desktop.

Interested in running Portainer in a business environment?

Portainer Business is our fully featured, fully supported business product. It is used by some of the largest organizations in the world to deliver a powerful self-service container management experience for developers and IT teams. With more than 1M active users, Portainer is proven to be the simplest and most effective way of managing Docker, Swarm, and Kubernetes environments.[Get 3 nodes of Portainer Business for FREE](/take-3)

To read more, visit [www.portainer.io](/) or [documentation.portainer.io](https://docs.portainer.io/)

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-vs-mirantis
title: Portainer vs Mirantis: A Users Point of View in 2021
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-vs-mirantis
hostname: portainer.io
description: Compare Mirantis vs Portainer for container management. Discover the features, community, support, pricing, and ease of experimentation with these 2 tools.
sitename: PORTAINER.IO
date: 2021-07-08
categories: []
tags: []
image: https://www.portainer.io/hubfs/Container%20Management%20Landscape%202621x2008.png
pagetype: article
filedate: 2025-01-18
-->

We were humbled to discover this recent blog post, created by Hrittik Roy from p3r. The article delves into a users' point of view on Mirantis vs Portainer - features, community support, pricing, and ease of experimentation with these 2 tools.

A while ago, I came across a video about two types of people – one managing and writing lines and lines of code and the other using [Portainer](https://portainer.io/). Quite exciting, and back then, I started to compare the available GUI options in the market to get my bucks’ best value.

The [Mirantis Kubernetes Engine](https://www.mirantis.com/software/mirantis-kubernetes-engine/) (formerly Docker Enterprise/UCP) stood out as a great competitor from the parents of docker enterprise.

In this post, I share my experience and observations after playing with these platforms, scrolling pages, and attending the [KubeCon](https://events.linuxfoundation.org/kubecon-cloudnativecon-europe/) booths. The aim is to share our thoughts so far and help you to weigh your options. I believe sharing is caring, and this post compares the latest version of the products in May 2021. Mentioning this, as quite a lot of outdated posts are circulating on the internet.

Let’s talk about Portainer vs Mirantis!

### Portainer vs Mirantis: Features

Mirantis and Portainer both offer quite common services and are equal in many aspects. So it’s pretty useless and a waste of time to go around the fact that Portainer is easier to set up and Mirantis not that much. I want to focus more on the features and limitations for this post’s scope, and the similar features might be a bit easier to set up or use. Let’s focus on Portainer vs Mirantis 😀

#### Advantages of Mirantis

[Calico](https://www.tigera.io/tigera-products/calico/)networking and the[Istio](https://istio.io/)service mesh are included as integrated components to make networking deployments easier.- It supports Windows Server 2019, allowing a Mirantis Kubernetes cluster to have both Windows and Linux nodes.
- Mirantis’ Launchpad deployment platform makes it easy to set up single node and production clusters.

#### Advantages of Portainer

- Portainer’s emphasis on allowing Kubernetes control through natural language behavior is a crucial differentiator and benefit.
- Portainer can be used as a layer on top of any current Kubernetes deployment, including self-hosted and managed environments.
- The platform establishes intelligent protection defaults to help mitigate the risks associated with incorrect configurations.
- Portainer can also be used to support Docker Swarm container clusters and Edge computing nodes, in addition to Kubernetes.
- The
[Portainer Business Edition](https://www.portainer.io/blog/portainer-launches-business-edition-bringing-simplified-container-management-platform-to-enterprise-scale)extends the[Portainer Community Edition](https://www.portainer.io/products)(Portainer CE) with identity and access management (IAM) and commercial service options. Now you can allow multiple users to access docker sockets on the same host.

### Portainer vs Mirantis: Community Support

KubeCon is something I look forward to every year. Quite interestingly, Portainer, even being relatively new, has an active community around its community edition (CE). So active that I missed getting into the first interactive session due to some technical issues on the CNCF end or maybe participants’ limitations.

I have skimmed across many blogs while facing issues, and some devs have already written something on the issue. I tend to get attracted to products with a community and looking at trends, community makes a product mass adopted and successful.

Independent sites like [g2](https://www.g2.com/compare/portainer-vs-mirantis-kubernetes-engine-formerly-docker-enterprise) anonymously claim that Portainer is headed in the right direction. I see they have an active Twitter account and Slack channel helping devs 🙂 Generally, **there’s quality support for the free community edition**, and it sets a ground for the excellent paid support plans. You can trust them with support.

Mirantis, on the other hand, has closed doors, and a blog post on its product is pretty invisible. You have to go through the typical support funnel to get a solution. It might be okayish with Enterprise level customers, but we all know you need to bet on the product after the purchase.

Request a Demo of Portainer Business

Let us introduce you to a world of fast and easy app deployment, governance, and management in Docker and Kubernetes. [Request a 1:1 demo](https://www.portainer.io/portainer-demo-request-kubernetesgui-dockergui) to see how Portainer Business helps to make teams more accurate and efficient in a business environment.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/how-to-manage-docker-kubernetes-concurrently-with-portainer-in-docker-desktop
title: How To: Manage Docker & Kubernetes concurrently with Portainer in Docker Desktop
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/how-to-manage-docker-kubernetes-concurrently-with-portainer-in-docker-desktop
hostname: portainer.io
description: Use Portainer to manage both Docker and Kubernetes in your Docker Desktop environment
sitename: PORTAINER.IO
date: 2021-08-28
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Aug-28-2021-01-37-28-62-AM.png
pagetype: article
filedate: 2025-01-18
-->

So, you are running Docker Desktop on your Windows PC, and you would like to have a rich, "follow your nose" UI to help you deploy, manage and monitor your applications for both your docker-ce instance AND the Docker Desktop deployed Kubernetes instance?

Docker Desktop includes a simplistic UI for managing the deployment of containers on their docker engine (their UI doesnt really help beyond the most basic of features), but does not provide any UI elements to assist with deploying to Kubernetes. Luckly, here at Portainer we have you covered for both.

So, lets get started...

We will assume for the sake of this blog that you have just installed Docker Desktop, and have not yet made any configuration changes to enable Kubernetes.

Lets guide you through configuring Kubernetes, deploying Portainer in the docker instance, and then attaching the Kubernetes cluster to Portainer.

Step 1. Open Docker Desktop, check your deployment is using WSL2

Note that at this stage, your Docker Desktop environment is likely only using a small amount of system ram, in my case 2GB, but thats about to change! (and no, thats not a dig at Docker Desktop, its a statement around the system impact of Kubernetes in general).

Step 2, Click on Kubernetes, tick the box "Enable Kubernetes", and then "Apply and Restart"

Step 3, Click "Install" on the confirmation box, and then wait... a while, in fact, go make a coffee.

Once you see the Green Kubernetes logo in the bottom left, you are good to go.

You can close the Docker Desktop UI now, you wont need this again :).

A quick check on system resources, and you can now see that Docker Desktop is using 4GB of RAM, with the extra 2GB being required to "idle" Kubernetes.

Step 4, Open a command window, and type "docker ps", you can see all of the Kubernetes components that Docker Desktop deployed for you; this is Kubernetes in Docker.

Step 5, Now lets get you up and running with Portainer.

Run the following commands:

`docker volume create portainer_data`

`docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce`

`kubectl apply -n portainer -f https://downloads.portainer.io/portainer-agent-k8s-nodeport.yaml`

This will get you up and running with Portainer (in Docker) and also deploy the Portainer agent inside Kubernetes.

Step 6, Now, go to your browser, and type localhost:9000

Step 7, Create yourself an initial user account, in my case, i used my name, and set my preferred password, then click "create user"

Choose to connect to Docker endpoint (we will add Kubernetes later), then click "Connect"

You are now up and running with the Portainer UI managing your local Docker instance.

Step 8, OK, so now lets add the local Kubernetes environment.

Click on Endpoints, then "add endpoint"

Select "Agent" and then give your endpoint a name, "docker-desktop-kube" made sense to me, for the endpoint URL, enter *kubernetes.docker.internal:30778* and for public IP, enter 127.0.0.1, then click "Add Endpoint"

You are now prompted to configure the cluster settings, which is where you define what you want to make available for use in the UI. We recommend enabling the "hostpath" storage option (for persistence), but leave everything else DEFAULT for now (as Docker Destop Kubernetes does not come with metrics server, a load balancer, or an ingress deployed) Click "Save Settings"

You are now redirected to the "home" page, and you can see your two endpoints.

Step 9, I recommend renaming "local" to docker-desktop-docker, so to do that, click on endpoints, click on "local" change the name, and then click "update endpoint"

That looks better (at least for OCD me)

You have now successfully deployed Portainer on your local machine, and configured it so you can manage both the Docker and Kubernetes instances running. Simply click on either of the endpoints to start using them.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/migrating-from-mirantis-to-portainer-business.-in-the-words-of-a-happy-portainer-business-customer
title: Migrating from Mirantis to Portainer Business. In the words of a happy Portainer Business customer
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/migrating-from-mirantis-to-portainer-business.-in-the-words-of-a-happy-portainer-business-customer
hostname: portainer.io
description: Migrating from Mirantis to Portainer in the words of a very happy Portainer Business customer.
sitename: PORTAINER.IO
date: 2021-07-14
categories: []
tags: []
image: https://www.portainer.io/hubfs/Stored%20Value-1.png
pagetype: article
filedate: 2025-01-18
-->

This email is shared in its raw form. Our thanks to Stored Value for allowing us to reproduce it. We are forever grateful. It captures the essence of what we do and what we are trying to achieve better than we ever could.

"We’re in the process of migrating currently. For us, it was a no brainer. So first, some backstory, we used Docker Support probably once prior to Mirantis’ purchase of Docker. The one time we did, we were told to migrate to a newer version. Fast forward a year or so, and Mirantis purchases Docker and with that came a litany of new support issues. So, with that as the baseline, let’s use that as the jumping off point into the RHEL [Red Hat Enterprise Linux] side of things and how best to solve a lot of issues.

Our goal was to maintain our Docker infrastructure while adding the ability for RBAC controls for developers to view logs in multiple environments while not having advanced privileges. Initially, we wanted Portainer but RBAC wasn’t quite ready. So for us, we went forward with Docker-EE. At that time it wasn’t a huge deal because it was still just Docker. With Mirantis however, the main focus was to push Kubernetes. It’s even in the name (MKE) for their replacement engine. On a conference call, we were told that Docker customers would be treated as first class citizens. I can tell you that’s very far from the truth. Even a base deploy now, whether you want it or not, includes Kubernetes....

Integrated Kubenerntes adds a major headache when it comes to networking. It also adds additional headaches with deployments. Once you’ve grappled with all of that, you get into the complexity of what RHEL has decided to do with RHEL 8 in disabling API access for Docker. In my experience, this causes stability issues no matter how you slice it. What’s worse, I poured through their documentation and it had nothing in terms of answers for how to properly set up Docker in RHEL 8. Point in fact, I asked about 7 or 8 questions via email, and they couldn’t answer them after 7 days.

Enter Portainer Business. Neil (Portainer CEO) and his team have bent over backwards to help from day one. And I do mean Neil and his team. He’s as responsive as any of the team and for me personally, as a father who also coaches his kids in about everything they play, I respond to that kind of leadership that leads from the front. Portainer just works. It does what Docker does best and uses the same KISS principle I grew up on. Just keep it simple. But instead of making this a very long email because honestly there is so much and you likely know how very technical this all is.

**Mirantis VS Portainer**

StoredValue has tried Mirantis and gave us a quick comparison:

Portainer has been far and away a better product in my opinion. Simply based off the deployment alone, it’s far more straight forward, and there’s nothing deployed that isn’t needed. One thing that Mirantis does (and I’m trying to think of the best/shortest way to say this) is deploy 10 services when they could/should deploy 1 or 2. So with that in mind, if we deploy on Linux we aren’t just deploying for the Linux environment, but also deploying Windows connectors and agents. This leaves us with multiple services that are scaled at 0/0. This is just unnecessary and seems like a security risk to have something constantly running/listening with no purpose. Further, it’s never been explained if we can remove them or not without causing problems with functionality. All this to say, Portainer is far more logical in deployment. Portainer is also ready to be used in current Docker environments. Mirantis can’t even be deployed in 20.04 LTS yet. Further it’s still running on Docker 19. Portainer offers far more flexibility. If we want to use a previous version, no problem. If we want to run newer, we can do that, too. We have choice.

One big thing I would point out is Mirantis’ move to Kubernetes. The fact that they renamed Docker Universal Control Plane (which ideally you would think they’d keep because it doesn’t specify Kubernetes or Docker...even if it was a contractual reason, they still are pursuing Kubernetes) to Mirantis Kubernetes Engine. It’s very apparent that the acquisition was solely to gain a base of users and move them to Kubernetes. As far as features go, I have yet to find anything they offer that isn’t done easier through Portainer. Portainer's UI is much easier to navigate. Even the small things that weren’t as straight forward, are still more simplistic than MKE. I would even push back on your mention of the CLI. At a certain point, you’re installing Portainer to use the CLI less. That isn’t a concern for us at all.

One addition that I remember offhand is adding another node either manager or worker. And maybe I’ve missed this but they do have a tab that displays the Manager Add command or worker instead of having to go to the CLI and run the command. I can’t see how that’s more or less beneficial as opposed to ‘they have this and you don’t’ type of feature. Again, Portainer might and I could’ve missed that. Another feature they have is the ability to add custom certs from the UI. I think Portainer is done through the deployment. Mirantis is either or.

Lastly, though I’ve had a terrible experience with it, they do have the option to upgrade the cluster from within the UI. I would think Portainer could be much simpler to do considering it’s just an agent and the Portainer-EE container rather than several. I know with the home addition I run on Open Media Vault, to upgrade, the easiest method is to simply re-run the installer which repulls and

deploys that way. Upgrading via the UI isn’t possible.

I wanted to say thank you again to you and all of your staff with how helpful you’ve been thus far. It’s been refreshing.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/rbac-for-kubernetes
title: RBAC for Kubernetes. Why is it so hard to provide secure user access into Kubernetes?
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/rbac-for-kubernetes
hostname: portainer.io
description: RBAC for Kubernetes. How to remove the complexity and get RBAC for Kubernetes the easy way.
sitename: PORTAINER.IO
date: 2021-08-19
categories: []
tags: []
image: https://www.portainer.io/hubfs/Untitled.png
pagetype: article
filedate: 2025-01-18
-->

Effective user authentication and authorization is a critical element of any container-based implementation (Kube or Docker) but as with anything Kube related, if you’re playing with native tools, it’s complicated. Really complicated...

For the uninitiated, setting up a user repository in Kubernetes, either internally, or through a connection to an external authentication store, is tricky. You need to install plugins, configure the connection, and then repeat for each and every cluster you manage. In addition, connecting Kubernetes to the authentication source is only half of the job, the other half is mapping (binding) authenticated users to roles. Kubernetes RBAC ensures that end users can only perform certain specific actions on specific namespaces /clusters. It’s critical to effective IT governance and stops all manner of bad things happening when everyone has Admin rights.

Natively, Kubernetes supports a number of different role types, which you can assign to a subject–eg Cluster Admin, Admin, Edit and View. These roles are perfectly practical, but hard to manage because Kubernetes doesn’t offer any automated tools to facilitate automatic granting of roles or updating of role bindings. That means admins must do everything manually namespace by namespace, cluster by cluster. In addition, Kubernetes offers no built-in tools for easily identifying which level of access a user has within a cluster which is an instant recipe for trouble when the team scales beyond a few users.

The challenge of managing RBAC gets exponentially harder when multiple clusters are involved, because RBAC–if you’re doing things manually–needs to be set up on a cluster by cluster basis. This is hugely labor intensive and error prone. To avoid the problem, some organizations are going as far as aligning individual users with individual clusters, which is wildly impractical and almost defeats the whole ‘cluster’ objective.

So, there’s got to be a better way, right?

Andy Magnussen outlines an alternative approach in his [blog](https://www.strongdm.com/blog/kubernetes-rbac-role-based-access-control), which includes a simplified manual approach involving Service Accounts; but there’s also a third way.

At Portainer we have a long history with RBAC from our Docker/ Swarm history. We’ve been helping organizations manage, govern, and secure their containerized environment for years and we know what works and what doesn’t. Over the last year, we’ve been gradually porting our Docker know-how to Kubernetes and, in Portainer Business, we’ve got a fully-featured, fully supported RBAC solution for multi-cluster, large scale Kubernetes implementations that’s proving hugely popular with customers.

Portainer’s RBAC for Kubernetes functionality implements a standardized set of roles (Endpoint Admin, Helpdesk, Operator, Standard User, Read-Only User), which are maintained within Portainer, but created in the clusters automatically as they are onboarded into Portainer. To grant a user access to a cluster or namespace(s), a Portainer admin simply grants them access via Portainer, and Portainer takes care of the rest. Behind the scenes, we create a “shadow” user record within Kubernetes, create the role bindings, and ensure that their access is secured. Users simply log in to the Portainer UI, and either obtain their kubeconfig file to access the clusters directly, or they can immediately start deploying apps via our UI. No manual work is needed by an admin directly in Kubernetes.

With Portainer you can

- Connect to your external authentication stores (LDAP/AD, OAuth)
- Syncronize your external groups with Portainer Teams
- Allow users to login to Portainer that are members of specific groups
- Automatically place users into Portainer teams based on their group membership
- Assign access to Clusters either by team or person
- Assign RBAC roles to access, either by team or person
- Perform RBAC access overrides should there be a specific need to restrict access fora certain user within a team

What’s important about Portainer is that not only can you apply RBAC to our own GUI-based tool, you can also connect any third party dashboard, CI/CD tool to our RBAC and give developers/end-users the flexibility to ‘bring your own tool’ safe in the knowledge that usage is safe and secure.

As you would expect, RBAC is only one element of the Portainer Business solution set and there’s a raft of other security and governance-based features in it that are exposed to admins and users via a simple GUI (including the ability to restrict access to generic namespaces which is the subject of [this related blog](/blog/why-restricting-access-to-the-default-namespace-is-key-to-running-a-secure-kubernetes-environment))

If you are interested in learning more this episode of our Portainerd series should be right up your street.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer.io-recognized-as-rising-star-in-forbes-2021-cloud-100-list
title: Portainer.io recognized as 'rising star' in Forbes' 2021 CLOUD 100 list
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer.io-recognized-as-rising-star-in-forbes-2021-cloud-100-list
hostname: portainer.io
description: Portainer recognized as rising star in Forbes' 2021 Cloud 100 ListForbe
sitename: PORTAINER.IO
date: 2021-08-10
categories: []
tags: []
image: https://www.portainer.io/hubfs/Forbes%20Rising%20Star%20Twitter-1.png
pagetype: article
filedate: 2025-01-18
-->

**AUCKLAND, New Zealand (August 10, 2021) ** – [Portainer.io](//portainer.io) is named as one of 20 Rising Stars in Forbes annual Cloud 100 list, the definitive curation of the top 100 private cloud companies in the world. The 20 Rising Stars represent young, high-growth cloud companies who have raised up to $25 million and are poised to join the Cloud 100 ranks.

“It’s fantastic to learn we are considered to be a “Rising Star” by Forbes… being from NZ we are a humble breed, and tend to downplay what we have built and its appeal to the global audience” said Portainer CEO Neil Cresswell.

“The Rising Stars of today are the Cloud 100 companies of tomorrow,” said Byron Deeter, a top cloud investor, and partner at Bessemer Venture Partners. “As they continue to gain momentum and ramp toward unicorn status, many of our past Rising Stars have gone on to become members of the exclusive Cloud 100. As an early partner to many mission-driven founders over the years, we are thrilled to celebrate the bright futures of our 2021 Rising Stars.”

“The Rising Stars epitomize the type of innovation that is driving the cloud industry forward,” said Alex Kayyal, Managing Partner, Salesforce Ventures. “The companies on this year’s list show great potential for reaching the Cloud 100 list in the future and I’m looking forward to watching what they can accomplish next.”

“The companies of the Cloud 100 list represent the best and brightest emerging companies in the cloud sector,” said Alex Konrad, senior editor at Forbes. “Every year, it gets more difficult to make this list — meaning even more elite company for those who do. Congratulations to each of the 2021 Cloud 100 honorees and to our 20 Rising Stars up-and-comers poised to join their ranks.”

The Forbes 2021 Cloud 100 and 20 Rising Stars lists are published online at[ www.forbes.com/cloud100](https://www.forbes.com/cloud100). Highlights of the list appear in the September 2021 issue of *Forbes* magazine.

The Cloud 100 and the 20 Rising Stars companies are publicly recognized at this year’s virtual Cloud 100 experience, hosted by[ Bessemer Venture Partners](https://www.bvp.com/),[ Salesforce Ventures](https://www.salesforce.com/company/ventures/), and[ Forbes](https://www.forbes.com/) on August 10th at thecloud100.com. A special thank you to virtual event sponsors Amazon Web Services (AWS), Bank of America, Cooley, FuelxMcKinsey, Goldman Sachs, J.P. Morgan, Morgan Stanley, Nasdaq, Qatalyst Partners, Silicon Valley Bank, and WisdomTree.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-on-microk8s-openebs-metallb-and-ingress
title: Portainer on MicroK8S + OpenEBS, MetalLB and Ingress
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-on-microk8s-openebs-metallb-and-ingress
hostname: portainer.io
description: The blog post shows how to deploy Portainer on MicroK8s with OpenEBS and MetalLB with Ingress plugins.
sitename: PORTAINER.IO
date: 2021-05-27
categories: []
tags: []
image: https://www.portainer.io/hubfs/undefined-May-27-2021-03-08-41-21-AM.png
pagetype: article
filedate: 2025-01-18
-->

Deploying Portainer on MicroK8s with OpenEBS is quite easy but it requires you to follow a sequence of steps in a given order for it to work. This blog post will walk you through those steps.

If you prefer to watch a video, you can find our how-to video on YouTube here ->

First some pre-reqs:

- Make sure that you run the commands as root
- Latest version of the Ubuntu server any other linux distribution/OS that can run MicroK8s (installation details can be found here:
[https://microk8s.io/docs](https://microk8s.io/docs)) - 3 nodes running MicroK8s v1.21
- Before deploying Portainer we have to make sure that MicroK8s has been deployed with the following addons enabled:
- ha-cluster (installed by default on MicroK8S)
- dns
- rbac
- storage

- First step is to install MicroK8S on all three nodes by running
`snap install microk8s --classic --channel=1.21/stable`

: - Now you need to create the Kubernetes cluster by adding the nodes to a cluster by running
`microk8s add-node`

on the machine you will use and your main cluster server.**Make sure you run the previous command on the main cluster node for every additional node you intend to include on the cluster. You cannot run the same output for all the nodes.** - Let's create an alias for
*kubectl*to make things easier bu running`echo "alias kubectl='microk8s kubectl'" >> .bash_aliases && source .bash_aliases`

- Now check if all nodes are ready by running
`kubectl get nodes`

: - Once all nodes are with a
**Ready**status you need to enable the*iscsid*driver required by**OpenEBS**by running on**every node**the following command:`systemctl enable --now iscsid`

- We will now only work on the main node you can now close terminal access to the 2 other nodes.
- Let's deploy the required plugins on your MicroK8S cluster by running
`microk8s enable rbac dns openebs storage`

This might take up to 5 minutes depending on your cluster setup. - OpenEBS might take some time to install. You can check that the plugin has finished deploying all it's pods by running
`watch microk8s kubectl get pod -n openebs`

: - Once the installation of the plugins above finish we need to make sure the OpenEBS plugin becomes the default StorageClass for your cluster by running the following two commands:
`kubectl patch storageclass openebs-jiva-default -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'`

`kubectl patch storageclass microk8s-hostpath -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"false"}}}'`

- This is required so you can install
**Portainer**. You cannot have two default StorageClasses defined on your cluster otherwise**Portainer**will complain during the installation. - Now we can finally install
**Portainer**by running`microk8s enable portainer`

.**Portainer**on MicroK8S with OpenEBS takes slightly longer than with the default storage plugin because of the storage replicas that OpenEBS needs to create. You can check the progress of the deployment with`watch microk8s kubectl get pod -n portainer`

. - Deploying Metallb and Ingress is quite simple by running
`microk8s enable ingress metallb`

- During the Metallb installation, you were asked to provide an IP range to be managed by the Load Balancer. Make sure you have an advanced route rule on your route/gateway that points to the main IP address of your main node. For example, in my case I have a routing rule on my router that directs any traffic of the 192.168.10.0 subnet to the IP address of my main node:
- Once
**Portainer**, Metallb, and Ingress are deployed you can open your browser and finish the installation by using the IP address of the main node and port 30777. - Final steps are:
- Create the first
*admin*user: - Connect
**Portainer**to the Kubernetes cluster: - Finish the Cluster Setup according to your Kubernetes environment:
- Enable MetalLB and the Ingress Controller. The name of the
**ingress class**for the MicroK8S ingress plugin is**public**and the type**ingress**: - Enable the
**openebs-jiva-default***StorageClass*:

- Enable MetalLB and the Ingress Controller. The name of the

- Create the first

That's it. Let us know how you go in the comments below.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/containers-as-a-service
title: Why you need Containers-as-a-Service for your Kubernetes environment
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/containers-as-a-service
hostname: portainer.io
description: Containers-as-a-service is the difference between having a large Kube implementation and a sustainable framework for delivering easy Kubernetes management.
sitename: PORTAINER.IO
date: 2021-08-19
categories: []
tags: []
image: https://www.portainer.io/hubfs/CaaS2.png
pagetype: article
filedate: 2025-01-18
-->

For the many organizations who uttered the fatal words ‘it’s Kubernetes, how hard can it be?’. This blog is for you. Because, as it turns out, doing Kubernetes properly is both complicated and time consuming. The sooner we stop trying to work against Kube and start working with it, the better off we will all be.

Before we get into the nuts and bolts, it’s worth taking a step back and remembering why we’re all doing this... **the goal of anyone deploying Kubernetes is to create a technically and economically sustainable process for users to deliver highly reliable and responsive cloud native applications**. The focus should be on creating a service framework for users, not on Kubernetes itself, which is where it’s going wrong.

If you’re jumping on the Kubernetes bandwagon, you’ve got to think about 4 things:

- Where are you going to host?
- How are you going to manage the Kube environment?
- How are you going to secure, protect and govern your environment?
- How are your end users going to consume it?

And there are lots of options - for example

##### Kubernetes Hosting

From a hosting perspective, you can host on prem or use a cloud IaaS provider like Google or AWS.

##### Kubernetes Management

From a Kubernetes management perspective, you can manage it yourself, outsource to an MSP or use a third-party vendor.

##### Kubernetes Security and Governance

From a security and governance perspective, you’ve got to figure out whether you’re going to try and configure Kubernetes RBAC, authentication etc manually or use a third-party platform to help solve the problem.

##### Kubernetes UI

And, from a consumption perspective, you’ve got to decide if a Kubernetes UI is right for your team, or in fact whether you’re going to give them any tools at all (and instead integrate Kubernetes directly with a CI/CD environment).

There’s a lot to think about. But come back to the beginning for a moment. The goal here is not to build a monster for the sake of it, the goal is to build a long-term sustainable service framework for end users and staying focused on that.

The whole DIY strategy (self-host, self-manage) is the domain of the early adopter, or the incredibly well funded, and there are a few organizations that have done it successfully, but it’s typically taken them years to get it right and cost millions. It demands the brightest minds and very deep pockets and it’s definitely not the preferred mainstream option.

At the other end of the continuum you’ve got the cloud provider ‘Kubernetes as a Service’ offerings from cloud providers, which makes sense as it eliminates the need for deep on-staff expertise and allows you to focus on what matters.

And then there’s a bunch of hybrid options in between whereby the cloud providers will manage your on-prem environment for you or you can employ a third-party vendor to provide a complete end to end managed solution for you.

It’s worth noting that although third-party vendors purport to sell you an a-la-carte solution, in reality they only really offer a fully managed service, which might be ok–if you’ve got deep pockets and don’t mind being locked-in to a single vendor solution.

But.... and there is a big but in the middle of all this. At the end of the day, regardless of which option(s) you choose, do you actually get a sustainable service framework, or are you still left with gaps?

Our experience is that even when you buy Kubernetes as a service from one of the cloud providers you still don’t get ‘containers as a service’. There’s still a gap in terms of governance and interaction, which is exactly where Portainer plays.

**Portainer is the difference between having Kubernetes running somewhere/anywhere and having a sustainable containers-as-a-service delivery framework. The need for Portainer exists in all 4 quadrants**

The role it plays in each quadrant is essentially the same. It provides:

- The security and governance framework that ensures users can only do what they’re permitted to do (via Kubernetes RBAC)
- It provides a super-simple Kubernetes GUI for end users to use and deploy their apps without having to worry about the underlying platform
- It provides an API (Kube or Docker API Proxy) to allow third party tools (including CI/CD tools to connect through).

Overall, we see a shakedown happening where, as the industry matures, the move to Kubernetes as a service will probably win out. But, remember, unless you’ve got Portainer running in your cloud environment, you still don’t have containers as a service, which is what this game is ultimately all about.

See for yourself, with a demo or free trial

Let us introduce you to a world of fast and easy app deployment, governance, and management in Docker/Swarm, Kubernetes or Nomad. Book a live demo to see how Portainer Business helps to make Engineering and DevOps teams more accurate and efficient in container management.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/congratulations-to-forbes-rising-stars
title: Congratulations to Forbes' rising stars.
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/congratulations-to-forbes-rising-stars
hostname: portainer.io
description: Congratulations to Forbes' other rising stars in the 2021 list of cloud computing giants.
sitename: PORTAINER.IO
date: 2021-08-13
categories: []
tags: []
image: https://www.portainer.io/hubfs/FKGHSDFTLAF255ROBHJJVPPB3A.jpeg
pagetype: article
filedate: 2025-01-18
-->

We're honoured to be recognized this week as a “[Rising Star](https://www.forbes.com/sites/rashishrivastava/2021/08/10/cloud-100-rising-stars-2021/?sh=70f4390fe2e0)” of the Cloud Computing industry by Forbes Magazine. We’re also proud to represent New Zealand in this global list of cloud companies and bring home the recognition with a feature in the [New Zealand Herald.](https://www.nzherald.co.nz/business/auckland-startup-portainer-makes-forbes-global-cloud-100-rising-stars-list/CYHJXXLP3UGGM3LDPSPNUDPPJQ/)

Our class of 20 Rising Star companies sits alongside Forbes’ [The Cloud 100](https://www.forbes.com/cloud100/#7a7494215f94) 2021 list and includes some incredible companies doing amazing things.

Congratulations to our fellow honorees:

[AbstractOps](https://www.abstractops.com/): Back-office operations automations.- Airplane: Developer platform for internal tools.
[Anrok](https://anrok.com/): Sales tax software for SaaS firms.[Cocoon](https://www.meetcocoon.com/): AI-powered tool for employee leave process.[CodeSee](https://www.codesee.io/): Codebase understanding and transparency.[GlossGenius](https://glossgenius.com/): Spa and salon workflow management software.[Hightouch](https://www.hightouch.io/): Data syncing platform.[Malomo](https://gomalomo.com/): E-commerce order tracking and marketing platform.[Mem](https://get.mem.ai/): Instant note-taking software.[Meroxa Inc.](https://meroxa.com/): Realtime data orchestration.- Noteable: Collaborative notebook platform for data.
[Pocus](https://www.pocus.com/): Data-driven platform for product-led sales.[Primer](https://primer.io/): Automation platform for payments.[RevOps](https://www.revops.io/): Automation tool to increase sales and revenue for SaaS businesses.[Rightfoot](https://www.rightfoot.com/): Student and credit card debt repayment API.[Spot AI](https://www.spot.ai/): Artificial intelligence for cloud video surveillance.[Transform](https://transform.co/): Centralized metrics store for data analysis.[Tribe](https://tribe.so/): Cloud-based community engagement platform.[TRM Labs](https://www.trmlabs.com/): Crypto fraud detection and financial crime.

Managing infrastructure, maintaining multiple multi-node clusters, and ensuring security are complex tasks in cloud-native development. At Portainer, we’re dedicated to providing radical simplicity and control across roles touching container management. Whether companies are just beginning to transition to the cloud or already working in the cloud, Portainer offers increased productivity, governability, and security to teams managing and deploying containers.

Thank you to our community. We wouldn’t be here without you. Now, back to work!…

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/why-restricting-access-to-the-default-namespace-is-key-to-running-a-secure-kubernetes-environment
title: Why restricting access to the default namespace is key to running a secure Kubernetes environment
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/why-restricting-access-to-the-default-namespace-is-key-to-running-a-secure-kubernetes-environment
hostname: portainer.io
description: Restricting access to the default namespace and using namespaces to manage resources is key to establishing an efficient Kubernetes environment.
sitename: PORTAINER.IO
date: 2021-08-22
categories: []
tags: []
image: https://www.portainer.io/hubfs/Brand%20Assets/Third-party%20icons/Kube.png
pagetype: article
filedate: 2025-01-18
-->

Just because you can, doesn’t mean you should, right? Wrong. Restricting access to the default namespace in Kubernetes is critical to running a secure and stable Kubernetes environment, particularly if you’re running Kubernetes at any kind of scale. Here’s why.

For the uninitiated, namespaces are objects that logically partition a K8s cluster into pools of isolated resources; they help different projects, teams, or customers to share a Kubernetes cluster without concern for unintended interaction.

At a more technical level, Namespaces allow administrators / platform managers to segregate and assign resources to individual users, teams, or applications. They also provide the basic building blocks for resource usage allowance, access control and isolation for applications or groups of users. Effective use of Namespaces means you can increase resource efficiencies as a cluster can now be used to manage a diverse set of workloads.

Unless a namespace is stipulated when creating a resource or performing management commands, Kubernetes assumes the default namespace. This means that it is very possible that users end up deploying their applications within, and can make inadvertent changes to running applications in the default namespace. In addition, it’s difficult to apply mandatory quota requirements and advanced RBAC to the default namespace, so accidental self-DDOS is completely possible if a user deploys a misbehaving application in the default namespace, which is clearly not ideal.

It is so important to restrict access to the default namespace that [CIS security recommendations](https://www.cisecurity.org/benchmark/kubernetes/), and in fact every single major Kubernetes provider recommends this as a best practice.

The risks of not using namespaces effectively are:

- Users are not mandated to deploy applications within resource constraints, leading to careless deployments and risks of unexpected cluster resource exhaustion,
- Unpredictable application performance issues for end users as apps compete for contended resources,
- Insufficient network isolation between application deployments,
- Security risks as configmaps and secrets are available to everyone that has access to a namespace, and by default everyone has access to the default namespace,
- Security risks as users can manipulate others resource in the default namespace.

To ensure applications can get access to the resources they need to run efficiently and predictably (without conflicting demands) we need to restrict access to the default namespace and force users to deploy only within isolated, and constrained namespaces.

As with all things Kubernetes, this can be done using CLI-based tools like Kubectl but it’s harder than it needs to be, easy to get wrong, and nearly impossible to scale beyond a few users/clusters.

Portainer lets you do two things easily; first, it lets you disable the ability to see, and deploy to, the default namespace, forcing users to only deploy within their allocated namespaces. Second, Portainer applies and enforces quota restrictions per namespace, so that every deployment has a quota assigned. In Portainer Business edition, we extend the quota assignment/enforcement beyond just CPU and RAM, and into Storage, Load Balancers, and Ingress controllers. This ensures that access to every single critical resource is managed by limits.

At Portainer, we recognize the importance of Namespaces in Kubernetes and have worked to provide Platform Managers with the visibility and control they need, without the need to use the CLI manually, or create their own scripts/tooling.

It takes just a few seconds to restrict access to the default namespace inside Portainer Business (see toggle on/off in the video below).

Once access to the default namespace has been constrained, Platform Managers can use the tools inside Portainer Business to set and manage resource quotas on each namespace, which is hugely important for any organization seeking to deploy Kubernetes in a production environment at scale.

The video below shows how easy it is to set up storage quotas for a defined namespace.

See for yourself, with a demo or free trial

Let us introduce you to a world of fast and easy app deployment, governance, and management in Docker/Swarm and Kubernetes. Join a group demo to see how Portainer Business helps to make Engineering and DevOps teams more accurate and efficient in container management.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-versions-why-were-matching-the-agent-with-the-portainer-release
title: Portainer Versions - Why we're matching the Agent with the Portainer Release
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-versions-why-were-matching-the-agent-with-the-portainer-release
hostname: portainer.io
description: Ready to upgrade Portainer? To make it easier to manage, we are matching the agent version with the respective Portainer versions.
sitename: PORTAINER.IO
date: 2021-06-04
categories: []
tags: []
image: https://www.portainer.io/hubfs/upgrade.jpg
pagetype: article
filedate: 2025-01-18
-->

We’re keeping it simple! Sometimes it can be hard managing all the different version numbers across software and which versions work with which. To make this more transparent and easier to manage, we are matching the agent version with the respective Portainer versions.

Going forward, there will be occasions where there is no change to the Agent, but changes to Portainer and vice versa (this will be detailed in our release notes).

**What does this mean exactly?**

When you install Portainer CE 2.6 there will be a matching Agent version 2.6 available. If you already have a Portainer instance 2.5.1 running, you’ll need to set up the Agent version 2.5.1.

This helps to remove confusion around version compatibilities when installing particular instances and when updating versions. Now, you might be asking what if I don’t follow this. What happens? Well, we want the agent to work across different versions of Portainer, however, in the future, this may not be possible. So, we recommend version pining to avoid any unplanned disruptions.

To learn more about the Portainer Agent visit

[https://documentation.portainer.io/agent/index.html](https://documentation.portainer.io/agent/index.html)To learn more about upgrading your Portainer instance visit

[https://documentation.portainer.io/upgrade/](https://documentation.portainer.io/upgrade/)[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/author/neil-cresswell/page/10
title: Portainer News and Blog | Neil Cresswell, CEO (10)
author: Neil Cresswell; CEO May 4
url: https://www.portainer.io/blog/author/neil-cresswell
hostname: portainer.io
description: Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization. (10)
sitename: Portainer.io
date: 2021-05-04
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

### Blog Post by Neil Cresswell, CEO

[
](https://www.portainer.io/blog/container-management-solution-portainer.io-raises-6m-series-a-round-to-accelerate-global-expansion)

Neil Cresswell, CEOMay 4, 20213 min read

### Container Management Solution Portainer.io Raises $6M Series A Round to Accelerate Global Expansion

Portainer announced today their $6 million Series A round led by Bessemer, and joined by ...

Start Reading
[
](https://www.portainer.io/blog/running-linux-and-windows-containers-at-the-same-time-on-windows-10)

Neil Cresswell, CEOApril 27, 2021< 1 min read

### Running Linux and Windows containers at the same time on Windows 10

Need to run Linux and Windows Docker containers at the same time on your Windows 10 ...

Start Reading
[
](https://www.portainer.io/blog/kubernetes-the-1m-problem)

Neil Cresswell, CEOApril 19, 20211 min read

### Kubernetes, the $1M problem??

Does it really cost $1M to get started with Kubernetes?

Start Reading
[
](https://www.portainer.io/blog/deploy-kubernetes-services-with-portainer)

Neil Cresswell, CEOApril 13, 20212 min read

### Deploy Kubernetes Services with Portainer

Learn how to use Portainer to deploy Kubernetes Services with applications. The Service ...

Start Reading
[
](https://www.portainer.io/blog/using-portainer-to-manage-canonical-charmed-kubernetes)

Neil Cresswell, CEOFebruary 26, 20215 min read

### Using Portainer to manage Canonical Charmed Kubernetes

Using Portainer to manage Canonical Charmed Kubernetes

Start Reading
[
](https://www.portainer.io/blog/discovering-boston-dynamics-spot-core-uses-portainer-for-docker-container-management)

Neil Cresswell, CEOFebruary 23, 20211 min read

### Discovering Boston Dynamics Spot CORE Uses Portainer for Docker Container Management

Discovering Boston Dynamics Spot CORE Uses Portainer for Docker Container Management

Start Reading
[
](https://www.portainer.io/blog/using-the-portainer-edge-agent-edge-groups-and-edge-stacks-part-1-0)

Neil Cresswell, CEOFebruary 23, 20212 min read

### Using the Portainer Edge Agent, Edge Groups, and Edge Stacks - part 2

Using the Portainer Edge Agent, Edge Groups, and Edge Stacks - part 2

Start Reading
[
](https://www.portainer.io/blog/proxy-and-load-balance-your-microk8s-services-using-ingress-and-metallb-with-portainer)

Neil Cresswell, CEOFebruary 16, 20215 min read

### Proxy and Load Balance your MicroK8s services using Ingress and MetalLB with Portainer

How to configure Ingress and MetalLB with Portainer on MicroK8s.

Start Reading
[
](https://www.portainer.io/blog/portainer-clickops-or-devops)

Neil Cresswell, CEOFebruary 14, 20213 min read

### Portainer, ClickOps or DevOps

Portainer, ClickOps or DevOps - explore the difference and where Portainer fits.

Start Reading
[
](https://www.portainer.io/blog/portainer-vs-rancher)

Neil Cresswell, CEOJanuary 13, 20214 min read

### Portainer vs Rancher: A Comparative Guide

Portainer Vs Rancher: A Quick Comparative Guide #DevOps #lowcodeplatform

Start Reading
[
](https://www.portainer.io/blog/portainer-ce-validated-configurations)

Neil Cresswell, CEOJanuary 7, 20212 min read

### Portainer CE Validated Configurations

What platforms do we test and validate Portainer against.

Start Reading
[
](https://www.portainer.io/blog/portainer-release-2.0.1)

Neil Cresswell, CEOJanuary 7, 20211 min read

### New Portainer CE 2.0.1 Release

Portainer CE Release 2.0.1

Start Reading

---
<!--
URL: https://www.portainer.io/blog/portainer-as-alternative-to-synology-docker-gui
title: Portainer as an alternative to Synology Docker GUI
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/portainer-as-alternative-to-synology-docker-gui
hostname: portainer.io
description: Why Portainer instead of Synology Docker GUI? Using Portainer offers access to all Docker features – not just the limited feature set provided by the Synology Docker GUI.
sitename: PORTAINER.IO
date: 2021-04-09
categories: []
tags: []
image: https://www.portainer.io/hubfs/portainer-text-on-white-paper-with-pencil.jpg
pagetype: article
filedate: 2025-01-18
-->

This guest blog post from [Technorabilia ](https://www.technorabilia.com/)takes a look at Portainer as an alternative to Synology Docker GUI. Using Portainer offers access to all Docker features – not just the limited feature set provided by the Synology Docker GUI.

### What is Portainer

[Portainer](https://github.com/portainer/portainer) is a lightweight management application that allows you to easily manage your Docker environment through a web interface.

If you haven’t installed Docker, please have a look at [Using Docker on Synology NAS](https://www.technorabilia.com/using-docker-on-synology-nas/).

Don’t forget to have a look at [Portainer App Templates for LinuxServer.io Docker containers](https://www.technorabilia.com/portainer-app-templates-for-linuxserver-io-docker-containers/) and install 140+ applications at the push of a button.

### Why use Portainer?

Although there is a Synology Docker GUI available, with the Portainer setup described here, you have an alternative to manage Docker containers on a Synology NAS.

But most importantly. Sometimes there is a need for settings, which can’t be done through the Synology Docker GUI. Using Portainer offers access to all Docker features – not just the limited feature set provided by the Synology Docker GUI. [Read more](https://www.technorabilia.com/portainer-as-alternative-to-synology-docker-gui/)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-release-2.1.1
title: New Portainer CE 2.1.1 Release - now with support for Compose >3 in standalone hosts, and Compose 3.8 for Swarm
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/portainer-release-2.1.1
hostname: portainer.io
description: Announcing Portainer CE Release 2.1.1. Discover the new features, fixes and tips for upgrading.
sitename: PORTAINER.IO
date: 2021-02-05
categories: []
tags: []
image: https://www.portainer.io/hubfs/Announcing%20Portainer%20CE%202.1.1-1.png
pagetype: article
filedate: 2025-01-18
-->

Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our [Portainer Features page](/features)*. *

We're excited to let you know that we've just released Portainer CE 2.1.1. This is a major release, that delivers 31 new features and fixes, including the much anticipated support for Compose >3 in standalone hosts, and Compose 3.8 for Swarm. We've highlighted the most significant changes below, and you'll find a link to our tips and tricks for upgrading.

1. Support for Compose v3.8 when deploying against standalone Docker Hosts

This feature has been in demand for over a year, so we're excited for you to get your hands on it. We now ship the compose binary as part of the Portainer container. This means you can now use plain Compose files up to 3.8 (or higher for standalone) to deploy stuff through the UI/API.

Note this feature is only available for AMD64 architectures (Windows & Linux). The team are still working on creating a standalone binary for Compose that works on ARM/ARM64 (we aim to add support for these architectures in a future release).

2. Support for Compose v3.8 when deploying against Swarm Hosts

Another feature that has been in hot demand! This one was a challenge, but you can now deploy any Compose v3.8 stack against Swarm.

3. Portainer Images now built with Docker Buildx

We needed to report our images to Buildx to get native support for all architectures, and importantly, to provide Windows images spanning 1809-2004. This was also needed in order to get Portainer working on Docker 20.04.x on platforms other than AMD64.

4. De-emphasis the Portainer Login box when OAuth is used

When you have OAuth authentication enabled, the Portainer login screen becomes somewhat pointless, as you don’t need to enter creds, instead you need to click a “login with OAuth” button; so we have now hidden the login screen and just show the “login with OAuth” button.

5. Advanced Deployment for Kubernetes

We already allowed admins to deploy Kubernetes apps using a manifest directly within Portainer, we have now expanded this to allow the creation of any Kubernetes resource.

**Bug Fix Highlights**

1. Fixes for usernames that include the @ sign when deploying resources in Kubernetes

Anyone using OAuth or LDAP authentication in Portainer that had the @ sign in their name would have been prevented from deploying resources in Kubernetes endpoints. This is because we pass the username to Kubernetes, which does not support the @ sign. We have now changed this behavior.

2. Fixed a bug that causes an “invalid duration” error to be logged in the Portainer container, that then stops Portainer from starting.

**Tips and tricks for Upgrading**We have tested and validated Portainer version upgrades from 1.24.0 to the latest (2.1.1). Although un-tested, it is possible an upgrade path that has not been validated might work. We recommended that you test any upgrade path on a non critical system before applying it to your active production systems.

See upgrade Instructions for Docker, Docker Swarm and Kubernetes [here](https://documentation.portainer.io/v2.0/upgrade/upgrade/).

You can pull the latest CE image by command:

docker pull portainer/portainer-ce:latest

Any questions, don't hesitate to drop me a line. Or join our [Slack channel](https://portainer.slack.com/join/shared_invite/enQtNDk3ODQ5MjI2MjI4LTcwNGYxMWQ5OGViYWZkNDY2ZjY4YTMwMTgzYmU4YmNiOTU0MDcxYmJjNTIyYmQ0MTM5Y2QwNTg3NzNkMTk5MDg#/) here.

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-access-control-setup
title: Portainer Access Control Setup via the API
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/portainer-access-control-setup
hostname: portainer.io
description: You can in fact very easily allow users or teams access. Assuming that we have a team dev, you can add a label like this
sitename: PORTAINER.IO
date: 2020-12-07
categories: []
tags: []
image: https://www.portainer.io/hubfs/access_control_authentication_privileges_network_connectivitaccess%20control%20y_security_by_metamorworks_gettyimages-966835276_2400x1600-100808099-large.jpg
pagetype: article
filedate: 2025-01-18
-->

Thanks to [@tobiasfenster](https://twitter.com/tobiasfenster) for this blog post on setting access control via the Portainer API.

[Portainer](https://portainer.io/) is a great tool to simplify container management, that I’ve been using for quite some time by now. In fact, my first blog post [on that topic](https://www.axians-infoma.de/techblog/nav-on-docker-with-portainer/) is from July 2017, and we are today relying on it as part of our Azure DevOps & Docker self-service offering. I had a blog post about the setup of access control in Portainer in my blog backlog for a while, because it took me a long time to figure out how it works through the API as it is way more complicated than necessary and needs ugly workarounds. Or at least I thought that, until I came across this [pull request](https://github.com/portainer/portainer/pull/3337) because of a discussion on the Portainer slack. [Read more.](https://tobiasfenster.io/portainer-access-control-setup)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/3-reasons-you-need-portainer-in-your-life
title: 3 Reasons you need Portainer in your life
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/3-reasons-you-need-portainer-in-your-life
hostname: portainer.io
description: Why you need Portainer to help manage Kubernetes
sitename: PORTAINER.IO
date: 2021-03-17
categories: []
tags: []
pagetype: article
filedate: 2025-01-18
-->

**1. Portainer removes the complexity associated with deploying and managing containers.**

Portainer’s goal is to deliver a world class container-native application deployment and Management tool that is truly platform agnostic. To achieve this, we’ve made the underlying container management platform (eg Kubernetes) invisible to the engineers who simply want to manage their apps. If you use Portainer you’re able to CONSUME the container platform without being an expert in it.

**2. Portainer streamlines the operations of container management.**

With Portainer, engineers can deploy and see the state of individual containers, restart them and debug them when necessary – all without needing to use the command line. Portainer also provides deep visibility into what’s running, where it's running and how it's running, which helps engineers optimize app performance.

And because Portainer connects to all your hosts and platforms, you get full visibility on a single webpage, which eliminates the need to connect to each individual container to check on its state. This saves masses of time time and lets engineers focus on what’s important.

**3.Portainer provides an enterprise sensitive tool that complies with IT governance best practice.**

Technology leaders need to be able to manage apps in a secure, repeatable, and scalable manner. Portainer provides a structured framework for that enables this to happen as well as enabling teams to work collaboratively. This reduces risk on your business and helps you be compliant in the way you deploy and manage your applications.

Identity and Access management is a problem in native container platform management and it’s a problem Portainer solves. It gives you the ability to assign specific roles with pre-set functionality limits to users and teams and even nest roles to create fine grained access rights.

And it doesn’t end there. Portainer automatically logs all actions taken around container management, capturing details on who created, maintained, or even deleted containers – helping you trace back any issues that might occur across your organization.

So there it is. 3 reasons why your business should use Portainer to manage its container-based applications.

Want to know more? Visit us at [www.Portainer.io](/) or request a demo here.

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/multi-cluster-management-with-portainer.io
title: Easy Multi Cluster Management for Kubernetes, Docker/Swarm and Edge
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/multi-cluster-management-with-portainer.io
hostname: portainer.io
description: Manage multiple remote clusters simultaneously from a single instance of Portainer – regardless of the orchestrator being used ie. Kubernetes, Docker/Swarm
sitename: PORTAINER.IO
date: 2021-02-09
categories: []
tags: []
image: https://www.portainer.io/hubfs/undefined-Feb-09-2021-01-13-25-95-AM.png
pagetype: article
filedate: 2025-01-18
-->

In this blog post, you will learn how to use Portainer to easily handle multi cluster management from a single instance of Portainer's easy [Kubernetes GUI](/solutions/kubernetes-ui). This is accomplished by deploying an instance of the Portainer agent in every cluster you wish to manage and then connecting the central Portainer instance to the agents. We've also posted a 'how-to' video on this topic on our YouTube channel [here](https://youtu.be/DQlixR6bd_Q).

For the purpose of this blog, the central instance of Portainer is running on a dedicated management instance using Docker,

**Pre-reqs and assumptions:**

- Run the commands as super-user (root) or with sudo;
- Use a modern Linux OS with
**snap**support (not necessary for the deployment of the agent on Azure);

**Deploy the centralized Portainer instance on Docker**

Let's start by deploying a standalone Portainer instance. This can be done on a machine running on a local network, personal computer or laptop.

- On a terminal app of your preferences with docker installed (you can follow the official documentation
[here](https://docs.docker.com/engine/install/)on how to install docker) run the commands below:`docker volume create portainer_data`

`docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce`

- Once
**Portainer**has been installed you can access the UI by opening a browser and typing the IP address of the machine where it has been deployed on port**9000**, for example**http://192.168.1.100:9000**. You will land on Create the administrator user page: - On the next screen make sure to select the
**Manage the local Docker environment**option, click on**Connect**... - ...and you should land on the local endpoint where your standalone
**Portainer**instance is running:

**Deploy the Kubernetes NodePort agent on the first remote cluster**

- Open your preferred terminal app;
- Login to the main node machine of your kubernetes cluster via ssh;
- Run the commands below as super-user or with
**sudo**:`curl -L https://downloads.portainer.io/portainer-agent-k8s-nodeport.yaml -o portainer-agent-k8s.yaml; kubectl apply -f portainer-agent-k8s.yaml`

`kubectl get pods --namespace=portainer`

–>*this will show the state of the agent*

- Open
**Portainer**on your browser and select Home->Endpoints: - Select
**Add endpoint**: - Select
**Portainer Agent**: - Fill the following variables on the form:
**Name:**pick a name to identify your environment cluster, for example*local kubernetes cluster***Endpoint URL:**{IP address:30778} where**IP address**is the ip of the machine where you installed the agent.

- If all goes well you should see a
**Endpoint created**pop-up box and the**Kubernetes features configuration**page : - For a kubernetes cluster running on-premise you can set the
**Enable features using metrics server**and the**microk8s-hostpath**options - Your
**Portainer**home screen should show the new Endpoint:

**Deploy the Docker Swarm agent on the second remote cluster**

The Docker Swarm agent installation is straightforward and easy.

- Open your preferred terminal app;
- Login to the manager machine via ssh;
- Run the commands below as super-user or with
**sudo**:`curl -L https://downloads.portainer.io/agent-stack.yml -o agent-stack.yml && docker stack deploy --compose-file=agent-stack.yml portainer-agent`

`docker service ls`

–>*this will show the state of the agent*

- Repeat steps 4 through 7 from the
but**Deploy the Kubernetes NodePort agent****making sure to use port 9001 instead of 30778**on the**Endpoint URL**

**Deploy the Azure AKS Load Balancer agent on the third remote cluster**

Installing the **Portainer** agent on Azure AKS can be 100% on the Azure Portal.

- Open
**Cloud Shell**on your Azure Portal: - Run the commands below:
`az aks get-credentials --resource-group portainer-endpoint-demo --name portainerEndpointDemo`

–>*downloads the credentials to the .kube/config file so you can manage the kubernetes cluster with kubectl*,**make sure to replace the resource group and the cluster name accordingly**`curl -L https://downloads.portainer.io/portainer-agent-k8s-lb.yaml -o portainer-agent-k8s.yaml; kubectl apply -f portainer-agent-k8s.yaml`

`kubectl get pods --namespace=portainer`

–>*this will show the state of the agent*

- Once the agent is installed you can close the Cloud Shell box and go to:
**Kubernetes services**:- Select the cluster where the agent was deployed:
- Open the
**Services and ingresses**option and you will see the public IP address deployed by the**Portainer**agent on the cluster:

- Repeat steps 4 through 7 from the
but**Deploy the Kubernetes NodePort agent****making sure to use the public IP assigned by the Azure service with port 9001**on the**Endpoint URL**. - The
**Kubernetes features configuration**is slightly different than the one used for the on-premise kubernetes cluster:- Enable the
*ingress controller*. For Azure the name of the controller is**nginx**and type**nginx** - Enable at least one Storage option:

- Enable the

- Explanation of the Azure Storage types can be found
.[here](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbTFKWVh3LTFOeUJoNVMza19MeWFuaGE1WlMtd3xBQ3Jtc0tsSE9JajZWRzJlRFVIRVRmRXgwVWtwV2NsbjBuUUdYV0oxcTFTdWhET0dIN21obmZEejBUNkx2UjVQRUNwZHJDMEJtWGZZbmhEczdMNFYtbUVjUXZydGtLZW5UcVBabVFxaVAwN09kbEtnSUd5cUMtMA&q=https%3A%2F%2Fdocs.microsoft.com%2Fen-us%2Fazure%2Faks%2Fconcepts-storage)

**Deploy the DigitalOcean Load Balancer agent on the fourth remote cluster**

- For DigitalOcean the pre-req is that you have their
**doctl**command line utility installed and authenticated. Please refer to the installation page for**doctl**[here](https://github.com/digitalocean/doctl). - The other pre-req is
**kubectl**installed via the snap package manager. Make sure to install the same version of**kubectl**as the one on your hosted cluster.

- Open your preferred terminal app
`curl -L https://downloads.portainer.io/portainer-agent-k8s-lb.yaml -o portainer-agent-k8s.yaml; kubectl apply -f portainer-agent-k8s.yaml`

`kubectl get pods --namespace=portainer`

–>*this will show the state of the agent*

- Go to the
**Networking**option on your DigitalOcean dashboard: - Will should see a public IP address assigned via a Load Balancer to your cluster:
- Repeat steps 4 through 7 from the
but**Deploy the Kubernetes NodePort agent****making sure to use port 9001 and the public IP assigned by Digital Ocean**on the**Endpoint URL**

[Slack channel](https://portainer.slack.com/join/shared_invite/enQtNDk3ODQ5MjI2MjI4LTcwNGYxMWQ5OGViYWZkNDY2ZjY4YTMwMTgzYmU4YmNiOTU0MDcxYmJjNTIyYmQ0MTM5Y2QwNTg3NzNkMTk5MDg#/).

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/deploy-and-manage-traefik-with-portainer-on-a-charmed-kubernetes-cluster
title: Deploy and Manage Traefik with Portainer on a Charmed Kubernetes cluster
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/deploy-and-manage-traefik-with-portainer-on-a-charmed-kubernetes-cluster
hostname: portainer.io
description: In this post you will learn a basic deployment of the Traefik ingress controller on a Charmed Kubernetes cluster and how to use it with Portainer.
sitename: PORTAINER.IO
date: 2021-03-18
categories: []
tags: []
image: https://www.portainer.io/hubfs/How-to%20Deploy%20and%20Manage%20Traefik%20with%20Portainer%20on%20a%20Charmed%20Kubernetes%20cluster.png
pagetype: article
filedate: 2025-01-18
-->

In this post you will learn a basic deployment of the Traefik ingress controller on a Charmed Kubernetes cluster and how to use it with Portainer. Please make sure to check our blog post [here](https://www.portainer.io/blog/using-portainer-to-manage-canonical-charmed-kubernetes) on how to use Portainer on a Charmed Kubernetes cluster as it is a pre-req for this tutorial.

Assumptions:

- You have a Charmed Kubernetes cluster deployed
- You have access to your cluster via
*kubectl* - You have
*helm*installed - You have a wildcard domain name setup on your DNS server. Another option is to add each host used on your cluster to your DNS server.

#### Initial prep-work

Let's start with some initial prep-work to prepare your cluster so you can do a basic deployment of Traefik.

- Download the Traefik
*values.yaml*file from their repository with the command :`wget https://raw.githubusercontent.com/traefik/traefik-helm-chart/master/traefik/values.yaml`

- Change the
*values.yaml*file with*sed*so Traefik has access to ports 80 and 443:`sed -i 's/\# hostPort: 8000/hostPort: 80/g' values.yaml sed -i 's/\# hostPort: 8443/hostPort: 443/g' values.yaml`

- Add the Trafik repo to
*helm*:`helm repo add traefik https://helm.traefik.io/traefik helm repo update`

- Remove the
*nginx-ingress-controller*:`kubectl delete namespace ingress-nginx-kubernetes-worker`

- Deploy
*traefik*:`helm install traefik traefik/traefik -f values.yaml`

- Access your
**Portainer**instance via a ssh tunnel:`juju ssh kubernetes-master/0 -L 30777:localhost:30777 -fN`

#### Setup Portainer

- Go to
**Cluster->Setup**and add the*traefik*ingress controller:

#### Adding an App

- Start by adding a Resource pool in order to deploy an app to be routed via
*traefik*: - In this tutorial we are going to deploy Caddy:
- Go to
**Applications->Add application**and fill in the options for Caddy. Make sure to select the*caddy*resource pool that you created earlier: - After selecting the appropriate options, the last step is to publish your app. At the end of the App creation you need to select:
- Ingress - Publish this application via the HTTP route
- Click on
**publish a new port** - Add the container port, in this case 80
- Add the route, in this case
**/**(root path)

- After the app is deployed you can open the HTTP route configured in your resource pool to access Caddy:
- You will see the default Caddy first page in your browser window:

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/secure-your-portainer-setup-with-security-controls
title: Secure Your Portainer Setup with Security Controls
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/secure-your-portainer-setup-with-security-controls
hostname: portainer.io
description: Discover the security controls available within Portainer to secure your setup.
sitename: PORTAINER.IO
date: 2021-03-05
categories: []
tags: []
image: https://www.portainer.io/hubfs/Secure%20Your%20Portainer%20Setup%20with%20Security%20Controls.png
pagetype: article
filedate: 2025-01-18
-->

In this post you are going to learn about some very interesting security controls that Portainer provides.

In the Settings page of Portainer you can select the options below as an administrator user:

**Disable bind mounts for non-administrators**: This security setting blocks the ability for non-admin users within Portainer to use bind mounts when creating containers and/or services/stacks. When this is enabled, the option to attach to a host file system path is removed.**Disable privileged mode for non-administrators**: This security setting blocks the ability for non-admin users within Portainer to elevate the privilege of a container to bypass SELinux/AppArmour. When this is enabled, the option to select "Privileged" mode when creating a container is removed.**Disable the use of host PID 1 for non-administrators**: This blocks the ability for non-admin users within Portainer to request that a deployed container operates AS the host PID. This is a security risk if used by a non-trustworthy authorized user as when they operate as PID1, they are in effect able to run any command in the container console as root on the host.**Disable the use of Stacks for non-administrators**: This is a "sledgehammer" method to remove any possibility for non-admin users within Portainer to find and use weaknesses in the Docker architecture. Whilst Portainer have provided the ability to disable some of the more common exploits, we cannot possibly block them all as there are any number of capabilities that could be added to a container to attempt to gain access to the host. This feature simply allows an admin to disable all possible entry-points.**Disable device mappings for non-administrators**: This blocks the ability for users to map host devices into containers. Whilst the ability to map devices is generally used for good (eg mapping a GPU into a container), it can equally be used by non-trustworthy authorized users to map a physical storage device into a container. It is possible to mount /dev/sda1 into a container, and then from a console of that container, the user would have complete access to the sda1 device without restriction. By enabling this feature, Portainer blocks the ability for non-admins to map ANY devices into containers.**Disable container capabilities for non-administrators**: Enabling the setting will hide the container capabilities tab for non-administrators when they are creating a container.

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/how-to-install-portainer-on-a-synology-nas
title: How to Install Portainer on a Synology NAS
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/how-to-install-portainer-on-a-synology-nas
hostname: portainer.io
description: Today we are going to take a look at how you can install Portainer on a Synology NAS.
sitename: PORTAINER.IO
date: 2021-03-31
categories: []
tags: []
image: https://www.portainer.io/hubfs/How%20to%20Install%20Portainer%20on%20a%20Synology%20NAS.png
pagetype: article
filedate: 2025-01-18
-->

This guest blog post from [WunderTech](https://www.wundertech.net/) takes a look at how you can install Portainer on a Synology NAS.

Portainer gives users a way to manage their Docker containers through a great web interface. For my Raspberry Pi and Ubuntu Docker instances, I use Portainer to manage my containers. For my Synology NAS, I generally use the front-end Docker GUI. Now, the front-end GUI of Docker on a Synology NAS leaves a lot to be desired, but overall, it’s an easy way to set up and maintain your containers.

The first question you’ll probably have is *why* you should install Portainer, and the truth is that you don’t have to. However, if you’re willing to experiment with it, you might find it easier to manage and use than Synology’s GUI. Portainer also gives you the ability to use stacks which is an easy way to create new containers and allows them to be created using a docker-compose format. If you haven’t used docker-compose before, it’s just an easy way to copy/paste pretty much all of the configuration you’ll need for a container and create it with the push of a button. [Read more](https://www.wundertech.net/how-to-install-portainer-on-a-synology-nas/)

Try Portainer with 3 Nodes Free

If you're ready to get started with Portainer Business, [3 nodes free](https://www.portainer.io/take-3) is a great place to begin. If you'd prefer to [get in touch with us](https://www.portainer.io/contact-sales), we'd love to hear from you!

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/how-to-deploy-portainer-on-microk8s
title: How to Deploy Portainer on MicroK8s
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/how-to-deploy-portainer-on-microk8s
hostname: portainer.io
description: Discover how easy it is to deploy Portainer in Kubernetes with the latest version of MicroK8s. #portainer #kubernetes #microk8s
sitename: PORTAINER.IO
date: 2021-01-26
categories: []
tags: []
image: https://www.portainer.io/hubfs/How%20to%20Deploy%20Portainer%20on%20MicroK8s.png
pagetype: article
filedate: 2025-01-18
-->

**Updated Sept 2022**.

Deploying Portainer on MicroK8s is extremely easy and fast. We are going to describe here how to have Portainer up and running in no time with one simple command. We've also posted a quick 5 minute video on our YouTube channel [here](https://youtu.be/XYcKmPi4McA).

First some pre-reqs:

- Make sure that you run the commands as
**root** - Ubuntu server v22.04 or any other linux distribution/OS that can run MicroK8s (installation details can be found here:
[https://microk8s.io/docs](https://microk8s.io/docs)) - MicroK8s v1.24.0
- Before deploying portainer we have to make sure that MicroK8s has been deployed with the following addons enabled:
- dns
- ha-cluster
- ingress
- metrics-server
- rbac
- hostpath-storage

- Before deploying portainer we have to make sure that MicroK8s has been deployed with the following addons enabled:

In order to check which addons are already enabled please run the command ```
microk8s status
```

.

The output should be something similar to this:

We can see here that the addons mentioned above are already deployed.

Enabling Portainer is as simple as running `microk8s enable community `

`and then microk8s enable portainer`

.

It takes less than a minute to install.

You can check the progress of the installation by running `kubectl get pods -n portainer`

.

It shouldn't take more than 25s to download, install and start. We can now swtich to a web browser to load the Portainer interface. Please make note of the IP address of the machine that is running Portainer.

You can check the IP address on linux by running `ip a`

or `ifconfig`

.

Portainer for MicroK8s runs on port **30779** and in our case the IP address of the node running Portainter was **10.51.1.200** so in order to load the web interface we used [https://10.51.1.200:307779](https://10.51.1.200:30777/) on our web browser.

Finally now we can finish installing Portainer on the web browser in 3 simple steps:

1. Create the initial adminstrator user and password (you can change the default **admin** to any other username):

2. Connect Portainer to the local Kubernetes environment:

3. The last step is to configure the Kubernetes features you would like to enable on your installation:

If the default ones are ok, you can simply click on **Save configuration** by scrolling down to the end:

You should see your local endpoint up and running with all the hardware resources recognized by Portainer:

Hope that worked well for you, and you're up and running with Portainer. If you have any questions or comments, please drop them into the comments section below, or join us on our [Slack channel](https://portainer.slack.com/join/shared_invite/enQtNDk3ODQ5MjI2MjI4LTcwNGYxMWQ5OGViYWZkNDY2ZjY4YTMwMTgzYmU4YmNiOTU0MDcxYmJjNTIyYmQ0MTM5Y2QwNTg3NzNkMTk5MDg#/).

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/deploy-applications-on-kubernetes-with-portainer-stateless-stateful-or-daemon
title: Deploy Applications on Kubernetes with Portainer - Stateless, Stateful or Daemon
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/deploy-applications-on-kubernetes-with-portainer-stateless-stateful-or-daemon
hostname: portainer.io
description: Deploying applications on Kubernetes can be done using at least 3 methods, Stateless, Stateful or Daemon. With Portainer it is very easy to deploy applications regardless of the method. Let's check how.
sitename: PORTAINER.IO
date: 2021-04-03
categories: []
tags: []
image: https://www.portainer.io/hubfs/Deploy%20apps%20on%20Kubernetes%20with%20Portainer%20-%20stateless,%20stateful%20or%20deamon.png
pagetype: article
filedate: 2025-01-18
-->

Deploying applications on Kubernetes can be done using at least 3 methods, Stateless, Stateful or Daemon. With Portainer it is very easy to deploy applications regardless of the method. Let's check how.

#### Stateless

- The
**Create application**option from Portainer by default will deploy applications as a Stateless/Deployment type that you can edit and scale up or down. Under**Deployment**make sure to select the**Replicated**option selected: - You can go back to the application after it is deployed to increase/reduce the amount of instances.
- It's that simple!

*If your application requires persistence, the amount of***Instance count**will be set to 1 to avoid data loss:

#### Stateful

- The difference from the method above is that a Stateful application, that necessarily requires persistence on the
**Data access policy**has to be selected as**Isolated**: - This is enough to deploy applications with a StatefulSet method.

#### DaemonSet

- To deploy applications as DaemonSets all you need to do is select a
**Global**deployment method so the pods are copied on every node of the Kubernetes cluster:

. - This will ensure that your application is deployed as a Daemon.

As you can see with Portainer it's extremely easy to deploy applications as Stateless, Stateful and as Daemon.

You can see a video walkthrough of this here:

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/swarm-on-azure-with-terraform
title: Creating a Docker Swarm on Azure with Terraform
author: Adolfo Delorenzo
url: https://www.portainer.io/blog/swarm-on-azure-with-terraform
hostname: portainer.io
description: Part 2 of the super helpful series on Creating a Docker Swarm on Azure with Terraform (in German). #dockerswarm
sitename: PORTAINER.IO
date: 2021-02-15
categories: []
tags: []
image: https://www.portainer.io/hubfs/TechWiese%20tile%20from%20Tobias%20Fenster.jfif
pagetype: article
filedate: 2025-01-18
-->

This guest post from [Tobias Fenster](https://www.microsoft.com/de-de/techwiese/cloud-native-community-blog/tobias-fenster.aspx) is Part 2 of the super helpful series on Creating a Docker Swarm on Azure with Terraform (in German).

Es ist schon eine Weile her, aber in [Teil 1](https://www.microsoft.com/de-de/techwiese/cloud-native-community-blog/erstellen-eines-docker-swarms-auf-azure-mit-terraform-teil-1.aspx) dieser Post-Serie habe ich die Gesamtarchitektur und den Ansatz zur Erstellung eines Windows-[Docker Swarms](https://docs.docker.com/engine/swarm/) auf Azure mit [Terraform](https://www.terraform.io/) erklärt, vorbereitet mit [Portainer](https://www.portainer.io/) und [Traefik](https://traefik.io/). In diesem zweiten Teil möchte ich tiefer in das Terraform-Setup sowie die dafür verwendeten Konfigurationsdateien einsteigen. [Read more](https://www.microsoft.com/de-de/techwiese/cloud-native-community-blog/erstellen-eines-docker-swarms-auf-azure-mit-terraform-teil-2.aspx)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-launches-business-edition-bringing-simplified-container-management-platform-to-enterprise-scale
title: Portainer Launches Business Edition for Enterprise Container Management
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-launches-business-edition-bringing-simplified-container-management-platform-to-enterprise-scale
hostname: portainer.io
description: Portainer.io, creator of open source tools to easily manage containers, has launched Portainer Business, which adds premium business-critical features to its container management platform.
sitename: PORTAINER.IO
date: 2020-12-09
categories: []
tags: []
image: https://www.portainer.io/hubfs/PB%20Screen%20Shots-1.png
pagetype: article
filedate: 2025-01-18
-->

[Portainer.io](//www.portainer.io/), creator of open source tools to easily manage containers, has launched Portainer Business, which adds premium business-critical features to its container management platform. Growing to 500,000 open source users in just two years, Portainer.io is anticipating rapid uptake of its business offering, particularly given the recent introduction of support for Kubernetes.

Portainer Business is built on top of Portainer.io’s beloved open source platform, which simplifies container management and orchestration without compromising functionality. Portainer Business serves the CIO and CISO community by offering the enhanced control and security needed to run Portainer in corporate Kubernetes, Docker, and Edge environments. The new product also incorporates the rigorous pre-release testing and comprehensive support business users need for an annual license fee, while continuing to decrease complexity and humanize container management.

Complexity and security are two of the top challenges facing teams deploying containers, according to CNCF data. Portainer Business solves both.

“We are thrilled to launch Portainer Business today because it will enable Portainer.io to remain true to our open source roots,” said Portainer.io CEO and Co-Founder Neil Cresswell. “We are a small team with big ambitions for our open source software and we want to be able to continue to innovate and respond to development requests from our community. With Portainer Business, we can meet the needs of commercial users in a sustainable way while continuing to fund Portainer’s open source Community Edition.”

Portainer.io is well-equipped to support a proven model of offering both paid and open source versions of its product. The Portainer.io team is spread across four continents and covers every time zone and multiple languages. As Portainer Business gains traction, the company will grow its support footprint further and work with partners to amplify its uptake.

By volume of users, Portainer.io is already one of the most successful software ventures to come out of New Zealand. Earlier in the year, the company attracted an initial seed funding round of US$1.2 million to fast-track its growth plans and is looking to rapidly convert its open source success into global revenue generation. Portainer Business is launching with more than 800 users already onboard and a backlog of 250 self-identified early adopters waiting to get their hands on its software.

[Compare Portainer CE with Portainer Business](/products)

--

**About Portainer.io**

Portainer.io was born in 2017 from founders Neil Cresswell and Anthony Lapenna's own struggle to learn Docker, with the vision to create a simple GUI-based tool to manage Docker - regardless of whether it was deployed standalone, in a cluster, on-premise, at the edge or in the cloud. In August 2020, the project was expanded to include support for Kubernetes and Azure ACI as well as retaining full support for Docker & Docker Swarm. Portainer Community Edition currently has over 500,000 global users. Portainer Business is the first business product Portainer.io has offered in its quest to humanize container management and orchestration.

The team most recently raised a $1.8M NZD/$1.2M USD seed round in August of 2020.

**Press Contact:**

Savannah Peterson

E: [Savannah@SavvyMillennial.com](mailto:Savannah@SavvyMillennial.com)

M: +1 805 550 1998

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/proxy-and-load-balance-your-microk8s-services-using-ingress-and-metallb-with-portainer
title: Proxy and Load Balance your MicroK8s services using Ingress and MetalLB with Portainer
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/proxy-and-load-balance-your-microk8s-services-using-ingress-and-metallb-with-portainer
hostname: portainer.io
description: How to configure Ingress and MetalLB with Portainer on MicroK8s.
sitename: PORTAINER.IO
date: 2021-02-16
categories: []
tags: []
image: https://www.portainer.io/hubfs/Proxy%20and%20Load%20Balance%20your%20MicroK8s%20services%20using%20Ingress%20and%20MetalLB%20with%20Portainer.png
pagetype: article
filedate: 2025-01-18
-->

Let's learn how to use two very cool MicroK8s networking addons with Portainer; **Ingress** and **MetalLB** and even how to combine them with applications deployed on Kubernetes.

I suggest you watch the [How-to: Deploy Portainer on MicroK8s](https://youtu.be/XYcKmPi4McA) video first so you have the right setup for this guide.

[MicroK8s](file:///C:/Users/neilc/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/ME7RDXHU/Proxy%20and%20Load%20Balance%20your%20MicroK8s%20services%20using%20Ingress%20and%20MetalLB%20with%20Portainer.html#MicroK8s) addons setup

[MicroK8s](file:///C:/Users/neilc/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/ME7RDXHU/Proxy%20and%20Load%20Balance%20your%20MicroK8s%20services%20using%20Ingress%20and%20MetalLB%20with%20Portainer.html#MicroK8s)addons setup

- Let's start by running
`microk8s status --wait-ready`

to see which addons are enable: - We need to enable
**ingress**and**metallb**by typing`microk8s enable ingress && microk8s enable metallb`

- You will notice that you need to provide an IP address range that will be managed by the load balancing feature of metallb.
- You can setup a static route on your router that will point to the IP address of the node/cluster where Metallb is being deployed. There are several other ways of doing this and by running a search on your preferred search engine with the string
*creating static route linux*will provide you with several examples. In my case I set a static route on my gateway like this:

The IP address of my main node is**10.51.1.165** - For
**metallb**I defined the IP address range of 10.51.2.10 to 10.51.2.50:

- You can setup a static route on your router that will point to the IP address of the node/cluster where Metallb is being deployed. There are several other ways of doing this and by running a search on your preferred search engine with the string

**Portainer setup**

You can now switch to **Portainer** to continue the setup.

- Login to
**Portainer**and select the endpoint where the**MicroK8s**were enabled: - On the left hand side menu select Cluster -> Setup:
- On the
**Networking**features of your node/cluster you have to:- Enable
**Allow users to use external load balancer** - Configure the
**Ingress controller**with the*Ingress class*name of**public**and type**nginx**:*It is important that you use public as the ingress class name otherwise the addon will not work.* - Finally you need to
**Enable features using metrics server**option and also enable the**Storage**with RWO, RWX access policy so more than one pods can access your storage concurrently:

- Enable

That's it for the **Portainer** setup. Now let's deploy two applications with access via **metallb** with load balancing and **ingress** with hostname mapping.

**Load Balancer setup example**

A good example of when to use the Load Balancer is when an application has to be accessed via a given port like for instance a database engine. So let's deploy a MySQL database:

- Select
**Applications**on the let hand side menu and then**Add application**:

- Configure your application by giving it a
**Name**; - Provide the image name on the
**Image**box, in this case**mysql:5.6**; - It is always good to bundle the deployment under a
**Stack**that I called**mysql**: - On the
**Environment variables**for**mysql**you need to add**MYSQL_ROOT_PASSWORD**that in this example I used**db1234**: - On the
**Persistent folders**option you might want to set the*path in container*to**/var/lib/mysql**and give the database engine at least**20GB**of storage: - On the
**Publishing the application**options you need to select**Load balancer**; - Click on
**publish a new port**; - Fill the
**container port**option and**load balancer port**option accordingly. For[MySQL](file:///C:/Users/neilc/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/ME7RDXHU/Proxy%20and%20Load%20Balance%20your%20MicroK8s%20services%20using%20Ingress%20and%20MetalLB%20with%20Portainer.html#MySQL)the default port is**3306**: - Finally click on
**Deploy Application**. You should see a message confirming the application has been successfully deployed:

- Configure your application by giving it a
- On the
**Application list**page you can enable a very cool feature of**Portainer**on the**Table settings**to Auto refresh so you can monitor the status of your applications: - On the
**Status**column you will see that the deployment has finished successfully when the**Replicated**staus is at least**1/1**: - Click on the name of the application
**mysql**to check the IP address that has been assigned by the Load Balancer:

In this case it was the first IP address defined when**metallb**was enabled with**MicroK8s**

That's it. MySQL has been successfully deployed and published via the ** MicroK8s metallb** addon via the IP address

**10.51.2.10**on port

**3306**.

**Ingress controller setup example**

Now we will combine the **ingress** addon with the previous MySQL database application by deplying a very popular frontend called **phpMyAdmin**.

- Start by adding a
**Resource pool**and then**Add resource pool**:

- Give the resource pool a name that you can easily identify for the application that you will deploy, in this case
**phpmyadmin**: - On the
**Ingressess**configuration make sure that**Allow users to use this ingress**is enabled; - You provide a discoverable
**Hostname**that is configured on your DNS server pointing to the main node IP address... - ... and you enable
**Redirect published routes to / in the application**: - Next click on
**Create resouce pool**

- Give the resource pool a name that you can easily identify for the application that you will deploy, in this case
- You can now add the
**phpMyAdmin**application just like steps #1 through #3 of the**Load Balancer setup example**above but make sure to select the*phpmyadmin*on the**Resource pool**option in this case:

You can use the same stack name defined previously for the MySQL database if you want - On the
**Environment variables**you will add the IP address of the MySQL database provided by**metallb**earlier of**10.51.2.10**using the**PMA_HOST**variable for**phpMyAdmin**: - You can add a
**Persistent folder**with 10GB, this should be more than enough for**phpMyAdmin**; - On the
**Publishing the application**configuration you now see the**Ingress**option available that you will select; - Click on
**publish a new port**that is slighlty different than what we saw on our previous example for the MySQL database and configure the**container port**to**80**, the**ingress**is already defined with**public**and the**route**needs to be**/**: - Click on
**Deploy application**and monitor the deployment of the application like in the previous example: - Open the application name by clicking on
**phpmyadmin**and you will see the**HTTP route**that was defined on the**Resouce pool**for**phpMyAdmin**: - Click on
**route**and you should be able to access the**phpMyAdmin**UI: - Let's test if our access to the MySQL database works by typing the
**Username:***root*and**Password***db1234*that we defined on our previous example. If all goes well you should see the default**phpMyAdmin**page:

In this tutorial we saw the power of combining **Portainer** with **MicroK8s** together with the amazing addons that we enabled and managed without having to write complex YAML files.

Hope that worked well for you, and you're up and running with Portainer. If you have any questions or comments, please drop them into the comments section below, or join us on our [Slack channel](https://portainer.slack.com/join/shared_invite/enQtNDk3ODQ5MjI2MjI4LTcwNGYxMWQ5OGViYWZkNDY2ZjY4YTMwMTgzYmU4YmNiOTU0MDcxYmJjNTIyYmQ0MTM5Y2QwNTg3NzNkMTk5MDg#/).

You can watch the YouYube video of this here:

Request a Demo of Portainer Business

Let us introduce you to a world of fast and easy app deployment, governance, and management in Docker, Kubernetes, and more. [Request a 1:1 demo](https://www.portainer.io/portainer-demo-request-kubernetesgui-dockergui) to see how Portainer Business helps to make teams more accurate and efficient in a business environment.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/running-linux-and-windows-containers-at-the-same-time-on-windows-10
title: Running Linux and Windows containers at the same time on Windows 10
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/running-linux-and-windows-containers-at-the-same-time-on-windows-10
hostname: portainer.io
description: Need to run Linux and Windows Docker containers at the same time on your Windows 10 machine? Catch this blog post to learn how!
sitename: PORTAINER.IO
date: 2021-04-27
categories: []
tags: []
image: https://tobiasfenster.io/images/docker-switch-warning.png
pagetype: article
filedate: 2025-01-18
-->

This guest blog post from [Tobias Fenster](https://tobiasfenster.io/) takes a look at how to run Linux and Windows containers at the same time on Windows 10.

I am typically using Docker on my Windows 10 laptop for dev containers, which (unfortunately) means only Linux containers, although my professional context mostly is Windows-oriented. However I recently did a demo using a local Windows container, so I had to switch back and forth and while I think I have seen the following message before, for the first time I read it properly:

Especially the yellow part got my interest as it clearly states that Linux containers keep running even if you switch to Windows containers. I’ve been tinkering with that idea [since 2016](https://www.axians-infoma.de/techblog/nav-2017-on-linux-sort-of/), so I decided to give it a try again. As a test case I used a Linux container for MS SQL and a Windows container for MS Dynamics 365 Business Central because official support for that combination was recently announced. [Read more](https://tobiasfenster.io/running-linux-and-windows-containers-at-the-same-time-on-windows-10)

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/kubernetes-the-1m-problem
title: Kubernetes, the $1M problem??
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/kubernetes-the-1m-problem
hostname: portainer.io
description: Does it really cost $1M to get started with Kubernetes?
sitename: PORTAINER.IO
date: 2021-04-19
categories: []
tags: []
image: https://www.portainer.io/hubfs/Kubernetes%20Costs.jpg
pagetype: article
filedate: 2025-01-18
-->

Over the weekend we saw a twitter post from ChangeLog (below), that reminded us of a number we had heard from multiple other sources too... we heard "in order to use Kubernetes in Production, you better be ready to add AT LEAST $1M to your IT costs". So seeing this same dollar value represented as "you need to have a million dollar problem" wasn't a surprise to us.

Anyway, when we first heard that "add $1M to your IT costs" comment last year, we dug around to try and understand if it was an off-hand comment, or if there was some logic to it.. turns out there was..

The logic was based around it being a 3 Year TCO, and it was to self-manage a small scale Kubernetes Cluster (scale wasn't mentioned, but for arguments sake lets say under 10 nodes) for a production critical environment (not a non-prod environment, a home lab, or sandpit) that is supported internally under an 11x5 SLA (and on-call out of hours). The logic said that two Kubernetes certified SREs would be needed (either new recruits or existing staff retrained) who would each likely command at least $150k annual salary (clearly this wasnt Silicon Valley numbers). The logic also said that if you use Kubernetes in Production you really should have some sort of support/subscription agreement for it, so there was an allowance of $50k p/a for that (Rancher starts at $60k p/a for a paid subscription, so $50k is actually a bit low).

So, (150k x 2 + 50k) x 3 = $1M.

And that was how the original 1M was calculated.

The original author also justified the number as incremental by saying "if you didn't go with Kubernetes, and stuck with VMs, you definitely do not need this additional cost."

Anyway, we neither agree nor disagree with the post nor the prior commentary, just giving more substance to the claims made by others from what we had heard through our external partners.

Are you running Kubernetes in production? What do you think? Let us know in the comments below.

Neil

"You need to have a million dollar problem to use Kubernetes" –

— Changelog (@changelog)[@benbjohnson]on[https://t.co/GBKYrVYt36]

Agree or disagree?🤔[#k8s][#cncf][#cloudnative][pic.twitter.com/kVc4oykWQG][April 17, 2021]

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/deploy-kubernetes-services-with-portainer
title: Deploy Kubernetes Services with Portainer
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/deploy-kubernetes-services-with-portainer
hostname: portainer.io
description: Learn how to use Portainer to deploy Kubernetes Services with applications. The Service Types covered are ClusterIP, NodePort, Load Balancer and Ingress.
sitename: PORTAINER.IO
date: 2021-04-13
categories: []
tags: []
image: https://www.portainer.io/hubfs/Deploy%20Kubernetes%20Services%20with%20Portainer.png
pagetype: article
filedate: 2025-01-18
-->

With Portainer it is very easy to configure Services Types with your Applications in Kubernetes. Let's check how this is done for ClusterIP, NodePort and Load Balancer.

**No Service Type**

- Deploying an Applications with no Service Type associated to it is very simple by not assigning any ports to it:

**ClusterIP Service Type**

- When deploying and Application that requires a ClusterIP Service type you simply publish a port with the
**Internal**publishing mode enabled:

**NodePort Service Type**

- When deploying and Application that requires a NodePort Service type you need to select the Cluster publishing mode and respective container+node ports required/used by the application:

**Load Balancer Service Type**

- When deploying and Application that requires a Load Balancer Service type you need to select the Load Balancer publishing mode and respective ports required or used by the application:
- In order to use the Load Balancer a plugin like MetalLB or similar has to be installed on your Kubernetes Cluster. You can then enable the Load Balancer via Portainer by:

- Opening you Cluster setup:
- Enabling the option in the Networking features of your Kubernetes cluster:

- Opening you Cluster setup:

**Ingress Service type**

- When deploying and Application that requires an Ingress Service type you need to first create a Resource Pool with the Ingress configured:
- You can the deploy the Application with the Ingress option making sure to select the proper Resource Pool:
- Once the proper Resource Pool is selected the Ingress option will be available for the application:
- In order to use the Ingress Service type an Ingress controller like Nginx or Traefik has to be installed on your Kubernetes Cluster. You can then enable the Ingress Controller via Portainer by:

- Opening you Cluster setup:
- Enabling the option in the Networking features of your Kubernetes cluster:

- Opening you Cluster setup:

**Additional features via Portainer**

**Auto-Scaling**

- Make sure the
**metrics server**plugin or similar is installed on your Kubernetes Cluster.- Enable the metrics server features via Portainer by opening you Cluster setup:
- Select the
**Enable features using metrics server**under**Resources and Metrics**:

- Enable the metrics server features via Portainer by opening you Cluster setup:
- When deploying an application you can select the auto scaling and respective minimum and maximum instances along with the
**Target CPU usage (%)**:

**Placement Rules**

- When deploying an application you can select the placement preferences under
**Placement preferences and constraints**and configuring the rule or rules you need for you application: - Make sure to select the
**Placement policy**accordingly:

We have also recorded a how-to video to show this in action.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/using-portainer-to-manage-canonical-charmed-kubernetes
title: Using Portainer to manage Canonical Charmed Kubernetes
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/using-portainer-to-manage-canonical-charmed-kubernetes
hostname: portainer.io
description: Using Portainer to manage Canonical Charmed Kubernetes
sitename: PORTAINER.IO
date: 2021-02-26
categories: []
tags: []
image: https://www.portainer.io/hubfs/undefined-Feb-26-2021-08-35-17-35-AM.png
pagetype: article
filedate: 2025-01-18
-->

So what about Deploying Portainer on a Canonical Charmed Kubernetes cluster? We have seen how to do this on MicroK8s that you can check on the link above but Charmed Kubernetes is an entirely different environment.

Canonical Charmed Kubernetes is demanding in terms of resources and is usually deployed on a Cloud provider like AWS, GCP or Azure. Oracle Cloud, Rackspace and CloudSigma can also be used to deploy Charmed Kubernetes. Local deployment is also possible but you have to make sure you have the right infrastructure to be able to do this.

Some pre-reqs for this tutorial:

- Access to a Linux machine via a ssh terminal, preferably Ubuntu on the latest version;
- You need the
**snap**package management app installed on the machine you are going to use for your deployment; - Access to a Cloud Service Provider like AWS, GCP or Azure. We will use Azure as the CSP for this tutorial so make sure you know what can be the equivalent interfaces/commands if you use a different provider.

**Initial setup**

During the initial setup you will learn how to install the tools are required to setup Charmed Kubernetes and deploy the cluster.

**Install the required tools**

- Run the commands below on your terminal:
`snap install juju --classic`

`snap install kubectl --classic`

`apt -y install nmap`

-> this optional and can be used to check the ports that are open on the public IP address of your node(s)

**Setup Juju with your cloud provider**

- Add the cloud provider credentials with
**juju**:`juju add-credential azure`

- You will be prompted to give this credential a name. You can use
*azure*for example: - The next prompt is the selection of the region you would like to use for the deployment. I picked
*eastus*: - The next step is to select the Auth Type, you can just go ahead and use
**[interactive]**by simply hitting*Enter*: - The next step is to type the Azure Subscription ID that you want to use to deploy your Charmed Kubernetes cluster:
- A link to finish setting up the credentials will appear that you need to open in your browser and paste the code to authenticate. A unique code will be generated every time you add the credentials via juju:
- If all goes well the following message will appear on your browser window:

**Deploying the Charmed Kubernetes cluster**

- Start the bootstrap of the
**juju**controller you will deploy on your cloud provider:`juju bootstrap azure <name>`

make sure to replacewith one of our preference. In this example I am going to use*name***charmed01**. This process can take up to 15 minutes:- Deploy your Charmed Kubernetes cluster:
- For a full cluster you can use
`juju deploy charmed-kubernetes`

. This will deploy at least 8 machines with 2 redundant master nodes. - An alternative is to deploy a smaller cluster with one master + one worker node and add more nodes afterwards:
`juju deploy cs:bundle/kubernetes-core-1200`

- Add at least 2 more nodes with
`juju add-unit kubernetes-worker -n 2`

. You can run this right after step #2 above.

- For a full cluster you can use
- You can monitor the progress of the deployment of your cluster with
`watch -c juju status --color`

: - This will take at least 20+ minutes. If all goes well you should see on your screen the following status:

You can hit*CTRL+C*to exit the juju status screen and go back to the prompt on your terminal window. - Make sure you have a folder called
*.kube*in your home folder. If you don't create is with`mkdir -p $HOME/.kube`

- Copy the config file from your master node in order to manage the cluster with kubectl:
`juju scp kubernetes-master/0:config ~/.kube/config`

- Run a quick test to make sure you can access your cluster with kubectl with
`kubectl get nodes`

. You should see your worker nodes on your cluster:

**Deploying **[OpenEBS](file:///C:/Users/Neil/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/AGGESFJ6/Using%20Portainer%20to%20manage%20Canonical%20Charmed%20Kubernetes.html#OpenEBS)

[OpenEBS](file:///C:/Users/Neil/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/AGGESFJ6/Using%20Portainer%20to%20manage%20Canonical%20Charmed%20Kubernetes.html#OpenEBS)

- OpenEBS is a amazing storage option for Kubernetes. Please visit their website to learn more about this project.
- Start by enabling the
**iscsid**service on all of your nodes with`juju ssh kubernetes-master/0 'sudo systemctl enable --now iscsid'`

. - Repeat this command for every worker node by replacing
**kubernetes-master/0**with**kubernetes-worker/0**for example:`juju ssh kubernetes-worker/0 'sudo systemctl enable --now iscsid'`

- Enable running privileged services on your master node:
`juju config kubernetes-master allow-privileged=true`

- Download the yaml file needed to deploy
**OpenEBS**on your cluster:`wget https://openebs.github.io/charts/openebs-operator.yaml`

- Even though we enabled running privileged services on our master node we still need to make a small change to the privileged string on the file:
`sed -i 's/privileged: true/privileged: false/g' openebs-operator.yaml && cat openebs-operator.yaml`

- Deploy
**OpenEBS**with kubectl:`kubectl apply -f openebs-operator.yaml`

- You can check the status of the
**OpenEBS**deployment with`kubectl get pod -n openebs`

- The deployment will finish once all the containers are running succesfully on your cluster:
- Finally we need to ensure that the
*openebs-jiva-default*storageclass is set as default by running:`kubectl patch storageclass openebs-jiva-default -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'`

- Run
`kubectl get sc`

to make sure the patch worked:**This is required otherwise Portainer cannot be installed**

- Start by enabling the

**Deploying Portainer**

- Installing
**Portainer**is very easy. All you need is to run`kubectl apply -n portainer -f https://raw.githubusercontent.com/portainer/k8s/master/deploy/manifests/portainer/portainer.yaml`

to install**Portainer**using**NodePort** - You can check the status of the instalation with
`kubectl get pod -n portainer`

. As soon as you see that the STATUS is*Running*then**Portainer**is ready to be used: **Portainer**when deployed on a**NodePort**will run on port**30777**. We need to open this port on Azure (or on the CSP you deployed your cluster) to make sure it is accessible on the public IP of your node. You can do this by going to the**All Resources**page on your Azure portal and selecting the**juju-internal-nsg**in the**juju-default-xxxxxxxx**Resource group:- Click on
**Inbound security rules**: - Create a rule that will open port
**30777**like this: - You should be able to access
**Portainer**by opening your browser with the public IP address of any of your nodes + port**30777**. In my case the public IP of my master node was**20.83.8.178**therefore the link to open**Portainer**was**http://20.83.8.178:30777**:

On this page you need to setup the administrator user for**Portainer** - The next step is to connect your
**Portainer**instance to you Kubernetes cluster: - The final step is to configure the Kubernetes features of your cluster on
**Portainer**by enabling the**metrics server features**: - and by enabling the
**openebs-jiva-default**storage class with a RWO,RWX and Volume Expansion: - Click on
**Save configuration**and your Charmed Kubernetes cluster is ready to managed with**Portainer**!!

You can watch this all via youtube here:

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/using-the-portainer-edge-agent-edge-groups-and-edge-stacks-part-1-0
title: Using the Portainer Edge Agent, Edge Groups, and Edge Stacks - part 2
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/using-the-portainer-edge-agent-edge-groups-and-edge-stacks-part-1-0
hostname: portainer.io
description: Using the Portainer Edge Agent, Edge Groups, and Edge Stacks - part 2
sitename: PORTAINER.IO
date: 2021-02-23
categories: []
tags: []
image: https://www.portainer.io/hubfs/Intro%20How-to%20Using%20the%20Portainer%20Edge%20Agent%5EJ%20Edge%20Groups%5EJ%20and%20Edge%20Stacks%20-%20part%202.png
pagetype: article
filedate: 2025-01-18
-->

Portainer has an amazing feature that lets you manage remote edge compute devices from a single centralized instance. You can manage for up to 25,000 x86 or ARM based edge devices running on unreliable or highly latent networks with support for Windows and Linux Operating Systems.

This is Part 2 of the **Using the Portainer Edge Agent, Edge Groups, and Edge Stacks** How-to. In part 1, we explain endpoint tags and adding endpoints using the edge agent (part one available [here](https://www.portainer.io/blog/using-the-portainer-edge-agent-edge-groups-and-edge-stacks-part-1)).

In this tutorial we will learn how to enable the **Edge Compute** features of **Portaner** and how to manage Edge with **Edge Groups** and **Edge Stacks**.

- Let's start by enabling the
**Edge Compute**feature. Click on**Settings**:

and scroll down to the the**Enable edge compute features**option: - You will notice that now there is a new submenu on the left hand side of
**Portainer**called*Edge Compute*: - Let's start with
**Edge Groups**. Please click on the option*Edge Groups*followed by**Add Edge group**: - There are two ways of creating
**Edge Groups**that you can name freely;**Static**and**Dynamic**:

- With
**Static**you add endpoints manually by clicking on them: - With
**Dynamic,**endpoints are added to the**Edge Group**according to the**Tags**defined when these were added (please check my previous video of this How-to[here](https://youtu.be/uSK2AtMdlOg?t=60)). **Dynamic**groups has two ways of matching endpoints:**Full match**where the endpoints tags must match all Tags:**Partial match**where endpoints may have any of the Tags:

- Once you have your
**Edge Groups**defined we can start deploying Stacks:

- With
- To start deploying Stacks click on
**Edge Stacks**and then on**Add stack**: - There are four ways of adding
**Edge Stacks**:- via the
**Web editor**where you can paste or type a`docker-compose`

file; - via the
**Upload**option where you can upload a`docker-compose.yml`

file; - via the
**git Repository**where you can download the`docker-compose.yml`

online from github or compatible git repository, and; - via the
**Template**option where you can simply select a pre-defined Stack template.

- via the
- In our example I am going to deploy a
*mysql*DB engine**Edge Stack**using the**Web editor**. Make sure to select a**Name**for your stack and select the**Edge groups**where you want to deploy the**Edge Stack**. One or Multiple**Edge Groups**can be selected. Once you finish adding your**Edge Stack**click on**Deploy the stack**: - You will now see a
**Edge Stacks list**page that will show the status of your deployment:- Blue shows how many endpoints acknowledged the stack;
- Green shows how many endpoints successfully deployed the stack, and;
- Red shows how many endpoints failed to deploy the stack.

This is a simple and efficient way for you to manage your edge devices with **Portainer**. If you have any questions or comments, please drop them into the comments section below, or join us on our [Slack channel](https://portainer.slack.com/join/shared_invite/enQtNDk3ODQ5MjI2MjI4LTcwNGYxMWQ5OGViYWZkNDY2ZjY4YTMwMTgzYmU4YmNiOTU0MDcxYmJjNTIyYmQ0MTM5Y2QwNTg3NzNkMTk5MDg#/).

See for yourself, with a demo or free trial

Let us introduce you to a world of fast and easy app deployment, governance, and management in Docker/Swarm and Kubernetes. Join a group demo to see how Portainer Business helps to make Engineering and DevOps teams more accurate and efficient in container management.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-clickops-or-devops
title: Portainer, ClickOps or DevOps
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-clickops-or-devops
hostname: portainer.io
description: Portainer, ClickOps or DevOps - explore the difference and where Portainer fits.
sitename: PORTAINER.IO
date: 2021-02-14
categories: []
tags: []
image: https://www.portainer.io/hubfs/image-png-Feb-11-2021-06-04-27-65-AM.png
pagetype: article
filedate: 2025-01-18
-->

Over the last 5 years enterprise IT has undergone a major transformation. As a general rule, transformations are good things, but on this occasion, things aren’t quite so clear cut.

The ‘old’ world - and indeed the current world for a significant proportion of the world - consists of developers who write application code for applications that add business value, and infrastructure people who figure out what hardware and environments are needed to run these applications reliably. Both groups have traditionally kept themselves to themselves and have equally strong views on just about everything….

Within each of those teams, there have been seismic shifts – dev teams have become agile and begun to embrace DevOps; while infrastructure teams have become platform teams, and engineers renamed to SREs. Along the way, technology has changed from servers, to VMs to Containers on Docker to Containers on Kubernetes, and even Containers on Serverless.

The problem of course is that developers and infrastructure teams generally talk very different languages and have very different skills, which might also explain why Portainer has experienced such rapid uptake. By acting as the ‘bridge’ between dev teams and infrastructure teams, Portainer has provided a common language and framework for the teams to share information, make decisions and manage applications.

Interestingly, many infrastructure teams exist in a ‘clickops’ world, one which means their day to day activities revolve around the functions of a management UI. This ClickOps construct has been enabled in part by Microsoft's domination of the Server OS world, and VMware's domination of the server virtualization world, both of which are almost exclusively controlled/managed from very well thought out, and extremely comprehensive management UIs that genuinely negate the need to ever use a CLI.

For those engineers used to a rich management UI, but being driven to embrace Docker/Kubernetes and all of its CLI glory, Portainer has turned out to be the perfect companion as it gives them full control of these environments in a very rich management UI, and without the need to learn new platform-specific syntax. As an added benefit it also puts a safety net in place that stops them making any demands of the infrastructure layer that can’t be fulfilled technically which significantly reduces the risk of failure.

Contrary to what DevOps evangelists tell you, there’s actually nothing wrong with ClickOps, it’s deeply embedded in the middle of the adoption bell curve and is with us for the long-haul and it explains why ClickOps tools will represent a massive opportunity for vendors for a long time to come.

A little further along the adoption curve, organizations have started to realize the benefits of merged application and infrastructure teams, in the form of DevOps (Development + Operations). In a DevOps world, teams run highly automated CI/CD toolsets where development engineers are responsible for not only their application development, but also the platform it runs upon. Some say that this requirement to manage the platform is a distraction, and robs the developer of valuable time; time that could be better spent creating a new feature or function in their application. This is one reason why DevOps relies so much on automation, so as to lessen the intrusion.

The main challenge in a DevOps world is complexity. Software developers are a bright bunch, but even the brightest can’t know everything, which is a problem Portainer has been hugely successful in solving. It turns out the poor relative in DevOps world is the ‘Ops’ part (who would have guessed?) which has allowed Portainer to again bridge the complexity gap. DevOps engineers have adopted Portainer to control and manage the environments into which they are deploying their applications.

But the story doesn’t stop there and DevOps is already morphing into something new. Engineers are always looking for the next piece of the automation puzzle, which has led to the creation of GitOps, where the management of the infrastructure is entirely code based, and managed out of a Git environment, again, trying to reduce the burdeon on the Developer.

Whether it’s ClickOps, DevOps, GitOps or whatevevercomesnextops, fundamentally, what all organizations ** need** is a way to deploy apps in an enterprise secure, consistent highly scalable manner with the least amount of complexity and risk possible which is, quite simply, Portainer’s raison d’etre.

Regardless of where your organization, or your people, are in their journey, Portainer speaks their language. Whether that is a human interaction with Portainer, clicking and completing forms to deploy app in a no-code manner; or by leveraging Portainer's rich API and/or Git integration to manage the deployment of applications through Portainer, but in an automated code-based manner.

Portainer, your ClickOps, DevOps, GitOps tool.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-ce-validated-configurations
title: Portainer CE Validated Configurations
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-ce-validated-configurations
hostname: portainer.io
description: What platforms do we test and validate Portainer against.
sitename: PORTAINER.IO
date: 2021-01-07
categories: []
tags: []
image: https://www.portainer.io/hubfs/validated_configs-2.png
pagetype: article
filedate: 2025-01-18
-->

This blog today serves an important purpose; it is setting expectations in regards to underlying software and hardware versions that we test our releases against, and how this may impact you.

Through our community channels, we are often asked, "is XYZ supported by Portainer", or "is latest version of Portainer supported on my version of Docker, or "does Portainer work with XYZ Kubernetes version".

As most of our users are aware, Portainer CE is a community supported product, and there is no formal support from Portainer.io for the CE version (Portainer Business includes formal support). Yes we do monitor our social channels, and we are active in managing reported issues/bugs/feature requests in our github repo; but this should not imply any level of formal support, nor should there be any expectations of a response SLA or that we will create a bugfix for a reported issue. Community support means just that, community supported.

As an aside, see this blog for how we prioritize fixing reported bugs and adding requested features - [https://www.portainer.io/blog/portainer-2.0-and-the-development-balancing-act](/blog/portainer-2.0-and-the-development-balancing-act)

All the above being said; every single release of Portainer goes through an extensive testing process (functional tests, release tests, post release tests) to ensure that what we are creating actually works as expected. Obviously though, we cannot possibly test Portainer against every single configuration variant out there, so we have elected to test against just a subset.

To try and alleviate confusion as to what we test against, we have elected to document this below; these configurations are the only configurations that we personally validate as "functional"; any other variant is not tested (this does not mean it wont work, it just means its not tested). If you report a bug for a configuration that is not on the list below, we will ask you to first update your environment to match a validated configuration before continuing.

There are often genuine reasons why users are unable to upgrade their Docker or Kubernetes Versions, and in these cases, we recommend you remain on an older version of Portainer, or if you do upgrade, be aware that you are in uncharted waters. Also note that as hardware ages (eg ARM), we are dropping it from our testing, favoring only the more modern ARM64 variant. Again, if you run ARM hardware, the latest versions of Portainer should work, but these are untested.

Remember, this is not a statement of what we will build container images for; we will continue to build images for Linux/ARM, Linux/ARM64, Linux/AMD64, Linux/PPC64le, Windows1809/AMD64; however these are purely automated builds.

Hopefully this helps you to understand what we test against, and what we dont; and helps you understand if we push back on a request for help if you are using a variant we have not tested.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/author/neil-cresswell/page/11
title: Portainer News and Blog | Neil Cresswell, CEO (11)
author: Neil Cresswell; CEO December
url: https://www.portainer.io/blog/author/neil-cresswell
hostname: portainer.io
description: Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization. (11)
sitename: Portainer.io
date: 2020-12-17
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

### Blog Post by Neil Cresswell, CEO

[
](https://www.portainer.io/blog/portainer-and-rootless-docker)

Neil Cresswell, CEODecember 17, 20202 min read

### Portainer and rootless Docker

How to deploy Portainer on Rootless Docker Host

Start Reading
[
](https://www.portainer.io/blog/portainer-launches-business-edition-bringing-simplified-container-management-platform-to-enterprise-scale)

Neil Cresswell, CEODecember 9, 20202 min read

### Portainer Launches Business Edition for Enterprise Container Management

Portainer.io, creator of open source tools to easily manage containers, has launched ...

Start Reading
[
](https://www.portainer.io/blog/portainer-business-is-here-and-heres-why-it-matters)

Neil Cresswell, CEODecember 9, 2020< 1 min read

### Portainer Business is here at last. Watch Neil tell the story...

Portainer Business launch video explaining what Portainer Business is, and why it matters

Start Reading
[
](https://www.portainer.io/blog/docker-hub-rate)

Neil Cresswell, CEONovember 6, 20203 min read

### Docker Hub Introduces Rate Limits from 2 November 2020

So, the 2nd of November has passed, and Docker is now enforcing Docker Hub pull rate ...

Start Reading
[
](https://www.portainer.io/blog/portainer-ce-2.0-with-kubernetes-is-here)

Neil Cresswell, CEOAugust 31, 20201 min read

### Portainer CE 2.0 with Kubernetes is here!

2.0

Start Reading
[
](https://www.portainer.io/blog/portainer-ce-2.0-what-to-expect)

Neil Cresswell, CEOAugust 26, 20208 min read

### Portainer CE 2.0 – What to expect

Portainer 2.0 What to Expect

Start Reading
[
](https://www.portainer.io/blog/portainer.io-closes-us1.2-million-seed-financing)

Neil Cresswell, CEOAugust 17, 20203 min read

### Portainer.io Closes US$1.2 Million Seed Financing

Seed funding

Start Reading
[
](https://www.portainer.io/blog/portainer4kube)

Neil Cresswell, CEOAugust 17, 20203 min read

### #Portainer4Kube

######

Start Reading
[
](https://www.portainer.io/blog/security-settings-introduced-in-portainer-1.24.1)

Neil Cresswell, CEOAugust 9, 20202 min read

### Security settings introduced in Portainer 1.24.1

Security settings

Start Reading
[
](https://www.portainer.io/blog/the-portainer-open-source-rationale-tao-of-open-source)

Neil Cresswell, CEOAugust 7, 20204 min read

### The Portainer Open Source Rationale (Tao of Open Source)

Tao of Portainer

Start Reading
[
](https://www.portainer.io/blog/portainer-business-a-fork-in-the-road)

Neil Cresswell, CEOJuly 8, 20202 min read

### Portainer Business – A fork in the road

Portainer Business fork in the road.

Start Reading
[
](https://www.portainer.io/blog/portainer-2.0-and-the-development-balancing-act)

Neil Cresswell, CEOJune 22, 20201 min read

### Portainer and the development “balancing act”

Balancing Act

Start Reading

---
<!--
URL: https://www.portainer.io/blog/discovering-boston-dynamics-spot-core-uses-portainer-for-docker-container-management
title: Discovering Boston Dynamics Spot CORE Uses Portainer for Docker Container Management
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/discovering-boston-dynamics-spot-core-uses-portainer-for-docker-container-management
hostname: portainer.io
description: Discovering Boston Dynamics Spot CORE Uses Portainer for Docker Container Management
sitename: PORTAINER.IO
date: 2021-02-23
categories: []
tags: []
image: https://www.portainer.io/hubfs/Spot%202.jpeg
pagetype: article
filedate: 2025-01-18
-->

We started Portainer to make using Docker containers easier for everyone. We hoped our open-source community edition would attract a diverse base of users, but even we were surprised by our latest community member, Boston Dynamics! Turns out they’re using Portainer to deploy Docker containers for [Spot CORE](https://dev.bostondynamics.com/docs/payload/docker_containers)!

Spot is their commercial “robot dog”. Spot is unique because it is designed to be accessible outside of traditional robotics. It’s more than just an OS, it’s a platform that allows customers to upload custom commands and actions that control Spot’s missions. And each robot is an independently configurable beast. The ability to load custom software applications or hardware add-ons known as “payloads” on Spot is a fundamental differentiator for Boston Dynamics and is the reason we see so many cool applications of Spot in the wild. Portainer is one of the tools that makes it easy for Boston Dynamics’ customers to upload their custom applications onto Spot.

To quote their blog: “Portainer is a complete software solution for container management to speed up software deployments and troubleshooting on the Spot CORE. It is the recommended method for managing Docker containers on Spot CORE.” Portainer was founded to make container management easier, and we’re dancing just like the robots (admittedly perhaps not quite as well) to learn of this application. We’re also keen to see where the Boston Dynamics community takes Spot next.

Now that they’ve introduced the new remote [inspection solution](https://www.bostondynamics.com/solutions/inspection), a new arm, and self-charging, the possibilities for Spot are continuously expanding.

See Spot’s new arm in the video below (and who wouldn’t love that laundry robot?)

Are you using Portainer (or Spot) in a unique way? Interested in learning more about how we make containerization easier? Let us know in the comments below, or send us a Tweet on [@portainerio](https://twitter.com/portainerio).

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-vs-rancher
title: Portainer vs Rancher vs OpenShift
url: https://www.portainer.io/portainer-vs-rancher-vs-openshift
hostname: portainer.io
description: Compare Portainer vs Rancher and OpenShift. See how they differ and check out the feature comparison table to learn which tool is right for you.
sitename: Portainer.io
date: 2024-01-01
categories: []
tags: []
filedate: 2025-01-18
-->

## Portainer, Rancher, OpenShift

[
](#)

###### TABLE OF CONTENTS

### How does Portainer compare to Rancher? How about to OpenShift?

This is a question we get asked almost daily by people looking for a Kubernetes management platform. For a long time, the answer was "well, we are not really sure, as we don't use those tools day in, day out". So we've done the research and created a comparison table for Portainer vs Rancher vs OpenShift.

We've spent considerable time deploying and understanding Rancher and OpenShift to discover their strengths, weaknesses (or functionality they don't attempt to provide), and seeing how we compare. We took a non-biased view of this assessment, as being biased doesn't help us to learn (and we hope you appreciate the transparency).

### Key Takeaways

[Read more below](#build-environments).

[Read more below](#multi-cluster-management).

[Read more below](#platform-vs-tool).

[Read more below](#ease-of-use).

### 1. Build Environments

Straight off the bat, Portainer and Rancher/OpenShift serve two very different needs. Rancher and OpenShift are both tools that you use to CONSTRUCT yourself a Kubernetes cluster, one that is self-managed (be that on prem or in-cloud).

Portainer as a company does not provide a Kubernetes distribution, but we have partnered with Canonical, and allow you to build a MicroK8s on-premises cluster in our app.

We allow you to build Kubernetes clusters through Cloud Provider KaaS offerings, which is arguably the most operationally efficient way of using Kubernetes anyway.

**Summary: Portainer helps you deploy managed Kubernetes clusters, which is our recommended way of consuming Kubernetes unless you have a large dedicated team of Kubernetes experts.**

### 2. Multi-Cluster Management

Secondly, the biggest difference we can see between both Portainer & Rancher vs OpenShift is that OpenShift is not a multi-cluster manager.

You use the [OpenShift installer](https://docs.openshift.com/container-platform/4.10/installing/index.html) to build a (singular) OpenShift cluster against either on-premises equipment or in a select number of cloud provider IaaS offerings, and the cluster gets deployed with a Management UI for that cluster. There is no way to deploy any additional clusters and manage them from the one management UI.

Of course, RedHat offer a premium version of OpenShift, known as OpenShift Platform Plus, which bundles a cloud service that delivers multi-cluster management. If you can afford to pay for OpenShift, then paying an additional $800 per month for this premium product is probably okay.

Rancher and Portainer both let you (natively) deploy or import any number of existing environments under the one management server, which is great when you are operating at scale.

**Summary: Portainer is a multi-cluster manager that is extremely lightweight and can provide centralized access control and governance at scale.**

### 3. Platform vs Tool

It's important to note that all three products are aiming to be a complete "turn-key" platform to manage containerized applications, with the analogy "Kubernetes is the engine, we are the car" commonly used.

All three products aim to be much more than just an alternative to the Kubernetes Dashboard (or variants of it, like Mirantis Lens).

In reality, all these products aim to provide a comprehensive Kubernetes management platform that includes an intuitive UI that guides less experienced users, an integrated GitOps capability, integrated monitoring/ observability, and integrated alerting.

Because of this, all three offer either native capability or integrations with 3rd party open source components (such as ArgoCD).

Portainer made a decision to integrate with the Kubernetes Metrics API, which gives a good level of observability, rather than requiring all users to deploy the resource-heavy Prometheus and Grafana. That said, there is nothing stopping you from using [Prometheus and Grafana](https://www.portainer.io/blog/deploy-prometheus-monitoring-stack-with-portainer?hsLang=en), or [ArgoCD](https://www.portainer.io/blog/deploy-and-use-argocd-with-portainer?hsLang=en) alongside Portainer.

**Summary: if you want a quick view of resource usage of your apps, and can't spare the additional resource overhead, Portainer is your only choice here.**

### 4. Ease of Use

Really though, the most impactful difference between the products is the target user. Portainer and OpenShift both provide a management experience that applies safe/secure best practices, and does so to ensure that non-experts can operate in an environment that they might not fully understand.

With Portainer, the admin can easily disable Portainer's applied defaults and customize them to suit the skills of the team, whereas with OpenShift the defaults are enforced. If the defaults don't suit you, then OpenShift will cause friction.

Rancher however takes a very different approach. Rancher's product appears to be tailored to Kubernetes experts, who are expected to know how to secure the platform and applications correctly.

**Summary: if you want a guided, intuitive, safe-by-default experience, with the ability for the admin to adjust the defaults, then choose Portainer.**

---
<!--
URL: https://www.portainer.io/blog/container-management-solution-portainer.io-raises-6m-series-a-round-to-accelerate-global-expansion
title: Container Management Solution Portainer.io Raises $6M Series A Round to Accelerate Global Expansion
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/container-management-solution-portainer.io-raises-6m-series-a-round-to-accelerate-global-expansion
hostname: portainer.io
description: Portainer announced today their $6 million Series A round led by Bessemer, and joined by Sonae Investment Management and Movac.
sitename: PORTAINER.IO
date: 2021-05-04
categories: []
tags: []
image: https://www.portainer.io/hubfs/neilbatik.jpeg
pagetype: article
filedate: 2025-01-18
-->

**Auckland, New Zealand, May 5th, 2021 **– [Portainer.io](https://www.portainer.io/) announced today their $6 million Series A round led by [Bessemer Venture Partners](https://www.bvp.com/), joined by prominent European investor [Sonae Investment Management](https://sonaeim.com/) and leading New Zealand technology investor [Movac](https://www.movac.co.nz/).

The round, which follows close on the heels of Portainer’s $1.2 million seed round announced in August 2020, will fund Portainer.io’s worldwide user expansion and product development, as Portainer.io charts the course for the future of container management. Portainer.io will also continue to scale and develop its enterprise offering, [Portainer Business](https://www.portainer.io/products/portainer-business), which launched in December 2020.

Launched in 2017 as an open source tool for managing containers in the Docker Swarm environment, Portainer.io’s open source Community Edition has grown to become a popular universal container management tool with a powerful Kubernetes GUI, in addition to supporting Docker, Docker Swarm, and Azure ACI, while Portainer Business offers enterprise-level security and control for deploying containers in business-critical environments.

Portainer.io’s focus on containers without the frustration has driven its explosive expansion: since January 2018, Portainer’s community now spans 190 countries, 4.8 million total users, and 500,000 regular monthly users, achieving 50% year-on-year growth. Portainer.io’s [team of advisors](https://www.portainer.io/about) includes developer advocate Kelsey Hightower and Bryan Rodriguez, a leading specialist for orchestration at the edge, boosting their focus on Portainer’s Edge Compute features.

“This investment lets us double down on pivoting Portainer from a simple management dashboard, into a fully-featured, container-native application deployment and management tool. We started by adding support for Azure ACI, then added Kubernetes, and now in 2021 we plan to add support for an ever increasing number of CaaS platforms, such as AWS Fargate, Google Cloud-Run, etc. On top of this we will continue to enhance what users can do within Portainer itself, extending into the Git-Ops/Automation realm.” said Neil Cresswell, Co-Founder and CEO of Portainer.io. “Portainer is laser-focused on unleashing the power of containers for everyone, giving existing IT/Developer teams, home users, students, and beyond the tools they need to manage containers without complicated code or risky deployments.”

“Bessemer is excited to partner with Portainer to support their continued growth, and help expand their efforts to provide the most seamless and flexible container management experience for developers,'' said Mike Droesch, Partner at Bessemer Venture Partners. “Portainer’s open source community has incredibly strong engagement and global scale, which is a true testament to the value the product provides. We are excited to help them accelerate investments in their strong open source product and continue to empower more developers to leverage the benefits of containers, while abstracting away the complexity.”

“From our experience in different sectors across Europe, we’ve gotten to know how challenging it can be to manage cloud infrastructure in a fast-paced environment of shorter development cycles, increasing complexity and skills shortage,” said Benjamin Junior, Investment Manager at Sonae IM. “Portainer attracted our attention for its easy adoption, light-weight deployment and great user experience, that has supported its massive adoption from the open-source community as a whole and leading enterprise customers in the market. With the growth of edge locations and accelerated development of ever complex IoT applications, Portainer provides a mission-critical solution to abstract container management and focus developer work in application development.”

**About Portainer.io**

[Portainer.io](//portainer.io/) is unleashing the potential of containers with its universal container management tool. The New Zealand-based tool was born in 2017 from founders Neil Cresswell and Anthony Lapenna's own struggle to learn Docker, with the vision to create a GUI-based tool to manage Docker without frustration - regardless of whether it was deployed standalone, in a cluster, on-premise, at the edge or in the cloud. In August 2020, Portainer expanded to include support for Kubernetes and Azure ACI as well as retaining full support for Docker & Docker Swarm. Portainer Community Edition currently has over 500,000 global monthly users. Portainer Business, Portainer.io’s first business product, launched in December 2020 with additional capabilities and security controls for business critical environments. The team most recently raised a US$6 million Series A round in May 2021.

**For Press Kit & Press Inquiries Please Contact:**

Savannah Peterson

E: [Savannah@SavvyMillennial.com](mailto:Savannah@SavvyMillennial.com)

M: +1 805 550 1998

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-release-2.0.1
title: New Portainer CE 2.0.1 Release
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-release-2.0.1
hostname: portainer.io
description: Portainer CE Release 2.0.1
sitename: PORTAINER.IO
date: 2021-01-07
categories: []
tags: []
image: https://www.portainer.io/hubfs/anna-gWuVzCmi3hg-unsplash.jpg
pagetype: article
filedate: 2025-01-18
-->

Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our [Portainer Features page](/features)*. *

We've just released Portainer CE 2.0.1. This is a 'dot' release, so largely bug fixes and a couple of minor new features thrown in for good measure. There are 27 updates in this release that address some of the common bug fix requests we've had since we released 2.0.0 in September.

**Bug Fix Highlights**

You can now upload binary files and present them as a config in either Kubernetes or Docker.

2. Kubernetes cannot create resource pool with "owner" in labels contains special characters.

If your Portainer username contains an @ sign, you are now able to use Portainer's Kubernetes features.

3. Edge compute - add support for Windows OS for Edge Agent

The edge compute agent now supports Windows Docker hosts.

1. Expose pods without workload as applications

This provides an aerial view of pods that are just being deployed as naked or bare pods.

2. Request confirmation upon volume removal

Deleting a volume means deleting data; this is a risky exercise that requires caution and care; we now request confirmation when attempting to delete a volume to avoid accidental deletion.

You can pull the latest CE image by command:

docker pull portainer/portainer-ce:latest

**Release Cadence**

Major releases will occur every two months, and will contain both new features and bug fixes, some of which may introduce breaking changes. Regardless, every month we will be releasing a new version of Portainer CE. Release will be targeted on or around the second to last day of each month.

For Portainer Business (PB), we need a slightly longer release cycle due to the increased depth of testing we have committed to our business users. There will be a major release once every 4 months, and a “dot” release midway between the major releases. The dot releases for BE will ONLY include bug fixes; there will be NO new features added in the mid-releases.

Any questions, drop me a line.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-2.0-and-the-development-balancing-act
title: Portainer and the development “balancing act”
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-2.0-and-the-development-balancing-act
hostname: portainer.io
description: Balancing Act
sitename: PORTAINER.IO
date: 2020-06-22
categories: []
tags: []
image: https://www.portainer.io/hubfs/dev_timelines.png
pagetype: article
filedate: 2025-01-18
-->

We have limited resources at Portainer, and a list of feature requests and opportunities as long as Route 66. We must make priority decisions every day, and inevitably, someone somewhere gets upset because we haven’t delivered to their expectations. We know this, and it’s something that we don’t like to see happening, but we must work within our means.

The way we make decisions on requested functionality additions / fixes to Portainer is as follows:- is this addressing a security vulnerability or potential exploit? if so, add it;
- is this a feature that we feel would have wide appeal? if so, add it;
- is this a feature that has at least 20 “thumbs up” or “hearts” inside Github? if so, add it;
- is this a feature that would benefit professional users of Portainer? if so, add it.

When there are feature requests / issues that exist only with a specific use cases, judged either by us or through a lack of community “thumbs up” then these sit “pending” until enough demand is identified for them (so don’t forget to thumbs up issues you care about). Also, it’s important to note that we don’t automatically maintain feature parity with Docker, so when they bring out new features in Docker CE, we evaluate each based on the 4 criteria above before deciding whether to add it to Portainer. With our current resources, we only add support for features we feel have real demand.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-ce-2.0-what-to-expect
title: Portainer CE 2.0 – What to expect
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-ce-2.0-what-to-expect
hostname: portainer.io
description: Portainer 2.0 What to Expect
sitename: PORTAINER.IO
date: 2020-08-26
categories: []
tags: []
pagetype: article
filedate: 2025-01-18
-->

With the announcement of the launch of Portainer CE 2.0 on the 31st August, I‘d like to provide additional context on our thinking behind this release, the value we hope it will bring, the target audience, and what you can expect to see from it, features-wise.

Portainer CE 2.0 includes a staggering number of enhancements (~150), as well as a few breaking changes. Before you upgrade, you need to understand the changes in order to decide if 2.0 is right for you.

We have purposely decided to release CE 2.0 as an entirely new image to ensure there are no auto-updaters (like watchtower) that will expose users to risks by automatically updating on release. The new image will be portainer/portainer-ce. The first tag will be :2.0 and we will also use :latest as a tag pointing to the latest release.

Portainer 1.24.x will continue as a separate code branch, released as portainer/portainer:latest, and will receive ongoing security updates until at least 1st Sept 2021. No new features will be added beyond what was available in 1.24.1.

For two reasons we have removed the concept of “extensions” from 2.0 completely. First, we have been criticized for having closed source features as part of the open source project, and so by removing them Portainer CE reverts back to being 100% open source. Second, we have learned that to be successful, extensions need to be delivered as part of a supported solution. Whilst extensions provided al-carte functionality, users really need (and indeed expect) support using them.

Moving forward, we will contain all of our proprietary functionality in a specific commercial version of Portainer called Portainer Business, which will come with full support. Existing extension customers should look out for specific communications about the transition.

As part of removing extensions, we have elected to roll basic oAUTH authentication support into CE, so now you can configure Portainer to authenticate users from an oAUTH source. Be aware, this is a very technical implementation, so you need to be competent with oAUTH before attempting it. The Business Edition will retain ‘click to configure’ simplicity for the most common oAUTH providers like Azure AD, GitHub, Google.

Off the back of our intention to remove the ability to disable Portainer internal authentication, we have added support for the Admin to set a custom “session timeout’. This setting defines how often users are forced to re-authenticate with their Portainer session; the default remains at 8 hours, but it can now be changed to up to 1 year. So, whilst we are not disabling authentication completely, we are trying to make the required authentication invisible for those that don’t care for it.

We’ve also changed the way we handle application templates. Previously we let admins/users customize the application template list, and we provided a rudimentary UX to add/remove applications to the template list. Moving forward, we have changed this behavior. Now, the list of application templates is published by Portainer, maintained and updated by Portainer, and users can’t change it. Admins can choose to unsubscribe from the list and instead provide their own centrally managed list, but it would be “consume only” from a user perspective.

In addition, we have elected to provide a feature called “custom templates” which is where Portainer users can create their own bespoke templates. Unlike previous capability, the new custom templates rely solely upon Stack/Compose files, so when you add a new template, you add it by pasting in (or uploading) a compose file and then annotating some detail around the file. Through Portainer access control, users can choose to publish their custom templates for themselves, for their team, or for all users within their organization.

One other cool addition to the custom templates is the ability to create one from a running stack... simply open a stack and click on the button “create template from stack” and voila, you have a reusable custom template.

This new method of managing application templates means there is a new schema, so any custom template files created for Portainer 1.x will need to be updated to accommodate Portainer 2.0. We have provided a tool to assist with this conversion ([https://github.com/portainer/helper-templates](https://github.com/portainer/helper-templates)).

Speaking of stacks, we have added the ability to stop a stack; this is a Portainer specific feature, and takes all services/containers offline, whilst retaining the configurations required to restart the stack within the Portainer DB should the need arise (simply click the “start stack” button). This is a neat feature that lets you centralize all of your stacks in one place, and control which run, and when.

Looking beyond Docker; we have further matured our support for Azure ACI. You can now reliably deploy applications in an Azure ACI instance from within Portainer. These containers are all stateless, and internet facing. It takes mere seconds to deploy any container in ACI with Portainer, which is very cool.

Regarding Edge Compute; we have relocated the former “Host Jobs” functionality into “Edge Jobs” and reconfigured the logic that underpins this so that they only function when used against Edge Agent enabled endpoints. This now means that the “Edge Compute” specific features includes; the ability to group edge endpoints, the ability to deploy stacks against groups of endpoints, and the ability to run cron jobs against edge endpoints.

**And finally, the biggest change of all, Kubernetes.**

We have introduced support for Kubernetes enabled endpoints as part of Portainer CE 2.0,. This means you can manage the deployment of applications atop Kubernetes clusters from within Portainer, using the familiar Portainer UX. We have safely abstracted as much of the unnecessary Kubernetes lingo as possible, leaving a clean UI that allows you to deploy/manage/monitor applications in Kubernetes without needing to know all that much about Kubernetes. We negate the need for you to learn YAML and how to write Kubernetes Manifests, we negate the need for you to learn all of the Kubernetes deployment “rules” and constraints, and when to use which deployment mode for what, and we negate the need for you to learn any of the Kube CLI commands.

It’s important to note, we’re not saying that organizations can fully embrace Kubernetes without having any technical insight into how Kubernetes works (as that’s just crazy talk). Like everything in the IT space, the more you know, generally the better off you are. What we are saying however is that with Portainer, not EVERYONE in your IT/Dev team needs to understand Kubernetes to the same degree. There will be some on the team that naturally gravitate to Kube and its infinite flexibility, but equally there will be some on the team that “just want to deploy an app”… Portainer has always been targeted at those that “just want it to work”… and that continues to ring true as we release Portainer CE 2.0.

So, what can you do in Portainer against Kubernetes; well, there is so much, a list is going to be easier to digest...

As an Administrator, you can:

- Define what cluster resources users have access to (eg persistent storage, load balancers, ingress, metrics)
- Create Resource Pools (Kubernetes namespaces) for users to deploy their apps within
- Assign CPU and RAM quota to resource pools
- Assign Ingresses to Resource Pools
- Assign permissions to Resource Pools, so only authorized users can access corresponding resource pools
- See the status and component health of the Kubernetes Cluster
- See the leader status, and which nodes are API endpoint enabled
- See Cluster Events
- See the Cluster resources assigned vs total
- See the Node resources assigned vs total
- Add Node Labels
- Add Node Taints
- See which applications are running on each node
- See and manage all applications deployed across the cluster
- See and manage all configs/secrets defined in the cluster
- See and manage all persistent volumes defined in the cluster
- Deploy applications by directly inputting a Kubernetes Manifest
- Deploy applications using the simplified UX
- See which users deployed which applications and when

As a User, you can:

- Deploy applications in the resource pools you are entitled
- Assign CPU and RAM reservations for applications up to your quota
- Add environment variables to your applications
- Create and Manage Configurations and Secrets for your applications
- Assign Persistent Storage to applications, if enabled by your administrator
- Assign Ingress or Load Balancers to applications, if enabled by your administrator
- Deploy either replicated or global applications
- Deploy one or more replica of an application
- Enable auto-scaling for an application if enabled by your administrator
- Assign placement rules for an application
- Publish an application either internally, across the cluster, or via Ingress/Load Balancers if enabled by your administrator
- See the logs of the Application components (PODs)
- Open a console of each application component (PODs)
- See the effective placement results (which nodes can the application run on)
- See the application events
- See the application resultant manifest
- See the resulting application deployment type (deployment, daemonset, etc)
- Edit and application and adjust any prior setting
- Roll back an application to the last version
- Redeploy an application
- Combine applications into logical groups, called Stacks, for simplified management
- Add annotations for applications to help other users understand the purpose and owner of the application

One final word; in Portainer CE 2.0, we made a change to how we collect anonymous usage data; prior versions leveraged Google Analytics, which was often criticized, and so in 2.0, we have moved to Matomo Analytics, which is hosted in Germany and fully GDPR compliant.

When Portainer first starts, you will be given the option to DISABLE analytics. If you don’t choose to disable it, Portainer will continue to collect anonymous usage as per our privacy policy. We need this basic telemetry to know which features of Portainer are in most demand, and it is the only mechanism we have in order to focus development efforts. Note that there is no personally identifiable information sent or stored at any time.

We are really looking forward to user feedback on Portainer CE 2.0, and can’t wait for you all to get your hands on it.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/the-portainer-open-source-rationale-tao-of-open-source
title: The Portainer Open Source Rationale (Tao of Open Source)
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/the-portainer-open-source-rationale-tao-of-open-source
hostname: portainer.io
description: Tao of Portainer
sitename: PORTAINER.IO
date: 2020-08-07
categories: []
tags: []
pagetype: article
filedate: 2025-01-18
-->

Over the past three years, Portainer has become a successful open source project, used all over the world by hundreds of thousands of engineers every month. The Portainer community grows at about 50% CAGR, and with our upcoming Kubernetes release, we expect to see it grow even faster.

While the product itself becomes ever more powerful, the team is working hard to make sure that we don’t deviate from our brand mission to *radically* *simplify the complex technologies of containers and orchestration*. This is no easy task.

As you’re no doubt aware, we are preparing to release our first commercial product, which is hugely exciting and a step change for the business. There are three main drivers for doing this:

- The current codebase has been developed and is maintained by a small team, funded by the founders. This is unsustainable. The codebase is large, complex and will only grow. A commercial version will allow us to fund the R&D and the ongoing development and maintenance of the open source project.
- Portainer solves a real problem and creates real value for many users. The founders have a vision for making the complex simple and making advanced tech (K8s, containers etc) accessible to everyman. We are excited by the commercial opportunity and we believe there is real value to be created.
- A commercial product will give Portainer longevity. Portainer has the opportunity to become a widely adopted tool in the IT ops arsenal. By offering a commercial version we give all Portainer users the safety and security of a long-term play.

In releasing a commercial version, we are following in the footsteps of some industry giants. We respect the work of GitLab, Kong, Cockroach DB among many others (Puppet, Chef, Hashicorp…). They have all made this move and their communities are richer for it. We aim to take the best of their experiences and model our behaviour on it.

From studying these success stories, we’ve learned how careful and clear we need to be managing two versions of the product. This blog is the first in what will be an ongoing series of articles designed to lay bare out our strategy for managing our Open Source and Commercial product streams.

Going forwards, Portainer will exist in two versions:

**Portainer Community Edition (CE).**CE is for anyone and everyone who wants to use Portainer for free. Now up to version 2.0, with Kubernetes support, it is freely licensed under the ZLib open source license, and its source code can be found in our Git Repository. We consider it to be an ‘edge’ or ‘Dev’ level code, where we take all practical steps to test and validate the code, however bugs may exist and can be reported and tracked through standard Git processes. CE is designed for a wide range of use cases that are non-critical and typically involve either a single user or a small team.**Portainer Business Edition (BE).**Portainer BE is our commercial offering. It’s first version will be 2.0 (implying a code consistency with CE) and is available under a proprietary license, with source available under specific conditions. It has a significantly more thorough test and release process and will typically be a version behind the open source product. While it is largely based on open source code, it is a separate branch and will include a range of features over and above those found in the CE version. Portainer BE includes a support service-level agreement, as well as a customer success program aimed to ensure that a customer’s underlying platform is solid and performant prior to the addition of Portainer. Portainer BE is designed for organizations who require any or all of the following:- a supported product
- business class features (RBAC, availability, etc – see feature chart)
- a slow release cycle and rigorous (and explicit) pre-release testing

BE customers will typically:

- Value time over cost – BE will include a number of pre-configured components that will allow rapid time to value in a business environment.
- See value in an explicit customer success program, which ensures ongoing alignment between use and best practice
- Use Portainer in a critical or production environment

The challenge for any open source company releasing a commercial variant is to remain clear and fair in respect to the features that are added to each product stream. We want our guiding principles to be clear:

- We will be as transparent as we can be (recognising competitive tensions)
- We expect this to be a conversation between the community and the company
- We won’t always get it right, but we will always listen
- We will never take a feature out of CE and put in BE. Once it’s in, it’s in
- Features will often move from BE to CE
- We will put more of our dev energy (time, money, effort) into the open source version than the commercial version.

We are hugely sensitive to the needs of the community and we hope that by engaging in this conversation early we can earn your trust (or at least the benefit of the doubt) while we figure out the right way to make decisions. This is a hard thing to get right, but the benefits of getting it right are huge and we’re committed to going on the journey with our community.

On behalf of the Portainer team, we thank you for reading this, and if you have any questions, please feel free to comment below.

Neil Cresswell

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-ce-2.0-with-kubernetes-is-here
title: Portainer CE 2.0 with Kubernetes is here!
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-ce-2.0-with-kubernetes-is-here
hostname: portainer.io
description: 2.0
sitename: PORTAINER.IO
date: 2020-08-31
categories: []
tags: []
pagetype: article
filedate: 2025-01-18
-->

**Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our Portainer Features page . **

**Auckland, New Zealand, August 31, 2020** – Open source software company, [Portainer.io](https://www.portainer.io/), has launched version 2.0 of its platform which includes support for the Kubernetes container orchestrator, for the first time.

In three years, Portainer.io has over half a million regular Docker Swarm users with its 1.X version. It is anticipated the addition of support for Kubernetes will further accelerate growth for the start up.

Portainer makes operating container platforms easy. It provides a simple, click-to-configure interface which removes all of the unnecessary complexity and negates the need for users to learn complex syntax. Portainer users can now deploy and manage notoriously complicated applications on a Kubernetes platform, quickly and easily. Users no longer need to know how to write YAML or understand the Kubernetes CLI or API. In addition to Kube, Portainer continues to operate across all major orchestration systems including Docker Swarm and Azure ACI.

According to Portainer.io CEO and Co-Founder, Neil Cresswell, Portainer CE 2.0 is a hugely important release for Portainer; “It takes the company back to its true open source roots as Portainer CE 2.0 no longer includes ‘Extensions’, Portainer’s previously paid-for features,” he explains.

“While the addition of Kubernetes embraces our ability to support the full breadth of the container management community. Portainer CE 2.0 also lays the foundational platform for Portainer Business, Portainer’s soon to be released premium service for business customers.”

Last month Portainer attracted an initial[ seed funding round](https://www.portainer.io/2020/08/portainer-io-closes-us1-2-million-seed-financing/) of US$1.2 million to fast-track its growth plans.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer.io-closes-us1.2-million-seed-financing
title: Portainer.io Closes US$1.2 Million Seed Financing
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer.io-closes-us1.2-million-seed-financing
hostname: portainer.io
description: Seed funding
sitename: PORTAINER.IO
date: 2020-08-17
categories: []
tags: []
pagetype: article
filedate: 2025-01-18
-->

**Kiwi open source startup receives significant international backing.**

Auckland, New Zealand, August, 18, 2020 -- NZ based software company, Portainer.io, today announced it has closed a US$1.2 million seed financing round. The round is backed by leading strategic investors Bessemer Venture Partners and Black Nova Group, as well as top New Zealand investors K1W1, AmpliPHI Ventures and a number of experienced senior business figures.

Portainer launched in 2017 as an open source product to radically simplify the deployment and management of Docker Swarm container-based environments. To date, Portainer has been downloaded more than two billion times and is actively used by approximately 500,000 users per month.

Enjoying 50% year-on-year growth, Portainer is poised to launch Version 2.0 including an advanced open source product and commercial business edition for Docker Swarm, Kubernetes and Edge computing. According to Portainer.io CEO and Co-Founder, Neil Cresswell, Portainer was developed to bring expert simplicity to the complex technologies in use by everyday IT teams;

“Extending Portainer to manage Kubernetes will enable organizations of any size to take advantage of the rich functionality without having to learn Kubernetes itself,” he says. “It quite literally makes an incredibly complex environment available to the average IT team, unleashing an immense advantage to teams using Portainer to deploy into Kubernetes or troubleshoot issues across its environments.”

The seed round enables Portainer to accelerate the growth of its open source version in the Kubernetes space, as well as bringing a fully supported business edition to market. Funding will be allocated to additional software engineering resources around the world, growing the Kubernetes community uptake and building traction for the commercial product.

“We have been watching the explosive growth of Portainer for some time” says Bessemer partner Michael Droesch. “We have been encouraged by what the team has achieved with their open source product and the engagement they have generated within the Portainer community. We believe Portainer can help bring ‘expert simplicity’ to leading cloud-native technologies like Docker and Kubernetes”

“We are looking forward to seeing Portainer.io accelerate its commercialization strategy” says Black Nova Group’s Managing Partner, Matt Browne, “Portainer’s development of a container management platform is helping software engineers and developers navigate through a rapidly growing market gap, as B2B SaaS increases in the current ever-changing market conditions”.

**About Bessemer Venture Partners**

Bessemer Venture Partners is the world's most experienced early-stage venture capital firm. With a portfolio of more than 200 companies, Bessemer helps visionary entrepreneurs lay strong foundations to create companies that matter, and supports them through every stage of their growth. The firm has backed more than 120 IPOs, including Pinterest, Shopify, Yelp, LinkedIn, Skype, LifeLock, Twilio, PagerDuty, SendGrid, DocuSign, Wix, and MindBody. Bessemer's 15 investing partners operate from offices in Silicon Valley, San Francisco, New York City, Boston, Israel, and India. Follow @BessemerVP and learn more at bvp.com.

**About Black Nova**

Black Nova Group exists to empower the next generation of iconic, tech startups. We inject capital and services into businesses looking to scale. We operate in Australia and Europe and are united by one goal; supporting great founders with ambitious dreams to achieve their potential. www.blacknova.xyz

**About AmpliPHI Ventures**

AmpliPHI Ventures is an Auckland based investment management firm, focused on providing investors access to the best private market opportunities in New Zealand. AmpliPHI’s founders have managed private equity and venture capital programs for leading local and regional institutional investors, investing alongside talented founders and partners in some of the biggest success stories to emerge from New Zealand. www.ampliphi.vc

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer4kube
title: #Portainer4Kube
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer4kube
hostname: portainer.io
description: #Portainer4Kube
sitename: PORTAINER.IO
date: 2020-08-17
categories: []
tags: []
pagetype: article
filedate: 2025-01-18
-->

So, the time has *finally* arrived. Portainer CE 2.0, with support for Kubernetes is finished... and it will be released to the public on Aug 31st.

Why are we so excited about this?

Well, because we have made Kubernetes so easy to use that you don't actually need to know ANYTHING about Kubernetes to use it. If you can use Docker on your laptop, you are now able to deploy even the most complex multi-tier applications, with data persistence, resource reservations, placement constraints, auto-scaling, load balancing; all of that Kubernetes awesomeness, just by following Portainer’s super simple UX.

There is no need to know how to write Kubernetes manifests, no need to learn helm, no need for kubectl commands; Portainer does it for you. We believe it’s a game changer and we hope you do, too.

In all seriousness, what we have done is….

1) created an intuitive UI experience that abstracts away all of the confusing Kubernetes lingo, and provides you with easy to follow steps to deploy your application. We ask you simple questions, and deduce from your answers how best to deploy within Kubernetes. From simple single-tier apps through to the most complex 12-factor apps, we have got you covered.

2) built substantial expertise into the Portainer UX as pre-deployment validations/rules, which means it’s very hard for users to make mistakes during deployments. We not only validate correct syntax, but we also enforce the deployment rules that Kubernetes needs for successful deployments. No more failed deployments. It’s that simple.

3) made it super easy for you to understand what is going on with your application if it’s not doing what you expected. This is an really valuable feature if you have deployed your app outside of Portainer and are more vulnerable to deployment errors. You can see if your deployment is being impacted by unexpected placement constraints, see if there are image pull issues, see if there are storage issues, see if there are network issue. You name it, we visualize it.

4) for people prefer to use CI/CD tools to manage the deployments of their apps onto Kubernetes, we respect that; in scenarios like this, we have ensured that any applications deployed using these CI/CD tools (instead of Portainer) can’t be changed by Portainer – but still can be monitored, without compromise, for troubleshooting purposes.

5) made it very simple for the Portainer administrator to define what Portainer users can see and do. Utilizing a combination of Kubernetes namespaces (which we call Resource Pools), and a new "Cluster Setup" page, admins can define what underlying Kubernetes resources are available for users to use. Don’t want your users to be able to use all the storage classes in your cluster? don’t have to. Don’t want the users to be able to use external load balancers? Don’t have to. Don’t want users to have access to ingresses or use auto-scaling? Don’t have to.. I’m sure you get the picture.

We can’t wait for the Kubernetes community to get its hands on our creation; but more importantly, we can’t wait for all those organizations that would LOVE to use Kubernetes, but simply can’t get their heads around it, to start using Portainer. We are bringing Kubernetes to the people (baby)..

Let’s get #Portainer4Kube trending... give Portainer CE 2.0 a try, and tweet us your thoughts with the hashtag #Portainer4Kube...

Visit our [#Portainer4Kube](//portainer-4731999.hs-sites.com/en-us/portainer4kube-launch) landing page to sign up for the launch webinar and see some preview vids.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/author/neil-cresswell/page/12
title: Portainer News and Blog | Neil Cresswell, CEO (12)
author: Neil Cresswell; CEO June
url: https://www.portainer.io/blog/author/neil-cresswell
hostname: portainer.io
description: Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization. (12)
sitename: Portainer.io
date: 2020-06-19
categories: []
tags: []
pagetype: blog
filedate: 2025-01-18
-->

Skip to content
Close
Product
Portainer Platform
Features
Kubernetes
Docker and Docker Swarm
Portainer Platform for Edge/IIoT
Edge Features
Portainer Managed Platform Services
Solutions
For Multi-Cluster Management
Common Use Cases
Deploy Containers
Triage and Remediate
Lifecycle Management
Platform Management
Security & Compliance
GitOps Automation
Developer Self Service
For Platform Engineering
For Small Business IT Operations
For Industrial IoT
Deployment Scenarios
Smart Manufacturing
Smart Buildings and Cities
Network Edge
Partner Solutions
Wago + Portainer
inray + Portainer
Innocens + Portainer
40Factory + Portainer
For Edge Compute Management
Resources
Learn
Academy
Blog
Documentation
Knowledge Base
Get a Demo
Videos
Reference Architecture
Connect
Contact Us
Get Support
Install
Renew
Portainer CE
Company
About Us
Careers
Become a Partner
Customers
Pricing
For
Business / Enterprise IT
IIoT / Edge
Home & Student
Buyer Guides
Building a Business Case for Portainer
Customer Stories
Containerization Operational Readiness Assessment
Portainer vs Rancher vs Openshift
Portainer Proof of Concept Test Plan
SEARCH
Get Started
Contact Us
Product
Portainer Platform
Features
Kubernetes
Docker and Docker Swarm
Portainer Platform for Edge/IIoT
Edge Features
Portainer Managed Platform Services
Solutions
For Multi-Cluster Management
Common Use Cases
Deploy Containers
Triage and Remediate
Lifecycle Management
Platform Management
Security & Compliance
GitOps Automation
Developer Self Service
For Platform Engineering
For Small Business IT Operations
For Industrial IoT
Deployment Scenarios
Smart Manufacturing
Smart Buildings and Cities
Network Edge
Partner Solutions
Wago + Portainer
inray + Portainer
Innocens + Portainer
40Factory + Portainer
For Edge Compute Management
Resources
Learn
Academy
Blog
Documentation
Knowledge Base
Get a Demo
Videos
Reference Architecture
Connect
Contact Us
Get Support
Install
Renew
Portainer CE
Company
About Us
Careers
Become a Partner
Customers
Pricing
For
Business / Enterprise IT
IIoT / Edge
Home & Student
Buyer Guides
Building a Business Case for Portainer
Customer Stories
Containerization Operational Readiness Assessment
Portainer vs Rancher vs Openshift
Portainer Proof of Concept Test Plan
Get Started
Contact Us
Quick results for "{search_term}"
The Portainer Platform
Securely manage Docker, Swarm, Kubernetes and Podman clusters in the cloud, on-premise, and in the data center.
Features
Kubernetes
Docker / Swarm
Portainer for Edge
Secure app deployment and device management for your Industrial IoT, IoT and Edge devices.
Edge-Specific Features
Managed Platform Services
Let Portainer's Managed Platform Services accelerate your containerization journey.
For Multi-Cluster Management
Manage all your Docker, Swarm, Kubernetes and Podman clusters from a single secure interface.
For Platform Engineering
Portainer empowers Platform Engineering teams to deliver efficient, user-centric services.
For Small Business IT Operations
Empower your business by adopting containerization the easy way with Portainer.
For Edge Compute
Deploy to and manage your fleet of remote devices centrally and securely.
For Industrial IoT
Onboard, manage and deploy workloads across hundreds of devices securely with Portainer.
Deployment scenarios
Smart Buildings and Cities
Smart Manufacturing
Network Edge
Partner Solutions
WAGO + Portainer
inray + Portainer
40Factory + Portainer
Innocens + Portainer
Softing + Portainer
Common Use Cases
Deploy Containers
Triage & Remediate
Lifecycle Management
Platform Management
Security and Compliance
GitOps Automation
Developer Self-Service
Learn
Academy
Blog
Documentation
Knowledge Base
Get a Demo
Videos
Reference Architecture
Connect
Contact Us
Get Support
Install
Renew
Portainer CE
Events
Company
About Us
Become a Partner
Meet Our Ambassadors
Careers
Get Pricing For
Business / Enterprise IT
IIoT / Edge
Home & Student
Contact Sales
Buyer Guides
Top Questions We Get Asked By Enterprises
Building a Business Case for Portainer
Containerization Operational Maturity Framework
Portainer vs Rancher vs OpenShift
Proof of Concept Test Plan
Neil Cresswell, CEO
Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.
Blog Post by
Neil Cresswell, CEO
Neil Cresswell, CEO
June 19, 2020
< 1
min read
Infographic – Portainer User Survey 2020
Infographic – Portainer User Survey 2020
Start Reading

---
<!--
URL: https://www.portainer.io/blog/portainer-business-a-fork-in-the-road
title: Portainer Business – A fork in the road
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-business-a-fork-in-the-road
hostname: portainer.io
description: Portainer Business fork in the road.
sitename: PORTAINER.IO
date: 2020-07-08
categories: []
tags: []
pagetype: article
filedate: 2025-01-18
-->

Continuing the theme of big changes in the Portainer world, today we’re announcing that we will be releasing a commercial version of Portainer in the next couple of months.

While our detailed thinking around the commercial versions of Portainer will be posted closer to the release, I would like to take this opportunity to outline our thoughts, as this is a pivotal and often polarizing moment in any OS project history.

For a while, a section of our community has been asking us for a fully supported, enterprise ready version of the Open Source product. In addition to support in the traditional sense, they want accelerated on-boarding, environment configuration validation, full platform support and other support services. These are all services we are keen to offer but are not feasible for our small team.

Additionally, some of the community have been asking for deeper enterprise functionality alongside the open source core. Features like granular access control, sophisticated authentication, high availability, even deep integration with complimentary technology. While we have attempted to answer some of these demands through our extensions program, it has become clear that this approach does not satisfy the requirement in a long term, sustainable way.

We are naturally drawn to the idea of a commercial variant of the product. We see this as a great way of securing the future of Portainer CE (Community Edition, the open source core). Like many before us, we plan to direct the benefits of the commercial product directly into our vision for the open source project. Benefits like bigger dev teams, deep R&D, funds available for Portainer community support. We believe that having a strong commercial option will enable us to continue to develop an absolutely outstanding CE version. In fact, without the support from a commercial version, we worry that developing Portainer will become unsustainable.

This is not new ground. Over the years many OS projects have successfully spun off commercial entities that have allowed OS projects to thrive. Cockroach, Kong, Red Hat have all managed to strike the balance and I’m confident we can too.

So, going forwards, Portainer 2.0 will exist in two variants. The fully Open Source version, with much of the Kubernetes and edge features I mentioned in previous blogs, and a fully supported commercial version which is derived from the open source version, but with additional features designed specifically for enterprise deployments. We will also offer a range of support options including what we are calling “Mission Critical” support, offering 24x7x1hr ‘full platform’ assistance.

It’s a big time for us. We have a bunch of interesting stuff coming up and there is lots going on. But I would like to conclude by underlining a few critical takeaways:

- Portainer is at its heart an open source company. While we will be releasing some commercial alternatives, they are based upon the open source codebase and will remain in lockstep with that codebase.
- We will not be moving away from our commitment and focus on the open source community and the principles which guide us in that space. We look forward to sharing the journey ahead with you, our community.

That's all for now... keep your eyes peeled for more information on Portainer Business in due course.

Neil

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/security-settings-introduced-in-portainer-1.24.1
title: Security settings introduced in Portainer 1.24.1
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/security-settings-introduced-in-portainer-1.24.1
hostname: portainer.io
description: Security settings
sitename: PORTAINER.IO
date: 2020-08-09
categories: []
tags: []
pagetype: article
filedate: 2025-01-18
-->

Please note that this blog is now out of date. For a full list of Portainer's current features and functionality please go to our [Portainer Features page](/features)*. *

Hi Portainer Fans...

As you would have no doubt already seen, we recently released Portainer 1.24.1 to address some security concerns raised by an external security professional. Full Credit to Iain Smart for reporting the findings (https://twitter.com/smarticu5).

Let me explain the changes, shown below, and why...

**1) Disable bind mounts for non-administrators**

This security setting has been around for a while, and blocks the ability for non-admin users within Portainer to use bind mounts when creating containers and/or services/stacks. When this is enabled, the option to attach to a host file system path is removed.

**2) Disable privileged mode for non-administrators**

This security setting has been around for a while, and blocks the ability for non-admin users within Portainer to elevate the privilege of a container to bypass SELinux/AppArmour. When this is enabled, the option to select "Privileged" mode when creating a container is removed.

**3) Enable volume management for non-administrators**

This security setting has been around for a while, and blocks the ability for non-admin users within Portainer to "browse" persistent volumes, which also removes their ability to upload/download/rename/delete files from within Portainer.

**4) Disable the use of host PID 1 for non-administrators**

This is a NEW feature, added in 1.24.1, and blocks the ability for non-admin users within Portainer to request that a deployed container operates AS the host PID. This is a security risk if used by a non-trustworthy authorized user as when they operate as PID1, they are in effect able to run any command in the container console as root on the host.

By enabling this feature, the ability to use HOST PID is removed.

**5) Disable the use of Stacks for non-administrators**

This is a NEW feature added in 1.24.1, and is a "sledgehammer" method to remove any possibility for non-admin users within Portainer to find and use weaknesses in the Docker architecture. Whilst Portainer have provided the ability to disable some of the more common exploits, we cannot possibly block them all as there are any number of capabilities that could be added to a container to attempt to gain access to the host. This feature simply allows an admin to disable all possible entry-points.

**6) Disable device mappings for non-administrators**

This is a NEW feature added in 1.24.1, and blocks the ability for users to map host devices into containers. Whilst the ability to map devices is generally used for good (eg mapping a GPU into a container), it can equally be used by non-trustworthy authorized users to map a physical storage device into a container. It is possible to mount /dev/sda1 into a container, and then from a console of that container, the user would have complete access to the sda1 device without restriction. By enabling this feature, Portainer blocks the ability for non-admins to map ANY devices into containers.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-and-rootless-docker
title: Portainer and rootless Docker
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-and-rootless-docker
hostname: portainer.io
description: How to deploy Portainer on Rootless Docker Host
sitename: PORTAINER.IO
date: 2020-12-17
categories: []
tags: []
image: https://www.portainer.io/hubfs/Portainer%20and%20rootless%20Docker.png
pagetype: article
filedate: 2025-01-18
-->

** Updated 22/08/2023 **

With the release of Docker 20.10, rootless Docker is now a supported feature. But what is rootless docker?

Simply, in all prior versions of Docker, the docker daemon ran as the root user, and therefore had complete control over the host operating system. By virtue, any container running under docker had the potential to "break free" and also get root access on the host. Rootless Docker changed that, so that Docker now runs as a non-root user, giving an additional security blanket to protect against host takeover.

As part of moving Docker into user space, there are a number of complications introduced, and these mean deploying Portainer with rootless Docker is somewhat less simple.

One thing to note; at present rootless docker does not work with overlay networks, which means that swarm is non functional. So for now, you can only use standalone docker hosts.

**Let me show you how to use rootless Docker with Portainer...**

First up lets get your docker host prepared. We recommend using Ubuntu 20.04 as your host, but others are supported.

As the root user, from the host console, you first need to ensure that the package "uidmap" is installed, so run the command "apt-get update && apt-get install uidmap" and check it completes.

Once that is done, create your non-root user, in our case, "docker" using the command "adduser docker"

and now add that user to the sudoers group using the command: usermod -aG sudo docker

now, using SSH, login as that account..

Run the rootless docker install script by using the command "curl -fsSL https://get.docker.com/rootless | sh"

note the instructions about adding environment variables to ~/.bashrc, lets do that now, but we will actually add them into ~/.bash_aliases instead. Once saved, logout and login to have them take effect.

Next, in order to allow you to publish containers using ports <1024, you need to run the following command: "sudo setcap cap_net_bind_service=ep $HOME/bin/rootlesskit"

Now you can set the Docker service to autostart and run using the commands:

systemctl --user start docker

systemctl --user enable docker

sudo loginctl enable-linger $(whoami)

you should now be able to run the command "docker info" to get info about your docker deployment:

You are now ready to deploy Portainer...

To deploy the Portainer SERVER, use the following command:

docker run -d -p 8000:8000 -p 9443:9443 --name=portainer --restart=always -v /$XDG_RUNTIME_DIR/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce

Connect to your instance on port 9443 and then connect to the local Docker engine.

Portainer is now running on the rootless Docker Instance.

As a variant, if you already have a Portainer instance running elsewhere, and you just want to deploy the Portainer AGENT on the rootless host, use the following command:

docker run -d -p 9001:9001 --name=portainer_agent --restart=always-v /$XDG_RUNTIME_DIR/docker.sock:/var/run/docker.sock -v ~/.local/share/docker/volumes:/var/lib/docker/volumes portainer/agent

and then you can connect to the agent via your central instance.

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/docker-hub-rate
title: Docker Hub Introduces Rate Limits from 2 November 2020
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/docker-hub-rate
hostname: portainer.io
description: So, the 2nd of November has passed, and Docker is now enforcing Docker Hub pull rate limits. Have you been caught out yet? In this blog post, our CEO, Neil Cresswell, explains the change and a possible solution.
sitename: PORTAINER.IO
date: 2020-11-06
categories: []
tags: []
image: https://www.portainer.io/hubfs/docker%20whale%20image.jpeg
pagetype: article
filedate: 2025-01-18
-->

So, the 2nd of November has been and gone, and Docker are now enforcing Docker Hub pull rate limits ... have you been caught out yet ? I know many have ...

One aspect of Docker Hub that is not well understood is that their "pulls" counter/metric is actually a representation of the number of times that a manifest for a particular image has been retrieved; It is not an indicator on the number of times an image has actually been downloaded.

If, for example, we take our own repository portainer/portainer-ce, we have over 77M pulls (we have 2Bn pulls of portainer/portainer), but i can tell you categorically, we don't have anywhere near that number of deployments (we have more like 70k deployments) ... so what causes the massive difference? Simple ... auto-updaters.

Auto-Updaters, such as watchtower or Ouroboros, are relatively rudimentary tools that facilitate a way to ensure Docker Containers running in your environment are always the latest version as per an image published on Docker Hub. These tools work by asking Docker Hub for the manifest of a container image, and then comparing the running container's image with the image available via the manifest.. and they do this (by default), every 5 minutes (think... are we there yet, are we there yet, and you get the gist). These tools get the job done and they allow organizations to implement a really simple CI/CD pipeline that triggers whenever a new container image is published. However, as mentioned above, this manifest download is counted as a "pull".

Historically, there was no real need to care about the number of pulls you (as a user or organization) were generating as they caused no harm, and served no real purpose (other than being a vanity number for organizations to quote, us included!).

However.. now that Docker have implemented these rate limits, every single pull you make counts towards your pull quota... so you need to make pulls count!

For a home user, this change is unlikely to really cause any impact, but for a company that uses auto-updaters in their environments, its likely to have a very negative effect.

Why? Two reasons... first, because the rate limits that Docker are enforcing for anonymous requests are per SOURCE IP, and second, even for authenticated users, the pull rate limit can quickly be exhausted through the use of auto-updaters.

Most organizations have a single internet POP for their access to the internet, and so anonymous pulls from that organization will appear (to docker) to come from the one IP... which means the rate limit that is applied is actually for the entire organization!!! so now the 100 anonymous pulls per 6 hours is actually 100 pulls per 6 hours for the entire organization. Not ideal.

I would hazard a guess that most deployments of auto-updaters are using these against public repositories, and likely do not authenticate their connection to Docker Hub, further aggravating the issue. That said, even if you are using an auto-updater with Docker Hub authentication you are now using up your pull quota for no purpose other than checking "is the current image i'm using the latest"..

The only solution here is to ensure that all use of Docker Hub (interactive or using auto-update tools) is as an authenticated user, and that your users are members of a Docker Hub organization that is on a paid plan, as these have no pull limits. However, if you don't want to do this (due to cost), you really do need to rethink your use of auto-updaters so as to remove unnecessary pulls from your quota.

Our view, its time for these auto-updating tools to be sunset, and everyone switch to using WebHooks to trigger the update of a container image.

Hope this helps you in some way.

Neil@Portainer

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/portainer-business-is-here-and-heres-why-it-matters
title: Portainer Business is here at last. Watch Neil tell the story...
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/portainer-business-is-here-and-heres-why-it-matters
hostname: portainer.io
description: Portainer Business launch video explaining what Portainer Business is, and why it matters
sitename: PORTAINER.IO
date: 2020-12-09
categories: []
tags: []
image: https://www.portainer.io/hubfs/Screen%20Shot%202020-12-09%20at%207.45.38%20PM.png
pagetype: article
filedate: 2025-01-18
-->

Skip to content
Close
Product
Portainer Platform
Features
Kubernetes
Docker and Docker Swarm
Portainer Platform for Edge/IIoT
Edge Features
Portainer Managed Platform Services
Solutions
For Multi-Cluster Management
Common Use Cases
Deploy Containers
Triage and Remediate
Lifecycle Management
Platform Management
Security & Compliance
GitOps Automation
Developer Self Service
For Platform Engineering
For Small Business IT Operations
For Industrial IoT
Deployment Scenarios
Smart Manufacturing
Smart Buildings and Cities
Network Edge
Partner Solutions
Wago + Portainer
inray + Portainer
Innocens + Portainer
40Factory + Portainer
For Edge Compute Management
Resources
Learn
Academy
Blog
Documentation
Knowledge Base
Get a Demo
Videos
Reference Architecture
Connect
Contact Us
Get Support
Install
Renew
Portainer CE
Company
About Us
Careers
Become a Partner
Customers
Pricing
For
Business / Enterprise IT
IIoT / Edge
Home & Student
Buyer Guides
Building a Business Case for Portainer
Customer Stories
Containerization Operational Readiness Assessment
Portainer vs Rancher vs Openshift
Portainer Proof of Concept Test Plan
SEARCH
Get Started
Contact Us
Product
Portainer Platform
Features
Kubernetes
Docker and Docker Swarm
Portainer Platform for Edge/IIoT
Edge Features
Portainer Managed Platform Services
Solutions
For Multi-Cluster Management
Common Use Cases
Deploy Containers
Triage and Remediate
Lifecycle Management
Platform Management
Security & Compliance
GitOps Automation
Developer Self Service
For Platform Engineering
For Small Business IT Operations
For Industrial IoT
Deployment Scenarios
Smart Manufacturing
Smart Buildings and Cities
Network Edge
Partner Solutions
Wago + Portainer
inray + Portainer
Innocens + Portainer
40Factory + Portainer
For Edge Compute Management
Resources
Learn
Academy
Blog
Documentation
Knowledge Base
Get a Demo
Videos
Reference Architecture
Connect
Contact Us
Get Support
Install
Renew
Portainer CE
Company
About Us
Careers
Become a Partner
Customers
Pricing
For
Business / Enterprise IT
IIoT / Edge
Home & Student
Buyer Guides
Building a Business Case for Portainer
Customer Stories
Containerization Operational Readiness Assessment
Portainer vs Rancher vs Openshift
Portainer Proof of Concept Test Plan
Get Started
Contact Us
Quick results for "{search_term}"
The Portainer Platform
Securely manage Docker, Swarm, Kubernetes and Podman clusters in the cloud, on-premise, and in the data center.
Features
Kubernetes
Docker / Swarm
Portainer for Edge
Secure app deployment and device management for your Industrial IoT, IoT and Edge devices.
Edge-Specific Features
Managed Platform Services
Let Portainer's Managed Platform Services accelerate your containerization journey.
For Multi-Cluster Management
Manage all your Docker, Swarm, Kubernetes and Podman clusters from a single secure interface.
For Platform Engineering
Portainer empowers Platform Engineering teams to deliver efficient, user-centric services.
For Small Business IT Operations
Empower your business by adopting containerization the easy way with Portainer.
For Edge Compute
Deploy to and manage your fleet of remote devices centrally and securely.
For Industrial IoT
Onboard, manage and deploy workloads across hundreds of devices securely with Portainer.
Deployment scenarios
Smart Buildings and Cities
Smart Manufacturing
Network Edge
Partner Solutions
WAGO + Portainer
inray + Portainer
40Factory + Portainer
Innocens + Portainer
Softing + Portainer
Common Use Cases
Deploy Containers
Triage & Remediate
Lifecycle Management
Platform Management
Security and Compliance
GitOps Automation
Developer Self-Service
Learn
Academy
Blog
Documentation
Knowledge Base
Get a Demo
Videos
Reference Architecture
Connect
Contact Us
Get Support
Install
Renew
Portainer CE
Events
Company
About Us
Become a Partner
Meet Our Ambassadors
Careers
Get Pricing For
Business / Enterprise IT
IIoT / Edge
Home & Student
Contact Sales
Buyer Guides
Top Questions We Get Asked By Enterprises
Building a Business Case for Portainer
Containerization Operational Maturity Framework
Portainer vs Rancher vs OpenShift
Proof of Concept Test Plan
Neil Cresswell, CEO
December 9, 2020
< 1 min read
Portainer Business is here at last. Watch Neil tell the story...
Neil Cresswell, CEO
Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.
COMMENTS
Related articles

### COMMENTS

---
<!--
URL: https://www.portainer.io/blog/infographic-portainer-user-survey-2020
title: Infographic – Portainer User Survey 2020
author: Neil Cresswell; CEO
url: https://www.portainer.io/blog/infographic-portainer-user-survey-2020
hostname: portainer.io
description: Infographic – Portainer User Survey 2020
sitename: PORTAINER.IO
date: 2020-06-19
categories: []
tags: []
pagetype: article
filedate: 2025-01-18
-->

Recently we requested your input to complete a survey on how you use Portainer, where you use, how you rate it, and which features you love... we also asked you to tell us what features we dont have that really should...

Well, after 1200 responses in 3 days (thank you, this is awesome!!) we have compiled the below info-graphic to summarize..

Click the picture to open in full screen...

[Neil brings more than twenty years’ experience in advanced technology including virtualization, storage and containerization.](https://www.portainer.io/blog/author/neil-cresswell)

### COMMENTS

---